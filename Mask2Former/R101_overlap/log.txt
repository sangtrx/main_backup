[08/01 16:23:49] detectron2 INFO: Rank of current process: 0. World size: 1
[08/01 16:23:50] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.20.1
detectron2              0.6 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.1
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA RTX A6000 (arch=8.6)
Driver version          470.129.06
CUDA_HOME               /usr
Pillow                  8.1.0
torchvision             0.10.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220305
iopath                  0.1.9
cv2                     4.5.5
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[08/01 16:23:50] detectron2 INFO: Command line arguments: Namespace(config_file='/home/tqsang/Mask2Former/configs/coco_front2class/panoptic-segmentation/maskformer2_R101_bs16_50ep.yaml', dist_url='tcp://127.0.0.1:50158', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './R101_overlap'], resume=False)
[08/01 16:23:50] detectron2 INFO: Contents of args.config_file=/home/tqsang/Mask2Former/configs/coco_front2class/panoptic-segmentation/maskformer2_R101_bs16_50ep.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2_R50_bs16_50ep_front_2class_2880to256to256.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mR-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;242m# NORM: "SyncBN"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[08/01 16:23:50] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_val_overlap_panoptic[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mR-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/01 16:23:50] detectron2 INFO: Full config saved to ./R101_overlap/config.yaml
[08/01 16:23:50] d2.utils.env INFO: Using a generated random seed 51439536
[08/01 16:23:53] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (deconv_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv2_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=3, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 2
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/01 16:23:53] mask2former.data.dataset_mappers.coco_panoptic_new_baseline_dataset_mapper INFO: [COCOPanopticNewBaselineDatasetMapper] Full TransformGens used in training: [RandomFlip(), ResizeScale(min_scale=1.0, max_scale=1.0, target_height=256, target_width=256), FixedSizeCrop(crop_size=(256, 256))]
[08/01 16:23:53] d2.data.build INFO: Using training sampler TrainingSampler
[08/01 16:23:53] d2.data.common INFO: Serializing 2115 elements to byte tensors and concatenating them all ...
[08/01 16:23:53] d2.data.common INFO: Serialized dataset takes 0.86 MiB
[08/01 16:23:54] fvcore.common.checkpoint INFO: [Checkpointer] Loading from R-101.pkl ...
[08/01 16:24:48] detectron2 INFO: Rank of current process: 0. World size: 1
[08/01 16:24:49] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.20.1
detectron2              0.6 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.1
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA RTX A6000 (arch=8.6)
Driver version          470.129.06
CUDA_HOME               /usr
Pillow                  8.1.0
torchvision             0.10.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220305
iopath                  0.1.9
cv2                     4.5.5
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[08/01 16:24:49] detectron2 INFO: Command line arguments: Namespace(config_file='/home/tqsang/Mask2Former/configs/coco_front2class/panoptic-segmentation/maskformer2_R101_bs16_50ep.yaml', dist_url='tcp://127.0.0.1:50158', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './R101_overlap'], resume=False)
[08/01 16:24:49] detectron2 INFO: Contents of args.config_file=/home/tqsang/Mask2Former/configs/coco_front2class/panoptic-segmentation/maskformer2_R101_bs16_50ep.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2_R50_bs16_50ep_front_2class_2880to256to256.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/torchvision/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;242m# NORM: "SyncBN"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[08/01 16:24:49] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_val_overlap_panoptic[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/01 16:24:49] detectron2 INFO: Full config saved to ./R101_overlap/config.yaml
[08/01 16:24:49] d2.utils.env INFO: Using a generated random seed 50345267
[08/01 16:24:52] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (deconv_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv2_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=3, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 2
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/01 16:24:52] mask2former.data.dataset_mappers.coco_panoptic_new_baseline_dataset_mapper INFO: [COCOPanopticNewBaselineDatasetMapper] Full TransformGens used in training: [RandomFlip(), ResizeScale(min_scale=1.0, max_scale=1.0, target_height=256, target_width=256), FixedSizeCrop(crop_size=(256, 256))]
[08/01 16:24:52] d2.data.build INFO: Using training sampler TrainingSampler
[08/01 16:24:52] d2.data.common INFO: Serializing 2115 elements to byte tensors and concatenating them all ...
[08/01 16:24:52] d2.data.common INFO: Serialized dataset takes 0.86 MiB
[08/01 16:24:52] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-101.pkl ...
[08/01 16:25:12] detectron2 INFO: Rank of current process: 0. World size: 1
[08/01 16:25:13] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.20.1
detectron2              0.6 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.1
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA RTX A6000 (arch=8.6)
Driver version          470.129.06
CUDA_HOME               /usr
Pillow                  8.1.0
torchvision             0.10.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220305
iopath                  0.1.9
cv2                     4.5.5
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[08/01 16:25:13] detectron2 INFO: Command line arguments: Namespace(config_file='/home/tqsang/Mask2Former/configs/coco_front2class/panoptic-segmentation/maskformer2_R101_bs16_50ep.yaml', dist_url='tcp://127.0.0.1:50158', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './R101_overlap'], resume=False)
[08/01 16:25:13] detectron2 INFO: Contents of args.config_file=/home/tqsang/Mask2Former/configs/coco_front2class/panoptic-segmentation/maskformer2_R101_bs16_50ep.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2_R50_bs16_50ep_front_2class_2880to256to256.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/torchvision/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;242m# NORM: "SyncBN"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[08/01 16:25:13] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_val_overlap_panoptic[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/01 16:25:13] detectron2 INFO: Full config saved to ./R101_overlap/config.yaml
[08/01 16:25:13] d2.utils.env INFO: Using a generated random seed 14509165
[08/01 16:25:16] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (deconv_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv2_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=3, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 2
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/01 16:25:16] mask2former.data.dataset_mappers.coco_panoptic_new_baseline_dataset_mapper INFO: [COCOPanopticNewBaselineDatasetMapper] Full TransformGens used in training: [RandomFlip(), ResizeScale(min_scale=1.0, max_scale=1.0, target_height=256, target_width=256), FixedSizeCrop(crop_size=(256, 256))]
[08/01 16:25:16] d2.data.build INFO: Using training sampler TrainingSampler
[08/01 16:25:16] d2.data.common INFO: Serializing 2115 elements to byte tensors and concatenating them all ...
[08/01 16:25:16] d2.data.common INFO: Serialized dataset takes 0.86 MiB
[08/01 16:25:16] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-101.pkl ...
[08/01 16:27:18] detectron2 INFO: Rank of current process: 0. World size: 1
[08/01 16:27:20] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.20.1
detectron2              0.6 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.1
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA RTX A6000 (arch=8.6)
Driver version          470.129.06
CUDA_HOME               /usr
Pillow                  8.1.0
torchvision             0.10.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220305
iopath                  0.1.9
cv2                     4.5.5
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[08/01 16:27:20] detectron2 INFO: Command line arguments: Namespace(config_file='/home/tqsang/Mask2Former/configs/coco_front2class/panoptic-segmentation/maskformer2_R101_bs16_50ep.yaml', dist_url='tcp://127.0.0.1:50158', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './R101_overlap'], resume=False)
[08/01 16:27:20] detectron2 INFO: Contents of args.config_file=/home/tqsang/Mask2Former/configs/coco_front2class/panoptic-segmentation/maskformer2_R101_bs16_50ep.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2_R50_bs16_50ep_front_2class_2880to256to256.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;242m# NORM: "SyncBN"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[08/01 16:27:20] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_val_overlap_panoptic[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/MSRA/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/01 16:27:20] detectron2 INFO: Full config saved to ./R101_overlap/config.yaml
[08/01 16:27:20] d2.utils.env INFO: Using a generated random seed 20856777
[08/01 16:27:22] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (deconv_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv2_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=3, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 2
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/01 16:27:22] mask2former.data.dataset_mappers.coco_panoptic_new_baseline_dataset_mapper INFO: [COCOPanopticNewBaselineDatasetMapper] Full TransformGens used in training: [RandomFlip(), ResizeScale(min_scale=1.0, max_scale=1.0, target_height=256, target_width=256), FixedSizeCrop(crop_size=(256, 256))]
[08/01 16:27:22] d2.data.build INFO: Using training sampler TrainingSampler
[08/01 16:27:22] d2.data.common INFO: Serializing 2115 elements to byte tensors and concatenating them all ...
[08/01 16:27:22] d2.data.common INFO: Serialized dataset takes 0.86 MiB
[08/01 16:27:22] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-101.pkl ...
[08/01 16:27:23] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[08/01 16:27:23] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[08/01 16:27:23] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.deconv2_mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.deconv_mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[08/01 16:27:23] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[08/01 16:27:23] d2.engine.train_loop INFO: Starting training from iteration 0
[08/01 16:27:28] d2.utils.events INFO:  eta: 1:36:20  iter: 19  total_loss: 73.22  loss_ce: 1.209  loss_mask: 2.089  loss_dice: 4.176  loss_ce_0: 2.123  loss_mask_0: 2.23  loss_dice_0: 4.14  loss_ce_1: 0.744  loss_mask_1: 2.093  loss_dice_1: 4.161  loss_ce_2: 0.9698  loss_mask_2: 2.062  loss_dice_2: 4.18  loss_ce_3: 1.063  loss_mask_3: 2.02  loss_dice_3: 4.214  loss_ce_4: 1.16  loss_mask_4: 2.04  loss_dice_4: 4.176  loss_ce_5: 1.236  loss_mask_5: 2.113  loss_dice_5: 4.145  loss_ce_6: 1.237  loss_mask_6: 2.072  loss_dice_6: 4.208  loss_ce_7: 1.249  loss_mask_7: 2.08  loss_dice_7: 4.166  loss_ce_8: 1.194  loss_mask_8: 2.03  loss_dice_8: 4.183  time: 0.1935  data_time: 0.0141  lr: 0.0001  max_mem: 1909M
[08/01 16:27:31] d2.utils.events INFO:  eta: 1:36:08  iter: 39  total_loss: 52.51  loss_ce: 1.169  loss_mask: 1.768  loss_dice: 2.514  loss_ce_0: 2.112  loss_mask_0: 1.711  loss_dice_0: 2.785  loss_ce_1: 0.2337  loss_mask_1: 1.68  loss_dice_1: 2.607  loss_ce_2: 0.3033  loss_mask_2: 1.722  loss_dice_2: 2.573  loss_ce_3: 0.5318  loss_mask_3: 1.734  loss_dice_3: 2.547  loss_ce_4: 0.7585  loss_mask_4: 1.739  loss_dice_4: 2.516  loss_ce_5: 0.9363  loss_mask_5: 1.808  loss_dice_5: 2.509  loss_ce_6: 1.082  loss_mask_6: 1.789  loss_dice_6: 2.483  loss_ce_7: 1.129  loss_mask_7: 1.753  loss_dice_7: 2.513  loss_ce_8: 1.162  loss_mask_8: 1.787  loss_dice_8: 2.476  time: 0.1762  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:27:34] d2.engine.hooks INFO: Overall training speed: 56 iterations in 0:00:09 (0.1752 s / it)
[08/01 16:27:34] d2.engine.hooks INFO: Total training time: 0:00:09 (0:00:00 on hooks)
[08/01 16:27:34] d2.utils.events INFO:  eta: 1:36:22  iter: 58  total_loss: 47.74  loss_ce: 1.055  loss_mask: 1.584  loss_dice: 2.085  loss_ce_0: 2.125  loss_mask_0: 1.423  loss_dice_0: 2.287  loss_ce_1: 0.1105  loss_mask_1: 1.494  loss_dice_1: 2.187  loss_ce_2: 0.1061  loss_mask_2: 1.491  loss_dice_2: 2.187  loss_ce_3: 0.1253  loss_mask_3: 1.554  loss_dice_3: 2.175  loss_ce_4: 0.1781  loss_mask_4: 1.568  loss_dice_4: 2.147  loss_ce_5: 0.3823  loss_mask_5: 1.597  loss_dice_5: 2.106  loss_ce_6: 0.6825  loss_mask_6: 1.637  loss_dice_6: 2.09  loss_ce_7: 0.9478  loss_mask_7: 1.61  loss_dice_7: 2.108  loss_ce_8: 1.044  loss_mask_8: 1.632  loss_dice_8: 2.093  time: 0.1724  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:30:18] detectron2 INFO: Rank of current process: 0. World size: 1
[08/01 16:30:19] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.20.1
detectron2              0.6 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.1
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA RTX A6000 (arch=8.6)
Driver version          470.129.06
CUDA_HOME               /usr
Pillow                  8.1.0
torchvision             0.10.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220305
iopath                  0.1.9
cv2                     4.5.5
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[08/01 16:30:19] detectron2 INFO: Command line arguments: Namespace(config_file='/home/tqsang/Mask2Former/configs/coco_front2class/panoptic-segmentation/maskformer2_R101_bs16_50ep.yaml', dist_url='tcp://127.0.0.1:50158', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './R101_overlap'], resume=False)
[08/01 16:30:19] detectron2 INFO: Contents of args.config_file=/home/tqsang/Mask2Former/configs/coco_front2class/panoptic-segmentation/maskformer2_R101_bs16_50ep.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2_R50_bs16_50ep_front_2class_2880to256to256.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;242m# NORM: "SyncBN"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[08/01 16:30:19] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_val_overlap_panoptic[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/MSRA/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/01 16:30:19] detectron2 INFO: Full config saved to ./R101_overlap/config.yaml
[08/01 16:30:19] d2.utils.env INFO: Using a generated random seed 20043908
[08/01 16:30:23] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (deconv_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv2_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=3, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 2
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/01 16:30:23] mask2former.data.dataset_mappers.coco_panoptic_new_baseline_dataset_mapper INFO: [COCOPanopticNewBaselineDatasetMapper] Full TransformGens used in training: [RandomFlip(), ResizeScale(min_scale=1.0, max_scale=1.0, target_height=256, target_width=256), FixedSizeCrop(crop_size=(256, 256))]
[08/01 16:30:23] d2.data.build INFO: Using training sampler TrainingSampler
[08/01 16:30:23] d2.data.common INFO: Serializing 2115 elements to byte tensors and concatenating them all ...
[08/01 16:30:23] d2.data.common INFO: Serialized dataset takes 0.86 MiB
[08/01 16:30:23] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-101.pkl ...
[08/01 16:30:23] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[08/01 16:30:23] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[08/01 16:30:23] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.deconv2_mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.deconv_mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[08/01 16:30:23] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[08/01 16:30:23] d2.engine.train_loop INFO: Starting training from iteration 0
[08/01 16:30:30] d2.utils.events INFO:  eta: 2:11:20  iter: 19  total_loss: 73.92  loss_ce: 1.213  loss_mask: 2.043  loss_dice: 4.317  loss_ce_0: 2.134  loss_mask_0: 2.334  loss_dice_0: 4.18  loss_ce_1: 0.8267  loss_mask_1: 2.065  loss_dice_1: 4.243  loss_ce_2: 0.9457  loss_mask_2: 2.045  loss_dice_2: 4.289  loss_ce_3: 1.083  loss_mask_3: 2.027  loss_dice_3: 4.344  loss_ce_4: 1.193  loss_mask_4: 2.036  loss_dice_4: 4.304  loss_ce_5: 1.236  loss_mask_5: 2.034  loss_dice_5: 4.308  loss_ce_6: 1.256  loss_mask_6: 2.04  loss_dice_6: 4.299  loss_ce_7: 1.241  loss_mask_7: 2.029  loss_dice_7: 4.348  loss_ce_8: 1.182  loss_mask_8: 2.028  loss_dice_8: 4.33  time: 0.2545  data_time: 0.0143  lr: 0.0001  max_mem: 1909M
[08/01 16:30:35] d2.utils.events INFO:  eta: 2:09:21  iter: 39  total_loss: 59.46  loss_ce: 1.14  loss_mask: 1.865  loss_dice: 2.662  loss_ce_0: 2.116  loss_mask_0: 1.669  loss_dice_0: 2.894  loss_ce_1: 0.3148  loss_mask_1: 1.777  loss_dice_1: 2.73  loss_ce_2: 0.4421  loss_mask_2: 1.858  loss_dice_2: 2.682  loss_ce_3: 0.7214  loss_mask_3: 1.824  loss_dice_3: 2.693  loss_ce_4: 0.9663  loss_mask_4: 1.84  loss_dice_4: 2.69  loss_ce_5: 1.087  loss_mask_5: 1.842  loss_dice_5: 2.65  loss_ce_6: 1.135  loss_mask_6: 1.866  loss_dice_6: 2.654  loss_ce_7: 1.144  loss_mask_7: 1.867  loss_dice_7: 2.714  loss_ce_8: 1.16  loss_mask_8: 1.903  loss_dice_8: 2.671  time: 0.2351  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:30:39] d2.utils.events INFO:  eta: 2:09:48  iter: 59  total_loss: 54.09  loss_ce: 1.076  loss_mask: 1.766  loss_dice: 2.349  loss_ce_0: 2.07  loss_mask_0: 1.542  loss_dice_0: 2.533  loss_ce_1: 0.271  loss_mask_1: 1.62  loss_dice_1: 2.391  loss_ce_2: 0.2915  loss_mask_2: 1.631  loss_dice_2: 2.413  loss_ce_3: 0.5022  loss_mask_3: 1.633  loss_dice_3: 2.367  loss_ce_4: 0.6608  loss_mask_4: 1.688  loss_dice_4: 2.348  loss_ce_5: 0.871  loss_mask_5: 1.699  loss_dice_5: 2.308  loss_ce_6: 1.012  loss_mask_6: 1.726  loss_dice_6: 2.292  loss_ce_7: 1.072  loss_mask_7: 1.753  loss_dice_7: 2.287  loss_ce_8: 1.032  loss_mask_8: 1.728  loss_dice_8: 2.311  time: 0.2308  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:30:44] d2.utils.events INFO:  eta: 2:09:44  iter: 79  total_loss: 48.47  loss_ce: 1.071  loss_mask: 1.54  loss_dice: 2.236  loss_ce_0: 2.049  loss_mask_0: 1.448  loss_dice_0: 2.405  loss_ce_1: 0.2126  loss_mask_1: 1.479  loss_dice_1: 2.265  loss_ce_2: 0.2017  loss_mask_2: 1.474  loss_dice_2: 2.253  loss_ce_3: 0.2068  loss_mask_3: 1.469  loss_dice_3: 2.281  loss_ce_4: 0.2793  loss_mask_4: 1.526  loss_dice_4: 2.206  loss_ce_5: 0.3628  loss_mask_5: 1.513  loss_dice_5: 2.248  loss_ce_6: 0.6323  loss_mask_6: 1.549  loss_dice_6: 2.196  loss_ce_7: 0.8372  loss_mask_7: 1.569  loss_dice_7: 2.203  loss_ce_8: 0.9804  loss_mask_8: 1.567  loss_dice_8: 2.224  time: 0.2290  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:30:48] d2.utils.events INFO:  eta: 2:10:21  iter: 99  total_loss: 31.49  loss_ce: 0.6488  loss_mask: 0.9882  loss_dice: 1.545  loss_ce_0: 2.082  loss_mask_0: 0.9431  loss_dice_0: 1.633  loss_ce_1: 0.09062  loss_mask_1: 0.9867  loss_dice_1: 1.566  loss_ce_2: 0.1226  loss_mask_2: 0.9937  loss_dice_2: 1.532  loss_ce_3: 0.1251  loss_mask_3: 0.994  loss_dice_3: 1.572  loss_ce_4: 0.1324  loss_mask_4: 1.019  loss_dice_4: 1.554  loss_ce_5: 0.1417  loss_mask_5: 1.001  loss_dice_5: 1.575  loss_ce_6: 0.1665  loss_mask_6: 0.9729  loss_dice_6: 1.549  loss_ce_7: 0.2184  loss_mask_7: 0.9726  loss_dice_7: 1.536  loss_ce_8: 0.3899  loss_mask_8: 0.9654  loss_dice_8: 1.528  time: 0.2278  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:30:53] d2.utils.events INFO:  eta: 2:10:22  iter: 119  total_loss: 31.41  loss_ce: 0.2532  loss_mask: 0.9672  loss_dice: 1.581  loss_ce_0: 2.048  loss_mask_0: 0.9295  loss_dice_0: 1.511  loss_ce_1: 0.1014  loss_mask_1: 0.9683  loss_dice_1: 1.456  loss_ce_2: 0.1186  loss_mask_2: 0.9712  loss_dice_2: 1.507  loss_ce_3: 0.1163  loss_mask_3: 0.9839  loss_dice_3: 1.524  loss_ce_4: 0.1365  loss_mask_4: 1.018  loss_dice_4: 1.544  loss_ce_5: 0.1995  loss_mask_5: 0.989  loss_dice_5: 1.59  loss_ce_6: 0.2362  loss_mask_6: 1.013  loss_dice_6: 1.616  loss_ce_7: 0.2114  loss_mask_7: 0.9934  loss_dice_7: 1.62  loss_ce_8: 0.1913  loss_mask_8: 1.013  loss_dice_8: 1.661  time: 0.2268  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:30:57] d2.utils.events INFO:  eta: 2:11:07  iter: 139  total_loss: 42.54  loss_ce: 0.3004  loss_mask: 1.512  loss_dice: 2.231  loss_ce_0: 1.928  loss_mask_0: 1.454  loss_dice_0: 2.311  loss_ce_1: 0.07549  loss_mask_1: 1.505  loss_dice_1: 2.248  loss_ce_2: 0.1082  loss_mask_2: 1.486  loss_dice_2: 2.293  loss_ce_3: 0.1153  loss_mask_3: 1.535  loss_dice_3: 2.265  loss_ce_4: 0.1206  loss_mask_4: 1.519  loss_dice_4: 2.254  loss_ce_5: 0.1473  loss_mask_5: 1.496  loss_dice_5: 2.241  loss_ce_6: 0.1843  loss_mask_6: 1.509  loss_dice_6: 2.284  loss_ce_7: 0.2351  loss_mask_7: 1.497  loss_dice_7: 2.268  loss_ce_8: 0.2579  loss_mask_8: 1.509  loss_dice_8: 2.253  time: 0.2264  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:31:02] d2.utils.events INFO:  eta: 2:11:08  iter: 159  total_loss: 40.75  loss_ce: 0.2154  loss_mask: 1.384  loss_dice: 2.183  loss_ce_0: 1.859  loss_mask_0: 1.396  loss_dice_0: 2.189  loss_ce_1: 0.08459  loss_mask_1: 1.419  loss_dice_1: 2.175  loss_ce_2: 0.09752  loss_mask_2: 1.407  loss_dice_2: 2.173  loss_ce_3: 0.1077  loss_mask_3: 1.39  loss_dice_3: 2.151  loss_ce_4: 0.1122  loss_mask_4: 1.4  loss_dice_4: 2.197  loss_ce_5: 0.1188  loss_mask_5: 1.391  loss_dice_5: 2.17  loss_ce_6: 0.1481  loss_mask_6: 1.401  loss_dice_6: 2.164  loss_ce_7: 0.1863  loss_mask_7: 1.407  loss_dice_7: 2.151  loss_ce_8: 0.1676  loss_mask_8: 1.388  loss_dice_8: 2.161  time: 0.2261  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:31:06] d2.utils.events INFO:  eta: 2:11:03  iter: 179  total_loss: 42.52  loss_ce: 0.3322  loss_mask: 1.407  loss_dice: 2.082  loss_ce_0: 1.796  loss_mask_0: 1.451  loss_dice_0: 2.082  loss_ce_1: 0.08067  loss_mask_1: 1.427  loss_dice_1: 2.093  loss_ce_2: 0.1081  loss_mask_2: 1.404  loss_dice_2: 2.121  loss_ce_3: 0.126  loss_mask_3: 1.419  loss_dice_3: 2.113  loss_ce_4: 0.1286  loss_mask_4: 1.427  loss_dice_4: 2.109  loss_ce_5: 0.1689  loss_mask_5: 1.423  loss_dice_5: 2.081  loss_ce_6: 0.2035  loss_mask_6: 1.434  loss_dice_6: 2.099  loss_ce_7: 0.2747  loss_mask_7: 1.413  loss_dice_7: 2.105  loss_ce_8: 0.288  loss_mask_8: 1.395  loss_dice_8: 2.113  time: 0.2259  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:31:11] d2.utils.events INFO:  eta: 2:11:07  iter: 199  total_loss: 40.97  loss_ce: 0.1725  loss_mask: 1.458  loss_dice: 2.278  loss_ce_0: 1.737  loss_mask_0: 1.427  loss_dice_0: 2.266  loss_ce_1: 0.04415  loss_mask_1: 1.437  loss_dice_1: 2.31  loss_ce_2: 0.05919  loss_mask_2: 1.429  loss_dice_2: 2.301  loss_ce_3: 0.07249  loss_mask_3: 1.434  loss_dice_3: 2.27  loss_ce_4: 0.0735  loss_mask_4: 1.448  loss_dice_4: 2.255  loss_ce_5: 0.09293  loss_mask_5: 1.442  loss_dice_5: 2.286  loss_ce_6: 0.1192  loss_mask_6: 1.439  loss_dice_6: 2.265  loss_ce_7: 0.131  loss_mask_7: 1.446  loss_dice_7: 2.242  loss_ce_8: 0.1399  loss_mask_8: 1.44  loss_dice_8: 2.301  time: 0.2258  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:31:15] d2.utils.events INFO:  eta: 2:11:08  iter: 219  total_loss: 39.69  loss_ce: 0.1099  loss_mask: 1.426  loss_dice: 2.141  loss_ce_0: 1.728  loss_mask_0: 1.447  loss_dice_0: 2.128  loss_ce_1: 0.08814  loss_mask_1: 1.441  loss_dice_1: 2.138  loss_ce_2: 0.09442  loss_mask_2: 1.436  loss_dice_2: 2.1  loss_ce_3: 0.09451  loss_mask_3: 1.422  loss_dice_3: 2.118  loss_ce_4: 0.1063  loss_mask_4: 1.431  loss_dice_4: 2.096  loss_ce_5: 0.1127  loss_mask_5: 1.451  loss_dice_5: 2.115  loss_ce_6: 0.09992  loss_mask_6: 1.438  loss_dice_6: 2.097  loss_ce_7: 0.09477  loss_mask_7: 1.461  loss_dice_7: 2.139  loss_ce_8: 0.09049  loss_mask_8: 1.433  loss_dice_8: 2.138  time: 0.2257  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:31:20] d2.utils.events INFO:  eta: 2:11:04  iter: 239  total_loss: 38.81  loss_ce: 0.09949  loss_mask: 1.327  loss_dice: 2.114  loss_ce_0: 1.668  loss_mask_0: 1.354  loss_dice_0: 2.111  loss_ce_1: 0.08071  loss_mask_1: 1.34  loss_dice_1: 2.111  loss_ce_2: 0.08187  loss_mask_2: 1.332  loss_dice_2: 2.112  loss_ce_3: 0.1018  loss_mask_3: 1.318  loss_dice_3: 2.127  loss_ce_4: 0.1085  loss_mask_4: 1.332  loss_dice_4: 2.134  loss_ce_5: 0.1118  loss_mask_5: 1.335  loss_dice_5: 2.119  loss_ce_6: 0.09814  loss_mask_6: 1.335  loss_dice_6: 2.141  loss_ce_7: 0.1091  loss_mask_7: 1.332  loss_dice_7: 2.14  loss_ce_8: 0.09522  loss_mask_8: 1.312  loss_dice_8: 2.125  time: 0.2258  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:31:24] d2.utils.events INFO:  eta: 2:11:04  iter: 259  total_loss: 8.531  loss_ce: 0.09681  loss_mask: 0.2637  loss_dice: 0.3467  loss_ce_0: 1.606  loss_mask_0: 0.2624  loss_dice_0: 0.3985  loss_ce_1: 0.0682  loss_mask_1: 0.2507  loss_dice_1: 0.3825  loss_ce_2: 0.08949  loss_mask_2: 0.2579  loss_dice_2: 0.3638  loss_ce_3: 0.09165  loss_mask_3: 0.2517  loss_dice_3: 0.3812  loss_ce_4: 0.08931  loss_mask_4: 0.2542  loss_dice_4: 0.3651  loss_ce_5: 0.08768  loss_mask_5: 0.271  loss_dice_5: 0.3604  loss_ce_6: 0.09595  loss_mask_6: 0.2638  loss_dice_6: 0.3596  loss_ce_7: 0.08833  loss_mask_7: 0.2637  loss_dice_7: 0.3543  loss_ce_8: 0.08427  loss_mask_8: 0.2495  loss_dice_8: 0.3385  time: 0.2257  data_time: 0.0010  lr: 0.0001  max_mem: 1909M
[08/01 16:31:29] d2.utils.events INFO:  eta: 2:11:00  iter: 279  total_loss: 39.21  loss_ce: 0.07744  loss_mask: 1.341  loss_dice: 2.211  loss_ce_0: 1.49  loss_mask_0: 1.371  loss_dice_0: 2.201  loss_ce_1: 0.08221  loss_mask_1: 1.343  loss_dice_1: 2.22  loss_ce_2: 0.08417  loss_mask_2: 1.343  loss_dice_2: 2.217  loss_ce_3: 0.07171  loss_mask_3: 1.338  loss_dice_3: 2.239  loss_ce_4: 0.07014  loss_mask_4: 1.334  loss_dice_4: 2.232  loss_ce_5: 0.07087  loss_mask_5: 1.355  loss_dice_5: 2.219  loss_ce_6: 0.08002  loss_mask_6: 1.344  loss_dice_6: 2.248  loss_ce_7: 0.07685  loss_mask_7: 1.359  loss_dice_7: 2.23  loss_ce_8: 0.08323  loss_mask_8: 1.357  loss_dice_8: 2.208  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:31:33] d2.utils.events INFO:  eta: 2:10:55  iter: 299  total_loss: 39.97  loss_ce: 0.08347  loss_mask: 1.363  loss_dice: 2.268  loss_ce_0: 1.448  loss_mask_0: 1.378  loss_dice_0: 2.216  loss_ce_1: 0.05371  loss_mask_1: 1.367  loss_dice_1: 2.253  loss_ce_2: 0.06187  loss_mask_2: 1.361  loss_dice_2: 2.265  loss_ce_3: 0.071  loss_mask_3: 1.313  loss_dice_3: 2.29  loss_ce_4: 0.08506  loss_mask_4: 1.337  loss_dice_4: 2.286  loss_ce_5: 0.0851  loss_mask_5: 1.363  loss_dice_5: 2.281  loss_ce_6: 0.08191  loss_mask_6: 1.375  loss_dice_6: 2.254  loss_ce_7: 0.0827  loss_mask_7: 1.382  loss_dice_7: 2.28  loss_ce_8: 0.07002  loss_mask_8: 1.35  loss_dice_8: 2.281  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:31:38] d2.utils.events INFO:  eta: 2:10:40  iter: 319  total_loss: 39.22  loss_ce: 0.08183  loss_mask: 1.326  loss_dice: 2.192  loss_ce_0: 1.397  loss_mask_0: 1.362  loss_dice_0: 2.159  loss_ce_1: 0.06074  loss_mask_1: 1.329  loss_dice_1: 2.208  loss_ce_2: 0.07108  loss_mask_2: 1.323  loss_dice_2: 2.183  loss_ce_3: 0.07349  loss_mask_3: 1.319  loss_dice_3: 2.169  loss_ce_4: 0.08215  loss_mask_4: 1.338  loss_dice_4: 2.186  loss_ce_5: 0.0845  loss_mask_5: 1.316  loss_dice_5: 2.196  loss_ce_6: 0.08089  loss_mask_6: 1.319  loss_dice_6: 2.197  loss_ce_7: 0.07787  loss_mask_7: 1.321  loss_dice_7: 2.179  loss_ce_8: 0.07972  loss_mask_8: 1.31  loss_dice_8: 2.177  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:31:42] d2.utils.events INFO:  eta: 2:10:36  iter: 339  total_loss: 39.63  loss_ce: 0.09299  loss_mask: 1.505  loss_dice: 2.084  loss_ce_0: 1.361  loss_mask_0: 1.535  loss_dice_0: 2.073  loss_ce_1: 0.09258  loss_mask_1: 1.505  loss_dice_1: 2.074  loss_ce_2: 0.09388  loss_mask_2: 1.489  loss_dice_2: 2.077  loss_ce_3: 0.09554  loss_mask_3: 1.505  loss_dice_3: 2.105  loss_ce_4: 0.1009  loss_mask_4: 1.483  loss_dice_4: 2.066  loss_ce_5: 0.0948  loss_mask_5: 1.5  loss_dice_5: 2.079  loss_ce_6: 0.09508  loss_mask_6: 1.522  loss_dice_6: 2.073  loss_ce_7: 0.09223  loss_mask_7: 1.513  loss_dice_7: 2.081  loss_ce_8: 0.09543  loss_mask_8: 1.503  loss_dice_8: 2.095  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:31:47] d2.utils.events INFO:  eta: 2:10:31  iter: 359  total_loss: 38.31  loss_ce: 0.09825  loss_mask: 1.295  loss_dice: 1.979  loss_ce_0: 1.339  loss_mask_0: 1.329  loss_dice_0: 1.998  loss_ce_1: 0.08338  loss_mask_1: 1.235  loss_dice_1: 1.948  loss_ce_2: 0.1046  loss_mask_2: 1.21  loss_dice_2: 1.9  loss_ce_3: 0.107  loss_mask_3: 1.236  loss_dice_3: 1.927  loss_ce_4: 0.1106  loss_mask_4: 1.249  loss_dice_4: 1.933  loss_ce_5: 0.1074  loss_mask_5: 1.243  loss_dice_5: 1.972  loss_ce_6: 0.1101  loss_mask_6: 1.266  loss_dice_6: 1.972  loss_ce_7: 0.09806  loss_mask_7: 1.263  loss_dice_7: 1.986  loss_ce_8: 0.09769  loss_mask_8: 1.27  loss_dice_8: 1.974  time: 0.2256  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:31:51] d2.utils.events INFO:  eta: 2:10:32  iter: 379  total_loss: 11.93  loss_ce: 0.2098  loss_mask: 0.3778  loss_dice: 0.4698  loss_ce_0: 1.344  loss_mask_0: 0.2952  loss_dice_0: 0.5659  loss_ce_1: 0.1391  loss_mask_1: 0.3219  loss_dice_1: 0.4129  loss_ce_2: 0.1409  loss_mask_2: 0.3595  loss_dice_2: 0.4864  loss_ce_3: 0.1722  loss_mask_3: 0.3645  loss_dice_3: 0.4499  loss_ce_4: 0.1762  loss_mask_4: 0.3371  loss_dice_4: 0.4181  loss_ce_5: 0.1601  loss_mask_5: 0.3456  loss_dice_5: 0.4064  loss_ce_6: 0.1555  loss_mask_6: 0.3703  loss_dice_6: 0.4039  loss_ce_7: 0.149  loss_mask_7: 0.3517  loss_dice_7: 0.4117  loss_ce_8: 0.1723  loss_mask_8: 0.3519  loss_dice_8: 0.4655  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:31:56] d2.utils.events INFO:  eta: 2:10:32  iter: 399  total_loss: 10.93  loss_ce: 0.2117  loss_mask: 0.2934  loss_dice: 0.367  loss_ce_0: 1.406  loss_mask_0: 0.2702  loss_dice_0: 0.4472  loss_ce_1: 0.1891  loss_mask_1: 0.3068  loss_dice_1: 0.3719  loss_ce_2: 0.1875  loss_mask_2: 0.2782  loss_dice_2: 0.3244  loss_ce_3: 0.1943  loss_mask_3: 0.2891  loss_dice_3: 0.3387  loss_ce_4: 0.1949  loss_mask_4: 0.3119  loss_dice_4: 0.358  loss_ce_5: 0.2277  loss_mask_5: 0.3293  loss_dice_5: 0.3563  loss_ce_6: 0.1684  loss_mask_6: 0.3156  loss_dice_6: 0.3693  loss_ce_7: 0.1663  loss_mask_7: 0.3028  loss_dice_7: 0.3775  loss_ce_8: 0.1887  loss_mask_8: 0.2849  loss_dice_8: 0.369  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:32:00] d2.utils.events INFO:  eta: 2:10:28  iter: 419  total_loss: 8.456  loss_ce: 0.1387  loss_mask: 0.2359  loss_dice: 0.2857  loss_ce_0: 1.273  loss_mask_0: 0.2617  loss_dice_0: 0.4717  loss_ce_1: 0.1034  loss_mask_1: 0.2337  loss_dice_1: 0.3042  loss_ce_2: 0.1261  loss_mask_2: 0.2447  loss_dice_2: 0.2908  loss_ce_3: 0.1401  loss_mask_3: 0.2357  loss_dice_3: 0.302  loss_ce_4: 0.1446  loss_mask_4: 0.2265  loss_dice_4: 0.2894  loss_ce_5: 0.1545  loss_mask_5: 0.2509  loss_dice_5: 0.282  loss_ce_6: 0.1583  loss_mask_6: 0.2297  loss_dice_6: 0.303  loss_ce_7: 0.1469  loss_mask_7: 0.2397  loss_dice_7: 0.2867  loss_ce_8: 0.1303  loss_mask_8: 0.236  loss_dice_8: 0.3033  time: 0.2254  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:32:05] d2.utils.events INFO:  eta: 2:10:23  iter: 439  total_loss: 8.746  loss_ce: 0.1178  loss_mask: 0.2294  loss_dice: 0.2832  loss_ce_0: 1.248  loss_mask_0: 0.2411  loss_dice_0: 0.3542  loss_ce_1: 0.1111  loss_mask_1: 0.2386  loss_dice_1: 0.3291  loss_ce_2: 0.1133  loss_mask_2: 0.2358  loss_dice_2: 0.3006  loss_ce_3: 0.137  loss_mask_3: 0.2262  loss_dice_3: 0.2976  loss_ce_4: 0.1355  loss_mask_4: 0.2289  loss_dice_4: 0.2948  loss_ce_5: 0.1387  loss_mask_5: 0.2246  loss_dice_5: 0.2844  loss_ce_6: 0.1435  loss_mask_6: 0.2227  loss_dice_6: 0.2889  loss_ce_7: 0.1455  loss_mask_7: 0.2328  loss_dice_7: 0.2929  loss_ce_8: 0.1276  loss_mask_8: 0.2244  loss_dice_8: 0.2844  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:32:09] d2.utils.events INFO:  eta: 2:10:19  iter: 459  total_loss: 8.14  loss_ce: 0.1564  loss_mask: 0.1871  loss_dice: 0.2532  loss_ce_0: 1.209  loss_mask_0: 0.1749  loss_dice_0: 0.2664  loss_ce_1: 0.1867  loss_mask_1: 0.176  loss_dice_1: 0.2531  loss_ce_2: 0.1737  loss_mask_2: 0.1779  loss_dice_2: 0.245  loss_ce_3: 0.1643  loss_mask_3: 0.1869  loss_dice_3: 0.2495  loss_ce_4: 0.1742  loss_mask_4: 0.1811  loss_dice_4: 0.2527  loss_ce_5: 0.1923  loss_mask_5: 0.1847  loss_dice_5: 0.2497  loss_ce_6: 0.1841  loss_mask_6: 0.1785  loss_dice_6: 0.2585  loss_ce_7: 0.1642  loss_mask_7: 0.1829  loss_dice_7: 0.2474  loss_ce_8: 0.1624  loss_mask_8: 0.1883  loss_dice_8: 0.2526  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:32:14] d2.utils.events INFO:  eta: 2:10:15  iter: 479  total_loss: 6.883  loss_ce: 0.1155  loss_mask: 0.2038  loss_dice: 0.2604  loss_ce_0: 1.151  loss_mask_0: 0.191  loss_dice_0: 0.2602  loss_ce_1: 0.09754  loss_mask_1: 0.2025  loss_dice_1: 0.2507  loss_ce_2: 0.08313  loss_mask_2: 0.208  loss_dice_2: 0.2659  loss_ce_3: 0.08443  loss_mask_3: 0.2094  loss_dice_3: 0.2616  loss_ce_4: 0.09371  loss_mask_4: 0.2114  loss_dice_4: 0.2603  loss_ce_5: 0.09164  loss_mask_5: 0.2217  loss_dice_5: 0.2658  loss_ce_6: 0.09117  loss_mask_6: 0.2006  loss_dice_6: 0.2834  loss_ce_7: 0.09269  loss_mask_7: 0.1993  loss_dice_7: 0.2483  loss_ce_8: 0.1101  loss_mask_8: 0.2074  loss_dice_8: 0.2517  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:32:18] d2.utils.events INFO:  eta: 2:10:10  iter: 499  total_loss: 6.784  loss_ce: 0.1561  loss_mask: 0.1893  loss_dice: 0.2475  loss_ce_0: 1.103  loss_mask_0: 0.1803  loss_dice_0: 0.2402  loss_ce_1: 0.1536  loss_mask_1: 0.1872  loss_dice_1: 0.2377  loss_ce_2: 0.168  loss_mask_2: 0.1892  loss_dice_2: 0.2343  loss_ce_3: 0.158  loss_mask_3: 0.1871  loss_dice_3: 0.234  loss_ce_4: 0.1585  loss_mask_4: 0.1926  loss_dice_4: 0.246  loss_ce_5: 0.1576  loss_mask_5: 0.1939  loss_dice_5: 0.2394  loss_ce_6: 0.1631  loss_mask_6: 0.1828  loss_dice_6: 0.2393  loss_ce_7: 0.1596  loss_mask_7: 0.1885  loss_dice_7: 0.2389  loss_ce_8: 0.16  loss_mask_8: 0.1841  loss_dice_8: 0.2303  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:32:23] d2.utils.events INFO:  eta: 2:10:06  iter: 519  total_loss: 6.254  loss_ce: 0.07457  loss_mask: 0.1792  loss_dice: 0.2388  loss_ce_0: 1.06  loss_mask_0: 0.1698  loss_dice_0: 0.2511  loss_ce_1: 0.08932  loss_mask_1: 0.1813  loss_dice_1: 0.2438  loss_ce_2: 0.08379  loss_mask_2: 0.1842  loss_dice_2: 0.2456  loss_ce_3: 0.08416  loss_mask_3: 0.1788  loss_dice_3: 0.2369  loss_ce_4: 0.081  loss_mask_4: 0.1786  loss_dice_4: 0.248  loss_ce_5: 0.08069  loss_mask_5: 0.1816  loss_dice_5: 0.2352  loss_ce_6: 0.08502  loss_mask_6: 0.1765  loss_dice_6: 0.2491  loss_ce_7: 0.08237  loss_mask_7: 0.1851  loss_dice_7: 0.2425  loss_ce_8: 0.07727  loss_mask_8: 0.1903  loss_dice_8: 0.2486  time: 0.2252  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:32:27] d2.utils.events INFO:  eta: 2:10:02  iter: 539  total_loss: 7.019  loss_ce: 0.1699  loss_mask: 0.1816  loss_dice: 0.2394  loss_ce_0: 1.062  loss_mask_0: 0.1735  loss_dice_0: 0.2493  loss_ce_1: 0.1442  loss_mask_1: 0.1887  loss_dice_1: 0.2458  loss_ce_2: 0.1522  loss_mask_2: 0.1842  loss_dice_2: 0.2479  loss_ce_3: 0.1595  loss_mask_3: 0.1888  loss_dice_3: 0.2433  loss_ce_4: 0.1729  loss_mask_4: 0.1911  loss_dice_4: 0.2412  loss_ce_5: 0.1692  loss_mask_5: 0.1811  loss_dice_5: 0.242  loss_ce_6: 0.1681  loss_mask_6: 0.1913  loss_dice_6: 0.2409  loss_ce_7: 0.1698  loss_mask_7: 0.1875  loss_dice_7: 0.241  loss_ce_8: 0.173  loss_mask_8: 0.1838  loss_dice_8: 0.2451  time: 0.2252  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:32:32] d2.utils.events INFO:  eta: 2:10:05  iter: 559  total_loss: 6.726  loss_ce: 0.1494  loss_mask: 0.1795  loss_dice: 0.2231  loss_ce_0: 0.9999  loss_mask_0: 0.1813  loss_dice_0: 0.2299  loss_ce_1: 0.1502  loss_mask_1: 0.1739  loss_dice_1: 0.2241  loss_ce_2: 0.1383  loss_mask_2: 0.1794  loss_dice_2: 0.2247  loss_ce_3: 0.1379  loss_mask_3: 0.1801  loss_dice_3: 0.2328  loss_ce_4: 0.1392  loss_mask_4: 0.1829  loss_dice_4: 0.2232  loss_ce_5: 0.1429  loss_mask_5: 0.1793  loss_dice_5: 0.2264  loss_ce_6: 0.1565  loss_mask_6: 0.1837  loss_dice_6: 0.2255  loss_ce_7: 0.1547  loss_mask_7: 0.1762  loss_dice_7: 0.2224  loss_ce_8: 0.1665  loss_mask_8: 0.1751  loss_dice_8: 0.2263  time: 0.2252  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:32:36] d2.utils.events INFO:  eta: 2:10:13  iter: 579  total_loss: 6.134  loss_ce: 0.133  loss_mask: 0.1805  loss_dice: 0.2475  loss_ce_0: 0.9483  loss_mask_0: 0.1837  loss_dice_0: 0.2531  loss_ce_1: 0.1373  loss_mask_1: 0.1822  loss_dice_1: 0.2479  loss_ce_2: 0.1316  loss_mask_2: 0.1827  loss_dice_2: 0.2476  loss_ce_3: 0.1319  loss_mask_3: 0.174  loss_dice_3: 0.2381  loss_ce_4: 0.1293  loss_mask_4: 0.173  loss_dice_4: 0.2355  loss_ce_5: 0.1232  loss_mask_5: 0.1801  loss_dice_5: 0.2403  loss_ce_6: 0.1366  loss_mask_6: 0.1811  loss_dice_6: 0.2503  loss_ce_7: 0.1277  loss_mask_7: 0.1778  loss_dice_7: 0.2355  loss_ce_8: 0.1252  loss_mask_8: 0.1774  loss_dice_8: 0.2403  time: 0.2252  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:32:41] d2.utils.events INFO:  eta: 2:09:56  iter: 599  total_loss: 6.063  loss_ce: 0.08575  loss_mask: 0.1745  loss_dice: 0.245  loss_ce_0: 0.9066  loss_mask_0: 0.1744  loss_dice_0: 0.2392  loss_ce_1: 0.08178  loss_mask_1: 0.1714  loss_dice_1: 0.2382  loss_ce_2: 0.083  loss_mask_2: 0.1802  loss_dice_2: 0.242  loss_ce_3: 0.08534  loss_mask_3: 0.1791  loss_dice_3: 0.2338  loss_ce_4: 0.0867  loss_mask_4: 0.1794  loss_dice_4: 0.2422  loss_ce_5: 0.08035  loss_mask_5: 0.1774  loss_dice_5: 0.2454  loss_ce_6: 0.07326  loss_mask_6: 0.1776  loss_dice_6: 0.2466  loss_ce_7: 0.07674  loss_mask_7: 0.1836  loss_dice_7: 0.2335  loss_ce_8: 0.07331  loss_mask_8: 0.1797  loss_dice_8: 0.2371  time: 0.2252  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:32:45] d2.utils.events INFO:  eta: 2:10:00  iter: 619  total_loss: 6.458  loss_ce: 0.1217  loss_mask: 0.1787  loss_dice: 0.2459  loss_ce_0: 0.8573  loss_mask_0: 0.1937  loss_dice_0: 0.258  loss_ce_1: 0.126  loss_mask_1: 0.1785  loss_dice_1: 0.2418  loss_ce_2: 0.1222  loss_mask_2: 0.1784  loss_dice_2: 0.2477  loss_ce_3: 0.1198  loss_mask_3: 0.186  loss_dice_3: 0.2518  loss_ce_4: 0.1225  loss_mask_4: 0.1932  loss_dice_4: 0.246  loss_ce_5: 0.1199  loss_mask_5: 0.1808  loss_dice_5: 0.2498  loss_ce_6: 0.1218  loss_mask_6: 0.1897  loss_dice_6: 0.2599  loss_ce_7: 0.1201  loss_mask_7: 0.1819  loss_dice_7: 0.2405  loss_ce_8: 0.1231  loss_mask_8: 0.1904  loss_dice_8: 0.2541  time: 0.2252  data_time: 0.0010  lr: 0.0001  max_mem: 1909M
[08/01 16:32:50] d2.utils.events INFO:  eta: 2:09:58  iter: 639  total_loss: 6.309  loss_ce: 0.1117  loss_mask: 0.1731  loss_dice: 0.2445  loss_ce_0: 0.8355  loss_mask_0: 0.1688  loss_dice_0: 0.2469  loss_ce_1: 0.1053  loss_mask_1: 0.1755  loss_dice_1: 0.2343  loss_ce_2: 0.107  loss_mask_2: 0.1755  loss_dice_2: 0.2378  loss_ce_3: 0.1077  loss_mask_3: 0.1695  loss_dice_3: 0.2448  loss_ce_4: 0.1072  loss_mask_4: 0.1705  loss_dice_4: 0.246  loss_ce_5: 0.1027  loss_mask_5: 0.1725  loss_dice_5: 0.2416  loss_ce_6: 0.1058  loss_mask_6: 0.1749  loss_dice_6: 0.2554  loss_ce_7: 0.1079  loss_mask_7: 0.1763  loss_dice_7: 0.2417  loss_ce_8: 0.108  loss_mask_8: 0.1709  loss_dice_8: 0.2419  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:32:54] d2.utils.events INFO:  eta: 2:09:54  iter: 659  total_loss: 5.964  loss_ce: 0.1056  loss_mask: 0.182  loss_dice: 0.2344  loss_ce_0: 0.7946  loss_mask_0: 0.1803  loss_dice_0: 0.2448  loss_ce_1: 0.1054  loss_mask_1: 0.1765  loss_dice_1: 0.238  loss_ce_2: 0.106  loss_mask_2: 0.171  loss_dice_2: 0.2203  loss_ce_3: 0.1099  loss_mask_3: 0.1805  loss_dice_3: 0.233  loss_ce_4: 0.1134  loss_mask_4: 0.1729  loss_dice_4: 0.2294  loss_ce_5: 0.1174  loss_mask_5: 0.1815  loss_dice_5: 0.2416  loss_ce_6: 0.1058  loss_mask_6: 0.1879  loss_dice_6: 0.2391  loss_ce_7: 0.103  loss_mask_7: 0.1805  loss_dice_7: 0.2394  loss_ce_8: 0.1049  loss_mask_8: 0.179  loss_dice_8: 0.2297  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:32:59] d2.utils.events INFO:  eta: 2:09:49  iter: 679  total_loss: 6.099  loss_ce: 0.07581  loss_mask: 0.1937  loss_dice: 0.2454  loss_ce_0: 0.7772  loss_mask_0: 0.1905  loss_dice_0: 0.2489  loss_ce_1: 0.07087  loss_mask_1: 0.193  loss_dice_1: 0.2426  loss_ce_2: 0.07011  loss_mask_2: 0.1868  loss_dice_2: 0.2482  loss_ce_3: 0.07087  loss_mask_3: 0.1931  loss_dice_3: 0.252  loss_ce_4: 0.07371  loss_mask_4: 0.1912  loss_dice_4: 0.2487  loss_ce_5: 0.07471  loss_mask_5: 0.1833  loss_dice_5: 0.2573  loss_ce_6: 0.07471  loss_mask_6: 0.1965  loss_dice_6: 0.2455  loss_ce_7: 0.07826  loss_mask_7: 0.2008  loss_dice_7: 0.2538  loss_ce_8: 0.07726  loss_mask_8: 0.1927  loss_dice_8: 0.2442  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:33:04] d2.utils.events INFO:  eta: 2:09:45  iter: 699  total_loss: 5.869  loss_ce: 0.1201  loss_mask: 0.1477  loss_dice: 0.2049  loss_ce_0: 0.7558  loss_mask_0: 0.1555  loss_dice_0: 0.2085  loss_ce_1: 0.129  loss_mask_1: 0.1528  loss_dice_1: 0.2014  loss_ce_2: 0.1235  loss_mask_2: 0.1526  loss_dice_2: 0.2095  loss_ce_3: 0.118  loss_mask_3: 0.1592  loss_dice_3: 0.209  loss_ce_4: 0.1147  loss_mask_4: 0.1564  loss_dice_4: 0.2167  loss_ce_5: 0.1235  loss_mask_5: 0.1544  loss_dice_5: 0.2108  loss_ce_6: 0.1144  loss_mask_6: 0.1524  loss_dice_6: 0.2061  loss_ce_7: 0.1163  loss_mask_7: 0.1502  loss_dice_7: 0.2133  loss_ce_8: 0.1192  loss_mask_8: 0.1537  loss_dice_8: 0.205  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:33:08] d2.utils.events INFO:  eta: 2:09:40  iter: 719  total_loss: 6.113  loss_ce: 0.1545  loss_mask: 0.1526  loss_dice: 0.2185  loss_ce_0: 0.7168  loss_mask_0: 0.159  loss_dice_0: 0.2302  loss_ce_1: 0.129  loss_mask_1: 0.1617  loss_dice_1: 0.2254  loss_ce_2: 0.1322  loss_mask_2: 0.1602  loss_dice_2: 0.2256  loss_ce_3: 0.1283  loss_mask_3: 0.1568  loss_dice_3: 0.2231  loss_ce_4: 0.1559  loss_mask_4: 0.1609  loss_dice_4: 0.2189  loss_ce_5: 0.1554  loss_mask_5: 0.1582  loss_dice_5: 0.2179  loss_ce_6: 0.1545  loss_mask_6: 0.1571  loss_dice_6: 0.226  loss_ce_7: 0.1453  loss_mask_7: 0.1605  loss_dice_7: 0.2229  loss_ce_8: 0.1446  loss_mask_8: 0.1586  loss_dice_8: 0.217  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:33:13] d2.utils.events INFO:  eta: 2:09:34  iter: 739  total_loss: 6.069  loss_ce: 0.1039  loss_mask: 0.1756  loss_dice: 0.2253  loss_ce_0: 0.6805  loss_mask_0: 0.1725  loss_dice_0: 0.2277  loss_ce_1: 0.1091  loss_mask_1: 0.18  loss_dice_1: 0.2345  loss_ce_2: 0.09822  loss_mask_2: 0.1727  loss_dice_2: 0.2251  loss_ce_3: 0.1049  loss_mask_3: 0.1793  loss_dice_3: 0.2262  loss_ce_4: 0.1102  loss_mask_4: 0.1781  loss_dice_4: 0.2377  loss_ce_5: 0.09561  loss_mask_5: 0.1833  loss_dice_5: 0.2265  loss_ce_6: 0.1027  loss_mask_6: 0.1724  loss_dice_6: 0.2288  loss_ce_7: 0.09998  loss_mask_7: 0.1811  loss_dice_7: 0.2341  loss_ce_8: 0.104  loss_mask_8: 0.1791  loss_dice_8: 0.2266  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:33:17] d2.utils.events INFO:  eta: 2:09:30  iter: 759  total_loss: 6.244  loss_ce: 0.1657  loss_mask: 0.176  loss_dice: 0.2391  loss_ce_0: 0.66  loss_mask_0: 0.175  loss_dice_0: 0.2405  loss_ce_1: 0.1664  loss_mask_1: 0.1747  loss_dice_1: 0.2441  loss_ce_2: 0.185  loss_mask_2: 0.1748  loss_dice_2: 0.2325  loss_ce_3: 0.1999  loss_mask_3: 0.1766  loss_dice_3: 0.2433  loss_ce_4: 0.1987  loss_mask_4: 0.1776  loss_dice_4: 0.2373  loss_ce_5: 0.1638  loss_mask_5: 0.1688  loss_dice_5: 0.2263  loss_ce_6: 0.1602  loss_mask_6: 0.1752  loss_dice_6: 0.2258  loss_ce_7: 0.1769  loss_mask_7: 0.1847  loss_dice_7: 0.2366  loss_ce_8: 0.1708  loss_mask_8: 0.1762  loss_dice_8: 0.2391  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:33:22] d2.utils.events INFO:  eta: 2:09:30  iter: 779  total_loss: 5.663  loss_ce: 0.1302  loss_mask: 0.1674  loss_dice: 0.2087  loss_ce_0: 0.6413  loss_mask_0: 0.1697  loss_dice_0: 0.2178  loss_ce_1: 0.1006  loss_mask_1: 0.1694  loss_dice_1: 0.2191  loss_ce_2: 0.1087  loss_mask_2: 0.1749  loss_dice_2: 0.22  loss_ce_3: 0.1154  loss_mask_3: 0.1691  loss_dice_3: 0.2174  loss_ce_4: 0.1242  loss_mask_4: 0.1695  loss_dice_4: 0.2137  loss_ce_5: 0.1297  loss_mask_5: 0.1738  loss_dice_5: 0.2156  loss_ce_6: 0.1199  loss_mask_6: 0.1727  loss_dice_6: 0.2163  loss_ce_7: 0.1253  loss_mask_7: 0.171  loss_dice_7: 0.2143  loss_ce_8: 0.1186  loss_mask_8: 0.1772  loss_dice_8: 0.2204  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:33:26] d2.utils.events INFO:  eta: 2:09:22  iter: 799  total_loss: 7.076  loss_ce: 0.1857  loss_mask: 0.1888  loss_dice: 0.2396  loss_ce_0: 0.6269  loss_mask_0: 0.1955  loss_dice_0: 0.2403  loss_ce_1: 0.2096  loss_mask_1: 0.1842  loss_dice_1: 0.2405  loss_ce_2: 0.2137  loss_mask_2: 0.2001  loss_dice_2: 0.2342  loss_ce_3: 0.2063  loss_mask_3: 0.1964  loss_dice_3: 0.2378  loss_ce_4: 0.2035  loss_mask_4: 0.1938  loss_dice_4: 0.2395  loss_ce_5: 0.1881  loss_mask_5: 0.1931  loss_dice_5: 0.2273  loss_ce_6: 0.1956  loss_mask_6: 0.1927  loss_dice_6: 0.2277  loss_ce_7: 0.1939  loss_mask_7: 0.1961  loss_dice_7: 0.2322  loss_ce_8: 0.1974  loss_mask_8: 0.2054  loss_dice_8: 0.2394  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:33:31] d2.utils.events INFO:  eta: 2:09:18  iter: 819  total_loss: 5.731  loss_ce: 0.15  loss_mask: 0.167  loss_dice: 0.214  loss_ce_0: 0.5934  loss_mask_0: 0.1636  loss_dice_0: 0.22  loss_ce_1: 0.1513  loss_mask_1: 0.168  loss_dice_1: 0.2239  loss_ce_2: 0.1527  loss_mask_2: 0.1672  loss_dice_2: 0.2165  loss_ce_3: 0.1478  loss_mask_3: 0.164  loss_dice_3: 0.2104  loss_ce_4: 0.1406  loss_mask_4: 0.1668  loss_dice_4: 0.2176  loss_ce_5: 0.1441  loss_mask_5: 0.1728  loss_dice_5: 0.2159  loss_ce_6: 0.1404  loss_mask_6: 0.1672  loss_dice_6: 0.2179  loss_ce_7: 0.1438  loss_mask_7: 0.1702  loss_dice_7: 0.2176  loss_ce_8: 0.1433  loss_mask_8: 0.1678  loss_dice_8: 0.2143  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:33:35] d2.utils.events INFO:  eta: 2:09:13  iter: 839  total_loss: 5.273  loss_ce: 0.1254  loss_mask: 0.1607  loss_dice: 0.2009  loss_ce_0: 0.5733  loss_mask_0: 0.1563  loss_dice_0: 0.2031  loss_ce_1: 0.1061  loss_mask_1: 0.1547  loss_dice_1: 0.205  loss_ce_2: 0.1153  loss_mask_2: 0.1529  loss_dice_2: 0.1993  loss_ce_3: 0.118  loss_mask_3: 0.155  loss_dice_3: 0.2024  loss_ce_4: 0.1366  loss_mask_4: 0.1503  loss_dice_4: 0.2041  loss_ce_5: 0.1335  loss_mask_5: 0.1536  loss_dice_5: 0.2089  loss_ce_6: 0.1307  loss_mask_6: 0.1528  loss_dice_6: 0.1993  loss_ce_7: 0.1211  loss_mask_7: 0.1509  loss_dice_7: 0.203  loss_ce_8: 0.1239  loss_mask_8: 0.1542  loss_dice_8: 0.2016  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:33:40] d2.utils.events INFO:  eta: 2:09:11  iter: 859  total_loss: 5.58  loss_ce: 0.1271  loss_mask: 0.1666  loss_dice: 0.2127  loss_ce_0: 0.5482  loss_mask_0: 0.1527  loss_dice_0: 0.2122  loss_ce_1: 0.1275  loss_mask_1: 0.1592  loss_dice_1: 0.2121  loss_ce_2: 0.1269  loss_mask_2: 0.1654  loss_dice_2: 0.2134  loss_ce_3: 0.128  loss_mask_3: 0.1589  loss_dice_3: 0.2134  loss_ce_4: 0.1284  loss_mask_4: 0.1601  loss_dice_4: 0.2143  loss_ce_5: 0.1292  loss_mask_5: 0.1614  loss_dice_5: 0.2153  loss_ce_6: 0.129  loss_mask_6: 0.1614  loss_dice_6: 0.2145  loss_ce_7: 0.1291  loss_mask_7: 0.1626  loss_dice_7: 0.214  loss_ce_8: 0.1275  loss_mask_8: 0.159  loss_dice_8: 0.2083  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:33:44] d2.utils.events INFO:  eta: 2:09:03  iter: 879  total_loss: 5.373  loss_ce: 0.1173  loss_mask: 0.1514  loss_dice: 0.2041  loss_ce_0: 0.5206  loss_mask_0: 0.1508  loss_dice_0: 0.1996  loss_ce_1: 0.1168  loss_mask_1: 0.1532  loss_dice_1: 0.2112  loss_ce_2: 0.1214  loss_mask_2: 0.1511  loss_dice_2: 0.2105  loss_ce_3: 0.1157  loss_mask_3: 0.1633  loss_dice_3: 0.2103  loss_ce_4: 0.1129  loss_mask_4: 0.155  loss_dice_4: 0.2103  loss_ce_5: 0.1217  loss_mask_5: 0.1503  loss_dice_5: 0.2108  loss_ce_6: 0.1176  loss_mask_6: 0.1576  loss_dice_6: 0.2183  loss_ce_7: 0.1133  loss_mask_7: 0.1483  loss_dice_7: 0.2073  loss_ce_8: 0.1196  loss_mask_8: 0.1532  loss_dice_8: 0.2103  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:33:49] d2.utils.events INFO:  eta: 2:08:58  iter: 899  total_loss: 5.661  loss_ce: 0.1608  loss_mask: 0.1513  loss_dice: 0.2057  loss_ce_0: 0.5012  loss_mask_0: 0.1566  loss_dice_0: 0.2089  loss_ce_1: 0.1499  loss_mask_1: 0.1554  loss_dice_1: 0.2103  loss_ce_2: 0.1492  loss_mask_2: 0.1605  loss_dice_2: 0.2117  loss_ce_3: 0.154  loss_mask_3: 0.1648  loss_dice_3: 0.2073  loss_ce_4: 0.1571  loss_mask_4: 0.154  loss_dice_4: 0.2039  loss_ce_5: 0.1581  loss_mask_5: 0.1589  loss_dice_5: 0.2089  loss_ce_6: 0.157  loss_mask_6: 0.1533  loss_dice_6: 0.2018  loss_ce_7: 0.1578  loss_mask_7: 0.1534  loss_dice_7: 0.1989  loss_ce_8: 0.1567  loss_mask_8: 0.1576  loss_dice_8: 0.2037  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:33:53] d2.utils.events INFO:  eta: 2:08:57  iter: 919  total_loss: 5.228  loss_ce: 0.09206  loss_mask: 0.1647  loss_dice: 0.2163  loss_ce_0: 0.479  loss_mask_0: 0.1723  loss_dice_0: 0.2214  loss_ce_1: 0.08954  loss_mask_1: 0.1622  loss_dice_1: 0.2134  loss_ce_2: 0.09052  loss_mask_2: 0.1648  loss_dice_2: 0.2152  loss_ce_3: 0.09141  loss_mask_3: 0.1667  loss_dice_3: 0.2145  loss_ce_4: 0.0901  loss_mask_4: 0.1648  loss_dice_4: 0.2192  loss_ce_5: 0.09481  loss_mask_5: 0.1658  loss_dice_5: 0.2194  loss_ce_6: 0.08873  loss_mask_6: 0.1647  loss_dice_6: 0.2193  loss_ce_7: 0.09103  loss_mask_7: 0.1666  loss_dice_7: 0.2185  loss_ce_8: 0.09244  loss_mask_8: 0.1586  loss_dice_8: 0.2199  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:33:58] d2.utils.events INFO:  eta: 2:08:53  iter: 939  total_loss: 5.615  loss_ce: 0.09757  loss_mask: 0.1592  loss_dice: 0.2253  loss_ce_0: 0.4601  loss_mask_0: 0.1641  loss_dice_0: 0.2289  loss_ce_1: 0.09901  loss_mask_1: 0.1716  loss_dice_1: 0.2296  loss_ce_2: 0.09791  loss_mask_2: 0.1679  loss_dice_2: 0.2434  loss_ce_3: 0.09489  loss_mask_3: 0.1694  loss_dice_3: 0.243  loss_ce_4: 0.0931  loss_mask_4: 0.1648  loss_dice_4: 0.2277  loss_ce_5: 0.09824  loss_mask_5: 0.1709  loss_dice_5: 0.2381  loss_ce_6: 0.09245  loss_mask_6: 0.163  loss_dice_6: 0.2255  loss_ce_7: 0.09405  loss_mask_7: 0.1633  loss_dice_7: 0.2354  loss_ce_8: 0.09983  loss_mask_8: 0.1673  loss_dice_8: 0.2359  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:34:02] d2.utils.events INFO:  eta: 2:08:48  iter: 959  total_loss: 5.692  loss_ce: 0.1145  loss_mask: 0.161  loss_dice: 0.2048  loss_ce_0: 0.446  loss_mask_0: 0.1573  loss_dice_0: 0.1976  loss_ce_1: 0.1132  loss_mask_1: 0.147  loss_dice_1: 0.1961  loss_ce_2: 0.1148  loss_mask_2: 0.1551  loss_dice_2: 0.2057  loss_ce_3: 0.1169  loss_mask_3: 0.1564  loss_dice_3: 0.2013  loss_ce_4: 0.113  loss_mask_4: 0.159  loss_dice_4: 0.2012  loss_ce_5: 0.1146  loss_mask_5: 0.1499  loss_dice_5: 0.1962  loss_ce_6: 0.1183  loss_mask_6: 0.1623  loss_dice_6: 0.2035  loss_ce_7: 0.1146  loss_mask_7: 0.1574  loss_dice_7: 0.1977  loss_ce_8: 0.1145  loss_mask_8: 0.1546  loss_dice_8: 0.2068  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:34:07] d2.utils.events INFO:  eta: 2:08:47  iter: 979  total_loss: 5.835  loss_ce: 0.1867  loss_mask: 0.153  loss_dice: 0.2185  loss_ce_0: 0.4292  loss_mask_0: 0.15  loss_dice_0: 0.215  loss_ce_1: 0.1979  loss_mask_1: 0.1461  loss_dice_1: 0.2207  loss_ce_2: 0.1921  loss_mask_2: 0.1515  loss_dice_2: 0.2167  loss_ce_3: 0.1933  loss_mask_3: 0.1509  loss_dice_3: 0.2148  loss_ce_4: 0.1968  loss_mask_4: 0.1508  loss_dice_4: 0.215  loss_ce_5: 0.1945  loss_mask_5: 0.1501  loss_dice_5: 0.2186  loss_ce_6: 0.1954  loss_mask_6: 0.1505  loss_dice_6: 0.2176  loss_ce_7: 0.198  loss_mask_7: 0.1553  loss_dice_7: 0.2216  loss_ce_8: 0.1939  loss_mask_8: 0.1542  loss_dice_8: 0.2175  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:34:11] d2.utils.events INFO:  eta: 2:08:42  iter: 999  total_loss: 5.306  loss_ce: 0.126  loss_mask: 0.1534  loss_dice: 0.2057  loss_ce_0: 0.4133  loss_mask_0: 0.1519  loss_dice_0: 0.2  loss_ce_1: 0.1276  loss_mask_1: 0.154  loss_dice_1: 0.204  loss_ce_2: 0.1262  loss_mask_2: 0.154  loss_dice_2: 0.2037  loss_ce_3: 0.1277  loss_mask_3: 0.1531  loss_dice_3: 0.2009  loss_ce_4: 0.124  loss_mask_4: 0.1582  loss_dice_4: 0.2054  loss_ce_5: 0.128  loss_mask_5: 0.1547  loss_dice_5: 0.2  loss_ce_6: 0.1257  loss_mask_6: 0.1494  loss_dice_6: 0.1935  loss_ce_7: 0.1243  loss_mask_7: 0.1542  loss_dice_7: 0.2036  loss_ce_8: 0.1253  loss_mask_8: 0.1571  loss_dice_8: 0.2032  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:34:16] d2.utils.events INFO:  eta: 2:08:38  iter: 1019  total_loss: 5.345  loss_ce: 0.1173  loss_mask: 0.1562  loss_dice: 0.2272  loss_ce_0: 0.4018  loss_mask_0: 0.1577  loss_dice_0: 0.2233  loss_ce_1: 0.1171  loss_mask_1: 0.1535  loss_dice_1: 0.2202  loss_ce_2: 0.1145  loss_mask_2: 0.1637  loss_dice_2: 0.2211  loss_ce_3: 0.1135  loss_mask_3: 0.1584  loss_dice_3: 0.2236  loss_ce_4: 0.1157  loss_mask_4: 0.159  loss_dice_4: 0.2204  loss_ce_5: 0.1164  loss_mask_5: 0.1497  loss_dice_5: 0.2204  loss_ce_6: 0.1113  loss_mask_6: 0.1576  loss_dice_6: 0.2153  loss_ce_7: 0.115  loss_mask_7: 0.1618  loss_dice_7: 0.222  loss_ce_8: 0.1164  loss_mask_8: 0.1522  loss_dice_8: 0.2229  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:34:21] d2.utils.events INFO:  eta: 2:08:52  iter: 1039  total_loss: 4.977  loss_ce: 0.09702  loss_mask: 0.1532  loss_dice: 0.2182  loss_ce_0: 0.3867  loss_mask_0: 0.1589  loss_dice_0: 0.2165  loss_ce_1: 0.09331  loss_mask_1: 0.159  loss_dice_1: 0.2167  loss_ce_2: 0.0968  loss_mask_2: 0.1551  loss_dice_2: 0.2156  loss_ce_3: 0.09862  loss_mask_3: 0.1571  loss_dice_3: 0.2127  loss_ce_4: 0.09736  loss_mask_4: 0.1557  loss_dice_4: 0.2116  loss_ce_5: 0.09966  loss_mask_5: 0.155  loss_dice_5: 0.2085  loss_ce_6: 0.09962  loss_mask_6: 0.1525  loss_dice_6: 0.2045  loss_ce_7: 0.09704  loss_mask_7: 0.155  loss_dice_7: 0.2075  loss_ce_8: 0.09943  loss_mask_8: 0.1541  loss_dice_8: 0.2089  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:34:25] d2.utils.events INFO:  eta: 2:08:43  iter: 1059  total_loss: 5.075  loss_ce: 0.1185  loss_mask: 0.1378  loss_dice: 0.1932  loss_ce_0: 0.3757  loss_mask_0: 0.1487  loss_dice_0: 0.1983  loss_ce_1: 0.1178  loss_mask_1: 0.1405  loss_dice_1: 0.2021  loss_ce_2: 0.1202  loss_mask_2: 0.1454  loss_dice_2: 0.2002  loss_ce_3: 0.1239  loss_mask_3: 0.1425  loss_dice_3: 0.1923  loss_ce_4: 0.1175  loss_mask_4: 0.1406  loss_dice_4: 0.1982  loss_ce_5: 0.1254  loss_mask_5: 0.1417  loss_dice_5: 0.1971  loss_ce_6: 0.121  loss_mask_6: 0.1434  loss_dice_6: 0.1887  loss_ce_7: 0.1156  loss_mask_7: 0.143  loss_dice_7: 0.192  loss_ce_8: 0.1221  loss_mask_8: 0.1465  loss_dice_8: 0.1917  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:34:30] d2.utils.events INFO:  eta: 2:08:32  iter: 1079  total_loss: 5.535  loss_ce: 0.157  loss_mask: 0.1477  loss_dice: 0.2029  loss_ce_0: 0.3578  loss_mask_0: 0.149  loss_dice_0: 0.2031  loss_ce_1: 0.1543  loss_mask_1: 0.1473  loss_dice_1: 0.2027  loss_ce_2: 0.1549  loss_mask_2: 0.1459  loss_dice_2: 0.2024  loss_ce_3: 0.1531  loss_mask_3: 0.1451  loss_dice_3: 0.197  loss_ce_4: 0.1536  loss_mask_4: 0.148  loss_dice_4: 0.2011  loss_ce_5: 0.1567  loss_mask_5: 0.1517  loss_dice_5: 0.2002  loss_ce_6: 0.1516  loss_mask_6: 0.1472  loss_dice_6: 0.1981  loss_ce_7: 0.153  loss_mask_7: 0.1423  loss_dice_7: 0.2043  loss_ce_8: 0.1547  loss_mask_8: 0.1423  loss_dice_8: 0.196  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:34:34] d2.utils.events INFO:  eta: 2:08:21  iter: 1099  total_loss: 5.28  loss_ce: 0.1781  loss_mask: 0.1465  loss_dice: 0.1971  loss_ce_0: 0.3476  loss_mask_0: 0.1425  loss_dice_0: 0.2008  loss_ce_1: 0.1683  loss_mask_1: 0.1481  loss_dice_1: 0.2073  loss_ce_2: 0.1729  loss_mask_2: 0.1441  loss_dice_2: 0.2086  loss_ce_3: 0.1713  loss_mask_3: 0.1438  loss_dice_3: 0.199  loss_ce_4: 0.1746  loss_mask_4: 0.1432  loss_dice_4: 0.1986  loss_ce_5: 0.1771  loss_mask_5: 0.1469  loss_dice_5: 0.2051  loss_ce_6: 0.1819  loss_mask_6: 0.1491  loss_dice_6: 0.2044  loss_ce_7: 0.1826  loss_mask_7: 0.1456  loss_dice_7: 0.1998  loss_ce_8: 0.1818  loss_mask_8: 0.1433  loss_dice_8: 0.1996  time: 0.2254  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:34:39] d2.utils.events INFO:  eta: 2:08:17  iter: 1119  total_loss: 4.672  loss_ce: 0.1108  loss_mask: 0.1297  loss_dice: 0.1842  loss_ce_0: 0.3436  loss_mask_0: 0.1342  loss_dice_0: 0.1845  loss_ce_1: 0.1282  loss_mask_1: 0.1329  loss_dice_1: 0.1865  loss_ce_2: 0.122  loss_mask_2: 0.1347  loss_dice_2: 0.1801  loss_ce_3: 0.1164  loss_mask_3: 0.1356  loss_dice_3: 0.1831  loss_ce_4: 0.1135  loss_mask_4: 0.1288  loss_dice_4: 0.1845  loss_ce_5: 0.111  loss_mask_5: 0.134  loss_dice_5: 0.1815  loss_ce_6: 0.1109  loss_mask_6: 0.1366  loss_dice_6: 0.1852  loss_ce_7: 0.1097  loss_mask_7: 0.1312  loss_dice_7: 0.1827  loss_ce_8: 0.1092  loss_mask_8: 0.1318  loss_dice_8: 0.1796  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:34:43] d2.utils.events INFO:  eta: 2:08:12  iter: 1139  total_loss: 4.712  loss_ce: 0.1182  loss_mask: 0.1475  loss_dice: 0.205  loss_ce_0: 0.3317  loss_mask_0: 0.144  loss_dice_0: 0.2082  loss_ce_1: 0.1123  loss_mask_1: 0.1467  loss_dice_1: 0.2012  loss_ce_2: 0.1141  loss_mask_2: 0.1455  loss_dice_2: 0.2028  loss_ce_3: 0.1154  loss_mask_3: 0.1429  loss_dice_3: 0.205  loss_ce_4: 0.1179  loss_mask_4: 0.143  loss_dice_4: 0.2069  loss_ce_5: 0.1159  loss_mask_5: 0.1445  loss_dice_5: 0.2041  loss_ce_6: 0.12  loss_mask_6: 0.1463  loss_dice_6: 0.203  loss_ce_7: 0.1173  loss_mask_7: 0.1449  loss_dice_7: 0.2095  loss_ce_8: 0.1171  loss_mask_8: 0.1443  loss_dice_8: 0.2032  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:34:48] d2.utils.events INFO:  eta: 2:08:13  iter: 1159  total_loss: 4.877  loss_ce: 0.1235  loss_mask: 0.1401  loss_dice: 0.1989  loss_ce_0: 0.3242  loss_mask_0: 0.1497  loss_dice_0: 0.1884  loss_ce_1: 0.119  loss_mask_1: 0.1459  loss_dice_1: 0.1944  loss_ce_2: 0.1195  loss_mask_2: 0.1456  loss_dice_2: 0.1962  loss_ce_3: 0.1198  loss_mask_3: 0.1469  loss_dice_3: 0.196  loss_ce_4: 0.1171  loss_mask_4: 0.1516  loss_dice_4: 0.2042  loss_ce_5: 0.1223  loss_mask_5: 0.1468  loss_dice_5: 0.1976  loss_ce_6: 0.123  loss_mask_6: 0.1444  loss_dice_6: 0.1966  loss_ce_7: 0.1221  loss_mask_7: 0.145  loss_dice_7: 0.1987  loss_ce_8: 0.1187  loss_mask_8: 0.1536  loss_dice_8: 0.196  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:34:52] d2.utils.events INFO:  eta: 2:08:04  iter: 1179  total_loss: 4.579  loss_ce: 0.07517  loss_mask: 0.1377  loss_dice: 0.1966  loss_ce_0: 0.31  loss_mask_0: 0.1438  loss_dice_0: 0.2039  loss_ce_1: 0.07734  loss_mask_1: 0.1435  loss_dice_1: 0.2054  loss_ce_2: 0.07571  loss_mask_2: 0.144  loss_dice_2: 0.2068  loss_ce_3: 0.07229  loss_mask_3: 0.1346  loss_dice_3: 0.1979  loss_ce_4: 0.0736  loss_mask_4: 0.1352  loss_dice_4: 0.2036  loss_ce_5: 0.07505  loss_mask_5: 0.1344  loss_dice_5: 0.2042  loss_ce_6: 0.07404  loss_mask_6: 0.1393  loss_dice_6: 0.2055  loss_ce_7: 0.07561  loss_mask_7: 0.1459  loss_dice_7: 0.2097  loss_ce_8: 0.07502  loss_mask_8: 0.1404  loss_dice_8: 0.2075  time: 0.2254  data_time: 0.0010  lr: 0.0001  max_mem: 1909M
[08/01 16:34:57] d2.utils.events INFO:  eta: 2:08:07  iter: 1199  total_loss: 4.96  loss_ce: 0.08827  loss_mask: 0.1506  loss_dice: 0.2037  loss_ce_0: 0.3048  loss_mask_0: 0.1451  loss_dice_0: 0.2038  loss_ce_1: 0.1271  loss_mask_1: 0.1537  loss_dice_1: 0.2095  loss_ce_2: 0.1186  loss_mask_2: 0.1565  loss_dice_2: 0.2158  loss_ce_3: 0.1059  loss_mask_3: 0.1466  loss_dice_3: 0.2044  loss_ce_4: 0.09158  loss_mask_4: 0.1505  loss_dice_4: 0.2081  loss_ce_5: 0.08582  loss_mask_5: 0.151  loss_dice_5: 0.2104  loss_ce_6: 0.08768  loss_mask_6: 0.1533  loss_dice_6: 0.208  loss_ce_7: 0.08584  loss_mask_7: 0.1445  loss_dice_7: 0.2055  loss_ce_8: 0.09298  loss_mask_8: 0.1519  loss_dice_8: 0.2007  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:35:01] d2.utils.events INFO:  eta: 2:08:14  iter: 1219  total_loss: 5.503  loss_ce: 0.1147  loss_mask: 0.154  loss_dice: 0.2342  loss_ce_0: 0.2949  loss_mask_0: 0.1533  loss_dice_0: 0.2225  loss_ce_1: 0.1411  loss_mask_1: 0.1523  loss_dice_1: 0.2313  loss_ce_2: 0.1258  loss_mask_2: 0.1623  loss_dice_2: 0.2296  loss_ce_3: 0.1128  loss_mask_3: 0.1614  loss_dice_3: 0.2386  loss_ce_4: 0.1146  loss_mask_4: 0.1608  loss_dice_4: 0.2296  loss_ce_5: 0.1124  loss_mask_5: 0.1566  loss_dice_5: 0.2321  loss_ce_6: 0.116  loss_mask_6: 0.1602  loss_dice_6: 0.2463  loss_ce_7: 0.1178  loss_mask_7: 0.1548  loss_dice_7: 0.2339  loss_ce_8: 0.1146  loss_mask_8: 0.1542  loss_dice_8: 0.233  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:35:06] d2.utils.events INFO:  eta: 2:07:57  iter: 1239  total_loss: 5.19  loss_ce: 0.1188  loss_mask: 0.1413  loss_dice: 0.2076  loss_ce_0: 0.2917  loss_mask_0: 0.1465  loss_dice_0: 0.2064  loss_ce_1: 0.1254  loss_mask_1: 0.1456  loss_dice_1: 0.2014  loss_ce_2: 0.12  loss_mask_2: 0.1453  loss_dice_2: 0.1995  loss_ce_3: 0.1254  loss_mask_3: 0.1479  loss_dice_3: 0.1992  loss_ce_4: 0.127  loss_mask_4: 0.1425  loss_dice_4: 0.2039  loss_ce_5: 0.1192  loss_mask_5: 0.1411  loss_dice_5: 0.1955  loss_ce_6: 0.1213  loss_mask_6: 0.1494  loss_dice_6: 0.2005  loss_ce_7: 0.1204  loss_mask_7: 0.1385  loss_dice_7: 0.198  loss_ce_8: 0.1225  loss_mask_8: 0.1466  loss_dice_8: 0.2043  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:35:10] d2.utils.events INFO:  eta: 2:07:53  iter: 1259  total_loss: 4.794  loss_ce: 0.1053  loss_mask: 0.1504  loss_dice: 0.2018  loss_ce_0: 0.2944  loss_mask_0: 0.1528  loss_dice_0: 0.2038  loss_ce_1: 0.1019  loss_mask_1: 0.1454  loss_dice_1: 0.2006  loss_ce_2: 0.09855  loss_mask_2: 0.1469  loss_dice_2: 0.1959  loss_ce_3: 0.09118  loss_mask_3: 0.1443  loss_dice_3: 0.1939  loss_ce_4: 0.09501  loss_mask_4: 0.147  loss_dice_4: 0.1983  loss_ce_5: 0.1006  loss_mask_5: 0.1483  loss_dice_5: 0.198  loss_ce_6: 0.1022  loss_mask_6: 0.1437  loss_dice_6: 0.1973  loss_ce_7: 0.1035  loss_mask_7: 0.1531  loss_dice_7: 0.2029  loss_ce_8: 0.1038  loss_mask_8: 0.1408  loss_dice_8: 0.1983  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:35:15] d2.utils.events INFO:  eta: 2:08:05  iter: 1279  total_loss: 5.368  loss_ce: 0.1583  loss_mask: 0.1545  loss_dice: 0.21  loss_ce_0: 0.2793  loss_mask_0: 0.1536  loss_dice_0: 0.201  loss_ce_1: 0.1311  loss_mask_1: 0.1539  loss_dice_1: 0.204  loss_ce_2: 0.1301  loss_mask_2: 0.1505  loss_dice_2: 0.2007  loss_ce_3: 0.1363  loss_mask_3: 0.1534  loss_dice_3: 0.2026  loss_ce_4: 0.1521  loss_mask_4: 0.1507  loss_dice_4: 0.2072  loss_ce_5: 0.1577  loss_mask_5: 0.1471  loss_dice_5: 0.1972  loss_ce_6: 0.156  loss_mask_6: 0.149  loss_dice_6: 0.1933  loss_ce_7: 0.1567  loss_mask_7: 0.1496  loss_dice_7: 0.2058  loss_ce_8: 0.1588  loss_mask_8: 0.1556  loss_dice_8: 0.2076  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:35:19] d2.utils.events INFO:  eta: 2:08:00  iter: 1299  total_loss: 4.84  loss_ce: 0.1178  loss_mask: 0.1419  loss_dice: 0.1967  loss_ce_0: 0.2787  loss_mask_0: 0.1444  loss_dice_0: 0.1916  loss_ce_1: 0.1107  loss_mask_1: 0.1417  loss_dice_1: 0.1931  loss_ce_2: 0.1227  loss_mask_2: 0.1451  loss_dice_2: 0.1994  loss_ce_3: 0.1234  loss_mask_3: 0.141  loss_dice_3: 0.1905  loss_ce_4: 0.1282  loss_mask_4: 0.1455  loss_dice_4: 0.2008  loss_ce_5: 0.1196  loss_mask_5: 0.1471  loss_dice_5: 0.2063  loss_ce_6: 0.1216  loss_mask_6: 0.1442  loss_dice_6: 0.1948  loss_ce_7: 0.1195  loss_mask_7: 0.1432  loss_dice_7: 0.1942  loss_ce_8: 0.1212  loss_mask_8: 0.1439  loss_dice_8: 0.1977  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:35:24] d2.utils.events INFO:  eta: 2:07:56  iter: 1319  total_loss: 4.872  loss_ce: 0.1478  loss_mask: 0.1388  loss_dice: 0.2012  loss_ce_0: 0.2708  loss_mask_0: 0.1367  loss_dice_0: 0.1935  loss_ce_1: 0.1428  loss_mask_1: 0.1451  loss_dice_1: 0.1975  loss_ce_2: 0.1439  loss_mask_2: 0.1405  loss_dice_2: 0.1937  loss_ce_3: 0.1429  loss_mask_3: 0.1412  loss_dice_3: 0.198  loss_ce_4: 0.1424  loss_mask_4: 0.1411  loss_dice_4: 0.1997  loss_ce_5: 0.1457  loss_mask_5: 0.1353  loss_dice_5: 0.2011  loss_ce_6: 0.1457  loss_mask_6: 0.1435  loss_dice_6: 0.2014  loss_ce_7: 0.1455  loss_mask_7: 0.1404  loss_dice_7: 0.2042  loss_ce_8: 0.1463  loss_mask_8: 0.1419  loss_dice_8: 0.1994  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:35:28] d2.utils.events INFO:  eta: 2:07:52  iter: 1339  total_loss: 5.191  loss_ce: 0.1482  loss_mask: 0.1376  loss_dice: 0.197  loss_ce_0: 0.267  loss_mask_0: 0.1386  loss_dice_0: 0.199  loss_ce_1: 0.1444  loss_mask_1: 0.143  loss_dice_1: 0.1958  loss_ce_2: 0.1513  loss_mask_2: 0.1412  loss_dice_2: 0.1942  loss_ce_3: 0.1499  loss_mask_3: 0.1443  loss_dice_3: 0.1944  loss_ce_4: 0.1485  loss_mask_4: 0.1414  loss_dice_4: 0.1967  loss_ce_5: 0.148  loss_mask_5: 0.1412  loss_dice_5: 0.1894  loss_ce_6: 0.1475  loss_mask_6: 0.139  loss_dice_6: 0.1908  loss_ce_7: 0.1492  loss_mask_7: 0.1383  loss_dice_7: 0.1954  loss_ce_8: 0.1497  loss_mask_8: 0.1367  loss_dice_8: 0.1933  time: 0.2254  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:35:33] d2.utils.events INFO:  eta: 2:07:47  iter: 1359  total_loss: 5.024  loss_ce: 0.1505  loss_mask: 0.1359  loss_dice: 0.2022  loss_ce_0: 0.2611  loss_mask_0: 0.1428  loss_dice_0: 0.1958  loss_ce_1: 0.1402  loss_mask_1: 0.1397  loss_dice_1: 0.198  loss_ce_2: 0.1521  loss_mask_2: 0.1427  loss_dice_2: 0.1969  loss_ce_3: 0.1574  loss_mask_3: 0.1388  loss_dice_3: 0.2025  loss_ce_4: 0.156  loss_mask_4: 0.1419  loss_dice_4: 0.2025  loss_ce_5: 0.1513  loss_mask_5: 0.1406  loss_dice_5: 0.1995  loss_ce_6: 0.1531  loss_mask_6: 0.1367  loss_dice_6: 0.2042  loss_ce_7: 0.1532  loss_mask_7: 0.1346  loss_dice_7: 0.2015  loss_ce_8: 0.154  loss_mask_8: 0.1394  loss_dice_8: 0.2058  time: 0.2253  data_time: 0.0010  lr: 0.0001  max_mem: 1909M
[08/01 16:35:37] d2.utils.events INFO:  eta: 2:07:43  iter: 1379  total_loss: 4.993  loss_ce: 0.1508  loss_mask: 0.1451  loss_dice: 0.201  loss_ce_0: 0.2578  loss_mask_0: 0.1455  loss_dice_0: 0.2034  loss_ce_1: 0.1481  loss_mask_1: 0.1427  loss_dice_1: 0.2004  loss_ce_2: 0.1488  loss_mask_2: 0.1458  loss_dice_2: 0.1961  loss_ce_3: 0.1474  loss_mask_3: 0.1422  loss_dice_3: 0.1981  loss_ce_4: 0.1489  loss_mask_4: 0.1436  loss_dice_4: 0.2039  loss_ce_5: 0.1491  loss_mask_5: 0.1456  loss_dice_5: 0.2007  loss_ce_6: 0.1471  loss_mask_6: 0.1388  loss_dice_6: 0.1988  loss_ce_7: 0.1492  loss_mask_7: 0.1429  loss_dice_7: 0.1921  loss_ce_8: 0.1478  loss_mask_8: 0.1457  loss_dice_8: 0.199  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:35:42] d2.utils.events INFO:  eta: 2:07:37  iter: 1399  total_loss: 4.755  loss_ce: 0.1066  loss_mask: 0.1412  loss_dice: 0.2049  loss_ce_0: 0.2481  loss_mask_0: 0.1358  loss_dice_0: 0.2005  loss_ce_1: 0.09854  loss_mask_1: 0.1418  loss_dice_1: 0.1935  loss_ce_2: 0.1001  loss_mask_2: 0.1377  loss_dice_2: 0.194  loss_ce_3: 0.09968  loss_mask_3: 0.1345  loss_dice_3: 0.1966  loss_ce_4: 0.1  loss_mask_4: 0.1334  loss_dice_4: 0.1971  loss_ce_5: 0.1027  loss_mask_5: 0.1353  loss_dice_5: 0.1975  loss_ce_6: 0.1006  loss_mask_6: 0.1362  loss_dice_6: 0.2015  loss_ce_7: 0.1027  loss_mask_7: 0.1368  loss_dice_7: 0.1957  loss_ce_8: 0.1045  loss_mask_8: 0.1368  loss_dice_8: 0.1982  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:35:46] d2.utils.events INFO:  eta: 2:07:32  iter: 1419  total_loss: 4.604  loss_ce: 0.08425  loss_mask: 0.1516  loss_dice: 0.2009  loss_ce_0: 0.237  loss_mask_0: 0.1532  loss_dice_0: 0.2063  loss_ce_1: 0.09033  loss_mask_1: 0.1481  loss_dice_1: 0.2002  loss_ce_2: 0.08763  loss_mask_2: 0.1429  loss_dice_2: 0.2069  loss_ce_3: 0.08876  loss_mask_3: 0.1462  loss_dice_3: 0.2125  loss_ce_4: 0.08782  loss_mask_4: 0.1437  loss_dice_4: 0.2035  loss_ce_5: 0.0866  loss_mask_5: 0.1418  loss_dice_5: 0.2069  loss_ce_6: 0.08668  loss_mask_6: 0.1462  loss_dice_6: 0.204  loss_ce_7: 0.08581  loss_mask_7: 0.1491  loss_dice_7: 0.2118  loss_ce_8: 0.0848  loss_mask_8: 0.1439  loss_dice_8: 0.2053  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:35:51] d2.utils.events INFO:  eta: 2:07:34  iter: 1439  total_loss: 5.183  loss_ce: 0.1351  loss_mask: 0.1392  loss_dice: 0.2027  loss_ce_0: 0.2437  loss_mask_0: 0.1363  loss_dice_0: 0.2042  loss_ce_1: 0.1282  loss_mask_1: 0.1343  loss_dice_1: 0.2059  loss_ce_2: 0.1318  loss_mask_2: 0.1371  loss_dice_2: 0.201  loss_ce_3: 0.1302  loss_mask_3: 0.1349  loss_dice_3: 0.2007  loss_ce_4: 0.1333  loss_mask_4: 0.1377  loss_dice_4: 0.2051  loss_ce_5: 0.1374  loss_mask_5: 0.1393  loss_dice_5: 0.2047  loss_ce_6: 0.1361  loss_mask_6: 0.1342  loss_dice_6: 0.2046  loss_ce_7: 0.1376  loss_mask_7: 0.1344  loss_dice_7: 0.1982  loss_ce_8: 0.1388  loss_mask_8: 0.139  loss_dice_8: 0.1941  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:35:56] d2.utils.events INFO:  eta: 2:07:29  iter: 1459  total_loss: 5.889  loss_ce: 0.1369  loss_mask: 0.1372  loss_dice: 0.1944  loss_ce_0: 0.2408  loss_mask_0: 0.1422  loss_dice_0: 0.1967  loss_ce_1: 0.1167  loss_mask_1: 0.1423  loss_dice_1: 0.2031  loss_ce_2: 0.1206  loss_mask_2: 0.1394  loss_dice_2: 0.2011  loss_ce_3: 0.1128  loss_mask_3: 0.1378  loss_dice_3: 0.1939  loss_ce_4: 0.1189  loss_mask_4: 0.1398  loss_dice_4: 0.1966  loss_ce_5: 0.1314  loss_mask_5: 0.1389  loss_dice_5: 0.1954  loss_ce_6: 0.1232  loss_mask_6: 0.1376  loss_dice_6: 0.198  loss_ce_7: 0.1276  loss_mask_7: 0.1389  loss_dice_7: 0.1975  loss_ce_8: 0.132  loss_mask_8: 0.142  loss_dice_8: 0.1985  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:36:00] d2.utils.events INFO:  eta: 2:07:21  iter: 1479  total_loss: 4.531  loss_ce: 0.1337  loss_mask: 0.1365  loss_dice: 0.2041  loss_ce_0: 0.2366  loss_mask_0: 0.1355  loss_dice_0: 0.1985  loss_ce_1: 0.1334  loss_mask_1: 0.1304  loss_dice_1: 0.1921  loss_ce_2: 0.1434  loss_mask_2: 0.137  loss_dice_2: 0.1937  loss_ce_3: 0.1463  loss_mask_3: 0.1328  loss_dice_3: 0.1971  loss_ce_4: 0.1416  loss_mask_4: 0.1341  loss_dice_4: 0.1988  loss_ce_5: 0.1295  loss_mask_5: 0.137  loss_dice_5: 0.2009  loss_ce_6: 0.1382  loss_mask_6: 0.135  loss_dice_6: 0.2039  loss_ce_7: 0.1346  loss_mask_7: 0.1337  loss_dice_7: 0.2071  loss_ce_8: 0.1344  loss_mask_8: 0.1363  loss_dice_8: 0.1955  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:36:05] d2.utils.events INFO:  eta: 2:07:20  iter: 1499  total_loss: 5.231  loss_ce: 0.1745  loss_mask: 0.146  loss_dice: 0.1955  loss_ce_0: 0.2366  loss_mask_0: 0.1479  loss_dice_0: 0.1961  loss_ce_1: 0.1754  loss_mask_1: 0.145  loss_dice_1: 0.1938  loss_ce_2: 0.1791  loss_mask_2: 0.1487  loss_dice_2: 0.1951  loss_ce_3: 0.1785  loss_mask_3: 0.1499  loss_dice_3: 0.1918  loss_ce_4: 0.1806  loss_mask_4: 0.1479  loss_dice_4: 0.1934  loss_ce_5: 0.1756  loss_mask_5: 0.1413  loss_dice_5: 0.1956  loss_ce_6: 0.1807  loss_mask_6: 0.1439  loss_dice_6: 0.1907  loss_ce_7: 0.1763  loss_mask_7: 0.1407  loss_dice_7: 0.1956  loss_ce_8: 0.1733  loss_mask_8: 0.1446  loss_dice_8: 0.1976  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:36:09] d2.utils.events INFO:  eta: 2:07:16  iter: 1519  total_loss: 4.913  loss_ce: 0.1634  loss_mask: 0.1302  loss_dice: 0.186  loss_ce_0: 0.2312  loss_mask_0: 0.1303  loss_dice_0: 0.195  loss_ce_1: 0.1635  loss_mask_1: 0.1322  loss_dice_1: 0.1908  loss_ce_2: 0.1675  loss_mask_2: 0.1348  loss_dice_2: 0.188  loss_ce_3: 0.1689  loss_mask_3: 0.1364  loss_dice_3: 0.1902  loss_ce_4: 0.168  loss_mask_4: 0.1322  loss_dice_4: 0.1875  loss_ce_5: 0.1679  loss_mask_5: 0.1352  loss_dice_5: 0.1928  loss_ce_6: 0.1673  loss_mask_6: 0.1359  loss_dice_6: 0.1893  loss_ce_7: 0.1693  loss_mask_7: 0.1312  loss_dice_7: 0.1882  loss_ce_8: 0.1663  loss_mask_8: 0.1324  loss_dice_8: 0.1912  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:36:14] d2.utils.events INFO:  eta: 2:07:05  iter: 1539  total_loss: 5.056  loss_ce: 0.1462  loss_mask: 0.1407  loss_dice: 0.2004  loss_ce_0: 0.2224  loss_mask_0: 0.1384  loss_dice_0: 0.2026  loss_ce_1: 0.1416  loss_mask_1: 0.137  loss_dice_1: 0.2001  loss_ce_2: 0.146  loss_mask_2: 0.1357  loss_dice_2: 0.2089  loss_ce_3: 0.1468  loss_mask_3: 0.1395  loss_dice_3: 0.2057  loss_ce_4: 0.1459  loss_mask_4: 0.1362  loss_dice_4: 0.2001  loss_ce_5: 0.1447  loss_mask_5: 0.1394  loss_dice_5: 0.2075  loss_ce_6: 0.1478  loss_mask_6: 0.1397  loss_dice_6: 0.2039  loss_ce_7: 0.147  loss_mask_7: 0.1348  loss_dice_7: 0.2041  loss_ce_8: 0.1454  loss_mask_8: 0.1377  loss_dice_8: 0.204  time: 0.2254  data_time: 0.0010  lr: 0.0001  max_mem: 1909M
[08/01 16:36:18] d2.utils.events INFO:  eta: 2:06:58  iter: 1559  total_loss: 5.411  loss_ce: 0.1464  loss_mask: 0.1536  loss_dice: 0.2215  loss_ce_0: 0.2162  loss_mask_0: 0.1472  loss_dice_0: 0.2123  loss_ce_1: 0.1466  loss_mask_1: 0.1535  loss_dice_1: 0.2208  loss_ce_2: 0.1451  loss_mask_2: 0.1421  loss_dice_2: 0.2204  loss_ce_3: 0.1462  loss_mask_3: 0.1496  loss_dice_3: 0.2134  loss_ce_4: 0.1472  loss_mask_4: 0.1491  loss_dice_4: 0.2192  loss_ce_5: 0.1469  loss_mask_5: 0.1536  loss_dice_5: 0.2255  loss_ce_6: 0.1462  loss_mask_6: 0.1451  loss_dice_6: 0.2198  loss_ce_7: 0.1471  loss_mask_7: 0.1495  loss_dice_7: 0.2142  loss_ce_8: 0.1487  loss_mask_8: 0.1477  loss_dice_8: 0.2149  time: 0.2254  data_time: 0.0010  lr: 0.0001  max_mem: 1909M
[08/01 16:36:23] d2.utils.events INFO:  eta: 2:06:49  iter: 1579  total_loss: 4.809  loss_ce: 0.1175  loss_mask: 0.1611  loss_dice: 0.2086  loss_ce_0: 0.2133  loss_mask_0: 0.156  loss_dice_0: 0.2044  loss_ce_1: 0.1182  loss_mask_1: 0.1585  loss_dice_1: 0.2067  loss_ce_2: 0.12  loss_mask_2: 0.1626  loss_dice_2: 0.2091  loss_ce_3: 0.1173  loss_mask_3: 0.163  loss_dice_3: 0.2162  loss_ce_4: 0.1202  loss_mask_4: 0.1593  loss_dice_4: 0.2113  loss_ce_5: 0.1194  loss_mask_5: 0.1562  loss_dice_5: 0.2045  loss_ce_6: 0.1168  loss_mask_6: 0.1634  loss_dice_6: 0.2049  loss_ce_7: 0.1186  loss_mask_7: 0.1599  loss_dice_7: 0.2141  loss_ce_8: 0.121  loss_mask_8: 0.1564  loss_dice_8: 0.208  time: 0.2254  data_time: 0.0010  lr: 0.0001  max_mem: 1909M
[08/01 16:36:27] d2.utils.events INFO:  eta: 2:06:54  iter: 1599  total_loss: 4.915  loss_ce: 0.1589  loss_mask: 0.1385  loss_dice: 0.1836  loss_ce_0: 0.2116  loss_mask_0: 0.1376  loss_dice_0: 0.185  loss_ce_1: 0.1603  loss_mask_1: 0.142  loss_dice_1: 0.1863  loss_ce_2: 0.1595  loss_mask_2: 0.1381  loss_dice_2: 0.1904  loss_ce_3: 0.1576  loss_mask_3: 0.1414  loss_dice_3: 0.1945  loss_ce_4: 0.1618  loss_mask_4: 0.1381  loss_dice_4: 0.1844  loss_ce_5: 0.1605  loss_mask_5: 0.138  loss_dice_5: 0.1866  loss_ce_6: 0.1585  loss_mask_6: 0.1392  loss_dice_6: 0.1837  loss_ce_7: 0.1601  loss_mask_7: 0.1359  loss_dice_7: 0.1915  loss_ce_8: 0.1626  loss_mask_8: 0.1394  loss_dice_8: 0.186  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:36:32] d2.utils.events INFO:  eta: 2:06:50  iter: 1619  total_loss: 5.025  loss_ce: 0.1778  loss_mask: 0.1287  loss_dice: 0.1862  loss_ce_0: 0.2107  loss_mask_0: 0.1276  loss_dice_0: 0.1846  loss_ce_1: 0.1847  loss_mask_1: 0.1329  loss_dice_1: 0.185  loss_ce_2: 0.1801  loss_mask_2: 0.1272  loss_dice_2: 0.1853  loss_ce_3: 0.1815  loss_mask_3: 0.1277  loss_dice_3: 0.1854  loss_ce_4: 0.1806  loss_mask_4: 0.1313  loss_dice_4: 0.1923  loss_ce_5: 0.1775  loss_mask_5: 0.1301  loss_dice_5: 0.1928  loss_ce_6: 0.1777  loss_mask_6: 0.1286  loss_dice_6: 0.1847  loss_ce_7: 0.179  loss_mask_7: 0.1268  loss_dice_7: 0.1901  loss_ce_8: 0.1797  loss_mask_8: 0.1309  loss_dice_8: 0.1883  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:36:36] d2.utils.events INFO:  eta: 2:06:44  iter: 1639  total_loss: 4.881  loss_ce: 0.1301  loss_mask: 0.1375  loss_dice: 0.1936  loss_ce_0: 0.2062  loss_mask_0: 0.1379  loss_dice_0: 0.1963  loss_ce_1: 0.1302  loss_mask_1: 0.1349  loss_dice_1: 0.1947  loss_ce_2: 0.1272  loss_mask_2: 0.1329  loss_dice_2: 0.1924  loss_ce_3: 0.1292  loss_mask_3: 0.1332  loss_dice_3: 0.1976  loss_ce_4: 0.1367  loss_mask_4: 0.1362  loss_dice_4: 0.1935  loss_ce_5: 0.1353  loss_mask_5: 0.1365  loss_dice_5: 0.1995  loss_ce_6: 0.1368  loss_mask_6: 0.1355  loss_dice_6: 0.1936  loss_ce_7: 0.1416  loss_mask_7: 0.1346  loss_dice_7: 0.1962  loss_ce_8: 0.1309  loss_mask_8: 0.1361  loss_dice_8: 0.1983  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:36:41] d2.utils.events INFO:  eta: 2:06:40  iter: 1659  total_loss: 5.086  loss_ce: 0.182  loss_mask: 0.1462  loss_dice: 0.1994  loss_ce_0: 0.2088  loss_mask_0: 0.1462  loss_dice_0: 0.2103  loss_ce_1: 0.1844  loss_mask_1: 0.1471  loss_dice_1: 0.1981  loss_ce_2: 0.1775  loss_mask_2: 0.1499  loss_dice_2: 0.203  loss_ce_3: 0.1804  loss_mask_3: 0.1508  loss_dice_3: 0.2063  loss_ce_4: 0.181  loss_mask_4: 0.153  loss_dice_4: 0.2097  loss_ce_5: 0.1869  loss_mask_5: 0.1544  loss_dice_5: 0.2007  loss_ce_6: 0.1854  loss_mask_6: 0.1553  loss_dice_6: 0.2102  loss_ce_7: 0.1852  loss_mask_7: 0.1486  loss_dice_7: 0.2069  loss_ce_8: 0.1809  loss_mask_8: 0.1469  loss_dice_8: 0.2037  time: 0.2254  data_time: 0.0010  lr: 0.0001  max_mem: 1909M
[08/01 16:36:45] d2.utils.events INFO:  eta: 2:06:34  iter: 1679  total_loss: 4.94  loss_ce: 0.148  loss_mask: 0.1334  loss_dice: 0.1966  loss_ce_0: 0.2032  loss_mask_0: 0.1341  loss_dice_0: 0.1895  loss_ce_1: 0.1385  loss_mask_1: 0.1307  loss_dice_1: 0.1804  loss_ce_2: 0.1425  loss_mask_2: 0.1349  loss_dice_2: 0.1903  loss_ce_3: 0.1387  loss_mask_3: 0.1343  loss_dice_3: 0.1899  loss_ce_4: 0.1414  loss_mask_4: 0.1322  loss_dice_4: 0.1915  loss_ce_5: 0.1465  loss_mask_5: 0.1352  loss_dice_5: 0.1912  loss_ce_6: 0.1405  loss_mask_6: 0.1338  loss_dice_6: 0.1924  loss_ce_7: 0.1433  loss_mask_7: 0.1367  loss_dice_7: 0.1899  loss_ce_8: 0.1488  loss_mask_8: 0.1366  loss_dice_8: 0.1926  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:36:50] d2.utils.events INFO:  eta: 2:06:29  iter: 1699  total_loss: 5.076  loss_ce: 0.1569  loss_mask: 0.1404  loss_dice: 0.1988  loss_ce_0: 0.2021  loss_mask_0: 0.1374  loss_dice_0: 0.1947  loss_ce_1: 0.16  loss_mask_1: 0.1357  loss_dice_1: 0.1928  loss_ce_2: 0.1621  loss_mask_2: 0.1399  loss_dice_2: 0.1954  loss_ce_3: 0.1608  loss_mask_3: 0.1369  loss_dice_3: 0.1992  loss_ce_4: 0.1568  loss_mask_4: 0.1371  loss_dice_4: 0.1994  loss_ce_5: 0.1524  loss_mask_5: 0.1368  loss_dice_5: 0.1948  loss_ce_6: 0.1589  loss_mask_6: 0.1391  loss_dice_6: 0.1898  loss_ce_7: 0.1559  loss_mask_7: 0.1348  loss_dice_7: 0.1906  loss_ce_8: 0.1548  loss_mask_8: 0.1385  loss_dice_8: 0.1936  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:36:54] d2.utils.events INFO:  eta: 2:06:25  iter: 1719  total_loss: 4.403  loss_ce: 0.1009  loss_mask: 0.1349  loss_dice: 0.201  loss_ce_0: 0.1996  loss_mask_0: 0.1377  loss_dice_0: 0.2023  loss_ce_1: 0.1021  loss_mask_1: 0.1349  loss_dice_1: 0.1992  loss_ce_2: 0.09982  loss_mask_2: 0.1374  loss_dice_2: 0.2065  loss_ce_3: 0.09924  loss_mask_3: 0.1364  loss_dice_3: 0.1935  loss_ce_4: 0.105  loss_mask_4: 0.1353  loss_dice_4: 0.2015  loss_ce_5: 0.1108  loss_mask_5: 0.1356  loss_dice_5: 0.1952  loss_ce_6: 0.1042  loss_mask_6: 0.1365  loss_dice_6: 0.1999  loss_ce_7: 0.1058  loss_mask_7: 0.1406  loss_dice_7: 0.1974  loss_ce_8: 0.1039  loss_mask_8: 0.1362  loss_dice_8: 0.2045  time: 0.2254  data_time: 0.0010  lr: 0.0001  max_mem: 1909M
[08/01 16:36:59] d2.utils.events INFO:  eta: 2:06:21  iter: 1739  total_loss: 5.154  loss_ce: 0.1569  loss_mask: 0.1475  loss_dice: 0.2078  loss_ce_0: 0.197  loss_mask_0: 0.1463  loss_dice_0: 0.2018  loss_ce_1: 0.1489  loss_mask_1: 0.1448  loss_dice_1: 0.2045  loss_ce_2: 0.153  loss_mask_2: 0.1479  loss_dice_2: 0.2  loss_ce_3: 0.1529  loss_mask_3: 0.1503  loss_dice_3: 0.2036  loss_ce_4: 0.1512  loss_mask_4: 0.1477  loss_dice_4: 0.203  loss_ce_5: 0.1537  loss_mask_5: 0.1517  loss_dice_5: 0.2016  loss_ce_6: 0.1517  loss_mask_6: 0.1405  loss_dice_6: 0.2065  loss_ce_7: 0.1522  loss_mask_7: 0.1494  loss_dice_7: 0.212  loss_ce_8: 0.1548  loss_mask_8: 0.147  loss_dice_8: 0.199  time: 0.2253  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:37:03] d2.utils.events INFO:  eta: 2:06:26  iter: 1759  total_loss: 4.585  loss_ce: 0.07517  loss_mask: 0.1441  loss_dice: 0.1966  loss_ce_0: 0.1954  loss_mask_0: 0.1531  loss_dice_0: 0.2015  loss_ce_1: 0.07549  loss_mask_1: 0.1418  loss_dice_1: 0.1987  loss_ce_2: 0.0714  loss_mask_2: 0.1454  loss_dice_2: 0.2096  loss_ce_3: 0.07375  loss_mask_3: 0.1426  loss_dice_3: 0.1931  loss_ce_4: 0.07385  loss_mask_4: 0.1427  loss_dice_4: 0.2033  loss_ce_5: 0.08099  loss_mask_5: 0.1445  loss_dice_5: 0.1996  loss_ce_6: 0.0789  loss_mask_6: 0.1428  loss_dice_6: 0.2005  loss_ce_7: 0.07661  loss_mask_7: 0.1425  loss_dice_7: 0.1954  loss_ce_8: 0.07549  loss_mask_8: 0.1391  loss_dice_8: 0.2041  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:37:08] d2.utils.events INFO:  eta: 2:06:17  iter: 1779  total_loss: 4.754  loss_ce: 0.1201  loss_mask: 0.1402  loss_dice: 0.1945  loss_ce_0: 0.1968  loss_mask_0: 0.1421  loss_dice_0: 0.1979  loss_ce_1: 0.1199  loss_mask_1: 0.1405  loss_dice_1: 0.2011  loss_ce_2: 0.1195  loss_mask_2: 0.1463  loss_dice_2: 0.1982  loss_ce_3: 0.1163  loss_mask_3: 0.1405  loss_dice_3: 0.2008  loss_ce_4: 0.1161  loss_mask_4: 0.1375  loss_dice_4: 0.1914  loss_ce_5: 0.12  loss_mask_5: 0.1487  loss_dice_5: 0.195  loss_ce_6: 0.1188  loss_mask_6: 0.1404  loss_dice_6: 0.2001  loss_ce_7: 0.1195  loss_mask_7: 0.1427  loss_dice_7: 0.2039  loss_ce_8: 0.1175  loss_mask_8: 0.1354  loss_dice_8: 0.1978  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:37:12] d2.utils.events INFO:  eta: 2:06:17  iter: 1799  total_loss: 4.83  loss_ce: 0.1386  loss_mask: 0.1425  loss_dice: 0.1977  loss_ce_0: 0.1938  loss_mask_0: 0.1406  loss_dice_0: 0.2012  loss_ce_1: 0.146  loss_mask_1: 0.1449  loss_dice_1: 0.2077  loss_ce_2: 0.1438  loss_mask_2: 0.1401  loss_dice_2: 0.2009  loss_ce_3: 0.1459  loss_mask_3: 0.1384  loss_dice_3: 0.1949  loss_ce_4: 0.1424  loss_mask_4: 0.141  loss_dice_4: 0.204  loss_ce_5: 0.1408  loss_mask_5: 0.1393  loss_dice_5: 0.209  loss_ce_6: 0.1421  loss_mask_6: 0.1422  loss_dice_6: 0.1928  loss_ce_7: 0.1402  loss_mask_7: 0.1441  loss_dice_7: 0.2065  loss_ce_8: 0.1395  loss_mask_8: 0.1367  loss_dice_8: 0.2065  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:37:17] d2.utils.events INFO:  eta: 2:06:19  iter: 1819  total_loss: 4.693  loss_ce: 0.07786  loss_mask: 0.1301  loss_dice: 0.1914  loss_ce_0: 0.1919  loss_mask_0: 0.1338  loss_dice_0: 0.187  loss_ce_1: 0.09517  loss_mask_1: 0.1428  loss_dice_1: 0.1973  loss_ce_2: 0.09111  loss_mask_2: 0.1367  loss_dice_2: 0.1886  loss_ce_3: 0.0787  loss_mask_3: 0.1313  loss_dice_3: 0.1941  loss_ce_4: 0.07664  loss_mask_4: 0.1391  loss_dice_4: 0.1833  loss_ce_5: 0.07653  loss_mask_5: 0.1338  loss_dice_5: 0.1901  loss_ce_6: 0.0795  loss_mask_6: 0.1363  loss_dice_6: 0.1947  loss_ce_7: 0.07484  loss_mask_7: 0.1299  loss_dice_7: 0.1878  loss_ce_8: 0.07931  loss_mask_8: 0.1315  loss_dice_8: 0.1917  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:37:21] d2.utils.events INFO:  eta: 2:06:11  iter: 1839  total_loss: 4.747  loss_ce: 0.1329  loss_mask: 0.1322  loss_dice: 0.2016  loss_ce_0: 0.1901  loss_mask_0: 0.1281  loss_dice_0: 0.2055  loss_ce_1: 0.1421  loss_mask_1: 0.1335  loss_dice_1: 0.2086  loss_ce_2: 0.1438  loss_mask_2: 0.1299  loss_dice_2: 0.2059  loss_ce_3: 0.1423  loss_mask_3: 0.1332  loss_dice_3: 0.2007  loss_ce_4: 0.1428  loss_mask_4: 0.1252  loss_dice_4: 0.2044  loss_ce_5: 0.1433  loss_mask_5: 0.1327  loss_dice_5: 0.1976  loss_ce_6: 0.14  loss_mask_6: 0.1383  loss_dice_6: 0.2048  loss_ce_7: 0.1441  loss_mask_7: 0.123  loss_dice_7: 0.2056  loss_ce_8: 0.1442  loss_mask_8: 0.1317  loss_dice_8: 0.197  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:37:26] d2.utils.events INFO:  eta: 2:06:06  iter: 1859  total_loss: 4.53  loss_ce: 0.08478  loss_mask: 0.1367  loss_dice: 0.2089  loss_ce_0: 0.1876  loss_mask_0: 0.1367  loss_dice_0: 0.203  loss_ce_1: 0.1035  loss_mask_1: 0.1374  loss_dice_1: 0.2061  loss_ce_2: 0.09763  loss_mask_2: 0.1371  loss_dice_2: 0.198  loss_ce_3: 0.09416  loss_mask_3: 0.1366  loss_dice_3: 0.1998  loss_ce_4: 0.09428  loss_mask_4: 0.1417  loss_dice_4: 0.2079  loss_ce_5: 0.08989  loss_mask_5: 0.1398  loss_dice_5: 0.2016  loss_ce_6: 0.08698  loss_mask_6: 0.1389  loss_dice_6: 0.2018  loss_ce_7: 0.08907  loss_mask_7: 0.1359  loss_dice_7: 0.2002  loss_ce_8: 0.0902  loss_mask_8: 0.1414  loss_dice_8: 0.203  time: 0.2254  data_time: 0.0010  lr: 0.0001  max_mem: 1909M
[08/01 16:37:30] d2.utils.events INFO:  eta: 2:06:08  iter: 1879  total_loss: 4.566  loss_ce: 0.1047  loss_mask: 0.1401  loss_dice: 0.1957  loss_ce_0: 0.1852  loss_mask_0: 0.1411  loss_dice_0: 0.1944  loss_ce_1: 0.09893  loss_mask_1: 0.1335  loss_dice_1: 0.1908  loss_ce_2: 0.1039  loss_mask_2: 0.1397  loss_dice_2: 0.1881  loss_ce_3: 0.1001  loss_mask_3: 0.1402  loss_dice_3: 0.1907  loss_ce_4: 0.0996  loss_mask_4: 0.1407  loss_dice_4: 0.1911  loss_ce_5: 0.1043  loss_mask_5: 0.1367  loss_dice_5: 0.1916  loss_ce_6: 0.1028  loss_mask_6: 0.1383  loss_dice_6: 0.1892  loss_ce_7: 0.1025  loss_mask_7: 0.1441  loss_dice_7: 0.1908  loss_ce_8: 0.1074  loss_mask_8: 0.1373  loss_dice_8: 0.188  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:37:35] d2.utils.events INFO:  eta: 2:06:05  iter: 1899  total_loss: 4.355  loss_ce: 0.07612  loss_mask: 0.1357  loss_dice: 0.207  loss_ce_0: 0.1835  loss_mask_0: 0.1391  loss_dice_0: 0.2072  loss_ce_1: 0.08957  loss_mask_1: 0.1441  loss_dice_1: 0.2152  loss_ce_2: 0.08397  loss_mask_2: 0.1289  loss_dice_2: 0.2097  loss_ce_3: 0.08049  loss_mask_3: 0.1336  loss_dice_3: 0.2094  loss_ce_4: 0.08363  loss_mask_4: 0.131  loss_dice_4: 0.2061  loss_ce_5: 0.07619  loss_mask_5: 0.1409  loss_dice_5: 0.2128  loss_ce_6: 0.07681  loss_mask_6: 0.1368  loss_dice_6: 0.2025  loss_ce_7: 0.07482  loss_mask_7: 0.1339  loss_dice_7: 0.2135  loss_ce_8: 0.08307  loss_mask_8: 0.1377  loss_dice_8: 0.2106  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:37:40] d2.utils.events INFO:  eta: 2:05:59  iter: 1919  total_loss: 5.19  loss_ce: 0.1168  loss_mask: 0.1452  loss_dice: 0.1924  loss_ce_0: 0.1847  loss_mask_0: 0.1418  loss_dice_0: 0.1913  loss_ce_1: 0.125  loss_mask_1: 0.1427  loss_dice_1: 0.1958  loss_ce_2: 0.1211  loss_mask_2: 0.1401  loss_dice_2: 0.1934  loss_ce_3: 0.1276  loss_mask_3: 0.1393  loss_dice_3: 0.1942  loss_ce_4: 0.1231  loss_mask_4: 0.1509  loss_dice_4: 0.1972  loss_ce_5: 0.1162  loss_mask_5: 0.1467  loss_dice_5: 0.1958  loss_ce_6: 0.117  loss_mask_6: 0.1479  loss_dice_6: 0.2027  loss_ce_7: 0.1142  loss_mask_7: 0.1579  loss_dice_7: 0.1938  loss_ce_8: 0.1179  loss_mask_8: 0.1411  loss_dice_8: 0.1992  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:37:44] d2.utils.events INFO:  eta: 2:05:52  iter: 1939  total_loss: 4.838  loss_ce: 0.1442  loss_mask: 0.1334  loss_dice: 0.1975  loss_ce_0: 0.1779  loss_mask_0: 0.1408  loss_dice_0: 0.204  loss_ce_1: 0.146  loss_mask_1: 0.1364  loss_dice_1: 0.1984  loss_ce_2: 0.146  loss_mask_2: 0.1357  loss_dice_2: 0.1967  loss_ce_3: 0.1396  loss_mask_3: 0.1295  loss_dice_3: 0.1944  loss_ce_4: 0.1469  loss_mask_4: 0.1396  loss_dice_4: 0.2025  loss_ce_5: 0.1515  loss_mask_5: 0.1376  loss_dice_5: 0.2013  loss_ce_6: 0.1481  loss_mask_6: 0.1326  loss_dice_6: 0.1934  loss_ce_7: 0.1544  loss_mask_7: 0.1332  loss_dice_7: 0.1975  loss_ce_8: 0.1485  loss_mask_8: 0.1347  loss_dice_8: 0.2023  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:37:49] d2.utils.events INFO:  eta: 2:05:51  iter: 1959  total_loss: 4.787  loss_ce: 0.1513  loss_mask: 0.1202  loss_dice: 0.185  loss_ce_0: 0.1759  loss_mask_0: 0.1266  loss_dice_0: 0.1895  loss_ce_1: 0.1534  loss_mask_1: 0.1259  loss_dice_1: 0.1785  loss_ce_2: 0.1524  loss_mask_2: 0.1222  loss_dice_2: 0.1896  loss_ce_3: 0.1489  loss_mask_3: 0.1227  loss_dice_3: 0.1795  loss_ce_4: 0.1502  loss_mask_4: 0.1244  loss_dice_4: 0.1824  loss_ce_5: 0.1514  loss_mask_5: 0.1221  loss_dice_5: 0.183  loss_ce_6: 0.1504  loss_mask_6: 0.1245  loss_dice_6: 0.1832  loss_ce_7: 0.1492  loss_mask_7: 0.1217  loss_dice_7: 0.1797  loss_ce_8: 0.153  loss_mask_8: 0.1214  loss_dice_8: 0.1804  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:37:53] d2.utils.events INFO:  eta: 2:05:46  iter: 1979  total_loss: 4.905  loss_ce: 0.1557  loss_mask: 0.1371  loss_dice: 0.2087  loss_ce_0: 0.1758  loss_mask_0: 0.1311  loss_dice_0: 0.207  loss_ce_1: 0.1544  loss_mask_1: 0.135  loss_dice_1: 0.2011  loss_ce_2: 0.1558  loss_mask_2: 0.1412  loss_dice_2: 0.2152  loss_ce_3: 0.1523  loss_mask_3: 0.1329  loss_dice_3: 0.201  loss_ce_4: 0.1561  loss_mask_4: 0.1281  loss_dice_4: 0.2007  loss_ce_5: 0.1572  loss_mask_5: 0.1305  loss_dice_5: 0.2017  loss_ce_6: 0.1541  loss_mask_6: 0.1347  loss_dice_6: 0.2083  loss_ce_7: 0.1577  loss_mask_7: 0.1315  loss_dice_7: 0.1986  loss_ce_8: 0.1582  loss_mask_8: 0.1316  loss_dice_8: 0.2092  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:37:58] d2.utils.events INFO:  eta: 2:05:42  iter: 1999  total_loss: 4.987  loss_ce: 0.156  loss_mask: 0.1356  loss_dice: 0.2077  loss_ce_0: 0.175  loss_mask_0: 0.1384  loss_dice_0: 0.2061  loss_ce_1: 0.1538  loss_mask_1: 0.1395  loss_dice_1: 0.2042  loss_ce_2: 0.1521  loss_mask_2: 0.1369  loss_dice_2: 0.1987  loss_ce_3: 0.15  loss_mask_3: 0.1389  loss_dice_3: 0.2056  loss_ce_4: 0.1518  loss_mask_4: 0.1418  loss_dice_4: 0.211  loss_ce_5: 0.1519  loss_mask_5: 0.1382  loss_dice_5: 0.2059  loss_ce_6: 0.1503  loss_mask_6: 0.1416  loss_dice_6: 0.2035  loss_ce_7: 0.152  loss_mask_7: 0.1425  loss_dice_7: 0.2047  loss_ce_8: 0.1525  loss_mask_8: 0.1379  loss_dice_8: 0.204  time: 0.2255  data_time: 0.0010  lr: 0.0001  max_mem: 1909M
[08/01 16:38:02] d2.utils.events INFO:  eta: 2:05:47  iter: 2019  total_loss: 5.083  loss_ce: 0.1486  loss_mask: 0.1411  loss_dice: 0.2059  loss_ce_0: 0.1763  loss_mask_0: 0.1406  loss_dice_0: 0.213  loss_ce_1: 0.147  loss_mask_1: 0.1395  loss_dice_1: 0.2071  loss_ce_2: 0.1462  loss_mask_2: 0.1338  loss_dice_2: 0.1975  loss_ce_3: 0.1428  loss_mask_3: 0.1375  loss_dice_3: 0.1987  loss_ce_4: 0.1451  loss_mask_4: 0.1375  loss_dice_4: 0.2011  loss_ce_5: 0.1464  loss_mask_5: 0.1365  loss_dice_5: 0.2012  loss_ce_6: 0.1433  loss_mask_6: 0.1385  loss_dice_6: 0.2108  loss_ce_7: 0.146  loss_mask_7: 0.137  loss_dice_7: 0.2076  loss_ce_8: 0.1469  loss_mask_8: 0.1361  loss_dice_8: 0.2038  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:38:07] d2.utils.events INFO:  eta: 2:05:37  iter: 2039  total_loss: 4.711  loss_ce: 0.1488  loss_mask: 0.1268  loss_dice: 0.184  loss_ce_0: 0.1743  loss_mask_0: 0.1248  loss_dice_0: 0.1889  loss_ce_1: 0.1497  loss_mask_1: 0.126  loss_dice_1: 0.1823  loss_ce_2: 0.1507  loss_mask_2: 0.1265  loss_dice_2: 0.1872  loss_ce_3: 0.1548  loss_mask_3: 0.1326  loss_dice_3: 0.1969  loss_ce_4: 0.1522  loss_mask_4: 0.1321  loss_dice_4: 0.1917  loss_ce_5: 0.1482  loss_mask_5: 0.1292  loss_dice_5: 0.1876  loss_ce_6: 0.1529  loss_mask_6: 0.1309  loss_dice_6: 0.1857  loss_ce_7: 0.15  loss_mask_7: 0.1355  loss_dice_7: 0.1989  loss_ce_8: 0.1474  loss_mask_8: 0.1283  loss_dice_8: 0.1862  time: 0.2255  data_time: 0.0010  lr: 0.0001  max_mem: 1909M
[08/01 16:38:11] d2.utils.events INFO:  eta: 2:05:29  iter: 2059  total_loss: 4.463  loss_ce: 0.08439  loss_mask: 0.1351  loss_dice: 0.1928  loss_ce_0: 0.171  loss_mask_0: 0.1313  loss_dice_0: 0.1883  loss_ce_1: 0.09931  loss_mask_1: 0.1312  loss_dice_1: 0.1855  loss_ce_2: 0.08848  loss_mask_2: 0.1333  loss_dice_2: 0.1854  loss_ce_3: 0.09043  loss_mask_3: 0.1353  loss_dice_3: 0.1949  loss_ce_4: 0.0871  loss_mask_4: 0.135  loss_dice_4: 0.1942  loss_ce_5: 0.08023  loss_mask_5: 0.1328  loss_dice_5: 0.1931  loss_ce_6: 0.0811  loss_mask_6: 0.1345  loss_dice_6: 0.1862  loss_ce_7: 0.07872  loss_mask_7: 0.133  loss_dice_7: 0.1894  loss_ce_8: 0.08217  loss_mask_8: 0.1354  loss_dice_8: 0.1911  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:38:16] d2.utils.events INFO:  eta: 2:05:23  iter: 2079  total_loss: 4.288  loss_ce: 0.1167  loss_mask: 0.1284  loss_dice: 0.1944  loss_ce_0: 0.1718  loss_mask_0: 0.1316  loss_dice_0: 0.198  loss_ce_1: 0.1184  loss_mask_1: 0.1305  loss_dice_1: 0.1962  loss_ce_2: 0.1196  loss_mask_2: 0.1286  loss_dice_2: 0.1937  loss_ce_3: 0.1147  loss_mask_3: 0.1306  loss_dice_3: 0.1964  loss_ce_4: 0.1175  loss_mask_4: 0.1312  loss_dice_4: 0.1955  loss_ce_5: 0.1153  loss_mask_5: 0.1283  loss_dice_5: 0.1979  loss_ce_6: 0.1144  loss_mask_6: 0.1251  loss_dice_6: 0.1913  loss_ce_7: 0.1147  loss_mask_7: 0.13  loss_dice_7: 0.1947  loss_ce_8: 0.1168  loss_mask_8: 0.1286  loss_dice_8: 0.191  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:38:20] d2.utils.events INFO:  eta: 2:05:19  iter: 2099  total_loss: 4.504  loss_ce: 0.1026  loss_mask: 0.1333  loss_dice: 0.1978  loss_ce_0: 0.1708  loss_mask_0: 0.1338  loss_dice_0: 0.1944  loss_ce_1: 0.1072  loss_mask_1: 0.1371  loss_dice_1: 0.1952  loss_ce_2: 0.1082  loss_mask_2: 0.1408  loss_dice_2: 0.1959  loss_ce_3: 0.1032  loss_mask_3: 0.133  loss_dice_3: 0.1932  loss_ce_4: 0.1057  loss_mask_4: 0.1339  loss_dice_4: 0.1917  loss_ce_5: 0.107  loss_mask_5: 0.1324  loss_dice_5: 0.1898  loss_ce_6: 0.1046  loss_mask_6: 0.1321  loss_dice_6: 0.1913  loss_ce_7: 0.1058  loss_mask_7: 0.127  loss_dice_7: 0.1909  loss_ce_8: 0.1041  loss_mask_8: 0.1324  loss_dice_8: 0.1894  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:38:25] d2.utils.events INFO:  eta: 2:05:14  iter: 2119  total_loss: 4.378  loss_ce: 0.08612  loss_mask: 0.1275  loss_dice: 0.189  loss_ce_0: 0.168  loss_mask_0: 0.1346  loss_dice_0: 0.196  loss_ce_1: 0.09468  loss_mask_1: 0.1325  loss_dice_1: 0.1879  loss_ce_2: 0.09496  loss_mask_2: 0.1322  loss_dice_2: 0.1803  loss_ce_3: 0.08875  loss_mask_3: 0.1349  loss_dice_3: 0.1855  loss_ce_4: 0.0922  loss_mask_4: 0.1318  loss_dice_4: 0.1828  loss_ce_5: 0.08887  loss_mask_5: 0.1326  loss_dice_5: 0.1881  loss_ce_6: 0.08838  loss_mask_6: 0.1317  loss_dice_6: 0.183  loss_ce_7: 0.08688  loss_mask_7: 0.1277  loss_dice_7: 0.177  loss_ce_8: 0.08993  loss_mask_8: 0.137  loss_dice_8: 0.1877  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:38:29] d2.utils.events INFO:  eta: 2:05:10  iter: 2139  total_loss: 4.744  loss_ce: 0.1551  loss_mask: 0.1346  loss_dice: 0.1921  loss_ce_0: 0.1733  loss_mask_0: 0.1348  loss_dice_0: 0.1964  loss_ce_1: 0.1641  loss_mask_1: 0.1328  loss_dice_1: 0.1895  loss_ce_2: 0.162  loss_mask_2: 0.1381  loss_dice_2: 0.1979  loss_ce_3: 0.1634  loss_mask_3: 0.1325  loss_dice_3: 0.1958  loss_ce_4: 0.1572  loss_mask_4: 0.1331  loss_dice_4: 0.1951  loss_ce_5: 0.1578  loss_mask_5: 0.1335  loss_dice_5: 0.1892  loss_ce_6: 0.162  loss_mask_6: 0.1317  loss_dice_6: 0.1922  loss_ce_7: 0.1581  loss_mask_7: 0.1325  loss_dice_7: 0.194  loss_ce_8: 0.1555  loss_mask_8: 0.1344  loss_dice_8: 0.19  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:38:34] d2.utils.events INFO:  eta: 2:05:05  iter: 2159  total_loss: 4.684  loss_ce: 0.1528  loss_mask: 0.1381  loss_dice: 0.2049  loss_ce_0: 0.173  loss_mask_0: 0.1369  loss_dice_0: 0.2082  loss_ce_1: 0.1648  loss_mask_1: 0.1346  loss_dice_1: 0.2068  loss_ce_2: 0.1509  loss_mask_2: 0.1372  loss_dice_2: 0.2097  loss_ce_3: 0.1484  loss_mask_3: 0.1343  loss_dice_3: 0.2032  loss_ce_4: 0.1456  loss_mask_4: 0.1383  loss_dice_4: 0.212  loss_ce_5: 0.1529  loss_mask_5: 0.1385  loss_dice_5: 0.2034  loss_ce_6: 0.1497  loss_mask_6: 0.1317  loss_dice_6: 0.2023  loss_ce_7: 0.1537  loss_mask_7: 0.1324  loss_dice_7: 0.2017  loss_ce_8: 0.1549  loss_mask_8: 0.1332  loss_dice_8: 0.198  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:38:38] d2.utils.events INFO:  eta: 2:05:08  iter: 2179  total_loss: 4.712  loss_ce: 0.1358  loss_mask: 0.142  loss_dice: 0.1898  loss_ce_0: 0.1738  loss_mask_0: 0.1462  loss_dice_0: 0.1971  loss_ce_1: 0.1264  loss_mask_1: 0.1383  loss_dice_1: 0.1941  loss_ce_2: 0.1323  loss_mask_2: 0.1345  loss_dice_2: 0.19  loss_ce_3: 0.1313  loss_mask_3: 0.1405  loss_dice_3: 0.198  loss_ce_4: 0.1321  loss_mask_4: 0.1367  loss_dice_4: 0.1897  loss_ce_5: 0.1276  loss_mask_5: 0.1401  loss_dice_5: 0.185  loss_ce_6: 0.1326  loss_mask_6: 0.1378  loss_dice_6: 0.1825  loss_ce_7: 0.1297  loss_mask_7: 0.139  loss_dice_7: 0.1861  loss_ce_8: 0.1295  loss_mask_8: 0.1346  loss_dice_8: 0.1965  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:38:43] d2.utils.events INFO:  eta: 2:05:03  iter: 2199  total_loss: 4.656  loss_ce: 0.1212  loss_mask: 0.1339  loss_dice: 0.2022  loss_ce_0: 0.1685  loss_mask_0: 0.1333  loss_dice_0: 0.2032  loss_ce_1: 0.1266  loss_mask_1: 0.1399  loss_dice_1: 0.2028  loss_ce_2: 0.1254  loss_mask_2: 0.1334  loss_dice_2: 0.2047  loss_ce_3: 0.1275  loss_mask_3: 0.1407  loss_dice_3: 0.1979  loss_ce_4: 0.1289  loss_mask_4: 0.1346  loss_dice_4: 0.2031  loss_ce_5: 0.1265  loss_mask_5: 0.1358  loss_dice_5: 0.2025  loss_ce_6: 0.1206  loss_mask_6: 0.1328  loss_dice_6: 0.1907  loss_ce_7: 0.1221  loss_mask_7: 0.1355  loss_dice_7: 0.1974  loss_ce_8: 0.121  loss_mask_8: 0.1332  loss_dice_8: 0.191  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:38:47] d2.utils.events INFO:  eta: 2:04:52  iter: 2219  total_loss: 4.692  loss_ce: 0.1245  loss_mask: 0.1316  loss_dice: 0.2169  loss_ce_0: 0.1667  loss_mask_0: 0.1329  loss_dice_0: 0.2168  loss_ce_1: 0.1288  loss_mask_1: 0.1345  loss_dice_1: 0.2148  loss_ce_2: 0.133  loss_mask_2: 0.1391  loss_dice_2: 0.2154  loss_ce_3: 0.1149  loss_mask_3: 0.1395  loss_dice_3: 0.223  loss_ce_4: 0.1217  loss_mask_4: 0.1336  loss_dice_4: 0.2172  loss_ce_5: 0.1205  loss_mask_5: 0.1356  loss_dice_5: 0.2138  loss_ce_6: 0.1059  loss_mask_6: 0.1357  loss_dice_6: 0.214  loss_ce_7: 0.1206  loss_mask_7: 0.1321  loss_dice_7: 0.2143  loss_ce_8: 0.1229  loss_mask_8: 0.1324  loss_dice_8: 0.216  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:38:52] d2.utils.events INFO:  eta: 2:04:54  iter: 2239  total_loss: 4.263  loss_ce: 0.06827  loss_mask: 0.138  loss_dice: 0.1921  loss_ce_0: 0.1588  loss_mask_0: 0.1369  loss_dice_0: 0.2041  loss_ce_1: 0.07302  loss_mask_1: 0.1413  loss_dice_1: 0.2015  loss_ce_2: 0.06639  loss_mask_2: 0.1375  loss_dice_2: 0.2024  loss_ce_3: 0.06963  loss_mask_3: 0.1354  loss_dice_3: 0.1981  loss_ce_4: 0.07164  loss_mask_4: 0.1398  loss_dice_4: 0.2022  loss_ce_5: 0.07098  loss_mask_5: 0.1354  loss_dice_5: 0.1942  loss_ce_6: 0.06752  loss_mask_6: 0.1369  loss_dice_6: 0.198  loss_ce_7: 0.06861  loss_mask_7: 0.1378  loss_dice_7: 0.2058  loss_ce_8: 0.06584  loss_mask_8: 0.1403  loss_dice_8: 0.2012  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:38:57] d2.utils.events INFO:  eta: 2:04:55  iter: 2259  total_loss: 4.962  loss_ce: 0.1379  loss_mask: 0.1389  loss_dice: 0.2011  loss_ce_0: 0.1635  loss_mask_0: 0.1349  loss_dice_0: 0.1967  loss_ce_1: 0.1353  loss_mask_1: 0.1397  loss_dice_1: 0.1944  loss_ce_2: 0.1348  loss_mask_2: 0.131  loss_dice_2: 0.1905  loss_ce_3: 0.1416  loss_mask_3: 0.1364  loss_dice_3: 0.1939  loss_ce_4: 0.1404  loss_mask_4: 0.142  loss_dice_4: 0.1967  loss_ce_5: 0.1365  loss_mask_5: 0.1396  loss_dice_5: 0.2032  loss_ce_6: 0.1391  loss_mask_6: 0.1382  loss_dice_6: 0.1993  loss_ce_7: 0.1368  loss_mask_7: 0.1379  loss_dice_7: 0.1921  loss_ce_8: 0.1376  loss_mask_8: 0.1409  loss_dice_8: 0.1939  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:39:01] d2.utils.events INFO:  eta: 2:04:39  iter: 2279  total_loss: 4.502  loss_ce: 0.09567  loss_mask: 0.1444  loss_dice: 0.2004  loss_ce_0: 0.1627  loss_mask_0: 0.1462  loss_dice_0: 0.2006  loss_ce_1: 0.1053  loss_mask_1: 0.1411  loss_dice_1: 0.195  loss_ce_2: 0.09819  loss_mask_2: 0.1389  loss_dice_2: 0.1954  loss_ce_3: 0.09857  loss_mask_3: 0.1431  loss_dice_3: 0.2  loss_ce_4: 0.09823  loss_mask_4: 0.1421  loss_dice_4: 0.2003  loss_ce_5: 0.1038  loss_mask_5: 0.141  loss_dice_5: 0.1987  loss_ce_6: 0.1002  loss_mask_6: 0.1413  loss_dice_6: 0.1996  loss_ce_7: 0.09746  loss_mask_7: 0.1492  loss_dice_7: 0.2002  loss_ce_8: 0.09803  loss_mask_8: 0.147  loss_dice_8: 0.2027  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:39:06] d2.utils.events INFO:  eta: 2:04:41  iter: 2299  total_loss: 4.767  loss_ce: 0.1287  loss_mask: 0.1377  loss_dice: 0.1962  loss_ce_0: 0.1622  loss_mask_0: 0.1473  loss_dice_0: 0.194  loss_ce_1: 0.1331  loss_mask_1: 0.1439  loss_dice_1: 0.1916  loss_ce_2: 0.1287  loss_mask_2: 0.1419  loss_dice_2: 0.1961  loss_ce_3: 0.1365  loss_mask_3: 0.1441  loss_dice_3: 0.198  loss_ce_4: 0.1274  loss_mask_4: 0.1379  loss_dice_4: 0.1942  loss_ce_5: 0.1296  loss_mask_5: 0.1399  loss_dice_5: 0.1919  loss_ce_6: 0.1263  loss_mask_6: 0.1398  loss_dice_6: 0.1926  loss_ce_7: 0.1277  loss_mask_7: 0.1367  loss_dice_7: 0.1864  loss_ce_8: 0.1217  loss_mask_8: 0.1398  loss_dice_8: 0.1934  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:39:10] d2.utils.events INFO:  eta: 2:04:36  iter: 2319  total_loss: 4.541  loss_ce: 0.1296  loss_mask: 0.143  loss_dice: 0.2005  loss_ce_0: 0.1588  loss_mask_0: 0.1309  loss_dice_0: 0.1959  loss_ce_1: 0.1381  loss_mask_1: 0.1377  loss_dice_1: 0.1999  loss_ce_2: 0.135  loss_mask_2: 0.1296  loss_dice_2: 0.1936  loss_ce_3: 0.1408  loss_mask_3: 0.1351  loss_dice_3: 0.1947  loss_ce_4: 0.1343  loss_mask_4: 0.1362  loss_dice_4: 0.1962  loss_ce_5: 0.1309  loss_mask_5: 0.1381  loss_dice_5: 0.2002  loss_ce_6: 0.1334  loss_mask_6: 0.1397  loss_dice_6: 0.2033  loss_ce_7: 0.13  loss_mask_7: 0.1305  loss_dice_7: 0.1962  loss_ce_8: 0.1306  loss_mask_8: 0.1409  loss_dice_8: 0.1929  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:39:15] d2.utils.events INFO:  eta: 2:04:25  iter: 2339  total_loss: 4.637  loss_ce: 0.1176  loss_mask: 0.1386  loss_dice: 0.2004  loss_ce_0: 0.1579  loss_mask_0: 0.1359  loss_dice_0: 0.1982  loss_ce_1: 0.1132  loss_mask_1: 0.1367  loss_dice_1: 0.1981  loss_ce_2: 0.1126  loss_mask_2: 0.1358  loss_dice_2: 0.196  loss_ce_3: 0.1136  loss_mask_3: 0.1379  loss_dice_3: 0.1952  loss_ce_4: 0.1157  loss_mask_4: 0.1426  loss_dice_4: 0.197  loss_ce_5: 0.1157  loss_mask_5: 0.133  loss_dice_5: 0.192  loss_ce_6: 0.1144  loss_mask_6: 0.1413  loss_dice_6: 0.1983  loss_ce_7: 0.1173  loss_mask_7: 0.1339  loss_dice_7: 0.196  loss_ce_8: 0.1181  loss_mask_8: 0.1405  loss_dice_8: 0.1962  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:39:19] d2.utils.events INFO:  eta: 2:04:20  iter: 2359  total_loss: 4.281  loss_ce: 0.07138  loss_mask: 0.1238  loss_dice: 0.1763  loss_ce_0: 0.1569  loss_mask_0: 0.1285  loss_dice_0: 0.18  loss_ce_1: 0.08484  loss_mask_1: 0.1269  loss_dice_1: 0.1784  loss_ce_2: 0.073  loss_mask_2: 0.1221  loss_dice_2: 0.1754  loss_ce_3: 0.06751  loss_mask_3: 0.1267  loss_dice_3: 0.1761  loss_ce_4: 0.07211  loss_mask_4: 0.1249  loss_dice_4: 0.1789  loss_ce_5: 0.06697  loss_mask_5: 0.1282  loss_dice_5: 0.1809  loss_ce_6: 0.0649  loss_mask_6: 0.1234  loss_dice_6: 0.182  loss_ce_7: 0.06544  loss_mask_7: 0.1252  loss_dice_7: 0.1775  loss_ce_8: 0.07114  loss_mask_8: 0.1278  loss_dice_8: 0.1783  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:39:24] d2.utils.events INFO:  eta: 2:04:17  iter: 2379  total_loss: 5.195  loss_ce: 0.1635  loss_mask: 0.1382  loss_dice: 0.203  loss_ce_0: 0.1572  loss_mask_0: 0.1372  loss_dice_0: 0.2049  loss_ce_1: 0.1768  loss_mask_1: 0.138  loss_dice_1: 0.2066  loss_ce_2: 0.1669  loss_mask_2: 0.143  loss_dice_2: 0.201  loss_ce_3: 0.1729  loss_mask_3: 0.1424  loss_dice_3: 0.2024  loss_ce_4: 0.17  loss_mask_4: 0.1449  loss_dice_4: 0.1994  loss_ce_5: 0.1632  loss_mask_5: 0.1412  loss_dice_5: 0.2022  loss_ce_6: 0.1724  loss_mask_6: 0.1378  loss_dice_6: 0.2058  loss_ce_7: 0.1637  loss_mask_7: 0.1457  loss_dice_7: 0.2017  loss_ce_8: 0.1619  loss_mask_8: 0.1405  loss_dice_8: 0.2033  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:39:28] d2.utils.events INFO:  eta: 2:04:14  iter: 2399  total_loss: 4.73  loss_ce: 0.1584  loss_mask: 0.1303  loss_dice: 0.1941  loss_ce_0: 0.1565  loss_mask_0: 0.1328  loss_dice_0: 0.1908  loss_ce_1: 0.1396  loss_mask_1: 0.1321  loss_dice_1: 0.1915  loss_ce_2: 0.1535  loss_mask_2: 0.1315  loss_dice_2: 0.1928  loss_ce_3: 0.1575  loss_mask_3: 0.1269  loss_dice_3: 0.1866  loss_ce_4: 0.1535  loss_mask_4: 0.1314  loss_dice_4: 0.1884  loss_ce_5: 0.1544  loss_mask_5: 0.1284  loss_dice_5: 0.186  loss_ce_6: 0.1566  loss_mask_6: 0.1279  loss_dice_6: 0.1917  loss_ce_7: 0.1563  loss_mask_7: 0.1313  loss_dice_7: 0.1877  loss_ce_8: 0.1548  loss_mask_8: 0.1301  loss_dice_8: 0.1876  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:39:33] d2.utils.events INFO:  eta: 2:04:07  iter: 2419  total_loss: 4.676  loss_ce: 0.1419  loss_mask: 0.1252  loss_dice: 0.1978  loss_ce_0: 0.1556  loss_mask_0: 0.1278  loss_dice_0: 0.1984  loss_ce_1: 0.1386  loss_mask_1: 0.1293  loss_dice_1: 0.1981  loss_ce_2: 0.1413  loss_mask_2: 0.1328  loss_dice_2: 0.1916  loss_ce_3: 0.1365  loss_mask_3: 0.1294  loss_dice_3: 0.1895  loss_ce_4: 0.1414  loss_mask_4: 0.1258  loss_dice_4: 0.1938  loss_ce_5: 0.14  loss_mask_5: 0.1304  loss_dice_5: 0.1943  loss_ce_6: 0.1381  loss_mask_6: 0.1329  loss_dice_6: 0.1938  loss_ce_7: 0.1417  loss_mask_7: 0.1333  loss_dice_7: 0.206  loss_ce_8: 0.1406  loss_mask_8: 0.1342  loss_dice_8: 0.2005  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:39:37] d2.utils.events INFO:  eta: 2:04:01  iter: 2439  total_loss: 4.699  loss_ce: 0.1428  loss_mask: 0.1328  loss_dice: 0.1936  loss_ce_0: 0.1539  loss_mask_0: 0.1284  loss_dice_0: 0.1934  loss_ce_1: 0.1526  loss_mask_1: 0.133  loss_dice_1: 0.193  loss_ce_2: 0.1519  loss_mask_2: 0.1296  loss_dice_2: 0.1948  loss_ce_3: 0.1355  loss_mask_3: 0.1333  loss_dice_3: 0.1893  loss_ce_4: 0.1512  loss_mask_4: 0.1329  loss_dice_4: 0.1944  loss_ce_5: 0.1526  loss_mask_5: 0.1318  loss_dice_5: 0.194  loss_ce_6: 0.141  loss_mask_6: 0.1296  loss_dice_6: 0.2003  loss_ce_7: 0.1546  loss_mask_7: 0.1303  loss_dice_7: 0.1945  loss_ce_8: 0.1532  loss_mask_8: 0.1257  loss_dice_8: 0.189  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:39:42] d2.utils.events INFO:  eta: 2:03:58  iter: 2459  total_loss: 4.435  loss_ce: 0.07969  loss_mask: 0.1393  loss_dice: 0.1985  loss_ce_0: 0.1514  loss_mask_0: 0.1306  loss_dice_0: 0.1959  loss_ce_1: 0.09438  loss_mask_1: 0.1357  loss_dice_1: 0.1925  loss_ce_2: 0.08443  loss_mask_2: 0.1364  loss_dice_2: 0.1892  loss_ce_3: 0.07916  loss_mask_3: 0.1327  loss_dice_3: 0.1925  loss_ce_4: 0.08034  loss_mask_4: 0.1364  loss_dice_4: 0.1938  loss_ce_5: 0.08017  loss_mask_5: 0.1415  loss_dice_5: 0.1969  loss_ce_6: 0.08168  loss_mask_6: 0.136  loss_dice_6: 0.194  loss_ce_7: 0.08115  loss_mask_7: 0.1383  loss_dice_7: 0.1916  loss_ce_8: 0.08193  loss_mask_8: 0.1384  loss_dice_8: 0.1956  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:39:46] d2.utils.events INFO:  eta: 2:03:49  iter: 2479  total_loss: 4.711  loss_ce: 0.1282  loss_mask: 0.1416  loss_dice: 0.1994  loss_ce_0: 0.1532  loss_mask_0: 0.142  loss_dice_0: 0.2056  loss_ce_1: 0.1146  loss_mask_1: 0.1397  loss_dice_1: 0.198  loss_ce_2: 0.123  loss_mask_2: 0.1359  loss_dice_2: 0.1965  loss_ce_3: 0.1163  loss_mask_3: 0.1396  loss_dice_3: 0.1922  loss_ce_4: 0.1215  loss_mask_4: 0.1347  loss_dice_4: 0.207  loss_ce_5: 0.1259  loss_mask_5: 0.1417  loss_dice_5: 0.2032  loss_ce_6: 0.1336  loss_mask_6: 0.1417  loss_dice_6: 0.1989  loss_ce_7: 0.127  loss_mask_7: 0.1405  loss_dice_7: 0.1999  loss_ce_8: 0.1247  loss_mask_8: 0.1361  loss_dice_8: 0.1995  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:39:51] d2.utils.events INFO:  eta: 2:03:34  iter: 2499  total_loss: 4.347  loss_ce: 0.06941  loss_mask: 0.1314  loss_dice: 0.188  loss_ce_0: 0.1509  loss_mask_0: 0.1298  loss_dice_0: 0.1876  loss_ce_1: 0.07446  loss_mask_1: 0.1336  loss_dice_1: 0.1854  loss_ce_2: 0.07312  loss_mask_2: 0.1282  loss_dice_2: 0.189  loss_ce_3: 0.08102  loss_mask_3: 0.1326  loss_dice_3: 0.1901  loss_ce_4: 0.07037  loss_mask_4: 0.1305  loss_dice_4: 0.1801  loss_ce_5: 0.06885  loss_mask_5: 0.1324  loss_dice_5: 0.1909  loss_ce_6: 0.0706  loss_mask_6: 0.1295  loss_dice_6: 0.1848  loss_ce_7: 0.07141  loss_mask_7: 0.1301  loss_dice_7: 0.1862  loss_ce_8: 0.06817  loss_mask_8: 0.1309  loss_dice_8: 0.1869  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:39:55] d2.utils.events INFO:  eta: 2:03:27  iter: 2519  total_loss: 4.608  loss_ce: 0.1313  loss_mask: 0.1281  loss_dice: 0.1851  loss_ce_0: 0.1513  loss_mask_0: 0.1286  loss_dice_0: 0.1835  loss_ce_1: 0.1274  loss_mask_1: 0.1206  loss_dice_1: 0.1815  loss_ce_2: 0.1211  loss_mask_2: 0.1268  loss_dice_2: 0.1823  loss_ce_3: 0.1378  loss_mask_3: 0.1253  loss_dice_3: 0.1798  loss_ce_4: 0.1204  loss_mask_4: 0.1274  loss_dice_4: 0.19  loss_ce_5: 0.1238  loss_mask_5: 0.1272  loss_dice_5: 0.1853  loss_ce_6: 0.131  loss_mask_6: 0.1234  loss_dice_6: 0.1804  loss_ce_7: 0.1172  loss_mask_7: 0.1259  loss_dice_7: 0.1812  loss_ce_8: 0.1167  loss_mask_8: 0.1306  loss_dice_8: 0.1826  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:40:00] d2.utils.events INFO:  eta: 2:03:25  iter: 2539  total_loss: 4.774  loss_ce: 0.1561  loss_mask: 0.1294  loss_dice: 0.1896  loss_ce_0: 0.1543  loss_mask_0: 0.1256  loss_dice_0: 0.1932  loss_ce_1: 0.1586  loss_mask_1: 0.1262  loss_dice_1: 0.1868  loss_ce_2: 0.1654  loss_mask_2: 0.1297  loss_dice_2: 0.1907  loss_ce_3: 0.1449  loss_mask_3: 0.1297  loss_dice_3: 0.1856  loss_ce_4: 0.1609  loss_mask_4: 0.1293  loss_dice_4: 0.1898  loss_ce_5: 0.1647  loss_mask_5: 0.1275  loss_dice_5: 0.1865  loss_ce_6: 0.1523  loss_mask_6: 0.1305  loss_dice_6: 0.1874  loss_ce_7: 0.169  loss_mask_7: 0.1303  loss_dice_7: 0.1848  loss_ce_8: 0.1657  loss_mask_8: 0.1296  loss_dice_8: 0.1871  time: 0.2254  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:40:04] d2.utils.events INFO:  eta: 2:03:21  iter: 2559  total_loss: 4.963  loss_ce: 0.1468  loss_mask: 0.137  loss_dice: 0.2033  loss_ce_0: 0.1515  loss_mask_0: 0.1362  loss_dice_0: 0.2078  loss_ce_1: 0.1564  loss_mask_1: 0.1366  loss_dice_1: 0.2015  loss_ce_2: 0.1617  loss_mask_2: 0.1385  loss_dice_2: 0.2033  loss_ce_3: 0.1356  loss_mask_3: 0.1408  loss_dice_3: 0.2023  loss_ce_4: 0.1576  loss_mask_4: 0.1392  loss_dice_4: 0.2005  loss_ce_5: 0.1662  loss_mask_5: 0.1397  loss_dice_5: 0.2033  loss_ce_6: 0.1439  loss_mask_6: 0.1366  loss_dice_6: 0.1979  loss_ce_7: 0.165  loss_mask_7: 0.1369  loss_dice_7: 0.2016  loss_ce_8: 0.1653  loss_mask_8: 0.1357  loss_dice_8: 0.2016  time: 0.2254  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:40:09] d2.utils.events INFO:  eta: 2:03:16  iter: 2579  total_loss: 4.515  loss_ce: 0.1024  loss_mask: 0.1293  loss_dice: 0.1906  loss_ce_0: 0.1497  loss_mask_0: 0.1276  loss_dice_0: 0.1896  loss_ce_1: 0.1019  loss_mask_1: 0.1279  loss_dice_1: 0.1913  loss_ce_2: 0.1056  loss_mask_2: 0.1293  loss_dice_2: 0.1868  loss_ce_3: 0.08972  loss_mask_3: 0.1243  loss_dice_3: 0.1849  loss_ce_4: 0.1025  loss_mask_4: 0.1303  loss_dice_4: 0.1939  loss_ce_5: 0.1072  loss_mask_5: 0.126  loss_dice_5: 0.1915  loss_ce_6: 0.103  loss_mask_6: 0.1285  loss_dice_6: 0.1917  loss_ce_7: 0.1074  loss_mask_7: 0.1256  loss_dice_7: 0.1925  loss_ce_8: 0.1077  loss_mask_8: 0.1258  loss_dice_8: 0.1878  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:40:13] d2.utils.events INFO:  eta: 2:03:12  iter: 2599  total_loss: 4.402  loss_ce: 0.07928  loss_mask: 0.1269  loss_dice: 0.1817  loss_ce_0: 0.1487  loss_mask_0: 0.1288  loss_dice_0: 0.1841  loss_ce_1: 0.09139  loss_mask_1: 0.1319  loss_dice_1: 0.1841  loss_ce_2: 0.09597  loss_mask_2: 0.1284  loss_dice_2: 0.1863  loss_ce_3: 0.07674  loss_mask_3: 0.1295  loss_dice_3: 0.1824  loss_ce_4: 0.08968  loss_mask_4: 0.1284  loss_dice_4: 0.1825  loss_ce_5: 0.09693  loss_mask_5: 0.1256  loss_dice_5: 0.1875  loss_ce_6: 0.08602  loss_mask_6: 0.1305  loss_dice_6: 0.1898  loss_ce_7: 0.08912  loss_mask_7: 0.1318  loss_dice_7: 0.1855  loss_ce_8: 0.09211  loss_mask_8: 0.1288  loss_dice_8: 0.1861  time: 0.2254  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:40:18] d2.utils.events INFO:  eta: 2:02:59  iter: 2619  total_loss: 4.948  loss_ce: 0.1016  loss_mask: 0.1314  loss_dice: 0.1827  loss_ce_0: 0.1487  loss_mask_0: 0.1271  loss_dice_0: 0.1893  loss_ce_1: 0.1155  loss_mask_1: 0.1294  loss_dice_1: 0.1904  loss_ce_2: 0.1173  loss_mask_2: 0.1305  loss_dice_2: 0.1872  loss_ce_3: 0.1003  loss_mask_3: 0.1319  loss_dice_3: 0.1813  loss_ce_4: 0.1072  loss_mask_4: 0.1296  loss_dice_4: 0.1843  loss_ce_5: 0.1189  loss_mask_5: 0.133  loss_dice_5: 0.1889  loss_ce_6: 0.1046  loss_mask_6: 0.1306  loss_dice_6: 0.1873  loss_ce_7: 0.1144  loss_mask_7: 0.13  loss_dice_7: 0.1868  loss_ce_8: 0.1147  loss_mask_8: 0.1299  loss_dice_8: 0.1892  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:40:23] d2.utils.events INFO:  eta: 2:02:59  iter: 2639  total_loss: 4.493  loss_ce: 0.134  loss_mask: 0.1299  loss_dice: 0.1871  loss_ce_0: 0.1468  loss_mask_0: 0.1212  loss_dice_0: 0.1734  loss_ce_1: 0.1395  loss_mask_1: 0.1302  loss_dice_1: 0.1882  loss_ce_2: 0.1357  loss_mask_2: 0.1263  loss_dice_2: 0.1835  loss_ce_3: 0.1272  loss_mask_3: 0.1254  loss_dice_3: 0.1841  loss_ce_4: 0.1389  loss_mask_4: 0.1256  loss_dice_4: 0.1884  loss_ce_5: 0.1354  loss_mask_5: 0.1219  loss_dice_5: 0.1874  loss_ce_6: 0.1332  loss_mask_6: 0.129  loss_dice_6: 0.1872  loss_ce_7: 0.1385  loss_mask_7: 0.1252  loss_dice_7: 0.1887  loss_ce_8: 0.1341  loss_mask_8: 0.1317  loss_dice_8: 0.1851  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:40:27] d2.utils.events INFO:  eta: 2:02:50  iter: 2659  total_loss: 4.737  loss_ce: 0.1063  loss_mask: 0.1387  loss_dice: 0.1971  loss_ce_0: 0.1508  loss_mask_0: 0.1378  loss_dice_0: 0.2037  loss_ce_1: 0.1284  loss_mask_1: 0.1421  loss_dice_1: 0.2065  loss_ce_2: 0.1388  loss_mask_2: 0.1395  loss_dice_2: 0.2073  loss_ce_3: 0.1176  loss_mask_3: 0.1423  loss_dice_3: 0.2095  loss_ce_4: 0.1328  loss_mask_4: 0.1402  loss_dice_4: 0.1959  loss_ce_5: 0.1417  loss_mask_5: 0.138  loss_dice_5: 0.1996  loss_ce_6: 0.09493  loss_mask_6: 0.1363  loss_dice_6: 0.1992  loss_ce_7: 0.1371  loss_mask_7: 0.1387  loss_dice_7: 0.1977  loss_ce_8: 0.142  loss_mask_8: 0.1353  loss_dice_8: 0.2017  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:40:32] d2.utils.events INFO:  eta: 2:02:50  iter: 2679  total_loss: 4.791  loss_ce: 0.1525  loss_mask: 0.1354  loss_dice: 0.1949  loss_ce_0: 0.1506  loss_mask_0: 0.1341  loss_dice_0: 0.1983  loss_ce_1: 0.1526  loss_mask_1: 0.1317  loss_dice_1: 0.1956  loss_ce_2: 0.1473  loss_mask_2: 0.1296  loss_dice_2: 0.1907  loss_ce_3: 0.1524  loss_mask_3: 0.1298  loss_dice_3: 0.1947  loss_ce_4: 0.1555  loss_mask_4: 0.1355  loss_dice_4: 0.1915  loss_ce_5: 0.1495  loss_mask_5: 0.1377  loss_dice_5: 0.1949  loss_ce_6: 0.1469  loss_mask_6: 0.1344  loss_dice_6: 0.1956  loss_ce_7: 0.1498  loss_mask_7: 0.1312  loss_dice_7: 0.1932  loss_ce_8: 0.1472  loss_mask_8: 0.1331  loss_dice_8: 0.2006  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:40:36] d2.utils.events INFO:  eta: 2:02:45  iter: 2699  total_loss: 4.681  loss_ce: 0.1557  loss_mask: 0.1279  loss_dice: 0.1793  loss_ce_0: 0.1516  loss_mask_0: 0.1301  loss_dice_0: 0.1876  loss_ce_1: 0.1581  loss_mask_1: 0.1289  loss_dice_1: 0.1872  loss_ce_2: 0.1625  loss_mask_2: 0.1297  loss_dice_2: 0.1787  loss_ce_3: 0.1515  loss_mask_3: 0.1329  loss_dice_3: 0.185  loss_ce_4: 0.1652  loss_mask_4: 0.1321  loss_dice_4: 0.1869  loss_ce_5: 0.1637  loss_mask_5: 0.1291  loss_dice_5: 0.1852  loss_ce_6: 0.1537  loss_mask_6: 0.1273  loss_dice_6: 0.1806  loss_ce_7: 0.1679  loss_mask_7: 0.1259  loss_dice_7: 0.1814  loss_ce_8: 0.165  loss_mask_8: 0.129  loss_dice_8: 0.185  time: 0.2255  data_time: 0.0010  lr: 0.0001  max_mem: 1909M
[08/01 16:40:41] d2.utils.events INFO:  eta: 2:02:36  iter: 2719  total_loss: 4.695  loss_ce: 0.1215  loss_mask: 0.1306  loss_dice: 0.1898  loss_ce_0: 0.1497  loss_mask_0: 0.1251  loss_dice_0: 0.1836  loss_ce_1: 0.1321  loss_mask_1: 0.1281  loss_dice_1: 0.1907  loss_ce_2: 0.1337  loss_mask_2: 0.1357  loss_dice_2: 0.1916  loss_ce_3: 0.1303  loss_mask_3: 0.1294  loss_dice_3: 0.1873  loss_ce_4: 0.1347  loss_mask_4: 0.1333  loss_dice_4: 0.1913  loss_ce_5: 0.1369  loss_mask_5: 0.1262  loss_dice_5: 0.1888  loss_ce_6: 0.1156  loss_mask_6: 0.1246  loss_dice_6: 0.1879  loss_ce_7: 0.1386  loss_mask_7: 0.1291  loss_dice_7: 0.1928  loss_ce_8: 0.1388  loss_mask_8: 0.127  loss_dice_8: 0.1871  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:40:45] d2.utils.events INFO:  eta: 2:02:26  iter: 2739  total_loss: 4.228  loss_ce: 0.1127  loss_mask: 0.1246  loss_dice: 0.1822  loss_ce_0: 0.1454  loss_mask_0: 0.1286  loss_dice_0: 0.1873  loss_ce_1: 0.1212  loss_mask_1: 0.1264  loss_dice_1: 0.1778  loss_ce_2: 0.1199  loss_mask_2: 0.1258  loss_dice_2: 0.1872  loss_ce_3: 0.11  loss_mask_3: 0.1283  loss_dice_3: 0.1857  loss_ce_4: 0.1213  loss_mask_4: 0.1299  loss_dice_4: 0.1879  loss_ce_5: 0.1207  loss_mask_5: 0.1302  loss_dice_5: 0.1894  loss_ce_6: 0.112  loss_mask_6: 0.1284  loss_dice_6: 0.1855  loss_ce_7: 0.1229  loss_mask_7: 0.1292  loss_dice_7: 0.1832  loss_ce_8: 0.1217  loss_mask_8: 0.1293  loss_dice_8: 0.1861  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:40:50] d2.utils.events INFO:  eta: 2:02:16  iter: 2759  total_loss: 4.363  loss_ce: 0.1043  loss_mask: 0.1249  loss_dice: 0.1821  loss_ce_0: 0.148  loss_mask_0: 0.1251  loss_dice_0: 0.1826  loss_ce_1: 0.08711  loss_mask_1: 0.1257  loss_dice_1: 0.1819  loss_ce_2: 0.08866  loss_mask_2: 0.1246  loss_dice_2: 0.1857  loss_ce_3: 0.1063  loss_mask_3: 0.127  loss_dice_3: 0.182  loss_ce_4: 0.09327  loss_mask_4: 0.1262  loss_dice_4: 0.1776  loss_ce_5: 0.09262  loss_mask_5: 0.1298  loss_dice_5: 0.1814  loss_ce_6: 0.1021  loss_mask_6: 0.1263  loss_dice_6: 0.1825  loss_ce_7: 0.09359  loss_mask_7: 0.1284  loss_dice_7: 0.1798  loss_ce_8: 0.09222  loss_mask_8: 0.1287  loss_dice_8: 0.1794  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:40:54] d2.utils.events INFO:  eta: 2:02:06  iter: 2779  total_loss: 4.723  loss_ce: 0.138  loss_mask: 0.1383  loss_dice: 0.1941  loss_ce_0: 0.1423  loss_mask_0: 0.1345  loss_dice_0: 0.1834  loss_ce_1: 0.1708  loss_mask_1: 0.1395  loss_dice_1: 0.1948  loss_ce_2: 0.1612  loss_mask_2: 0.1371  loss_dice_2: 0.2  loss_ce_3: 0.1371  loss_mask_3: 0.1371  loss_dice_3: 0.1916  loss_ce_4: 0.1534  loss_mask_4: 0.1423  loss_dice_4: 0.1983  loss_ce_5: 0.1587  loss_mask_5: 0.1413  loss_dice_5: 0.1991  loss_ce_6: 0.15  loss_mask_6: 0.1298  loss_dice_6: 0.1924  loss_ce_7: 0.1579  loss_mask_7: 0.1419  loss_dice_7: 0.1953  loss_ce_8: 0.1587  loss_mask_8: 0.1408  loss_dice_8: 0.193  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:40:59] d2.utils.events INFO:  eta: 2:02:00  iter: 2799  total_loss: 4.027  loss_ce: 0.09668  loss_mask: 0.1271  loss_dice: 0.1853  loss_ce_0: 0.1477  loss_mask_0: 0.1261  loss_dice_0: 0.1739  loss_ce_1: 0.1226  loss_mask_1: 0.1254  loss_dice_1: 0.1833  loss_ce_2: 0.111  loss_mask_2: 0.1278  loss_dice_2: 0.1812  loss_ce_3: 0.08919  loss_mask_3: 0.1269  loss_dice_3: 0.1864  loss_ce_4: 0.1122  loss_mask_4: 0.1272  loss_dice_4: 0.1796  loss_ce_5: 0.1076  loss_mask_5: 0.1221  loss_dice_5: 0.172  loss_ce_6: 0.08163  loss_mask_6: 0.1264  loss_dice_6: 0.1797  loss_ce_7: 0.1057  loss_mask_7: 0.1257  loss_dice_7: 0.1793  loss_ce_8: 0.1036  loss_mask_8: 0.1281  loss_dice_8: 0.181  time: 0.2255  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:41:03] d2.utils.events INFO:  eta: 2:01:53  iter: 2819  total_loss: 4.223  loss_ce: 0.07584  loss_mask: 0.1276  loss_dice: 0.1806  loss_ce_0: 0.148  loss_mask_0: 0.1286  loss_dice_0: 0.1807  loss_ce_1: 0.0982  loss_mask_1: 0.1282  loss_dice_1: 0.177  loss_ce_2: 0.1026  loss_mask_2: 0.1277  loss_dice_2: 0.1797  loss_ce_3: 0.06693  loss_mask_3: 0.1349  loss_dice_3: 0.1811  loss_ce_4: 0.09727  loss_mask_4: 0.1305  loss_dice_4: 0.1789  loss_ce_5: 0.1074  loss_mask_5: 0.1286  loss_dice_5: 0.1824  loss_ce_6: 0.07505  loss_mask_6: 0.1284  loss_dice_6: 0.1782  loss_ce_7: 0.1096  loss_mask_7: 0.1308  loss_dice_7: 0.1803  loss_ce_8: 0.1039  loss_mask_8: 0.1262  loss_dice_8: 0.1728  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:41:08] d2.utils.events INFO:  eta: 2:01:51  iter: 2839  total_loss: 4.607  loss_ce: 0.09235  loss_mask: 0.1281  loss_dice: 0.1947  loss_ce_0: 0.146  loss_mask_0: 0.1261  loss_dice_0: 0.1894  loss_ce_1: 0.17  loss_mask_1: 0.1343  loss_dice_1: 0.19  loss_ce_2: 0.1641  loss_mask_2: 0.1281  loss_dice_2: 0.1909  loss_ce_3: 0.09106  loss_mask_3: 0.126  loss_dice_3: 0.1904  loss_ce_4: 0.1659  loss_mask_4: 0.133  loss_dice_4: 0.192  loss_ce_5: 0.1634  loss_mask_5: 0.1332  loss_dice_5: 0.1929  loss_ce_6: 0.1058  loss_mask_6: 0.1293  loss_dice_6: 0.1941  loss_ce_7: 0.162  loss_mask_7: 0.1312  loss_dice_7: 0.1922  loss_ce_8: 0.1633  loss_mask_8: 0.1257  loss_dice_8: 0.1904  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:41:12] d2.utils.events INFO:  eta: 2:01:48  iter: 2859  total_loss: 4.546  loss_ce: 0.08569  loss_mask: 0.1265  loss_dice: 0.1873  loss_ce_0: 0.1462  loss_mask_0: 0.1302  loss_dice_0: 0.1835  loss_ce_1: 0.164  loss_mask_1: 0.1291  loss_dice_1: 0.1872  loss_ce_2: 0.1695  loss_mask_2: 0.1306  loss_dice_2: 0.188  loss_ce_3: 0.07824  loss_mask_3: 0.1285  loss_dice_3: 0.1938  loss_ce_4: 0.1314  loss_mask_4: 0.1286  loss_dice_4: 0.1912  loss_ce_5: 0.1611  loss_mask_5: 0.1309  loss_dice_5: 0.196  loss_ce_6: 0.07803  loss_mask_6: 0.1336  loss_dice_6: 0.1899  loss_ce_7: 0.1559  loss_mask_7: 0.1252  loss_dice_7: 0.1865  loss_ce_8: 0.1629  loss_mask_8: 0.1289  loss_dice_8: 0.1857  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:41:17] d2.utils.events INFO:  eta: 2:01:47  iter: 2879  total_loss: 4.816  loss_ce: 0.07405  loss_mask: 0.1407  loss_dice: 0.1948  loss_ce_0: 0.145  loss_mask_0: 0.1385  loss_dice_0: 0.1927  loss_ce_1: 0.1606  loss_mask_1: 0.1418  loss_dice_1: 0.1984  loss_ce_2: 0.1653  loss_mask_2: 0.1399  loss_dice_2: 0.1949  loss_ce_3: 0.07723  loss_mask_3: 0.142  loss_dice_3: 0.2007  loss_ce_4: 0.1598  loss_mask_4: 0.1448  loss_dice_4: 0.1983  loss_ce_5: 0.1621  loss_mask_5: 0.1444  loss_dice_5: 0.1978  loss_ce_6: 0.07874  loss_mask_6: 0.1426  loss_dice_6: 0.1981  loss_ce_7: 0.1623  loss_mask_7: 0.1463  loss_dice_7: 0.2001  loss_ce_8: 0.1612  loss_mask_8: 0.1403  loss_dice_8: 0.1962  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:41:21] d2.utils.events INFO:  eta: 2:01:37  iter: 2899  total_loss: 4.304  loss_ce: 0.06949  loss_mask: 0.1481  loss_dice: 0.1983  loss_ce_0: 0.1451  loss_mask_0: 0.1402  loss_dice_0: 0.1994  loss_ce_1: 0.124  loss_mask_1: 0.144  loss_dice_1: 0.2043  loss_ce_2: 0.0973  loss_mask_2: 0.1429  loss_dice_2: 0.2065  loss_ce_3: 0.06835  loss_mask_3: 0.1414  loss_dice_3: 0.2022  loss_ce_4: 0.1027  loss_mask_4: 0.1372  loss_dice_4: 0.2008  loss_ce_5: 0.1058  loss_mask_5: 0.1452  loss_dice_5: 0.2055  loss_ce_6: 0.09002  loss_mask_6: 0.1394  loss_dice_6: 0.2009  loss_ce_7: 0.1128  loss_mask_7: 0.1405  loss_dice_7: 0.2052  loss_ce_8: 0.1026  loss_mask_8: 0.1385  loss_dice_8: 0.2029  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:41:26] d2.utils.events INFO:  eta: 2:01:30  iter: 2919  total_loss: 4.549  loss_ce: 0.1335  loss_mask: 0.1302  loss_dice: 0.1805  loss_ce_0: 0.1513  loss_mask_0: 0.1255  loss_dice_0: 0.1842  loss_ce_1: 0.1792  loss_mask_1: 0.1297  loss_dice_1: 0.1797  loss_ce_2: 0.1775  loss_mask_2: 0.1299  loss_dice_2: 0.1808  loss_ce_3: 0.1263  loss_mask_3: 0.1305  loss_dice_3: 0.1804  loss_ce_4: 0.1579  loss_mask_4: 0.1289  loss_dice_4: 0.18  loss_ce_5: 0.177  loss_mask_5: 0.1297  loss_dice_5: 0.1812  loss_ce_6: 0.1349  loss_mask_6: 0.1254  loss_dice_6: 0.1795  loss_ce_7: 0.1722  loss_mask_7: 0.1293  loss_dice_7: 0.1766  loss_ce_8: 0.1744  loss_mask_8: 0.1297  loss_dice_8: 0.1838  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:41:30] d2.utils.events INFO:  eta: 2:01:26  iter: 2939  total_loss: 4.293  loss_ce: 0.09855  loss_mask: 0.1249  loss_dice: 0.1669  loss_ce_0: 0.1492  loss_mask_0: 0.1283  loss_dice_0: 0.1741  loss_ce_1: 0.1517  loss_mask_1: 0.1326  loss_dice_1: 0.1729  loss_ce_2: 0.1556  loss_mask_2: 0.1306  loss_dice_2: 0.1739  loss_ce_3: 0.09445  loss_mask_3: 0.1291  loss_dice_3: 0.1714  loss_ce_4: 0.1449  loss_mask_4: 0.1286  loss_dice_4: 0.1713  loss_ce_5: 0.1571  loss_mask_5: 0.1216  loss_dice_5: 0.1716  loss_ce_6: 0.104  loss_mask_6: 0.125  loss_dice_6: 0.1709  loss_ce_7: 0.1518  loss_mask_7: 0.1258  loss_dice_7: 0.1734  loss_ce_8: 0.1497  loss_mask_8: 0.1268  loss_dice_8: 0.1761  time: 0.2254  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:41:35] d2.utils.events INFO:  eta: 2:01:18  iter: 2959  total_loss: 4.639  loss_ce: 0.06425  loss_mask: 0.1304  loss_dice: 0.188  loss_ce_0: 0.1482  loss_mask_0: 0.1278  loss_dice_0: 0.1856  loss_ce_1: 0.1594  loss_mask_1: 0.1267  loss_dice_1: 0.1882  loss_ce_2: 0.1576  loss_mask_2: 0.1251  loss_dice_2: 0.1879  loss_ce_3: 0.07152  loss_mask_3: 0.1276  loss_dice_3: 0.1875  loss_ce_4: 0.1472  loss_mask_4: 0.1289  loss_dice_4: 0.1835  loss_ce_5: 0.1632  loss_mask_5: 0.1274  loss_dice_5: 0.1865  loss_ce_6: 0.07261  loss_mask_6: 0.1309  loss_dice_6: 0.1868  loss_ce_7: 0.1484  loss_mask_7: 0.13  loss_dice_7: 0.1812  loss_ce_8: 0.1379  loss_mask_8: 0.1305  loss_dice_8: 0.1842  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:41:39] d2.utils.events INFO:  eta: 2:01:13  iter: 2979  total_loss: 4.989  loss_ce: 0.1218  loss_mask: 0.1337  loss_dice: 0.1972  loss_ce_0: 0.153  loss_mask_0: 0.1329  loss_dice_0: 0.1946  loss_ce_1: 0.1741  loss_mask_1: 0.1382  loss_dice_1: 0.1993  loss_ce_2: 0.1408  loss_mask_2: 0.142  loss_dice_2: 0.1935  loss_ce_3: 0.1044  loss_mask_3: 0.1381  loss_dice_3: 0.1909  loss_ce_4: 0.1797  loss_mask_4: 0.1361  loss_dice_4: 0.1981  loss_ce_5: 0.1617  loss_mask_5: 0.1328  loss_dice_5: 0.1971  loss_ce_6: 0.1011  loss_mask_6: 0.1383  loss_dice_6: 0.2001  loss_ce_7: 0.1758  loss_mask_7: 0.1379  loss_dice_7: 0.2001  loss_ce_8: 0.1352  loss_mask_8: 0.1394  loss_dice_8: 0.1977  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:41:44] d2.utils.events INFO:  eta: 2:01:09  iter: 2999  total_loss: 4.528  loss_ce: 0.08396  loss_mask: 0.1301  loss_dice: 0.1853  loss_ce_0: 0.147  loss_mask_0: 0.1282  loss_dice_0: 0.1898  loss_ce_1: 0.1115  loss_mask_1: 0.1292  loss_dice_1: 0.187  loss_ce_2: 0.1045  loss_mask_2: 0.1297  loss_dice_2: 0.1938  loss_ce_3: 0.07314  loss_mask_3: 0.1326  loss_dice_3: 0.192  loss_ce_4: 0.1153  loss_mask_4: 0.1301  loss_dice_4: 0.1852  loss_ce_5: 0.09536  loss_mask_5: 0.1326  loss_dice_5: 0.1891  loss_ce_6: 0.078  loss_mask_6: 0.1319  loss_dice_6: 0.1981  loss_ce_7: 0.1107  loss_mask_7: 0.1256  loss_dice_7: 0.19  loss_ce_8: 0.0858  loss_mask_8: 0.1286  loss_dice_8: 0.1886  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:41:49] d2.utils.events INFO:  eta: 2:01:04  iter: 3019  total_loss: 4.584  loss_ce: 0.1014  loss_mask: 0.1297  loss_dice: 0.1815  loss_ce_0: 0.1459  loss_mask_0: 0.1298  loss_dice_0: 0.1826  loss_ce_1: 0.1674  loss_mask_1: 0.1308  loss_dice_1: 0.1822  loss_ce_2: 0.1608  loss_mask_2: 0.1304  loss_dice_2: 0.1865  loss_ce_3: 0.1079  loss_mask_3: 0.1321  loss_dice_3: 0.1884  loss_ce_4: 0.1429  loss_mask_4: 0.1315  loss_dice_4: 0.1758  loss_ce_5: 0.1462  loss_mask_5: 0.1329  loss_dice_5: 0.1843  loss_ce_6: 0.101  loss_mask_6: 0.1343  loss_dice_6: 0.1807  loss_ce_7: 0.1098  loss_mask_7: 0.1305  loss_dice_7: 0.1764  loss_ce_8: 0.1383  loss_mask_8: 0.1309  loss_dice_8: 0.1813  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:41:53] d2.utils.events INFO:  eta: 2:00:58  iter: 3039  total_loss: 4.348  loss_ce: 0.1002  loss_mask: 0.139  loss_dice: 0.1892  loss_ce_0: 0.1459  loss_mask_0: 0.1326  loss_dice_0: 0.1873  loss_ce_1: 0.1267  loss_mask_1: 0.1299  loss_dice_1: 0.1841  loss_ce_2: 0.131  loss_mask_2: 0.1317  loss_dice_2: 0.1909  loss_ce_3: 0.1009  loss_mask_3: 0.1361  loss_dice_3: 0.1858  loss_ce_4: 0.1129  loss_mask_4: 0.1316  loss_dice_4: 0.1875  loss_ce_5: 0.1139  loss_mask_5: 0.1306  loss_dice_5: 0.1903  loss_ce_6: 0.1069  loss_mask_6: 0.1332  loss_dice_6: 0.1874  loss_ce_7: 0.1056  loss_mask_7: 0.1321  loss_dice_7: 0.1914  loss_ce_8: 0.09888  loss_mask_8: 0.1329  loss_dice_8: 0.1914  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:41:58] d2.utils.events INFO:  eta: 2:00:52  iter: 3059  total_loss: 4.388  loss_ce: 0.05099  loss_mask: 0.1354  loss_dice: 0.2013  loss_ce_0: 0.1418  loss_mask_0: 0.1406  loss_dice_0: 0.2033  loss_ce_1: 0.1256  loss_mask_1: 0.1377  loss_dice_1: 0.2006  loss_ce_2: 0.1084  loss_mask_2: 0.136  loss_dice_2: 0.1936  loss_ce_3: 0.05463  loss_mask_3: 0.1403  loss_dice_3: 0.2063  loss_ce_4: 0.08356  loss_mask_4: 0.1393  loss_dice_4: 0.2012  loss_ce_5: 0.1152  loss_mask_5: 0.1383  loss_dice_5: 0.1988  loss_ce_6: 0.05877  loss_mask_6: 0.1367  loss_dice_6: 0.2048  loss_ce_7: 0.1168  loss_mask_7: 0.1307  loss_dice_7: 0.1974  loss_ce_8: 0.08877  loss_mask_8: 0.1367  loss_dice_8: 0.201  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:42:02] d2.utils.events INFO:  eta: 2:00:56  iter: 3079  total_loss: 4.428  loss_ce: 0.03129  loss_mask: 0.1344  loss_dice: 0.1956  loss_ce_0: 0.1425  loss_mask_0: 0.1349  loss_dice_0: 0.1947  loss_ce_1: 0.1417  loss_mask_1: 0.146  loss_dice_1: 0.2019  loss_ce_2: 0.1141  loss_mask_2: 0.1384  loss_dice_2: 0.1956  loss_ce_3: 0.02944  loss_mask_3: 0.1428  loss_dice_3: 0.2024  loss_ce_4: 0.07713  loss_mask_4: 0.1305  loss_dice_4: 0.1881  loss_ce_5: 0.1016  loss_mask_5: 0.135  loss_dice_5: 0.2011  loss_ce_6: 0.03339  loss_mask_6: 0.1371  loss_dice_6: 0.1851  loss_ce_7: 0.09617  loss_mask_7: 0.1399  loss_dice_7: 0.1931  loss_ce_8: 0.09083  loss_mask_8: 0.1419  loss_dice_8: 0.2022  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:42:07] d2.utils.events INFO:  eta: 2:00:46  iter: 3099  total_loss: 4.244  loss_ce: 0.06395  loss_mask: 0.1289  loss_dice: 0.179  loss_ce_0: 0.1424  loss_mask_0: 0.1227  loss_dice_0: 0.176  loss_ce_1: 0.1511  loss_mask_1: 0.1263  loss_dice_1: 0.1839  loss_ce_2: 0.1534  loss_mask_2: 0.131  loss_dice_2: 0.1746  loss_ce_3: 0.05326  loss_mask_3: 0.1281  loss_dice_3: 0.174  loss_ce_4: 0.07578  loss_mask_4: 0.1303  loss_dice_4: 0.1746  loss_ce_5: 0.1146  loss_mask_5: 0.126  loss_dice_5: 0.1788  loss_ce_6: 0.0542  loss_mask_6: 0.1218  loss_dice_6: 0.1817  loss_ce_7: 0.08609  loss_mask_7: 0.1275  loss_dice_7: 0.1813  loss_ce_8: 0.1229  loss_mask_8: 0.1268  loss_dice_8: 0.1856  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:42:11] d2.utils.events INFO:  eta: 2:00:41  iter: 3119  total_loss: 4.203  loss_ce: 0.04009  loss_mask: 0.1394  loss_dice: 0.1941  loss_ce_0: 0.1395  loss_mask_0: 0.1389  loss_dice_0: 0.1972  loss_ce_1: 0.144  loss_mask_1: 0.1423  loss_dice_1: 0.1942  loss_ce_2: 0.1304  loss_mask_2: 0.1397  loss_dice_2: 0.1971  loss_ce_3: 0.03271  loss_mask_3: 0.1376  loss_dice_3: 0.1953  loss_ce_4: 0.07764  loss_mask_4: 0.1393  loss_dice_4: 0.1941  loss_ce_5: 0.1118  loss_mask_5: 0.1355  loss_dice_5: 0.1907  loss_ce_6: 0.04252  loss_mask_6: 0.1424  loss_dice_6: 0.1917  loss_ce_7: 0.0764  loss_mask_7: 0.1379  loss_dice_7: 0.1955  loss_ce_8: 0.1053  loss_mask_8: 0.1405  loss_dice_8: 0.1993  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:42:16] d2.utils.events INFO:  eta: 2:00:37  iter: 3139  total_loss: 4.414  loss_ce: 0.07851  loss_mask: 0.1307  loss_dice: 0.1761  loss_ce_0: 0.142  loss_mask_0: 0.13  loss_dice_0: 0.1787  loss_ce_1: 0.1743  loss_mask_1: 0.1283  loss_dice_1: 0.1796  loss_ce_2: 0.1683  loss_mask_2: 0.1336  loss_dice_2: 0.1853  loss_ce_3: 0.06638  loss_mask_3: 0.134  loss_dice_3: 0.1854  loss_ce_4: 0.107  loss_mask_4: 0.1314  loss_dice_4: 0.1769  loss_ce_5: 0.1651  loss_mask_5: 0.1342  loss_dice_5: 0.1864  loss_ce_6: 0.06426  loss_mask_6: 0.136  loss_dice_6: 0.18  loss_ce_7: 0.1096  loss_mask_7: 0.1341  loss_dice_7: 0.1797  loss_ce_8: 0.1312  loss_mask_8: 0.1285  loss_dice_8: 0.1834  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:42:20] d2.utils.events INFO:  eta: 2:00:31  iter: 3159  total_loss: 3.75  loss_ce: 0.03066  loss_mask: 0.1228  loss_dice: 0.175  loss_ce_0: 0.145  loss_mask_0: 0.1241  loss_dice_0: 0.1826  loss_ce_1: 0.09438  loss_mask_1: 0.1204  loss_dice_1: 0.1793  loss_ce_2: 0.07621  loss_mask_2: 0.1175  loss_dice_2: 0.1754  loss_ce_3: 0.02439  loss_mask_3: 0.1275  loss_dice_3: 0.1797  loss_ce_4: 0.04116  loss_mask_4: 0.1267  loss_dice_4: 0.1791  loss_ce_5: 0.0641  loss_mask_5: 0.1234  loss_dice_5: 0.1725  loss_ce_6: 0.02563  loss_mask_6: 0.1271  loss_dice_6: 0.1834  loss_ce_7: 0.04551  loss_mask_7: 0.1222  loss_dice_7: 0.1804  loss_ce_8: 0.06947  loss_mask_8: 0.1286  loss_dice_8: 0.1827  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:42:25] d2.utils.events INFO:  eta: 2:00:25  iter: 3179  total_loss: 3.955  loss_ce: 0.0369  loss_mask: 0.1273  loss_dice: 0.1828  loss_ce_0: 0.145  loss_mask_0: 0.1264  loss_dice_0: 0.1921  loss_ce_1: 0.113  loss_mask_1: 0.1283  loss_dice_1: 0.1854  loss_ce_2: 0.1087  loss_mask_2: 0.1299  loss_dice_2: 0.1866  loss_ce_3: 0.03612  loss_mask_3: 0.131  loss_dice_3: 0.1819  loss_ce_4: 0.06359  loss_mask_4: 0.1324  loss_dice_4: 0.187  loss_ce_5: 0.09982  loss_mask_5: 0.1324  loss_dice_5: 0.1899  loss_ce_6: 0.03182  loss_mask_6: 0.1292  loss_dice_6: 0.1838  loss_ce_7: 0.06336  loss_mask_7: 0.1335  loss_dice_7: 0.1876  loss_ce_8: 0.07596  loss_mask_8: 0.1325  loss_dice_8: 0.1919  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:42:29] d2.utils.events INFO:  eta: 2:00:20  iter: 3199  total_loss: 4.38  loss_ce: 0.04831  loss_mask: 0.1333  loss_dice: 0.1914  loss_ce_0: 0.1485  loss_mask_0: 0.1379  loss_dice_0: 0.2009  loss_ce_1: 0.1405  loss_mask_1: 0.1372  loss_dice_1: 0.1982  loss_ce_2: 0.1241  loss_mask_2: 0.1359  loss_dice_2: 0.1976  loss_ce_3: 0.05012  loss_mask_3: 0.1344  loss_dice_3: 0.1932  loss_ce_4: 0.07132  loss_mask_4: 0.137  loss_dice_4: 0.2007  loss_ce_5: 0.1122  loss_mask_5: 0.137  loss_dice_5: 0.1947  loss_ce_6: 0.03852  loss_mask_6: 0.1433  loss_dice_6: 0.1984  loss_ce_7: 0.05283  loss_mask_7: 0.1434  loss_dice_7: 0.2033  loss_ce_8: 0.1218  loss_mask_8: 0.1286  loss_dice_8: 0.1979  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:42:34] d2.utils.events INFO:  eta: 2:00:17  iter: 3219  total_loss: 4.715  loss_ce: 0.07104  loss_mask: 0.1517  loss_dice: 0.2161  loss_ce_0: 0.1365  loss_mask_0: 0.1497  loss_dice_0: 0.2174  loss_ce_1: 0.1519  loss_mask_1: 0.1512  loss_dice_1: 0.217  loss_ce_2: 0.08361  loss_mask_2: 0.1429  loss_dice_2: 0.2099  loss_ce_3: 0.06555  loss_mask_3: 0.1544  loss_dice_3: 0.2043  loss_ce_4: 0.1079  loss_mask_4: 0.1453  loss_dice_4: 0.2114  loss_ce_5: 0.1003  loss_mask_5: 0.1491  loss_dice_5: 0.2183  loss_ce_6: 0.1095  loss_mask_6: 0.1615  loss_dice_6: 0.2044  loss_ce_7: 0.1301  loss_mask_7: 0.1581  loss_dice_7: 0.2096  loss_ce_8: 0.09364  loss_mask_8: 0.1404  loss_dice_8: 0.2208  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:42:38] d2.utils.events INFO:  eta: 2:00:11  iter: 3239  total_loss: 4.694  loss_ce: 0.08524  loss_mask: 0.143  loss_dice: 0.2061  loss_ce_0: 0.1423  loss_mask_0: 0.1418  loss_dice_0: 0.1987  loss_ce_1: 0.1501  loss_mask_1: 0.1431  loss_dice_1: 0.199  loss_ce_2: 0.08434  loss_mask_2: 0.144  loss_dice_2: 0.2073  loss_ce_3: 0.06203  loss_mask_3: 0.1465  loss_dice_3: 0.2087  loss_ce_4: 0.08895  loss_mask_4: 0.1461  loss_dice_4: 0.2029  loss_ce_5: 0.1009  loss_mask_5: 0.1472  loss_dice_5: 0.1991  loss_ce_6: 0.06915  loss_mask_6: 0.1529  loss_dice_6: 0.2039  loss_ce_7: 0.1208  loss_mask_7: 0.1383  loss_dice_7: 0.1956  loss_ce_8: 0.09136  loss_mask_8: 0.1434  loss_dice_8: 0.206  time: 0.2255  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:42:43] d2.utils.events INFO:  eta: 2:00:04  iter: 3259  total_loss: 4.322  loss_ce: 0.07034  loss_mask: 0.1312  loss_dice: 0.1822  loss_ce_0: 0.1424  loss_mask_0: 0.1356  loss_dice_0: 0.1799  loss_ce_1: 0.1612  loss_mask_1: 0.138  loss_dice_1: 0.1859  loss_ce_2: 0.09273  loss_mask_2: 0.1343  loss_dice_2: 0.1886  loss_ce_3: 0.07299  loss_mask_3: 0.1326  loss_dice_3: 0.1889  loss_ce_4: 0.08679  loss_mask_4: 0.1337  loss_dice_4: 0.1847  loss_ce_5: 0.09115  loss_mask_5: 0.137  loss_dice_5: 0.1824  loss_ce_6: 0.09821  loss_mask_6: 0.1368  loss_dice_6: 0.1801  loss_ce_7: 0.1206  loss_mask_7: 0.1321  loss_dice_7: 0.1925  loss_ce_8: 0.07645  loss_mask_8: 0.138  loss_dice_8: 0.1959  time: 0.2255  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:42:48] d2.utils.events INFO:  eta: 2:00:02  iter: 3279  total_loss: 4.021  loss_ce: 0.08046  loss_mask: 0.1375  loss_dice: 0.1837  loss_ce_0: 0.1413  loss_mask_0: 0.1374  loss_dice_0: 0.1902  loss_ce_1: 0.1457  loss_mask_1: 0.1332  loss_dice_1: 0.187  loss_ce_2: 0.05656  loss_mask_2: 0.1343  loss_dice_2: 0.1892  loss_ce_3: 0.06814  loss_mask_3: 0.1385  loss_dice_3: 0.1892  loss_ce_4: 0.05392  loss_mask_4: 0.1351  loss_dice_4: 0.1836  loss_ce_5: 0.03838  loss_mask_5: 0.1344  loss_dice_5: 0.1943  loss_ce_6: 0.0825  loss_mask_6: 0.133  loss_dice_6: 0.1811  loss_ce_7: 0.09082  loss_mask_7: 0.1359  loss_dice_7: 0.1879  loss_ce_8: 0.05006  loss_mask_8: 0.1404  loss_dice_8: 0.19  time: 0.2257  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:42:56] d2.utils.events INFO:  eta: 2:00:29  iter: 3299  total_loss: 4.063  loss_ce: 0.04493  loss_mask: 0.134  loss_dice: 0.1848  loss_ce_0: 0.1458  loss_mask_0: 0.1333  loss_dice_0: 0.1948  loss_ce_1: 0.1151  loss_mask_1: 0.1295  loss_dice_1: 0.1903  loss_ce_2: 0.04199  loss_mask_2: 0.1305  loss_dice_2: 0.1844  loss_ce_3: 0.0487  loss_mask_3: 0.1337  loss_dice_3: 0.1876  loss_ce_4: 0.03327  loss_mask_4: 0.1295  loss_dice_4: 0.1918  loss_ce_5: 0.03342  loss_mask_5: 0.1281  loss_dice_5: 0.1894  loss_ce_6: 0.04408  loss_mask_6: 0.1327  loss_dice_6: 0.189  loss_ce_7: 0.04521  loss_mask_7: 0.1275  loss_dice_7: 0.1907  loss_ce_8: 0.03734  loss_mask_8: 0.1262  loss_dice_8: 0.1909  time: 0.2268  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:43:04] d2.utils.events INFO:  eta: 2:00:43  iter: 3319  total_loss: 4.096  loss_ce: 0.04593  loss_mask: 0.126  loss_dice: 0.1815  loss_ce_0: 0.1446  loss_mask_0: 0.1301  loss_dice_0: 0.1827  loss_ce_1: 0.09291  loss_mask_1: 0.1291  loss_dice_1: 0.1805  loss_ce_2: 0.09459  loss_mask_2: 0.1337  loss_dice_2: 0.183  loss_ce_3: 0.04619  loss_mask_3: 0.1302  loss_dice_3: 0.1831  loss_ce_4: 0.06623  loss_mask_4: 0.128  loss_dice_4: 0.1799  loss_ce_5: 0.07349  loss_mask_5: 0.1306  loss_dice_5: 0.1814  loss_ce_6: 0.04122  loss_mask_6: 0.1263  loss_dice_6: 0.1788  loss_ce_7: 0.0668  loss_mask_7: 0.1304  loss_dice_7: 0.1812  loss_ce_8: 0.06839  loss_mask_8: 0.1305  loss_dice_8: 0.1785  time: 0.2278  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:43:12] d2.utils.events INFO:  eta: 2:01:28  iter: 3339  total_loss: 4.321  loss_ce: 0.06316  loss_mask: 0.1381  loss_dice: 0.1965  loss_ce_0: 0.1337  loss_mask_0: 0.14  loss_dice_0: 0.1951  loss_ce_1: 0.0911  loss_mask_1: 0.1386  loss_dice_1: 0.1994  loss_ce_2: 0.08479  loss_mask_2: 0.1347  loss_dice_2: 0.1962  loss_ce_3: 0.06369  loss_mask_3: 0.1329  loss_dice_3: 0.191  loss_ce_4: 0.07516  loss_mask_4: 0.1344  loss_dice_4: 0.1917  loss_ce_5: 0.06698  loss_mask_5: 0.1386  loss_dice_5: 0.1927  loss_ce_6: 0.05825  loss_mask_6: 0.1343  loss_dice_6: 0.1903  loss_ce_7: 0.07146  loss_mask_7: 0.1395  loss_dice_7: 0.199  loss_ce_8: 0.07337  loss_mask_8: 0.1358  loss_dice_8: 0.1901  time: 0.2289  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:43:20] d2.utils.events INFO:  eta: 2:01:38  iter: 3359  total_loss: 4.668  loss_ce: 0.07634  loss_mask: 0.1275  loss_dice: 0.1791  loss_ce_0: 0.1397  loss_mask_0: 0.1287  loss_dice_0: 0.1777  loss_ce_1: 0.156  loss_mask_1: 0.1279  loss_dice_1: 0.1743  loss_ce_2: 0.1143  loss_mask_2: 0.1296  loss_dice_2: 0.1847  loss_ce_3: 0.1018  loss_mask_3: 0.1283  loss_dice_3: 0.1861  loss_ce_4: 0.1346  loss_mask_4: 0.1351  loss_dice_4: 0.1896  loss_ce_5: 0.1425  loss_mask_5: 0.1293  loss_dice_5: 0.1853  loss_ce_6: 0.09966  loss_mask_6: 0.1242  loss_dice_6: 0.1836  loss_ce_7: 0.1415  loss_mask_7: 0.1273  loss_dice_7: 0.1839  loss_ce_8: 0.1493  loss_mask_8: 0.1303  loss_dice_8: 0.1815  time: 0.2299  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:43:28] d2.utils.events INFO:  eta: 2:01:47  iter: 3379  total_loss: 4.336  loss_ce: 0.06132  loss_mask: 0.1257  loss_dice: 0.1772  loss_ce_0: 0.1552  loss_mask_0: 0.1296  loss_dice_0: 0.1788  loss_ce_1: 0.1027  loss_mask_1: 0.1327  loss_dice_1: 0.1875  loss_ce_2: 0.09988  loss_mask_2: 0.1366  loss_dice_2: 0.182  loss_ce_3: 0.08091  loss_mask_3: 0.1352  loss_dice_3: 0.184  loss_ce_4: 0.09177  loss_mask_4: 0.1362  loss_dice_4: 0.1798  loss_ce_5: 0.1334  loss_mask_5: 0.131  loss_dice_5: 0.1773  loss_ce_6: 0.0666  loss_mask_6: 0.1307  loss_dice_6: 0.1737  loss_ce_7: 0.08755  loss_mask_7: 0.1274  loss_dice_7: 0.1836  loss_ce_8: 0.08692  loss_mask_8: 0.1267  loss_dice_8: 0.1823  time: 0.2309  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:43:36] d2.utils.events INFO:  eta: 2:01:56  iter: 3399  total_loss: 4.487  loss_ce: 0.03905  loss_mask: 0.1321  loss_dice: 0.1846  loss_ce_0: 0.1365  loss_mask_0: 0.1318  loss_dice_0: 0.2023  loss_ce_1: 0.1218  loss_mask_1: 0.1299  loss_dice_1: 0.1914  loss_ce_2: 0.1043  loss_mask_2: 0.1365  loss_dice_2: 0.1973  loss_ce_3: 0.07239  loss_mask_3: 0.1438  loss_dice_3: 0.1962  loss_ce_4: 0.11  loss_mask_4: 0.1432  loss_dice_4: 0.1875  loss_ce_5: 0.1343  loss_mask_5: 0.1405  loss_dice_5: 0.1884  loss_ce_6: 0.06401  loss_mask_6: 0.1404  loss_dice_6: 0.1939  loss_ce_7: 0.1048  loss_mask_7: 0.1319  loss_dice_7: 0.1867  loss_ce_8: 0.08986  loss_mask_8: 0.133  loss_dice_8: 0.1926  time: 0.2319  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:43:44] d2.utils.events INFO:  eta: 2:02:30  iter: 3419  total_loss: 3.997  loss_ce: 0.03024  loss_mask: 0.1287  loss_dice: 0.1822  loss_ce_0: 0.1363  loss_mask_0: 0.125  loss_dice_0: 0.188  loss_ce_1: 0.1012  loss_mask_1: 0.1287  loss_dice_1: 0.1829  loss_ce_2: 0.09334  loss_mask_2: 0.1331  loss_dice_2: 0.1783  loss_ce_3: 0.03435  loss_mask_3: 0.1392  loss_dice_3: 0.1873  loss_ce_4: 0.04316  loss_mask_4: 0.1314  loss_dice_4: 0.1801  loss_ce_5: 0.07586  loss_mask_5: 0.1323  loss_dice_5: 0.1848  loss_ce_6: 0.02575  loss_mask_6: 0.128  loss_dice_6: 0.1799  loss_ce_7: 0.04493  loss_mask_7: 0.1242  loss_dice_7: 0.1849  loss_ce_8: 0.05854  loss_mask_8: 0.1313  loss_dice_8: 0.1796  time: 0.2329  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:43:52] d2.utils.events INFO:  eta: 2:02:48  iter: 3439  total_loss: 4.113  loss_ce: 0.05231  loss_mask: 0.1262  loss_dice: 0.1777  loss_ce_0: 0.1507  loss_mask_0: 0.1328  loss_dice_0: 0.1892  loss_ce_1: 0.05667  loss_mask_1: 0.1266  loss_dice_1: 0.1839  loss_ce_2: 0.05787  loss_mask_2: 0.1278  loss_dice_2: 0.1795  loss_ce_3: 0.05173  loss_mask_3: 0.1278  loss_dice_3: 0.1863  loss_ce_4: 0.073  loss_mask_4: 0.133  loss_dice_4: 0.186  loss_ce_5: 0.06162  loss_mask_5: 0.1297  loss_dice_5: 0.1882  loss_ce_6: 0.06188  loss_mask_6: 0.128  loss_dice_6: 0.1877  loss_ce_7: 0.06447  loss_mask_7: 0.1274  loss_dice_7: 0.1864  loss_ce_8: 0.06498  loss_mask_8: 0.1281  loss_dice_8: 0.1868  time: 0.2338  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:44:01] d2.utils.events INFO:  eta: 2:02:59  iter: 3459  total_loss: 4.38  loss_ce: 0.03274  loss_mask: 0.1383  loss_dice: 0.1882  loss_ce_0: 0.1448  loss_mask_0: 0.1304  loss_dice_0: 0.1868  loss_ce_1: 0.08549  loss_mask_1: 0.1321  loss_dice_1: 0.1876  loss_ce_2: 0.04504  loss_mask_2: 0.1348  loss_dice_2: 0.185  loss_ce_3: 0.02643  loss_mask_3: 0.1379  loss_dice_3: 0.182  loss_ce_4: 0.04621  loss_mask_4: 0.1314  loss_dice_4: 0.1822  loss_ce_5: 0.03468  loss_mask_5: 0.1345  loss_dice_5: 0.1841  loss_ce_6: 0.03651  loss_mask_6: 0.1354  loss_dice_6: 0.1841  loss_ce_7: 0.03674  loss_mask_7: 0.1345  loss_dice_7: 0.1868  loss_ce_8: 0.04117  loss_mask_8: 0.1321  loss_dice_8: 0.1833  time: 0.2348  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:44:09] d2.utils.events INFO:  eta: 2:03:18  iter: 3479  total_loss: 4.528  loss_ce: 0.04108  loss_mask: 0.1484  loss_dice: 0.2018  loss_ce_0: 0.144  loss_mask_0: 0.1516  loss_dice_0: 0.2105  loss_ce_1: 0.1187  loss_mask_1: 0.1397  loss_dice_1: 0.196  loss_ce_2: 0.05483  loss_mask_2: 0.1433  loss_dice_2: 0.1993  loss_ce_3: 0.05179  loss_mask_3: 0.1448  loss_dice_3: 0.1952  loss_ce_4: 0.08757  loss_mask_4: 0.1542  loss_dice_4: 0.2026  loss_ce_5: 0.07411  loss_mask_5: 0.1472  loss_dice_5: 0.1972  loss_ce_6: 0.05729  loss_mask_6: 0.1453  loss_dice_6: 0.1982  loss_ce_7: 0.06386  loss_mask_7: 0.145  loss_dice_7: 0.1932  loss_ce_8: 0.04522  loss_mask_8: 0.1446  loss_dice_8: 0.1895  time: 0.2358  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:44:17] d2.utils.events INFO:  eta: 2:03:32  iter: 3499  total_loss: 4.221  loss_ce: 0.06198  loss_mask: 0.1363  loss_dice: 0.1967  loss_ce_0: 0.1423  loss_mask_0: 0.1386  loss_dice_0: 0.2069  loss_ce_1: 0.06116  loss_mask_1: 0.1364  loss_dice_1: 0.2017  loss_ce_2: 0.07129  loss_mask_2: 0.1375  loss_dice_2: 0.1981  loss_ce_3: 0.067  loss_mask_3: 0.1394  loss_dice_3: 0.2004  loss_ce_4: 0.08784  loss_mask_4: 0.1399  loss_dice_4: 0.1981  loss_ce_5: 0.08052  loss_mask_5: 0.136  loss_dice_5: 0.1938  loss_ce_6: 0.07572  loss_mask_6: 0.1384  loss_dice_6: 0.2005  loss_ce_7: 0.08181  loss_mask_7: 0.1325  loss_dice_7: 0.1989  loss_ce_8: 0.06317  loss_mask_8: 0.141  loss_dice_8: 0.2015  time: 0.2368  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:44:24] d2.utils.events INFO:  eta: 2:03:43  iter: 3519  total_loss: 3.658  loss_ce: 0.02475  loss_mask: 0.1239  loss_dice: 0.1738  loss_ce_0: 0.144  loss_mask_0: 0.1281  loss_dice_0: 0.1722  loss_ce_1: 0.06011  loss_mask_1: 0.13  loss_dice_1: 0.1745  loss_ce_2: 0.03405  loss_mask_2: 0.1241  loss_dice_2: 0.1705  loss_ce_3: 0.02663  loss_mask_3: 0.1294  loss_dice_3: 0.1736  loss_ce_4: 0.039  loss_mask_4: 0.1311  loss_dice_4: 0.1712  loss_ce_5: 0.04867  loss_mask_5: 0.1292  loss_dice_5: 0.1725  loss_ce_6: 0.02934  loss_mask_6: 0.1291  loss_dice_6: 0.1709  loss_ce_7: 0.03054  loss_mask_7: 0.1255  loss_dice_7: 0.1735  loss_ce_8: 0.03095  loss_mask_8: 0.1252  loss_dice_8: 0.1778  time: 0.2376  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:44:33] d2.utils.events INFO:  eta: 2:03:53  iter: 3539  total_loss: 3.947  loss_ce: 0.04511  loss_mask: 0.1419  loss_dice: 0.197  loss_ce_0: 0.1341  loss_mask_0: 0.1392  loss_dice_0: 0.1882  loss_ce_1: 0.07515  loss_mask_1: 0.1401  loss_dice_1: 0.195  loss_ce_2: 0.04625  loss_mask_2: 0.1358  loss_dice_2: 0.1926  loss_ce_3: 0.04431  loss_mask_3: 0.1328  loss_dice_3: 0.1844  loss_ce_4: 0.03876  loss_mask_4: 0.1392  loss_dice_4: 0.1983  loss_ce_5: 0.04773  loss_mask_5: 0.1421  loss_dice_5: 0.1848  loss_ce_6: 0.04877  loss_mask_6: 0.1386  loss_dice_6: 0.1927  loss_ce_7: 0.03554  loss_mask_7: 0.1374  loss_dice_7: 0.1926  loss_ce_8: 0.04377  loss_mask_8: 0.1423  loss_dice_8: 0.1951  time: 0.2386  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:44:41] d2.utils.events INFO:  eta: 2:04:04  iter: 3559  total_loss: 3.65  loss_ce: 0.02559  loss_mask: 0.1273  loss_dice: 0.1772  loss_ce_0: 0.1435  loss_mask_0: 0.122  loss_dice_0: 0.1775  loss_ce_1: 0.04616  loss_mask_1: 0.1205  loss_dice_1: 0.1763  loss_ce_2: 0.03889  loss_mask_2: 0.121  loss_dice_2: 0.1731  loss_ce_3: 0.04629  loss_mask_3: 0.1216  loss_dice_3: 0.1815  loss_ce_4: 0.03379  loss_mask_4: 0.1216  loss_dice_4: 0.184  loss_ce_5: 0.03565  loss_mask_5: 0.122  loss_dice_5: 0.1731  loss_ce_6: 0.04186  loss_mask_6: 0.1215  loss_dice_6: 0.1723  loss_ce_7: 0.03566  loss_mask_7: 0.1241  loss_dice_7: 0.176  loss_ce_8: 0.03536  loss_mask_8: 0.1218  loss_dice_8: 0.1773  time: 0.2395  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:44:49] d2.utils.events INFO:  eta: 2:04:28  iter: 3579  total_loss: 3.849  loss_ce: 0.01294  loss_mask: 0.1423  loss_dice: 0.1846  loss_ce_0: 0.1398  loss_mask_0: 0.1346  loss_dice_0: 0.1934  loss_ce_1: 0.07017  loss_mask_1: 0.1401  loss_dice_1: 0.1922  loss_ce_2: 0.08109  loss_mask_2: 0.1419  loss_dice_2: 0.1863  loss_ce_3: 0.01412  loss_mask_3: 0.1438  loss_dice_3: 0.1906  loss_ce_4: 0.02114  loss_mask_4: 0.1413  loss_dice_4: 0.1912  loss_ce_5: 0.05248  loss_mask_5: 0.1431  loss_dice_5: 0.1877  loss_ce_6: 0.009538  loss_mask_6: 0.1463  loss_dice_6: 0.1924  loss_ce_7: 0.02038  loss_mask_7: 0.1464  loss_dice_7: 0.1863  loss_ce_8: 0.0411  loss_mask_8: 0.1432  loss_dice_8: 0.1885  time: 0.2404  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:44:57] d2.utils.events INFO:  eta: 2:04:52  iter: 3599  total_loss: 3.723  loss_ce: 0.01661  loss_mask: 0.1277  loss_dice: 0.1833  loss_ce_0: 0.1415  loss_mask_0: 0.1333  loss_dice_0: 0.1855  loss_ce_1: 0.07741  loss_mask_1: 0.1359  loss_dice_1: 0.1861  loss_ce_2: 0.08367  loss_mask_2: 0.1247  loss_dice_2: 0.1836  loss_ce_3: 0.027  loss_mask_3: 0.129  loss_dice_3: 0.1827  loss_ce_4: 0.04665  loss_mask_4: 0.1308  loss_dice_4: 0.1811  loss_ce_5: 0.08055  loss_mask_5: 0.1315  loss_dice_5: 0.1831  loss_ce_6: 0.02714  loss_mask_6: 0.13  loss_dice_6: 0.1867  loss_ce_7: 0.03777  loss_mask_7: 0.1295  loss_dice_7: 0.1806  loss_ce_8: 0.06061  loss_mask_8: 0.1279  loss_dice_8: 0.187  time: 0.2413  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:45:05] d2.utils.events INFO:  eta: 2:04:57  iter: 3619  total_loss: 3.771  loss_ce: 0.02267  loss_mask: 0.1309  loss_dice: 0.1793  loss_ce_0: 0.1401  loss_mask_0: 0.1289  loss_dice_0: 0.1833  loss_ce_1: 0.05455  loss_mask_1: 0.1292  loss_dice_1: 0.1805  loss_ce_2: 0.0623  loss_mask_2: 0.1289  loss_dice_2: 0.1723  loss_ce_3: 0.04005  loss_mask_3: 0.1271  loss_dice_3: 0.1763  loss_ce_4: 0.03367  loss_mask_4: 0.128  loss_dice_4: 0.1814  loss_ce_5: 0.05446  loss_mask_5: 0.1309  loss_dice_5: 0.1826  loss_ce_6: 0.02613  loss_mask_6: 0.1443  loss_dice_6: 0.1902  loss_ce_7: 0.03216  loss_mask_7: 0.1359  loss_dice_7: 0.1831  loss_ce_8: 0.02784  loss_mask_8: 0.1323  loss_dice_8: 0.1783  time: 0.2424  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:45:15] d2.utils.events INFO:  eta: 2:05:14  iter: 3639  total_loss: 4.112  loss_ce: 0.04055  loss_mask: 0.1393  loss_dice: 0.1931  loss_ce_0: 0.1399  loss_mask_0: 0.1321  loss_dice_0: 0.1863  loss_ce_1: 0.06546  loss_mask_1: 0.1326  loss_dice_1: 0.1883  loss_ce_2: 0.04889  loss_mask_2: 0.139  loss_dice_2: 0.1949  loss_ce_3: 0.06789  loss_mask_3: 0.1385  loss_dice_3: 0.1861  loss_ce_4: 0.03479  loss_mask_4: 0.1357  loss_dice_4: 0.1913  loss_ce_5: 0.05078  loss_mask_5: 0.1346  loss_dice_5: 0.1899  loss_ce_6: 0.09367  loss_mask_6: 0.1381  loss_dice_6: 0.187  loss_ce_7: 0.04979  loss_mask_7: 0.1376  loss_dice_7: 0.1873  loss_ce_8: 0.03939  loss_mask_8: 0.1378  loss_dice_8: 0.1914  time: 0.2437  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:45:25] d2.utils.events INFO:  eta: 2:05:34  iter: 3659  total_loss: 3.802  loss_ce: 0.03098  loss_mask: 0.1382  loss_dice: 0.1845  loss_ce_0: 0.1426  loss_mask_0: 0.1275  loss_dice_0: 0.1944  loss_ce_1: 0.07207  loss_mask_1: 0.1352  loss_dice_1: 0.1888  loss_ce_2: 0.05031  loss_mask_2: 0.1281  loss_dice_2: 0.1889  loss_ce_3: 0.0343  loss_mask_3: 0.131  loss_dice_3: 0.1786  loss_ce_4: 0.04037  loss_mask_4: 0.1332  loss_dice_4: 0.1892  loss_ce_5: 0.04842  loss_mask_5: 0.1385  loss_dice_5: 0.1822  loss_ce_6: 0.03534  loss_mask_6: 0.1295  loss_dice_6: 0.1774  loss_ce_7: 0.03921  loss_mask_7: 0.1346  loss_dice_7: 0.1858  loss_ce_8: 0.03556  loss_mask_8: 0.134  loss_dice_8: 0.1916  time: 0.2451  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:45:35] d2.utils.events INFO:  eta: 2:05:56  iter: 3679  total_loss: 4.103  loss_ce: 0.0958  loss_mask: 0.1335  loss_dice: 0.1848  loss_ce_0: 0.1391  loss_mask_0: 0.1309  loss_dice_0: 0.1858  loss_ce_1: 0.06328  loss_mask_1: 0.1249  loss_dice_1: 0.1745  loss_ce_2: 0.04375  loss_mask_2: 0.1349  loss_dice_2: 0.1841  loss_ce_3: 0.09341  loss_mask_3: 0.1347  loss_dice_3: 0.1875  loss_ce_4: 0.06452  loss_mask_4: 0.1303  loss_dice_4: 0.1774  loss_ce_5: 0.03097  loss_mask_5: 0.1407  loss_dice_5: 0.1846  loss_ce_6: 0.1064  loss_mask_6: 0.1313  loss_dice_6: 0.1738  loss_ce_7: 0.06083  loss_mask_7: 0.1321  loss_dice_7: 0.1811  loss_ce_8: 0.02725  loss_mask_8: 0.134  loss_dice_8: 0.1811  time: 0.2465  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:45:45] d2.utils.events INFO:  eta: 2:06:16  iter: 3699  total_loss: 3.588  loss_ce: 0.0586  loss_mask: 0.1201  loss_dice: 0.1708  loss_ce_0: 0.1415  loss_mask_0: 0.1199  loss_dice_0: 0.179  loss_ce_1: 0.07045  loss_mask_1: 0.1208  loss_dice_1: 0.1774  loss_ce_2: 0.04718  loss_mask_2: 0.1253  loss_dice_2: 0.1772  loss_ce_3: 0.04999  loss_mask_3: 0.1241  loss_dice_3: 0.1735  loss_ce_4: 0.05236  loss_mask_4: 0.1221  loss_dice_4: 0.1778  loss_ce_5: 0.0466  loss_mask_5: 0.127  loss_dice_5: 0.181  loss_ce_6: 0.05572  loss_mask_6: 0.1249  loss_dice_6: 0.1691  loss_ce_7: 0.06874  loss_mask_7: 0.1197  loss_dice_7: 0.1733  loss_ce_8: 0.03839  loss_mask_8: 0.128  loss_dice_8: 0.1796  time: 0.2479  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:45:55] d2.utils.events INFO:  eta: 2:06:37  iter: 3719  total_loss: 3.716  loss_ce: 0.01749  loss_mask: 0.1365  loss_dice: 0.1867  loss_ce_0: 0.1378  loss_mask_0: 0.1353  loss_dice_0: 0.1825  loss_ce_1: 0.05442  loss_mask_1: 0.1354  loss_dice_1: 0.1828  loss_ce_2: 0.03882  loss_mask_2: 0.1382  loss_dice_2: 0.184  loss_ce_3: 0.02431  loss_mask_3: 0.1328  loss_dice_3: 0.1813  loss_ce_4: 0.02317  loss_mask_4: 0.1307  loss_dice_4: 0.191  loss_ce_5: 0.03344  loss_mask_5: 0.1325  loss_dice_5: 0.1918  loss_ce_6: 0.01964  loss_mask_6: 0.1435  loss_dice_6: 0.1881  loss_ce_7: 0.02305  loss_mask_7: 0.1351  loss_dice_7: 0.1853  loss_ce_8: 0.02922  loss_mask_8: 0.1395  loss_dice_8: 0.1858  time: 0.2492  data_time: 0.0014  lr: 0.0001  max_mem: 1909M
[08/01 16:46:05] d2.utils.events INFO:  eta: 2:07:41  iter: 3739  total_loss: 3.705  loss_ce: 0.04443  loss_mask: 0.1258  loss_dice: 0.1799  loss_ce_0: 0.1451  loss_mask_0: 0.1311  loss_dice_0: 0.1859  loss_ce_1: 0.03374  loss_mask_1: 0.1287  loss_dice_1: 0.1869  loss_ce_2: 0.03268  loss_mask_2: 0.1313  loss_dice_2: 0.184  loss_ce_3: 0.04782  loss_mask_3: 0.1288  loss_dice_3: 0.183  loss_ce_4: 0.04591  loss_mask_4: 0.129  loss_dice_4: 0.1817  loss_ce_5: 0.03264  loss_mask_5: 0.1285  loss_dice_5: 0.1825  loss_ce_6: 0.03393  loss_mask_6: 0.1356  loss_dice_6: 0.1852  loss_ce_7: 0.03751  loss_mask_7: 0.1293  loss_dice_7: 0.1806  loss_ce_8: 0.02654  loss_mask_8: 0.1322  loss_dice_8: 0.1824  time: 0.2505  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:46:15] d2.utils.events INFO:  eta: 2:08:59  iter: 3759  total_loss: 3.951  loss_ce: 0.04459  loss_mask: 0.1394  loss_dice: 0.1986  loss_ce_0: 0.1396  loss_mask_0: 0.1429  loss_dice_0: 0.2018  loss_ce_1: 0.03978  loss_mask_1: 0.1376  loss_dice_1: 0.1937  loss_ce_2: 0.04447  loss_mask_2: 0.1401  loss_dice_2: 0.2017  loss_ce_3: 0.04561  loss_mask_3: 0.1377  loss_dice_3: 0.1987  loss_ce_4: 0.02815  loss_mask_4: 0.1375  loss_dice_4: 0.1957  loss_ce_5: 0.03565  loss_mask_5: 0.1415  loss_dice_5: 0.1964  loss_ce_6: 0.03437  loss_mask_6: 0.1433  loss_dice_6: 0.1959  loss_ce_7: 0.02198  loss_mask_7: 0.1378  loss_dice_7: 0.1983  loss_ce_8: 0.03077  loss_mask_8: 0.1393  loss_dice_8: 0.197  time: 0.2518  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:46:25] d2.utils.events INFO:  eta: 3:05:31  iter: 3779  total_loss: 3.742  loss_ce: 0.06026  loss_mask: 0.1237  loss_dice: 0.1697  loss_ce_0: 0.138  loss_mask_0: 0.1204  loss_dice_0: 0.17  loss_ce_1: 0.08903  loss_mask_1: 0.1257  loss_dice_1: 0.1713  loss_ce_2: 0.118  loss_mask_2: 0.1235  loss_dice_2: 0.1678  loss_ce_3: 0.07166  loss_mask_3: 0.1231  loss_dice_3: 0.1671  loss_ce_4: 0.04982  loss_mask_4: 0.1215  loss_dice_4: 0.169  loss_ce_5: 0.08782  loss_mask_5: 0.1261  loss_dice_5: 0.1725  loss_ce_6: 0.06113  loss_mask_6: 0.13  loss_dice_6: 0.1734  loss_ce_7: 0.07108  loss_mask_7: 0.1257  loss_dice_7: 0.1728  loss_ce_8: 0.09738  loss_mask_8: 0.1239  loss_dice_8: 0.1683  time: 0.2531  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:46:35] d2.utils.events INFO:  eta: 3:12:03  iter: 3799  total_loss: 3.654  loss_ce: 0.04445  loss_mask: 0.1204  loss_dice: 0.1719  loss_ce_0: 0.137  loss_mask_0: 0.1235  loss_dice_0: 0.1791  loss_ce_1: 0.04525  loss_mask_1: 0.1252  loss_dice_1: 0.1784  loss_ce_2: 0.04015  loss_mask_2: 0.1237  loss_dice_2: 0.1771  loss_ce_3: 0.04549  loss_mask_3: 0.1268  loss_dice_3: 0.1813  loss_ce_4: 0.02865  loss_mask_4: 0.1273  loss_dice_4: 0.1769  loss_ce_5: 0.04595  loss_mask_5: 0.1229  loss_dice_5: 0.1796  loss_ce_6: 0.04281  loss_mask_6: 0.1266  loss_dice_6: 0.1762  loss_ce_7: 0.04874  loss_mask_7: 0.1258  loss_dice_7: 0.1741  loss_ce_8: 0.04754  loss_mask_8: 0.126  loss_dice_8: 0.1766  time: 0.2544  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:46:45] d2.utils.events INFO:  eta: 3:15:47  iter: 3819  total_loss: 3.687  loss_ce: 0.02863  loss_mask: 0.129  loss_dice: 0.1769  loss_ce_0: 0.1338  loss_mask_0: 0.1283  loss_dice_0: 0.1821  loss_ce_1: 0.02771  loss_mask_1: 0.1267  loss_dice_1: 0.1732  loss_ce_2: 0.0324  loss_mask_2: 0.1272  loss_dice_2: 0.1782  loss_ce_3: 0.02944  loss_mask_3: 0.1351  loss_dice_3: 0.1839  loss_ce_4: 0.02546  loss_mask_4: 0.1288  loss_dice_4: 0.1784  loss_ce_5: 0.03671  loss_mask_5: 0.1349  loss_dice_5: 0.1859  loss_ce_6: 0.03943  loss_mask_6: 0.1301  loss_dice_6: 0.1752  loss_ce_7: 0.02795  loss_mask_7: 0.1287  loss_dice_7: 0.1805  loss_ce_8: 0.03109  loss_mask_8: 0.1282  loss_dice_8: 0.1791  time: 0.2556  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:46:55] d2.utils.events INFO:  eta: 3:18:04  iter: 3839  total_loss: 3.519  loss_ce: 0.02381  loss_mask: 0.1284  loss_dice: 0.184  loss_ce_0: 0.1362  loss_mask_0: 0.1265  loss_dice_0: 0.1788  loss_ce_1: 0.06585  loss_mask_1: 0.1284  loss_dice_1: 0.1828  loss_ce_2: 0.03856  loss_mask_2: 0.13  loss_dice_2: 0.179  loss_ce_3: 0.01551  loss_mask_3: 0.1311  loss_dice_3: 0.1775  loss_ce_4: 0.02083  loss_mask_4: 0.1251  loss_dice_4: 0.1826  loss_ce_5: 0.0309  loss_mask_5: 0.1271  loss_dice_5: 0.1791  loss_ce_6: 0.01567  loss_mask_6: 0.1316  loss_dice_6: 0.1818  loss_ce_7: 0.02177  loss_mask_7: 0.1296  loss_dice_7: 0.1808  loss_ce_8: 0.02414  loss_mask_8: 0.1286  loss_dice_8: 0.1803  time: 0.2569  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:47:05] d2.utils.events INFO:  eta: 3:20:19  iter: 3859  total_loss: 3.741  loss_ce: 0.02068  loss_mask: 0.1233  loss_dice: 0.1786  loss_ce_0: 0.1352  loss_mask_0: 0.1299  loss_dice_0: 0.1907  loss_ce_1: 0.03951  loss_mask_1: 0.128  loss_dice_1: 0.1887  loss_ce_2: 0.02508  loss_mask_2: 0.1243  loss_dice_2: 0.1803  loss_ce_3: 0.01949  loss_mask_3: 0.1229  loss_dice_3: 0.1862  loss_ce_4: 0.02088  loss_mask_4: 0.1297  loss_dice_4: 0.1916  loss_ce_5: 0.02125  loss_mask_5: 0.1298  loss_dice_5: 0.1877  loss_ce_6: 0.02272  loss_mask_6: 0.1293  loss_dice_6: 0.1845  loss_ce_7: 0.02601  loss_mask_7: 0.1264  loss_dice_7: 0.1856  loss_ce_8: 0.01959  loss_mask_8: 0.1267  loss_dice_8: 0.1828  time: 0.2581  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:47:14] d2.utils.events INFO:  eta: 3:21:30  iter: 3879  total_loss: 3.827  loss_ce: 0.01645  loss_mask: 0.1355  loss_dice: 0.1929  loss_ce_0: 0.132  loss_mask_0: 0.1326  loss_dice_0: 0.1999  loss_ce_1: 0.01846  loss_mask_1: 0.1376  loss_dice_1: 0.2073  loss_ce_2: 0.009967  loss_mask_2: 0.1301  loss_dice_2: 0.198  loss_ce_3: 0.01914  loss_mask_3: 0.1335  loss_dice_3: 0.1958  loss_ce_4: 0.01584  loss_mask_4: 0.1268  loss_dice_4: 0.1946  loss_ce_5: 0.01198  loss_mask_5: 0.1334  loss_dice_5: 0.1986  loss_ce_6: 0.01867  loss_mask_6: 0.1342  loss_dice_6: 0.1921  loss_ce_7: 0.01119  loss_mask_7: 0.1369  loss_dice_7: 0.1987  loss_ce_8: 0.01089  loss_mask_8: 0.1356  loss_dice_8: 0.2029  time: 0.2593  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:47:24] d2.utils.events INFO:  eta: 3:22:47  iter: 3899  total_loss: 3.882  loss_ce: 0.01468  loss_mask: 0.1406  loss_dice: 0.1964  loss_ce_0: 0.1355  loss_mask_0: 0.1351  loss_dice_0: 0.1929  loss_ce_1: 0.02997  loss_mask_1: 0.1421  loss_dice_1: 0.1936  loss_ce_2: 0.01138  loss_mask_2: 0.1446  loss_dice_2: 0.195  loss_ce_3: 0.0134  loss_mask_3: 0.1481  loss_dice_3: 0.1983  loss_ce_4: 0.007537  loss_mask_4: 0.1364  loss_dice_4: 0.1922  loss_ce_5: 0.0171  loss_mask_5: 0.1385  loss_dice_5: 0.1888  loss_ce_6: 0.01425  loss_mask_6: 0.1408  loss_dice_6: 0.189  loss_ce_7: 0.01194  loss_mask_7: 0.132  loss_dice_7: 0.1895  loss_ce_8: 0.01829  loss_mask_8: 0.1412  loss_dice_8: 0.1909  time: 0.2605  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:47:34] d2.utils.events INFO:  eta: 3:24:20  iter: 3919  total_loss: 4.196  loss_ce: 0.03847  loss_mask: 0.1319  loss_dice: 0.1815  loss_ce_0: 0.1339  loss_mask_0: 0.134  loss_dice_0: 0.1817  loss_ce_1: 0.1088  loss_mask_1: 0.1317  loss_dice_1: 0.1814  loss_ce_2: 0.09484  loss_mask_2: 0.1321  loss_dice_2: 0.1815  loss_ce_3: 0.03491  loss_mask_3: 0.1333  loss_dice_3: 0.1816  loss_ce_4: 0.04893  loss_mask_4: 0.1299  loss_dice_4: 0.1847  loss_ce_5: 0.0816  loss_mask_5: 0.1307  loss_dice_5: 0.1758  loss_ce_6: 0.03446  loss_mask_6: 0.1325  loss_dice_6: 0.1824  loss_ce_7: 0.04921  loss_mask_7: 0.1293  loss_dice_7: 0.1852  loss_ce_8: 0.08341  loss_mask_8: 0.1324  loss_dice_8: 0.1789  time: 0.2617  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:47:44] d2.utils.events INFO:  eta: 3:25:36  iter: 3939  total_loss: 3.684  loss_ce: 0.01836  loss_mask: 0.1268  loss_dice: 0.1851  loss_ce_0: 0.1408  loss_mask_0: 0.1299  loss_dice_0: 0.1903  loss_ce_1: 0.04519  loss_mask_1: 0.1271  loss_dice_1: 0.1842  loss_ce_2: 0.05171  loss_mask_2: 0.1311  loss_dice_2: 0.1896  loss_ce_3: 0.0168  loss_mask_3: 0.1289  loss_dice_3: 0.1868  loss_ce_4: 0.01242  loss_mask_4: 0.1304  loss_dice_4: 0.1883  loss_ce_5: 0.02681  loss_mask_5: 0.1248  loss_dice_5: 0.1803  loss_ce_6: 0.01708  loss_mask_6: 0.1276  loss_dice_6: 0.1901  loss_ce_7: 0.01499  loss_mask_7: 0.1274  loss_dice_7: 0.1847  loss_ce_8: 0.03004  loss_mask_8: 0.1317  loss_dice_8: 0.185  time: 0.2630  data_time: 0.0013  lr: 0.0001  max_mem: 1909M
[08/01 16:47:55] d2.utils.events INFO:  eta: 3:27:55  iter: 3959  total_loss: 3.631  loss_ce: 0.00766  loss_mask: 0.1315  loss_dice: 0.1914  loss_ce_0: 0.1387  loss_mask_0: 0.1318  loss_dice_0: 0.1927  loss_ce_1: 0.02723  loss_mask_1: 0.1292  loss_dice_1: 0.1843  loss_ce_2: 0.02036  loss_mask_2: 0.1292  loss_dice_2: 0.1885  loss_ce_3: 0.007279  loss_mask_3: 0.1296  loss_dice_3: 0.1786  loss_ce_4: 0.00582  loss_mask_4: 0.1269  loss_dice_4: 0.1838  loss_ce_5: 0.01485  loss_mask_5: 0.1308  loss_dice_5: 0.1824  loss_ce_6: 0.007635  loss_mask_6: 0.1253  loss_dice_6: 0.1802  loss_ce_7: 0.007953  loss_mask_7: 0.1264  loss_dice_7: 0.178  loss_ce_8: 0.01238  loss_mask_8: 0.1278  loss_dice_8: 0.1822  time: 0.2644  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:48:09] d2.utils.events INFO:  eta: 3:29:58  iter: 3979  total_loss: 3.486  loss_ce: 0.01735  loss_mask: 0.1311  loss_dice: 0.1745  loss_ce_0: 0.1374  loss_mask_0: 0.1289  loss_dice_0: 0.1785  loss_ce_1: 0.03151  loss_mask_1: 0.1322  loss_dice_1: 0.1794  loss_ce_2: 0.02442  loss_mask_2: 0.1295  loss_dice_2: 0.1765  loss_ce_3: 0.01569  loss_mask_3: 0.1292  loss_dice_3: 0.1704  loss_ce_4: 0.01824  loss_mask_4: 0.1293  loss_dice_4: 0.179  loss_ce_5: 0.0195  loss_mask_5: 0.1338  loss_dice_5: 0.1784  loss_ce_6: 0.01764  loss_mask_6: 0.1302  loss_dice_6: 0.1764  loss_ce_7: 0.02531  loss_mask_7: 0.1324  loss_dice_7: 0.1794  loss_ce_8: 0.01827  loss_mask_8: 0.1313  loss_dice_8: 0.1747  time: 0.2665  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:48:23] d2.utils.events INFO:  eta: 3:32:31  iter: 3999  total_loss: 3.323  loss_ce: 0.01  loss_mask: 0.1201  loss_dice: 0.1739  loss_ce_0: 0.1404  loss_mask_0: 0.1208  loss_dice_0: 0.1715  loss_ce_1: 0.01619  loss_mask_1: 0.1232  loss_dice_1: 0.1775  loss_ce_2: 0.01296  loss_mask_2: 0.1247  loss_dice_2: 0.1789  loss_ce_3: 0.009381  loss_mask_3: 0.1227  loss_dice_3: 0.1775  loss_ce_4: 0.006778  loss_mask_4: 0.1246  loss_dice_4: 0.1739  loss_ce_5: 0.01235  loss_mask_5: 0.1255  loss_dice_5: 0.1786  loss_ce_6: 0.01115  loss_mask_6: 0.1236  loss_dice_6: 0.1758  loss_ce_7: 0.009551  loss_mask_7: 0.1194  loss_dice_7: 0.1742  loss_ce_8: 0.01085  loss_mask_8: 0.1252  loss_dice_8: 0.1799  time: 0.2687  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:48:38] d2.utils.events INFO:  eta: 3:34:46  iter: 4019  total_loss: 3.469  loss_ce: 0.007178  loss_mask: 0.13  loss_dice: 0.181  loss_ce_0: 0.1366  loss_mask_0: 0.13  loss_dice_0: 0.1798  loss_ce_1: 0.009161  loss_mask_1: 0.1309  loss_dice_1: 0.1786  loss_ce_2: 0.009657  loss_mask_2: 0.1301  loss_dice_2: 0.1768  loss_ce_3: 0.01209  loss_mask_3: 0.1296  loss_dice_3: 0.1797  loss_ce_4: 0.007431  loss_mask_4: 0.1262  loss_dice_4: 0.1752  loss_ce_5: 0.008861  loss_mask_5: 0.129  loss_dice_5: 0.18  loss_ce_6: 0.01183  loss_mask_6: 0.1329  loss_dice_6: 0.1817  loss_ce_7: 0.01366  loss_mask_7: 0.132  loss_dice_7: 0.1839  loss_ce_8: 0.006232  loss_mask_8: 0.1284  loss_dice_8: 0.1837  time: 0.2712  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:48:54] d2.utils.events INFO:  eta: 3:37:27  iter: 4039  total_loss: 3.58  loss_ce: 0.003656  loss_mask: 0.1242  loss_dice: 0.1913  loss_ce_0: 0.1357  loss_mask_0: 0.1291  loss_dice_0: 0.1942  loss_ce_1: 0.006296  loss_mask_1: 0.1247  loss_dice_1: 0.1926  loss_ce_2: 0.005085  loss_mask_2: 0.127  loss_dice_2: 0.1959  loss_ce_3: 0.003249  loss_mask_3: 0.1279  loss_dice_3: 0.1975  loss_ce_4: 0.002609  loss_mask_4: 0.1247  loss_dice_4: 0.1937  loss_ce_5: 0.00336  loss_mask_5: 0.1308  loss_dice_5: 0.1899  loss_ce_6: 0.005208  loss_mask_6: 0.1269  loss_dice_6: 0.1968  loss_ce_7: 0.003931  loss_mask_7: 0.1214  loss_dice_7: 0.1902  loss_ce_8: 0.004356  loss_mask_8: 0.1331  loss_dice_8: 0.1965  time: 0.2737  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:49:11] d2.utils.events INFO:  eta: 3:39:30  iter: 4059  total_loss: 3.469  loss_ce: 0.003516  loss_mask: 0.1258  loss_dice: 0.1817  loss_ce_0: 0.1379  loss_mask_0: 0.1276  loss_dice_0: 0.1767  loss_ce_1: 0.007395  loss_mask_1: 0.1282  loss_dice_1: 0.1853  loss_ce_2: 0.006493  loss_mask_2: 0.1221  loss_dice_2: 0.1791  loss_ce_3: 0.006209  loss_mask_3: 0.1291  loss_dice_3: 0.1876  loss_ce_4: 0.003151  loss_mask_4: 0.1249  loss_dice_4: 0.177  loss_ce_5: 0.006999  loss_mask_5: 0.1251  loss_dice_5: 0.1798  loss_ce_6: 0.004449  loss_mask_6: 0.1257  loss_dice_6: 0.1797  loss_ce_7: 0.003705  loss_mask_7: 0.1247  loss_dice_7: 0.1775  loss_ce_8: 0.006372  loss_mask_8: 0.1295  loss_dice_8: 0.1773  time: 0.2764  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:49:27] d2.utils.events INFO:  eta: 3:41:50  iter: 4079  total_loss: 3.657  loss_ce: 0.005369  loss_mask: 0.1346  loss_dice: 0.1792  loss_ce_0: 0.1365  loss_mask_0: 0.1346  loss_dice_0: 0.1806  loss_ce_1: 0.02513  loss_mask_1: 0.1303  loss_dice_1: 0.1832  loss_ce_2: 0.01245  loss_mask_2: 0.1325  loss_dice_2: 0.1894  loss_ce_3: 0.009528  loss_mask_3: 0.1286  loss_dice_3: 0.1882  loss_ce_4: 0.006665  loss_mask_4: 0.135  loss_dice_4: 0.19  loss_ce_5: 0.007797  loss_mask_5: 0.1252  loss_dice_5: 0.1791  loss_ce_6: 0.007612  loss_mask_6: 0.1323  loss_dice_6: 0.1819  loss_ce_7: 0.003873  loss_mask_7: 0.1335  loss_dice_7: 0.1869  loss_ce_8: 0.00909  loss_mask_8: 0.1304  loss_dice_8: 0.1917  time: 0.2792  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:49:44] d2.utils.events INFO:  eta: 3:43:50  iter: 4099  total_loss: 3.338  loss_ce: 0.003591  loss_mask: 0.1231  loss_dice: 0.1813  loss_ce_0: 0.137  loss_mask_0: 0.1259  loss_dice_0: 0.1871  loss_ce_1: 0.02158  loss_mask_1: 0.1274  loss_dice_1: 0.1865  loss_ce_2: 0.008199  loss_mask_2: 0.1297  loss_dice_2: 0.195  loss_ce_3: 0.003256  loss_mask_3: 0.1265  loss_dice_3: 0.1875  loss_ce_4: 0.00294  loss_mask_4: 0.1261  loss_dice_4: 0.1882  loss_ce_5: 0.004515  loss_mask_5: 0.1244  loss_dice_5: 0.1867  loss_ce_6: 0.004744  loss_mask_6: 0.13  loss_dice_6: 0.189  loss_ce_7: 0.004057  loss_mask_7: 0.1304  loss_dice_7: 0.1882  loss_ce_8: 0.005902  loss_mask_8: 0.1308  loss_dice_8: 0.1921  time: 0.2819  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:50:00] d2.utils.events INFO:  eta: 3:48:06  iter: 4119  total_loss: 3.426  loss_ce: 0.00486  loss_mask: 0.1243  loss_dice: 0.1835  loss_ce_0: 0.1379  loss_mask_0: 0.1243  loss_dice_0: 0.1829  loss_ce_1: 0.01533  loss_mask_1: 0.1293  loss_dice_1: 0.1868  loss_ce_2: 0.008641  loss_mask_2: 0.1252  loss_dice_2: 0.1823  loss_ce_3: 0.004988  loss_mask_3: 0.1271  loss_dice_3: 0.1884  loss_ce_4: 0.003208  loss_mask_4: 0.1272  loss_dice_4: 0.1902  loss_ce_5: 0.004991  loss_mask_5: 0.1218  loss_dice_5: 0.1865  loss_ce_6: 0.006319  loss_mask_6: 0.1278  loss_dice_6: 0.187  loss_ce_7: 0.003424  loss_mask_7: 0.1266  loss_dice_7: 0.1883  loss_ce_8: 0.006057  loss_mask_8: 0.127  loss_dice_8: 0.1899  time: 0.2843  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:50:15] d2.utils.events INFO:  eta: 3:54:46  iter: 4139  total_loss: 3.199  loss_ce: 0.003066  loss_mask: 0.1219  loss_dice: 0.1799  loss_ce_0: 0.1347  loss_mask_0: 0.1233  loss_dice_0: 0.1758  loss_ce_1: 0.007086  loss_mask_1: 0.1214  loss_dice_1: 0.1784  loss_ce_2: 0.002954  loss_mask_2: 0.1239  loss_dice_2: 0.1796  loss_ce_3: 0.003404  loss_mask_3: 0.1196  loss_dice_3: 0.1742  loss_ce_4: 0.001353  loss_mask_4: 0.1255  loss_dice_4: 0.1803  loss_ce_5: 0.001326  loss_mask_5: 0.118  loss_dice_5: 0.1785  loss_ce_6: 0.004125  loss_mask_6: 0.1199  loss_dice_6: 0.1818  loss_ce_7: 0.001234  loss_mask_7: 0.1192  loss_dice_7: 0.1762  loss_ce_8: 0.002239  loss_mask_8: 0.1214  loss_dice_8: 0.1806  time: 0.2867  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:50:32] d2.utils.events INFO:  eta: 3:59:08  iter: 4159  total_loss: 3.488  loss_ce: 0.001845  loss_mask: 0.1363  loss_dice: 0.1911  loss_ce_0: 0.1357  loss_mask_0: 0.1305  loss_dice_0: 0.1877  loss_ce_1: 0.006356  loss_mask_1: 0.134  loss_dice_1: 0.1955  loss_ce_2: 0.002254  loss_mask_2: 0.1301  loss_dice_2: 0.1906  loss_ce_3: 0.002637  loss_mask_3: 0.1271  loss_dice_3: 0.1899  loss_ce_4: 0.0009889  loss_mask_4: 0.128  loss_dice_4: 0.1969  loss_ce_5: 0.001488  loss_mask_5: 0.1304  loss_dice_5: 0.188  loss_ce_6: 0.002612  loss_mask_6: 0.1321  loss_dice_6: 0.1919  loss_ce_7: 0.001119  loss_mask_7: 0.1326  loss_dice_7: 0.1893  loss_ce_8: 0.001982  loss_mask_8: 0.1308  loss_dice_8: 0.1923  time: 0.2892  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:50:48] d2.utils.events INFO:  eta: 4:02:03  iter: 4179  total_loss: 3.292  loss_ce: 0.0009106  loss_mask: 0.1221  loss_dice: 0.1837  loss_ce_0: 0.135  loss_mask_0: 0.1283  loss_dice_0: 0.1833  loss_ce_1: 0.002411  loss_mask_1: 0.1291  loss_dice_1: 0.1854  loss_ce_2: 0.001122  loss_mask_2: 0.1266  loss_dice_2: 0.1864  loss_ce_3: 0.0008662  loss_mask_3: 0.1297  loss_dice_3: 0.1901  loss_ce_4: 0.0007482  loss_mask_4: 0.1273  loss_dice_4: 0.1875  loss_ce_5: 0.0009513  loss_mask_5: 0.1258  loss_dice_5: 0.182  loss_ce_6: 0.001183  loss_mask_6: 0.1288  loss_dice_6: 0.1905  loss_ce_7: 0.0006177  loss_mask_7: 0.1265  loss_dice_7: 0.1884  loss_ce_8: 0.001132  loss_mask_8: 0.1308  loss_dice_8: 0.1926  time: 0.2918  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:51:05] d2.utils.events INFO:  eta: 4:05:18  iter: 4199  total_loss: 3.36  loss_ce: 0.0008735  loss_mask: 0.1322  loss_dice: 0.1846  loss_ce_0: 0.1307  loss_mask_0: 0.1321  loss_dice_0: 0.1894  loss_ce_1: 0.00284  loss_mask_1: 0.1265  loss_dice_1: 0.1831  loss_ce_2: 0.001042  loss_mask_2: 0.1321  loss_dice_2: 0.1868  loss_ce_3: 0.0008178  loss_mask_3: 0.1274  loss_dice_3: 0.1807  loss_ce_4: 0.0006563  loss_mask_4: 0.1331  loss_dice_4: 0.1944  loss_ce_5: 0.0009331  loss_mask_5: 0.1311  loss_dice_5: 0.1848  loss_ce_6: 0.001121  loss_mask_6: 0.1283  loss_dice_6: 0.1794  loss_ce_7: 0.0005528  loss_mask_7: 0.1282  loss_dice_7: 0.1853  loss_ce_8: 0.001045  loss_mask_8: 0.1294  loss_dice_8: 0.1855  time: 0.2944  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:51:21] d2.utils.events INFO:  eta: 4:07:31  iter: 4219  total_loss: 3.13  loss_ce: 0.0008645  loss_mask: 0.1248  loss_dice: 0.1762  loss_ce_0: 0.1413  loss_mask_0: 0.121  loss_dice_0: 0.1749  loss_ce_1: 0.001719  loss_mask_1: 0.1244  loss_dice_1: 0.1776  loss_ce_2: 0.001068  loss_mask_2: 0.1242  loss_dice_2: 0.1747  loss_ce_3: 0.001275  loss_mask_3: 0.1222  loss_dice_3: 0.1745  loss_ce_4: 0.000575  loss_mask_4: 0.1223  loss_dice_4: 0.1751  loss_ce_5: 0.0008967  loss_mask_5: 0.1226  loss_dice_5: 0.1805  loss_ce_6: 0.001187  loss_mask_6: 0.1204  loss_dice_6: 0.1739  loss_ce_7: 0.0005198  loss_mask_7: 0.1217  loss_dice_7: 0.1733  loss_ce_8: 0.0009537  loss_mask_8: 0.1221  loss_dice_8: 0.1741  time: 0.2969  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:51:38] d2.utils.events INFO:  eta: 4:09:34  iter: 4239  total_loss: 3.202  loss_ce: 0.0008708  loss_mask: 0.1192  loss_dice: 0.1758  loss_ce_0: 0.1337  loss_mask_0: 0.1221  loss_dice_0: 0.1685  loss_ce_1: 0.001838  loss_mask_1: 0.1202  loss_dice_1: 0.1744  loss_ce_2: 0.0008227  loss_mask_2: 0.1255  loss_dice_2: 0.1776  loss_ce_3: 0.001331  loss_mask_3: 0.1217  loss_dice_3: 0.1763  loss_ce_4: 0.0006879  loss_mask_4: 0.1247  loss_dice_4: 0.1843  loss_ce_5: 0.000831  loss_mask_5: 0.1206  loss_dice_5: 0.1733  loss_ce_6: 0.001592  loss_mask_6: 0.1216  loss_dice_6: 0.1722  loss_ce_7: 0.0005969  loss_mask_7: 0.1207  loss_dice_7: 0.1794  loss_ce_8: 0.0008766  loss_mask_8: 0.1234  loss_dice_8: 0.1793  time: 0.2995  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:51:55] d2.utils.events INFO:  eta: 4:11:23  iter: 4259  total_loss: 3.552  loss_ce: 0.001231  loss_mask: 0.1268  loss_dice: 0.1783  loss_ce_0: 0.1361  loss_mask_0: 0.1255  loss_dice_0: 0.1821  loss_ce_1: 0.002288  loss_mask_1: 0.1277  loss_dice_1: 0.1815  loss_ce_2: 0.002284  loss_mask_2: 0.1268  loss_dice_2: 0.1815  loss_ce_3: 0.001843  loss_mask_3: 0.1344  loss_dice_3: 0.1837  loss_ce_4: 0.0007804  loss_mask_4: 0.1302  loss_dice_4: 0.1804  loss_ce_5: 0.001097  loss_mask_5: 0.1276  loss_dice_5: 0.1778  loss_ce_6: 0.00193  loss_mask_6: 0.1231  loss_dice_6: 0.1734  loss_ce_7: 0.000845  loss_mask_7: 0.1285  loss_dice_7: 0.1799  loss_ce_8: 0.001192  loss_mask_8: 0.1256  loss_dice_8: 0.1719  time: 0.3020  data_time: 0.0014  lr: 0.0001  max_mem: 1909M
[08/01 16:52:12] d2.utils.events INFO:  eta: 4:12:26  iter: 4279  total_loss: 3.626  loss_ce: 0.001952  loss_mask: 0.1349  loss_dice: 0.1892  loss_ce_0: 0.1325  loss_mask_0: 0.1298  loss_dice_0: 0.189  loss_ce_1: 0.003145  loss_mask_1: 0.1337  loss_dice_1: 0.184  loss_ce_2: 0.0007998  loss_mask_2: 0.1377  loss_dice_2: 0.1943  loss_ce_3: 0.003011  loss_mask_3: 0.1346  loss_dice_3: 0.1922  loss_ce_4: 0.001607  loss_mask_4: 0.1351  loss_dice_4: 0.185  loss_ce_5: 0.001371  loss_mask_5: 0.1339  loss_dice_5: 0.1862  loss_ce_6: 0.004638  loss_mask_6: 0.1373  loss_dice_6: 0.1921  loss_ce_7: 0.001097  loss_mask_7: 0.134  loss_dice_7: 0.1848  loss_ce_8: 0.0009672  loss_mask_8: 0.1343  loss_dice_8: 0.1969  time: 0.3045  data_time: 0.0013  lr: 0.0001  max_mem: 1909M
[08/01 16:52:29] d2.utils.events INFO:  eta: 4:14:58  iter: 4299  total_loss: 3.548  loss_ce: 0.001506  loss_mask: 0.1291  loss_dice: 0.1912  loss_ce_0: 0.1317  loss_mask_0: 0.1286  loss_dice_0: 0.2002  loss_ce_1: 0.002005  loss_mask_1: 0.1312  loss_dice_1: 0.1971  loss_ce_2: 0.001351  loss_mask_2: 0.1276  loss_dice_2: 0.1966  loss_ce_3: 0.002222  loss_mask_3: 0.1363  loss_dice_3: 0.1993  loss_ce_4: 0.001199  loss_mask_4: 0.129  loss_dice_4: 0.1956  loss_ce_5: 0.0009321  loss_mask_5: 0.1308  loss_dice_5: 0.197  loss_ce_6: 0.002141  loss_mask_6: 0.1342  loss_dice_6: 0.2002  loss_ce_7: 0.000664  loss_mask_7: 0.1386  loss_dice_7: 0.2045  loss_ce_8: 0.001176  loss_mask_8: 0.1353  loss_dice_8: 0.1992  time: 0.3070  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 16:52:45] d2.utils.events INFO:  eta: 4:17:10  iter: 4319  total_loss: 3.449  loss_ce: 0.001953  loss_mask: 0.1339  loss_dice: 0.203  loss_ce_0: 0.1323  loss_mask_0: 0.1285  loss_dice_0: 0.1931  loss_ce_1: 0.003146  loss_mask_1: 0.1321  loss_dice_1: 0.2001  loss_ce_2: 0.001398  loss_mask_2: 0.1338  loss_dice_2: 0.2059  loss_ce_3: 0.00231  loss_mask_3: 0.1331  loss_dice_3: 0.2056  loss_ce_4: 0.001531  loss_mask_4: 0.131  loss_dice_4: 0.2002  loss_ce_5: 0.00104  loss_mask_5: 0.1279  loss_dice_5: 0.1986  loss_ce_6: 0.002932  loss_mask_6: 0.1329  loss_dice_6: 0.1969  loss_ce_7: 0.001119  loss_mask_7: 0.1272  loss_dice_7: 0.1992  loss_ce_8: 0.001133  loss_mask_8: 0.1298  loss_dice_8: 0.2027  time: 0.3095  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:53:02] d2.utils.events INFO:  eta: 4:18:54  iter: 4339  total_loss: 3.245  loss_ce: 0.0007636  loss_mask: 0.1325  loss_dice: 0.184  loss_ce_0: 0.1362  loss_mask_0: 0.1282  loss_dice_0: 0.1845  loss_ce_1: 0.001783  loss_mask_1: 0.1316  loss_dice_1: 0.1776  loss_ce_2: 0.001107  loss_mask_2: 0.1297  loss_dice_2: 0.1827  loss_ce_3: 0.0008293  loss_mask_3: 0.129  loss_dice_3: 0.181  loss_ce_4: 0.0005401  loss_mask_4: 0.1268  loss_dice_4: 0.1771  loss_ce_5: 0.0005556  loss_mask_5: 0.1243  loss_dice_5: 0.1783  loss_ce_6: 0.0008446  loss_mask_6: 0.1264  loss_dice_6: 0.1764  loss_ce_7: 0.0004347  loss_mask_7: 0.1249  loss_dice_7: 0.1801  loss_ce_8: 0.001106  loss_mask_8: 0.128  loss_dice_8: 0.1803  time: 0.3119  data_time: 0.0013  lr: 0.0001  max_mem: 1909M
[08/01 16:53:19] d2.utils.events INFO:  eta: 4:21:23  iter: 4359  total_loss: 3.299  loss_ce: 0.0007357  loss_mask: 0.1265  loss_dice: 0.182  loss_ce_0: 0.1361  loss_mask_0: 0.1288  loss_dice_0: 0.1815  loss_ce_1: 0.001693  loss_mask_1: 0.1276  loss_dice_1: 0.1825  loss_ce_2: 0.000961  loss_mask_2: 0.1317  loss_dice_2: 0.1782  loss_ce_3: 0.0007223  loss_mask_3: 0.1341  loss_dice_3: 0.1785  loss_ce_4: 0.0005264  loss_mask_4: 0.133  loss_dice_4: 0.1839  loss_ce_5: 0.0004881  loss_mask_5: 0.1296  loss_dice_5: 0.1803  loss_ce_6: 0.000944  loss_mask_6: 0.1266  loss_dice_6: 0.1771  loss_ce_7: 0.0005052  loss_mask_7: 0.1296  loss_dice_7: 0.1803  loss_ce_8: 0.0008582  loss_mask_8: 0.1297  loss_dice_8: 0.1769  time: 0.3144  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:53:36] d2.utils.events INFO:  eta: 4:25:27  iter: 4379  total_loss: 3.428  loss_ce: 0.0006783  loss_mask: 0.1288  loss_dice: 0.1951  loss_ce_0: 0.1351  loss_mask_0: 0.1246  loss_dice_0: 0.1881  loss_ce_1: 0.001843  loss_mask_1: 0.1294  loss_dice_1: 0.1978  loss_ce_2: 0.0006788  loss_mask_2: 0.1272  loss_dice_2: 0.1955  loss_ce_3: 0.0009593  loss_mask_3: 0.1272  loss_dice_3: 0.1996  loss_ce_4: 0.0006242  loss_mask_4: 0.1323  loss_dice_4: 0.1963  loss_ce_5: 0.000432  loss_mask_5: 0.1261  loss_dice_5: 0.1876  loss_ce_6: 0.001089  loss_mask_6: 0.1252  loss_dice_6: 0.1916  loss_ce_7: 0.0005037  loss_mask_7: 0.1283  loss_dice_7: 0.1973  loss_ce_8: 0.0006279  loss_mask_8: 0.1273  loss_dice_8: 0.1885  time: 0.3168  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:53:53] d2.utils.events INFO:  eta: 4:28:29  iter: 4399  total_loss: 3.453  loss_ce: 0.0006937  loss_mask: 0.1389  loss_dice: 0.2022  loss_ce_0: 0.1351  loss_mask_0: 0.1368  loss_dice_0: 0.1958  loss_ce_1: 0.001352  loss_mask_1: 0.1339  loss_dice_1: 0.1932  loss_ce_2: 0.0003847  loss_mask_2: 0.1364  loss_dice_2: 0.1975  loss_ce_3: 0.0006417  loss_mask_3: 0.1439  loss_dice_3: 0.2007  loss_ce_4: 0.0004877  loss_mask_4: 0.1378  loss_dice_4: 0.1948  loss_ce_5: 0.0004173  loss_mask_5: 0.1457  loss_dice_5: 0.1955  loss_ce_6: 0.0008018  loss_mask_6: 0.1362  loss_dice_6: 0.199  loss_ce_7: 0.0003725  loss_mask_7: 0.1326  loss_dice_7: 0.1911  loss_ce_8: 0.0005057  loss_mask_8: 0.133  loss_dice_8: 0.1992  time: 0.3191  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:54:10] d2.utils.events INFO:  eta: 4:33:09  iter: 4419  total_loss: 3.162  loss_ce: 0.0004699  loss_mask: 0.124  loss_dice: 0.1763  loss_ce_0: 0.1334  loss_mask_0: 0.123  loss_dice_0: 0.1756  loss_ce_1: 0.001223  loss_mask_1: 0.1286  loss_dice_1: 0.1815  loss_ce_2: 0.0005889  loss_mask_2: 0.1288  loss_dice_2: 0.1844  loss_ce_3: 0.0005497  loss_mask_3: 0.1298  loss_dice_3: 0.1795  loss_ce_4: 0.0004306  loss_mask_4: 0.1251  loss_dice_4: 0.1752  loss_ce_5: 0.0003736  loss_mask_5: 0.128  loss_dice_5: 0.1735  loss_ce_6: 0.0006791  loss_mask_6: 0.1296  loss_dice_6: 0.1813  loss_ce_7: 0.0003792  loss_mask_7: 0.1268  loss_dice_7: 0.1784  loss_ce_8: 0.0005052  loss_mask_8: 0.1284  loss_dice_8: 0.1775  time: 0.3215  data_time: 0.0013  lr: 0.0001  max_mem: 1909M
[08/01 16:54:27] d2.utils.events INFO:  eta: 4:40:13  iter: 4439  total_loss: 3.286  loss_ce: 0.0004691  loss_mask: 0.1274  loss_dice: 0.1845  loss_ce_0: 0.1339  loss_mask_0: 0.1269  loss_dice_0: 0.1818  loss_ce_1: 0.001274  loss_mask_1: 0.1302  loss_dice_1: 0.1882  loss_ce_2: 0.0005051  loss_mask_2: 0.128  loss_dice_2: 0.1852  loss_ce_3: 0.0006135  loss_mask_3: 0.1267  loss_dice_3: 0.1817  loss_ce_4: 0.0004435  loss_mask_4: 0.1305  loss_dice_4: 0.185  loss_ce_5: 0.0003235  loss_mask_5: 0.1272  loss_dice_5: 0.1819  loss_ce_6: 0.0006406  loss_mask_6: 0.1299  loss_dice_6: 0.1862  loss_ce_7: 0.0003338  loss_mask_7: 0.1271  loss_dice_7: 0.1826  loss_ce_8: 0.0004425  loss_mask_8: 0.1294  loss_dice_8: 0.1835  time: 0.3239  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:54:43] d2.utils.events INFO:  eta: 5:22:49  iter: 4459  total_loss: 3.521  loss_ce: 0.0003419  loss_mask: 0.1368  loss_dice: 0.2036  loss_ce_0: 0.1335  loss_mask_0: 0.1303  loss_dice_0: 0.2065  loss_ce_1: 0.0007805  loss_mask_1: 0.133  loss_dice_1: 0.2063  loss_ce_2: 0.0004045  loss_mask_2: 0.1334  loss_dice_2: 0.2081  loss_ce_3: 0.000388  loss_mask_3: 0.1329  loss_dice_3: 0.2022  loss_ce_4: 0.000348  loss_mask_4: 0.1306  loss_dice_4: 0.1961  loss_ce_5: 0.0002703  loss_mask_5: 0.1356  loss_dice_5: 0.2015  loss_ce_6: 0.0004421  loss_mask_6: 0.1323  loss_dice_6: 0.2033  loss_ce_7: 0.0002762  loss_mask_7: 0.1348  loss_dice_7: 0.2111  loss_ce_8: 0.0003816  loss_mask_8: 0.1316  loss_dice_8: 0.202  time: 0.3262  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:55:00] d2.utils.events INFO:  eta: 5:50:22  iter: 4479  total_loss: 3.348  loss_ce: 0.0003851  loss_mask: 0.1286  loss_dice: 0.1833  loss_ce_0: 0.1332  loss_mask_0: 0.1271  loss_dice_0: 0.1912  loss_ce_1: 0.0008044  loss_mask_1: 0.1275  loss_dice_1: 0.1912  loss_ce_2: 0.0003796  loss_mask_2: 0.1309  loss_dice_2: 0.1885  loss_ce_3: 0.0002916  loss_mask_3: 0.1268  loss_dice_3: 0.186  loss_ce_4: 0.0003179  loss_mask_4: 0.1283  loss_dice_4: 0.1905  loss_ce_5: 0.000201  loss_mask_5: 0.1325  loss_dice_5: 0.1822  loss_ce_6: 0.0004642  loss_mask_6: 0.1316  loss_dice_6: 0.1824  loss_ce_7: 0.0002353  loss_mask_7: 0.1301  loss_dice_7: 0.1868  loss_ce_8: 0.0003751  loss_mask_8: 0.1316  loss_dice_8: 0.1919  time: 0.3285  data_time: 0.0015  lr: 0.0001  max_mem: 1909M
[08/01 16:55:17] d2.utils.events INFO:  eta: 6:08:32  iter: 4499  total_loss: 3.694  loss_ce: 0.0006991  loss_mask: 0.1336  loss_dice: 0.2016  loss_ce_0: 0.1321  loss_mask_0: 0.1341  loss_dice_0: 0.2038  loss_ce_1: 0.00116  loss_mask_1: 0.1356  loss_dice_1: 0.1988  loss_ce_2: 0.0005945  loss_mask_2: 0.1361  loss_dice_2: 0.1934  loss_ce_3: 0.0007513  loss_mask_3: 0.1324  loss_dice_3: 0.1977  loss_ce_4: 0.0006024  loss_mask_4: 0.1313  loss_dice_4: 0.1958  loss_ce_5: 0.0003902  loss_mask_5: 0.1377  loss_dice_5: 0.1907  loss_ce_6: 0.0009649  loss_mask_6: 0.1308  loss_dice_6: 0.1912  loss_ce_7: 0.0005506  loss_mask_7: 0.1336  loss_dice_7: 0.1914  loss_ce_8: 0.0005189  loss_mask_8: 0.1312  loss_dice_8: 0.1917  time: 0.3309  data_time: 0.0014  lr: 0.0001  max_mem: 1909M
[08/01 16:55:34] d2.utils.events INFO:  eta: 6:21:39  iter: 4519  total_loss: 3.445  loss_ce: 0.0005844  loss_mask: 0.1336  loss_dice: 0.1978  loss_ce_0: 0.1281  loss_mask_0: 0.1324  loss_dice_0: 0.2061  loss_ce_1: 0.00124  loss_mask_1: 0.1309  loss_dice_1: 0.1977  loss_ce_2: 0.000663  loss_mask_2: 0.1312  loss_dice_2: 0.1928  loss_ce_3: 0.0009664  loss_mask_3: 0.132  loss_dice_3: 0.192  loss_ce_4: 0.0006723  loss_mask_4: 0.1299  loss_dice_4: 0.1911  loss_ce_5: 0.0003074  loss_mask_5: 0.1309  loss_dice_5: 0.1913  loss_ce_6: 0.001278  loss_mask_6: 0.1344  loss_dice_6: 0.2038  loss_ce_7: 0.0007461  loss_mask_7: 0.1325  loss_dice_7: 0.1909  loss_ce_8: 0.0004955  loss_mask_8: 0.1305  loss_dice_8: 0.1957  time: 0.3331  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:55:51] d2.utils.events INFO:  eta: 6:28:52  iter: 4539  total_loss: 3.463  loss_ce: 0.0007118  loss_mask: 0.1317  loss_dice: 0.1967  loss_ce_0: 0.1284  loss_mask_0: 0.1287  loss_dice_0: 0.2024  loss_ce_1: 0.001427  loss_mask_1: 0.1303  loss_dice_1: 0.1914  loss_ce_2: 0.0009029  loss_mask_2: 0.1297  loss_dice_2: 0.2001  loss_ce_3: 0.001858  loss_mask_3: 0.1316  loss_dice_3: 0.1973  loss_ce_4: 0.0009672  loss_mask_4: 0.1309  loss_dice_4: 0.1931  loss_ce_5: 0.0006712  loss_mask_5: 0.1307  loss_dice_5: 0.198  loss_ce_6: 0.001831  loss_mask_6: 0.131  loss_dice_6: 0.1998  loss_ce_7: 0.0009121  loss_mask_7: 0.1334  loss_dice_7: 0.2047  loss_ce_8: 0.0005946  loss_mask_8: 0.1339  loss_dice_8: 0.1954  time: 0.3353  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:56:08] d2.utils.events INFO:  eta: 6:32:52  iter: 4559  total_loss: 3.759  loss_ce: 0.00576  loss_mask: 0.1337  loss_dice: 0.1979  loss_ce_0: 0.1325  loss_mask_0: 0.1327  loss_dice_0: 0.1978  loss_ce_1: 0.0067  loss_mask_1: 0.1381  loss_dice_1: 0.201  loss_ce_2: 0.002713  loss_mask_2: 0.1408  loss_dice_2: 0.1971  loss_ce_3: 0.01166  loss_mask_3: 0.1335  loss_dice_3: 0.1995  loss_ce_4: 0.008051  loss_mask_4: 0.1442  loss_dice_4: 0.2001  loss_ce_5: 0.003186  loss_mask_5: 0.1353  loss_dice_5: 0.1935  loss_ce_6: 0.01453  loss_mask_6: 0.1341  loss_dice_6: 0.2057  loss_ce_7: 0.01168  loss_mask_7: 0.1361  loss_dice_7: 0.1959  loss_ce_8: 0.004666  loss_mask_8: 0.1419  loss_dice_8: 0.2024  time: 0.3375  data_time: 0.0014  lr: 0.0001  max_mem: 1909M
[08/01 16:56:25] d2.utils.events INFO:  eta: 6:35:26  iter: 4579  total_loss: 3.324  loss_ce: 0.0009919  loss_mask: 0.1237  loss_dice: 0.1936  loss_ce_0: 0.1322  loss_mask_0: 0.1232  loss_dice_0: 0.1838  loss_ce_1: 0.003512  loss_mask_1: 0.1251  loss_dice_1: 0.1901  loss_ce_2: 0.001697  loss_mask_2: 0.1256  loss_dice_2: 0.1828  loss_ce_3: 0.001751  loss_mask_3: 0.1222  loss_dice_3: 0.1924  loss_ce_4: 0.003267  loss_mask_4: 0.1267  loss_dice_4: 0.1853  loss_ce_5: 0.001125  loss_mask_5: 0.1328  loss_dice_5: 0.1929  loss_ce_6: 0.00462  loss_mask_6: 0.1266  loss_dice_6: 0.1794  loss_ce_7: 0.001911  loss_mask_7: 0.1243  loss_dice_7: 0.1843  loss_ce_8: 0.001442  loss_mask_8: 0.1181  loss_dice_8: 0.1863  time: 0.3398  data_time: 0.0013  lr: 0.0001  max_mem: 1909M
[08/01 16:56:42] d2.utils.events INFO:  eta: 6:38:18  iter: 4599  total_loss: 3.481  loss_ce: 0.001965  loss_mask: 0.1317  loss_dice: 0.1801  loss_ce_0: 0.1331  loss_mask_0: 0.1343  loss_dice_0: 0.1861  loss_ce_1: 0.003742  loss_mask_1: 0.1296  loss_dice_1: 0.1846  loss_ce_2: 0.002447  loss_mask_2: 0.1328  loss_dice_2: 0.1802  loss_ce_3: 0.002547  loss_mask_3: 0.1297  loss_dice_3: 0.1848  loss_ce_4: 0.003017  loss_mask_4: 0.1303  loss_dice_4: 0.1876  loss_ce_5: 0.001434  loss_mask_5: 0.1333  loss_dice_5: 0.1824  loss_ce_6: 0.00319  loss_mask_6: 0.1285  loss_dice_6: 0.1877  loss_ce_7: 0.002495  loss_mask_7: 0.133  loss_dice_7: 0.1846  loss_ce_8: 0.002502  loss_mask_8: 0.134  loss_dice_8: 0.1808  time: 0.3420  data_time: 0.0015  lr: 0.0001  max_mem: 1909M
[08/01 16:56:59] d2.utils.events INFO:  eta: 6:41:22  iter: 4619  total_loss: 3.288  loss_ce: 0.00191  loss_mask: 0.1236  loss_dice: 0.1798  loss_ce_0: 0.1325  loss_mask_0: 0.1166  loss_dice_0: 0.1759  loss_ce_1: 0.002838  loss_mask_1: 0.1198  loss_dice_1: 0.1789  loss_ce_2: 0.001664  loss_mask_2: 0.1213  loss_dice_2: 0.1805  loss_ce_3: 0.001752  loss_mask_3: 0.12  loss_dice_3: 0.1782  loss_ce_4: 0.002391  loss_mask_4: 0.122  loss_dice_4: 0.1837  loss_ce_5: 0.001292  loss_mask_5: 0.1275  loss_dice_5: 0.174  loss_ce_6: 0.002246  loss_mask_6: 0.1218  loss_dice_6: 0.1798  loss_ce_7: 0.002297  loss_mask_7: 0.1178  loss_dice_7: 0.1796  loss_ce_8: 0.00192  loss_mask_8: 0.119  loss_dice_8: 0.1804  time: 0.3442  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:57:16] d2.utils.events INFO:  eta: 6:43:31  iter: 4639  total_loss: 3.289  loss_ce: 0.001835  loss_mask: 0.1269  loss_dice: 0.1825  loss_ce_0: 0.131  loss_mask_0: 0.1266  loss_dice_0: 0.1871  loss_ce_1: 0.002063  loss_mask_1: 0.128  loss_dice_1: 0.182  loss_ce_2: 0.001047  loss_mask_2: 0.1259  loss_dice_2: 0.1824  loss_ce_3: 0.001547  loss_mask_3: 0.1301  loss_dice_3: 0.1851  loss_ce_4: 0.001907  loss_mask_4: 0.1299  loss_dice_4: 0.1853  loss_ce_5: 0.0009452  loss_mask_5: 0.129  loss_dice_5: 0.1861  loss_ce_6: 0.00189  loss_mask_6: 0.1273  loss_dice_6: 0.1835  loss_ce_7: 0.001832  loss_mask_7: 0.1285  loss_dice_7: 0.1808  loss_ce_8: 0.001382  loss_mask_8: 0.1242  loss_dice_8: 0.183  time: 0.3464  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:57:33] d2.utils.events INFO:  eta: 6:45:25  iter: 4659  total_loss: 3.332  loss_ce: 0.002208  loss_mask: 0.1275  loss_dice: 0.1836  loss_ce_0: 0.1328  loss_mask_0: 0.1267  loss_dice_0: 0.1802  loss_ce_1: 0.00236  loss_mask_1: 0.1246  loss_dice_1: 0.1804  loss_ce_2: 0.0011  loss_mask_2: 0.1234  loss_dice_2: 0.1718  loss_ce_3: 0.003275  loss_mask_3: 0.1246  loss_dice_3: 0.1808  loss_ce_4: 0.001924  loss_mask_4: 0.1271  loss_dice_4: 0.1844  loss_ce_5: 0.0009763  loss_mask_5: 0.1242  loss_dice_5: 0.1859  loss_ce_6: 0.002749  loss_mask_6: 0.1232  loss_dice_6: 0.1834  loss_ce_7: 0.002067  loss_mask_7: 0.1238  loss_dice_7: 0.185  loss_ce_8: 0.001641  loss_mask_8: 0.1287  loss_dice_8: 0.1842  time: 0.3485  data_time: 0.0013  lr: 0.0001  max_mem: 1909M
[08/01 16:57:50] d2.utils.events INFO:  eta: 6:46:55  iter: 4679  total_loss: 3.403  loss_ce: 0.0007268  loss_mask: 0.1354  loss_dice: 0.1889  loss_ce_0: 0.1326  loss_mask_0: 0.1285  loss_dice_0: 0.1934  loss_ce_1: 0.0008485  loss_mask_1: 0.1286  loss_dice_1: 0.1891  loss_ce_2: 0.0004923  loss_mask_2: 0.1302  loss_dice_2: 0.1869  loss_ce_3: 0.0008595  loss_mask_3: 0.1304  loss_dice_3: 0.1877  loss_ce_4: 0.0008126  loss_mask_4: 0.1314  loss_dice_4: 0.1864  loss_ce_5: 0.0005136  loss_mask_5: 0.1316  loss_dice_5: 0.1876  loss_ce_6: 0.001035  loss_mask_6: 0.1322  loss_dice_6: 0.1846  loss_ce_7: 0.0006893  loss_mask_7: 0.1282  loss_dice_7: 0.1792  loss_ce_8: 0.0006186  loss_mask_8: 0.1275  loss_dice_8: 0.1859  time: 0.3506  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:58:06] d2.utils.events INFO:  eta: 6:47:18  iter: 4699  total_loss: 3.382  loss_ce: 0.000497  loss_mask: 0.1307  loss_dice: 0.1938  loss_ce_0: 0.1324  loss_mask_0: 0.1322  loss_dice_0: 0.193  loss_ce_1: 0.0006849  loss_mask_1: 0.1339  loss_dice_1: 0.1943  loss_ce_2: 0.0003652  loss_mask_2: 0.1313  loss_dice_2: 0.1997  loss_ce_3: 0.0004875  loss_mask_3: 0.1336  loss_dice_3: 0.1937  loss_ce_4: 0.0005612  loss_mask_4: 0.1284  loss_dice_4: 0.1942  loss_ce_5: 0.0004306  loss_mask_5: 0.1308  loss_dice_5: 0.1885  loss_ce_6: 0.0007085  loss_mask_6: 0.1309  loss_dice_6: 0.1948  loss_ce_7: 0.0004626  loss_mask_7: 0.1273  loss_dice_7: 0.1908  loss_ce_8: 0.0004627  loss_mask_8: 0.1289  loss_dice_8: 0.1995  time: 0.3525  data_time: 0.0013  lr: 0.0001  max_mem: 1909M
[08/01 16:58:22] d2.utils.events INFO:  eta: 6:47:35  iter: 4719  total_loss: 3.02  loss_ce: 0.0007108  loss_mask: 0.1214  loss_dice: 0.1693  loss_ce_0: 0.1318  loss_mask_0: 0.1185  loss_dice_0: 0.1716  loss_ce_1: 0.001096  loss_mask_1: 0.1235  loss_dice_1: 0.1713  loss_ce_2: 0.0005556  loss_mask_2: 0.1227  loss_dice_2: 0.1661  loss_ce_3: 0.0009527  loss_mask_3: 0.1198  loss_dice_3: 0.1672  loss_ce_4: 0.0007332  loss_mask_4: 0.1226  loss_dice_4: 0.1699  loss_ce_5: 0.0005214  loss_mask_5: 0.1198  loss_dice_5: 0.1689  loss_ce_6: 0.001044  loss_mask_6: 0.1224  loss_dice_6: 0.1652  loss_ce_7: 0.0006924  loss_mask_7: 0.1192  loss_dice_7: 0.1683  loss_ce_8: 0.0005406  loss_mask_8: 0.1228  loss_dice_8: 0.1694  time: 0.3544  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:58:37] d2.utils.events INFO:  eta: 6:47:33  iter: 4739  total_loss: 3.063  loss_ce: 0.0005314  loss_mask: 0.1267  loss_dice: 0.1727  loss_ce_0: 0.1313  loss_mask_0: 0.122  loss_dice_0: 0.173  loss_ce_1: 0.0007846  loss_mask_1: 0.1213  loss_dice_1: 0.1712  loss_ce_2: 0.0004015  loss_mask_2: 0.122  loss_dice_2: 0.1745  loss_ce_3: 0.0005425  loss_mask_3: 0.1254  loss_dice_3: 0.1768  loss_ce_4: 0.0006141  loss_mask_4: 0.1209  loss_dice_4: 0.1721  loss_ce_5: 0.0004288  loss_mask_5: 0.1211  loss_dice_5: 0.17  loss_ce_6: 0.0006956  loss_mask_6: 0.1212  loss_dice_6: 0.1723  loss_ce_7: 0.0005705  loss_mask_7: 0.1225  loss_dice_7: 0.1772  loss_ce_8: 0.0003866  loss_mask_8: 0.1208  loss_dice_8: 0.1724  time: 0.3562  data_time: 0.0015  lr: 0.0001  max_mem: 1909M
[08/01 16:58:53] d2.utils.events INFO:  eta: 6:47:59  iter: 4759  total_loss: 3.253  loss_ce: 0.0004724  loss_mask: 0.1297  loss_dice: 0.1788  loss_ce_0: 0.1315  loss_mask_0: 0.1318  loss_dice_0: 0.1773  loss_ce_1: 0.0008386  loss_mask_1: 0.1218  loss_dice_1: 0.173  loss_ce_2: 0.0003978  loss_mask_2: 0.1288  loss_dice_2: 0.1755  loss_ce_3: 0.0005664  loss_mask_3: 0.1239  loss_dice_3: 0.1733  loss_ce_4: 0.0005182  loss_mask_4: 0.1248  loss_dice_4: 0.1739  loss_ce_5: 0.0004132  loss_mask_5: 0.1268  loss_dice_5: 0.1743  loss_ce_6: 0.0006292  loss_mask_6: 0.1248  loss_dice_6: 0.1704  loss_ce_7: 0.0005147  loss_mask_7: 0.1245  loss_dice_7: 0.1701  loss_ce_8: 0.0004258  loss_mask_8: 0.1256  loss_dice_8: 0.174  time: 0.3581  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:59:09] d2.utils.events INFO:  eta: 6:48:27  iter: 4779  total_loss: 3.349  loss_ce: 0.0009586  loss_mask: 0.1247  loss_dice: 0.1888  loss_ce_0: 0.1327  loss_mask_0: 0.126  loss_dice_0: 0.1915  loss_ce_1: 0.000997  loss_mask_1: 0.1288  loss_dice_1: 0.1904  loss_ce_2: 0.0006234  loss_mask_2: 0.1212  loss_dice_2: 0.1817  loss_ce_3: 0.0009138  loss_mask_3: 0.1252  loss_dice_3: 0.1873  loss_ce_4: 0.0006796  loss_mask_4: 0.1238  loss_dice_4: 0.1844  loss_ce_5: 0.0005407  loss_mask_5: 0.1265  loss_dice_5: 0.186  loss_ce_6: 0.000853  loss_mask_6: 0.1271  loss_dice_6: 0.1914  loss_ce_7: 0.0008364  loss_mask_7: 0.1232  loss_dice_7: 0.1821  loss_ce_8: 0.001072  loss_mask_8: 0.1214  loss_dice_8: 0.187  time: 0.3599  data_time: 0.0013  lr: 0.0001  max_mem: 1909M
[08/01 16:59:25] d2.utils.events INFO:  eta: 6:48:52  iter: 4799  total_loss: 3.049  loss_ce: 0.0004465  loss_mask: 0.1186  loss_dice: 0.1733  loss_ce_0: 0.132  loss_mask_0: 0.123  loss_dice_0: 0.1762  loss_ce_1: 0.0007139  loss_mask_1: 0.1191  loss_dice_1: 0.1713  loss_ce_2: 0.0003467  loss_mask_2: 0.1171  loss_dice_2: 0.1748  loss_ce_3: 0.0004709  loss_mask_3: 0.1193  loss_dice_3: 0.1742  loss_ce_4: 0.0003627  loss_mask_4: 0.1196  loss_dice_4: 0.1718  loss_ce_5: 0.0002904  loss_mask_5: 0.1263  loss_dice_5: 0.1765  loss_ce_6: 0.0005219  loss_mask_6: 0.1194  loss_dice_6: 0.1686  loss_ce_7: 0.0003768  loss_mask_7: 0.1191  loss_dice_7: 0.17  loss_ce_8: 0.0005283  loss_mask_8: 0.1214  loss_dice_8: 0.1736  time: 0.3617  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 16:59:41] d2.utils.events INFO:  eta: 6:49:12  iter: 4819  total_loss: 3.114  loss_ce: 0.0005343  loss_mask: 0.1222  loss_dice: 0.179  loss_ce_0: 0.1312  loss_mask_0: 0.1243  loss_dice_0: 0.1809  loss_ce_1: 0.0008158  loss_mask_1: 0.1232  loss_dice_1: 0.1763  loss_ce_2: 0.0004952  loss_mask_2: 0.1209  loss_dice_2: 0.1793  loss_ce_3: 0.0006845  loss_mask_3: 0.1237  loss_dice_3: 0.1766  loss_ce_4: 0.0005302  loss_mask_4: 0.1232  loss_dice_4: 0.1817  loss_ce_5: 0.0004348  loss_mask_5: 0.1247  loss_dice_5: 0.1791  loss_ce_6: 0.0006147  loss_mask_6: 0.1189  loss_dice_6: 0.1783  loss_ce_7: 0.0006447  loss_mask_7: 0.1217  loss_dice_7: 0.1746  loss_ce_8: 0.0007596  loss_mask_8: 0.1248  loss_dice_8: 0.182  time: 0.3635  data_time: 0.0015  lr: 0.0001  max_mem: 1909M
[08/01 16:59:57] d2.utils.events INFO:  eta: 6:49:38  iter: 4839  total_loss: 3.094  loss_ce: 0.0002551  loss_mask: 0.1179  loss_dice: 0.1756  loss_ce_0: 0.1264  loss_mask_0: 0.1185  loss_dice_0: 0.1698  loss_ce_1: 0.0002165  loss_mask_1: 0.1172  loss_dice_1: 0.1716  loss_ce_2: 0.0002307  loss_mask_2: 0.1208  loss_dice_2: 0.1725  loss_ce_3: 0.0002422  loss_mask_3: 0.1211  loss_dice_3: 0.1691  loss_ce_4: 0.0001855  loss_mask_4: 0.1212  loss_dice_4: 0.1727  loss_ce_5: 0.0001739  loss_mask_5: 0.1246  loss_dice_5: 0.179  loss_ce_6: 0.0002892  loss_mask_6: 0.1182  loss_dice_6: 0.1696  loss_ce_7: 0.0001165  loss_mask_7: 0.1154  loss_dice_7: 0.1741  loss_ce_8: 0.0003599  loss_mask_8: 0.1179  loss_dice_8: 0.174  time: 0.3653  data_time: 0.0013  lr: 0.0001  max_mem: 1909M
[08/01 17:00:13] d2.utils.events INFO:  eta: 6:49:58  iter: 4859  total_loss: 2.909  loss_ce: 9.015e-05  loss_mask: 0.1198  loss_dice: 0.1754  loss_ce_0: 0.1363  loss_mask_0: 0.1191  loss_dice_0: 0.1717  loss_ce_1: 0.0001636  loss_mask_1: 0.1154  loss_dice_1: 0.1669  loss_ce_2: 0.0001174  loss_mask_2: 0.119  loss_dice_2: 0.1708  loss_ce_3: 0.0001226  loss_mask_3: 0.1229  loss_dice_3: 0.1745  loss_ce_4: 0.0001109  loss_mask_4: 0.1224  loss_dice_4: 0.171  loss_ce_5: 0.0001241  loss_mask_5: 0.1179  loss_dice_5: 0.1717  loss_ce_6: 0.0001331  loss_mask_6: 0.1132  loss_dice_6: 0.1678  loss_ce_7: 7.575e-05  loss_mask_7: 0.1174  loss_dice_7: 0.1693  loss_ce_8: 0.0001477  loss_mask_8: 0.1186  loss_dice_8: 0.1692  time: 0.3670  data_time: 0.0019  lr: 0.0001  max_mem: 1909M
[08/01 17:00:29] d2.utils.events INFO:  eta: 6:49:56  iter: 4879  total_loss: 3.893  loss_ce: 0.000226  loss_mask: 0.1412  loss_dice: 0.2312  loss_ce_0: 0.1344  loss_mask_0: 0.1432  loss_dice_0: 0.2213  loss_ce_1: 0.0004932  loss_mask_1: 0.1424  loss_dice_1: 0.2328  loss_ce_2: 0.0002787  loss_mask_2: 0.1429  loss_dice_2: 0.2376  loss_ce_3: 0.0003422  loss_mask_3: 0.1446  loss_dice_3: 0.2369  loss_ce_4: 0.0002455  loss_mask_4: 0.1421  loss_dice_4: 0.2354  loss_ce_5: 0.0002248  loss_mask_5: 0.1365  loss_dice_5: 0.2238  loss_ce_6: 0.0004067  loss_mask_6: 0.1472  loss_dice_6: 0.2355  loss_ce_7: 0.0002619  loss_mask_7: 0.1451  loss_dice_7: 0.232  loss_ce_8: 0.0004254  loss_mask_8: 0.1421  loss_dice_8: 0.2261  time: 0.3688  data_time: 0.0017  lr: 0.0001  max_mem: 1909M
[08/01 17:00:44] d2.utils.events INFO:  eta: 6:49:54  iter: 4899  total_loss: 3.617  loss_ce: 0.0004839  loss_mask: 0.1431  loss_dice: 0.1954  loss_ce_0: 0.1315  loss_mask_0: 0.1469  loss_dice_0: 0.1999  loss_ce_1: 0.001532  loss_mask_1: 0.1477  loss_dice_1: 0.1927  loss_ce_2: 0.0006572  loss_mask_2: 0.1411  loss_dice_2: 0.2018  loss_ce_3: 0.0004996  loss_mask_3: 0.1435  loss_dice_3: 0.1986  loss_ce_4: 0.0003558  loss_mask_4: 0.1439  loss_dice_4: 0.1972  loss_ce_5: 0.0003286  loss_mask_5: 0.1449  loss_dice_5: 0.2002  loss_ce_6: 0.0005015  loss_mask_6: 0.139  loss_dice_6: 0.2004  loss_ce_7: 0.0005091  loss_mask_7: 0.1458  loss_dice_7: 0.1992  loss_ce_8: 0.0005686  loss_mask_8: 0.1416  loss_dice_8: 0.194  time: 0.3705  data_time: 0.0013  lr: 0.0001  max_mem: 1909M
[08/01 17:01:00] d2.utils.events INFO:  eta: 6:50:14  iter: 4919  total_loss: 3.717  loss_ce: 0.0003787  loss_mask: 0.1442  loss_dice: 0.2092  loss_ce_0: 0.1333  loss_mask_0: 0.1387  loss_dice_0: 0.2219  loss_ce_1: 0.04737  loss_mask_1: 0.145  loss_dice_1: 0.2187  loss_ce_2: 0.0005726  loss_mask_2: 0.1409  loss_dice_2: 0.218  loss_ce_3: 0.0004013  loss_mask_3: 0.1438  loss_dice_3: 0.2185  loss_ce_4: 0.0004495  loss_mask_4: 0.1414  loss_dice_4: 0.2156  loss_ce_5: 0.0005105  loss_mask_5: 0.1451  loss_dice_5: 0.2161  loss_ce_6: 0.0003851  loss_mask_6: 0.1485  loss_dice_6: 0.2172  loss_ce_7: 0.0004443  loss_mask_7: 0.1382  loss_dice_7: 0.209  loss_ce_8: 0.0005111  loss_mask_8: 0.1398  loss_dice_8: 0.216  time: 0.3722  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 17:01:16] d2.utils.events INFO:  eta: 6:50:31  iter: 4939  total_loss: 3.021  loss_ce: 0.0003157  loss_mask: 0.1176  loss_dice: 0.1694  loss_ce_0: 0.1298  loss_mask_0: 0.1165  loss_dice_0: 0.1743  loss_ce_1: 0.004187  loss_mask_1: 0.1174  loss_dice_1: 0.1698  loss_ce_2: 0.000533  loss_mask_2: 0.1183  loss_dice_2: 0.1701  loss_ce_3: 0.0004076  loss_mask_3: 0.1161  loss_dice_3: 0.1685  loss_ce_4: 0.0005121  loss_mask_4: 0.1145  loss_dice_4: 0.166  loss_ce_5: 0.0003561  loss_mask_5: 0.1224  loss_dice_5: 0.1714  loss_ce_6: 0.0002369  loss_mask_6: 0.1191  loss_dice_6: 0.1676  loss_ce_7: 0.0004551  loss_mask_7: 0.1157  loss_dice_7: 0.1677  loss_ce_8: 0.0004449  loss_mask_8: 0.1166  loss_dice_8: 0.1631  time: 0.3740  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 17:01:32] d2.utils.events INFO:  eta: 6:50:26  iter: 4959  total_loss: 3.308  loss_ce: 0.0001569  loss_mask: 0.121  loss_dice: 0.186  loss_ce_0: 0.1279  loss_mask_0: 0.1217  loss_dice_0: 0.1885  loss_ce_1: 0.002669  loss_mask_1: 0.1246  loss_dice_1: 0.1827  loss_ce_2: 0.000151  loss_mask_2: 0.1232  loss_dice_2: 0.1864  loss_ce_3: 0.0002859  loss_mask_3: 0.1224  loss_dice_3: 0.184  loss_ce_4: 0.0001553  loss_mask_4: 0.1212  loss_dice_4: 0.1857  loss_ce_5: 0.000101  loss_mask_5: 0.1182  loss_dice_5: 0.1822  loss_ce_6: 0.0001785  loss_mask_6: 0.1274  loss_dice_6: 0.1814  loss_ce_7: 8.52e-05  loss_mask_7: 0.1225  loss_dice_7: 0.1822  loss_ce_8: 0.0001312  loss_mask_8: 0.1236  loss_dice_8: 0.185  time: 0.3757  data_time: 0.0012  lr: 0.0001  max_mem: 1909M
[08/01 17:01:48] d2.utils.events INFO:  eta: 6:50:42  iter: 4979  total_loss: 3.545  loss_ce: 0.0007976  loss_mask: 0.1324  loss_dice: 0.1872  loss_ce_0: 0.1345  loss_mask_0: 0.1326  loss_dice_0: 0.1893  loss_ce_1: 0.004255  loss_mask_1: 0.1297  loss_dice_1: 0.1865  loss_ce_2: 0.001196  loss_mask_2: 0.1352  loss_dice_2: 0.1812  loss_ce_3: 0.0009687  loss_mask_3: 0.1376  loss_dice_3: 0.1852  loss_ce_4: 0.0009751  loss_mask_4: 0.1353  loss_dice_4: 0.1893  loss_ce_5: 0.0008452  loss_mask_5: 0.1398  loss_dice_5: 0.1856  loss_ce_6: 0.0009048  loss_mask_6: 0.1326  loss_dice_6: 0.1869  loss_ce_7: 0.00104  loss_mask_7: 0.1356  loss_dice_7: 0.1838  loss_ce_8: 0.0009114  loss_mask_8: 0.1328  loss_dice_8: 0.18  time: 0.3773  data_time: 0.0011  lr: 0.0001  max_mem: 1909M
[08/01 17:02:04] fvcore.common.checkpoint INFO: Saving checkpoint to ./R101_overlap/model_0004999.pth
[08/01 17:02:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(256, 256), max_size=256, sample_style='choice')]
[08/01 17:02:04] d2.data.common INFO: Serializing 535 elements to byte tensors and concatenating them all ...
[08/01 17:02:04] d2.data.common INFO: Serialized dataset takes 0.22 MiB
[08/01 17:02:04] d2.evaluation.evaluator INFO: Start inference on 535 batches
[08/01 17:02:27] d2.evaluation.evaluator INFO: Inference done 11/535. Dataloading: 0.0004 s/iter. Inference: 1.0856 s/iter. Eval: 0.9368 s/iter. Total: 2.0229 s/iter. ETA=0:17:40
[08/01 17:02:34] d2.evaluation.evaluator INFO: Inference done 14/535. Dataloading: 0.0006 s/iter. Inference: 1.1142 s/iter. Eval: 0.9416 s/iter. Total: 2.0565 s/iter. ETA=0:17:51
[08/01 17:02:40] d2.evaluation.evaluator INFO: Inference done 17/535. Dataloading: 0.0006 s/iter. Inference: 1.0900 s/iter. Eval: 0.9586 s/iter. Total: 2.0493 s/iter. ETA=0:17:41
[08/01 17:02:46] d2.evaluation.evaluator INFO: Inference done 20/535. Dataloading: 0.0006 s/iter. Inference: 1.1042 s/iter. Eval: 0.9536 s/iter. Total: 2.0585 s/iter. ETA=0:17:40
[08/01 17:02:52] d2.evaluation.evaluator INFO: Inference done 23/535. Dataloading: 0.0006 s/iter. Inference: 1.0936 s/iter. Eval: 0.9512 s/iter. Total: 2.0455 s/iter. ETA=0:17:27
[08/01 17:02:58] d2.evaluation.evaluator INFO: Inference done 26/535. Dataloading: 0.0007 s/iter. Inference: 1.1034 s/iter. Eval: 0.9517 s/iter. Total: 2.0558 s/iter. ETA=0:17:26
[08/01 17:03:04] d2.evaluation.evaluator INFO: Inference done 29/535. Dataloading: 0.0007 s/iter. Inference: 1.1027 s/iter. Eval: 0.9514 s/iter. Total: 2.0548 s/iter. ETA=0:17:19
[08/01 17:03:11] d2.evaluation.evaluator INFO: Inference done 32/535. Dataloading: 0.0007 s/iter. Inference: 1.1122 s/iter. Eval: 0.9500 s/iter. Total: 2.0630 s/iter. ETA=0:17:17
[08/01 17:03:17] d2.evaluation.evaluator INFO: Inference done 35/535. Dataloading: 0.0007 s/iter. Inference: 1.1166 s/iter. Eval: 0.9497 s/iter. Total: 2.0670 s/iter. ETA=0:17:13
[08/01 17:03:23] d2.evaluation.evaluator INFO: Inference done 38/535. Dataloading: 0.0007 s/iter. Inference: 1.1182 s/iter. Eval: 0.9500 s/iter. Total: 2.0689 s/iter. ETA=0:17:08
[08/01 17:03:29] d2.evaluation.evaluator INFO: Inference done 41/535. Dataloading: 0.0007 s/iter. Inference: 1.1135 s/iter. Eval: 0.9500 s/iter. Total: 2.0643 s/iter. ETA=0:16:59
[08/01 17:03:36] d2.evaluation.evaluator INFO: Inference done 44/535. Dataloading: 0.0007 s/iter. Inference: 1.1164 s/iter. Eval: 0.9502 s/iter. Total: 2.0675 s/iter. ETA=0:16:55
[08/01 17:03:42] d2.evaluation.evaluator INFO: Inference done 47/535. Dataloading: 0.0007 s/iter. Inference: 1.1216 s/iter. Eval: 0.9528 s/iter. Total: 2.0752 s/iter. ETA=0:16:52
[08/01 17:03:49] d2.evaluation.evaluator INFO: Inference done 50/535. Dataloading: 0.0007 s/iter. Inference: 1.1239 s/iter. Eval: 0.9551 s/iter. Total: 2.0798 s/iter. ETA=0:16:48
[08/01 17:03:55] d2.evaluation.evaluator INFO: Inference done 53/535. Dataloading: 0.0007 s/iter. Inference: 1.1205 s/iter. Eval: 0.9553 s/iter. Total: 2.0766 s/iter. ETA=0:16:40
[08/01 17:04:01] d2.evaluation.evaluator INFO: Inference done 56/535. Dataloading: 0.0007 s/iter. Inference: 1.1226 s/iter. Eval: 0.9564 s/iter. Total: 2.0798 s/iter. ETA=0:16:36
[08/01 17:04:07] d2.evaluation.evaluator INFO: Inference done 59/535. Dataloading: 0.0007 s/iter. Inference: 1.1215 s/iter. Eval: 0.9565 s/iter. Total: 2.0789 s/iter. ETA=0:16:29
[08/01 17:04:14] d2.evaluation.evaluator INFO: Inference done 62/535. Dataloading: 0.0007 s/iter. Inference: 1.1232 s/iter. Eval: 0.9563 s/iter. Total: 2.0803 s/iter. ETA=0:16:23
[08/01 17:04:20] d2.evaluation.evaluator INFO: Inference done 65/535. Dataloading: 0.0007 s/iter. Inference: 1.1207 s/iter. Eval: 0.9572 s/iter. Total: 2.0787 s/iter. ETA=0:16:16
[08/01 17:04:26] d2.evaluation.evaluator INFO: Inference done 68/535. Dataloading: 0.0007 s/iter. Inference: 1.1216 s/iter. Eval: 0.9562 s/iter. Total: 2.0786 s/iter. ETA=0:16:10
[08/01 17:04:32] d2.evaluation.evaluator INFO: Inference done 71/535. Dataloading: 0.0007 s/iter. Inference: 1.1217 s/iter. Eval: 0.9551 s/iter. Total: 2.0776 s/iter. ETA=0:16:03
[08/01 17:04:38] d2.evaluation.evaluator INFO: Inference done 74/535. Dataloading: 0.0007 s/iter. Inference: 1.1196 s/iter. Eval: 0.9556 s/iter. Total: 2.0761 s/iter. ETA=0:15:57
[08/01 17:04:45] d2.evaluation.evaluator INFO: Inference done 77/535. Dataloading: 0.0007 s/iter. Inference: 1.1209 s/iter. Eval: 0.9547 s/iter. Total: 2.0764 s/iter. ETA=0:15:50
[08/01 17:04:51] d2.evaluation.evaluator INFO: Inference done 80/535. Dataloading: 0.0007 s/iter. Inference: 1.1208 s/iter. Eval: 0.9548 s/iter. Total: 2.0764 s/iter. ETA=0:15:44
[08/01 17:04:57] d2.evaluation.evaluator INFO: Inference done 83/535. Dataloading: 0.0007 s/iter. Inference: 1.1190 s/iter. Eval: 0.9543 s/iter. Total: 2.0742 s/iter. ETA=0:15:37
[08/01 17:05:03] d2.evaluation.evaluator INFO: Inference done 86/535. Dataloading: 0.0007 s/iter. Inference: 1.1197 s/iter. Eval: 0.9546 s/iter. Total: 2.0751 s/iter. ETA=0:15:31
[08/01 17:05:10] d2.evaluation.evaluator INFO: Inference done 89/535. Dataloading: 0.0007 s/iter. Inference: 1.1198 s/iter. Eval: 0.9550 s/iter. Total: 2.0757 s/iter. ETA=0:15:25
[08/01 17:05:16] d2.evaluation.evaluator INFO: Inference done 92/535. Dataloading: 0.0007 s/iter. Inference: 1.1198 s/iter. Eval: 0.9548 s/iter. Total: 2.0755 s/iter. ETA=0:15:19
[08/01 17:05:22] d2.evaluation.evaluator INFO: Inference done 95/535. Dataloading: 0.0007 s/iter. Inference: 1.1204 s/iter. Eval: 0.9553 s/iter. Total: 2.0765 s/iter. ETA=0:15:13
[08/01 17:05:28] d2.evaluation.evaluator INFO: Inference done 98/535. Dataloading: 0.0007 s/iter. Inference: 1.1211 s/iter. Eval: 0.9545 s/iter. Total: 2.0765 s/iter. ETA=0:15:07
[08/01 17:05:34] d2.evaluation.evaluator INFO: Inference done 101/535. Dataloading: 0.0007 s/iter. Inference: 1.1208 s/iter. Eval: 0.9543 s/iter. Total: 2.0760 s/iter. ETA=0:15:00
[08/01 17:05:41] d2.evaluation.evaluator INFO: Inference done 104/535. Dataloading: 0.0007 s/iter. Inference: 1.1208 s/iter. Eval: 0.9540 s/iter. Total: 2.0756 s/iter. ETA=0:14:54
[08/01 17:05:47] d2.evaluation.evaluator INFO: Inference done 107/535. Dataloading: 0.0007 s/iter. Inference: 1.1208 s/iter. Eval: 0.9550 s/iter. Total: 2.0767 s/iter. ETA=0:14:48
[08/01 17:05:53] d2.evaluation.evaluator INFO: Inference done 110/535. Dataloading: 0.0007 s/iter. Inference: 1.1227 s/iter. Eval: 0.9551 s/iter. Total: 2.0787 s/iter. ETA=0:14:43
[08/01 17:06:00] d2.evaluation.evaluator INFO: Inference done 113/535. Dataloading: 0.0007 s/iter. Inference: 1.1227 s/iter. Eval: 0.9554 s/iter. Total: 2.0790 s/iter. ETA=0:14:37
[08/01 17:06:06] d2.evaluation.evaluator INFO: Inference done 116/535. Dataloading: 0.0007 s/iter. Inference: 1.1228 s/iter. Eval: 0.9559 s/iter. Total: 2.0795 s/iter. ETA=0:14:31
[08/01 17:06:12] d2.evaluation.evaluator INFO: Inference done 119/535. Dataloading: 0.0007 s/iter. Inference: 1.1239 s/iter. Eval: 0.9557 s/iter. Total: 2.0804 s/iter. ETA=0:14:25
[08/01 17:06:18] d2.evaluation.evaluator INFO: Inference done 122/535. Dataloading: 0.0007 s/iter. Inference: 1.1227 s/iter. Eval: 0.9550 s/iter. Total: 2.0786 s/iter. ETA=0:14:18
[08/01 17:06:24] d2.evaluation.evaluator INFO: Inference done 125/535. Dataloading: 0.0007 s/iter. Inference: 1.1212 s/iter. Eval: 0.9556 s/iter. Total: 2.0776 s/iter. ETA=0:14:11
[08/01 17:06:31] d2.evaluation.evaluator INFO: Inference done 128/535. Dataloading: 0.0007 s/iter. Inference: 1.1213 s/iter. Eval: 0.9552 s/iter. Total: 2.0773 s/iter. ETA=0:14:05
[08/01 17:06:37] d2.evaluation.evaluator INFO: Inference done 131/535. Dataloading: 0.0007 s/iter. Inference: 1.1222 s/iter. Eval: 0.9548 s/iter. Total: 2.0779 s/iter. ETA=0:13:59
[08/01 17:06:43] d2.evaluation.evaluator INFO: Inference done 134/535. Dataloading: 0.0007 s/iter. Inference: 1.1214 s/iter. Eval: 0.9544 s/iter. Total: 2.0767 s/iter. ETA=0:13:52
[08/01 17:06:49] d2.evaluation.evaluator INFO: Inference done 137/535. Dataloading: 0.0007 s/iter. Inference: 1.1197 s/iter. Eval: 0.9542 s/iter. Total: 2.0747 s/iter. ETA=0:13:45
[08/01 17:06:55] d2.evaluation.evaluator INFO: Inference done 140/535. Dataloading: 0.0007 s/iter. Inference: 1.1177 s/iter. Eval: 0.9538 s/iter. Total: 2.0724 s/iter. ETA=0:13:38
[08/01 17:07:01] d2.evaluation.evaluator INFO: Inference done 143/535. Dataloading: 0.0007 s/iter. Inference: 1.1184 s/iter. Eval: 0.9539 s/iter. Total: 2.0731 s/iter. ETA=0:13:32
[08/01 17:07:07] d2.evaluation.evaluator INFO: Inference done 146/535. Dataloading: 0.0007 s/iter. Inference: 1.1176 s/iter. Eval: 0.9533 s/iter. Total: 2.0718 s/iter. ETA=0:13:25
[08/01 17:07:13] d2.evaluation.evaluator INFO: Inference done 149/535. Dataloading: 0.0007 s/iter. Inference: 1.1159 s/iter. Eval: 0.9530 s/iter. Total: 2.0697 s/iter. ETA=0:13:18
[08/01 17:07:19] d2.evaluation.evaluator INFO: Inference done 152/535. Dataloading: 0.0007 s/iter. Inference: 1.1155 s/iter. Eval: 0.9525 s/iter. Total: 2.0688 s/iter. ETA=0:13:12
[08/01 17:07:25] d2.evaluation.evaluator INFO: Inference done 155/535. Dataloading: 0.0007 s/iter. Inference: 1.1148 s/iter. Eval: 0.9521 s/iter. Total: 2.0677 s/iter. ETA=0:13:05
[08/01 17:07:32] d2.evaluation.evaluator INFO: Inference done 158/535. Dataloading: 0.0007 s/iter. Inference: 1.1153 s/iter. Eval: 0.9519 s/iter. Total: 2.0681 s/iter. ETA=0:12:59
[08/01 17:07:38] d2.evaluation.evaluator INFO: Inference done 161/535. Dataloading: 0.0007 s/iter. Inference: 1.1149 s/iter. Eval: 0.9516 s/iter. Total: 2.0674 s/iter. ETA=0:12:53
[08/01 17:07:44] d2.evaluation.evaluator INFO: Inference done 164/535. Dataloading: 0.0007 s/iter. Inference: 1.1154 s/iter. Eval: 0.9515 s/iter. Total: 2.0678 s/iter. ETA=0:12:47
[08/01 17:07:50] d2.evaluation.evaluator INFO: Inference done 167/535. Dataloading: 0.0007 s/iter. Inference: 1.1161 s/iter. Eval: 0.9516 s/iter. Total: 2.0686 s/iter. ETA=0:12:41
[08/01 17:07:56] d2.evaluation.evaluator INFO: Inference done 170/535. Dataloading: 0.0007 s/iter. Inference: 1.1153 s/iter. Eval: 0.9514 s/iter. Total: 2.0675 s/iter. ETA=0:12:34
[08/01 17:08:03] d2.evaluation.evaluator INFO: Inference done 173/535. Dataloading: 0.0007 s/iter. Inference: 1.1157 s/iter. Eval: 0.9515 s/iter. Total: 2.0680 s/iter. ETA=0:12:28
[08/01 17:08:09] d2.evaluation.evaluator INFO: Inference done 176/535. Dataloading: 0.0007 s/iter. Inference: 1.1144 s/iter. Eval: 0.9513 s/iter. Total: 2.0665 s/iter. ETA=0:12:21
[08/01 17:08:15] d2.evaluation.evaluator INFO: Inference done 179/535. Dataloading: 0.0007 s/iter. Inference: 1.1147 s/iter. Eval: 0.9513 s/iter. Total: 2.0669 s/iter. ETA=0:12:15
[08/01 17:08:21] d2.evaluation.evaluator INFO: Inference done 182/535. Dataloading: 0.0007 s/iter. Inference: 1.1143 s/iter. Eval: 0.9515 s/iter. Total: 2.0667 s/iter. ETA=0:12:09
[08/01 17:08:27] d2.evaluation.evaluator INFO: Inference done 185/535. Dataloading: 0.0007 s/iter. Inference: 1.1149 s/iter. Eval: 0.9516 s/iter. Total: 2.0673 s/iter. ETA=0:12:03
[08/01 17:08:33] d2.evaluation.evaluator INFO: Inference done 188/535. Dataloading: 0.0007 s/iter. Inference: 1.1152 s/iter. Eval: 0.9513 s/iter. Total: 2.0673 s/iter. ETA=0:11:57
[08/01 17:08:40] d2.evaluation.evaluator INFO: Inference done 191/535. Dataloading: 0.0007 s/iter. Inference: 1.1155 s/iter. Eval: 0.9512 s/iter. Total: 2.0675 s/iter. ETA=0:11:51
[08/01 17:08:46] d2.evaluation.evaluator INFO: Inference done 194/535. Dataloading: 0.0007 s/iter. Inference: 1.1157 s/iter. Eval: 0.9515 s/iter. Total: 2.0680 s/iter. ETA=0:11:45
[08/01 17:08:52] d2.evaluation.evaluator INFO: Inference done 197/535. Dataloading: 0.0007 s/iter. Inference: 1.1142 s/iter. Eval: 0.9514 s/iter. Total: 2.0664 s/iter. ETA=0:11:38
[08/01 17:08:58] d2.evaluation.evaluator INFO: Inference done 200/535. Dataloading: 0.0007 s/iter. Inference: 1.1144 s/iter. Eval: 0.9515 s/iter. Total: 2.0668 s/iter. ETA=0:11:32
[08/01 17:09:05] d2.evaluation.evaluator INFO: Inference done 203/535. Dataloading: 0.0007 s/iter. Inference: 1.1152 s/iter. Eval: 0.9517 s/iter. Total: 2.0677 s/iter. ETA=0:11:26
[08/01 17:09:11] d2.evaluation.evaluator INFO: Inference done 206/535. Dataloading: 0.0007 s/iter. Inference: 1.1157 s/iter. Eval: 0.9515 s/iter. Total: 2.0680 s/iter. ETA=0:11:20
[08/01 17:09:17] d2.evaluation.evaluator INFO: Inference done 209/535. Dataloading: 0.0007 s/iter. Inference: 1.1162 s/iter. Eval: 0.9521 s/iter. Total: 2.0691 s/iter. ETA=0:11:14
[08/01 17:09:23] d2.evaluation.evaluator INFO: Inference done 212/535. Dataloading: 0.0007 s/iter. Inference: 1.1162 s/iter. Eval: 0.9518 s/iter. Total: 2.0689 s/iter. ETA=0:11:08
[08/01 17:09:30] d2.evaluation.evaluator INFO: Inference done 215/535. Dataloading: 0.0007 s/iter. Inference: 1.1158 s/iter. Eval: 0.9517 s/iter. Total: 2.0684 s/iter. ETA=0:11:01
[08/01 17:09:36] d2.evaluation.evaluator INFO: Inference done 218/535. Dataloading: 0.0007 s/iter. Inference: 1.1159 s/iter. Eval: 0.9519 s/iter. Total: 2.0687 s/iter. ETA=0:10:55
[08/01 17:09:42] d2.evaluation.evaluator INFO: Inference done 221/535. Dataloading: 0.0007 s/iter. Inference: 1.1144 s/iter. Eval: 0.9516 s/iter. Total: 2.0669 s/iter. ETA=0:10:48
[08/01 17:09:48] d2.evaluation.evaluator INFO: Inference done 224/535. Dataloading: 0.0007 s/iter. Inference: 1.1146 s/iter. Eval: 0.9514 s/iter. Total: 2.0668 s/iter. ETA=0:10:42
[08/01 17:09:54] d2.evaluation.evaluator INFO: Inference done 227/535. Dataloading: 0.0007 s/iter. Inference: 1.1156 s/iter. Eval: 0.9512 s/iter. Total: 2.0676 s/iter. ETA=0:10:36
[08/01 17:10:00] d2.evaluation.evaluator INFO: Inference done 230/535. Dataloading: 0.0007 s/iter. Inference: 1.1156 s/iter. Eval: 0.9515 s/iter. Total: 2.0680 s/iter. ETA=0:10:30
[08/01 17:10:06] d2.evaluation.evaluator INFO: Inference done 233/535. Dataloading: 0.0007 s/iter. Inference: 1.1149 s/iter. Eval: 0.9512 s/iter. Total: 2.0670 s/iter. ETA=0:10:24
[08/01 17:10:13] d2.evaluation.evaluator INFO: Inference done 236/535. Dataloading: 0.0007 s/iter. Inference: 1.1147 s/iter. Eval: 0.9513 s/iter. Total: 2.0668 s/iter. ETA=0:10:17
[08/01 17:10:19] d2.evaluation.evaluator INFO: Inference done 239/535. Dataloading: 0.0007 s/iter. Inference: 1.1136 s/iter. Eval: 0.9512 s/iter. Total: 2.0656 s/iter. ETA=0:10:11
[08/01 17:10:25] d2.evaluation.evaluator INFO: Inference done 242/535. Dataloading: 0.0007 s/iter. Inference: 1.1139 s/iter. Eval: 0.9510 s/iter. Total: 2.0658 s/iter. ETA=0:10:05
[08/01 17:10:31] d2.evaluation.evaluator INFO: Inference done 245/535. Dataloading: 0.0007 s/iter. Inference: 1.1155 s/iter. Eval: 0.9506 s/iter. Total: 2.0670 s/iter. ETA=0:09:59
[08/01 17:10:38] d2.evaluation.evaluator INFO: Inference done 248/535. Dataloading: 0.0007 s/iter. Inference: 1.1162 s/iter. Eval: 0.9503 s/iter. Total: 2.0673 s/iter. ETA=0:09:53
[08/01 17:10:44] d2.evaluation.evaluator INFO: Inference done 251/535. Dataloading: 0.0007 s/iter. Inference: 1.1159 s/iter. Eval: 0.9501 s/iter. Total: 2.0668 s/iter. ETA=0:09:46
[08/01 17:10:49] d2.evaluation.evaluator INFO: Inference done 254/535. Dataloading: 0.0007 s/iter. Inference: 1.1143 s/iter. Eval: 0.9499 s/iter. Total: 2.0651 s/iter. ETA=0:09:40
[08/01 17:10:55] d2.evaluation.evaluator INFO: Inference done 257/535. Dataloading: 0.0007 s/iter. Inference: 1.1111 s/iter. Eval: 0.9498 s/iter. Total: 2.0617 s/iter. ETA=0:09:33
[08/01 17:11:00] d2.evaluation.evaluator INFO: Inference done 260/535. Dataloading: 0.0007 s/iter. Inference: 1.1083 s/iter. Eval: 0.9496 s/iter. Total: 2.0587 s/iter. ETA=0:09:26
[08/01 17:11:06] d2.evaluation.evaluator INFO: Inference done 263/535. Dataloading: 0.0007 s/iter. Inference: 1.1056 s/iter. Eval: 0.9495 s/iter. Total: 2.0560 s/iter. ETA=0:09:19
[08/01 17:11:11] d2.evaluation.evaluator INFO: Inference done 266/535. Dataloading: 0.0007 s/iter. Inference: 1.1027 s/iter. Eval: 0.9495 s/iter. Total: 2.0530 s/iter. ETA=0:09:12
[08/01 17:11:17] d2.evaluation.evaluator INFO: Inference done 269/535. Dataloading: 0.0007 s/iter. Inference: 1.1005 s/iter. Eval: 0.9493 s/iter. Total: 2.0506 s/iter. ETA=0:09:05
[08/01 17:11:22] d2.evaluation.evaluator INFO: Inference done 272/535. Dataloading: 0.0007 s/iter. Inference: 1.0984 s/iter. Eval: 0.9489 s/iter. Total: 2.0481 s/iter. ETA=0:08:58
[08/01 17:11:27] d2.evaluation.evaluator INFO: Inference done 275/535. Dataloading: 0.0007 s/iter. Inference: 1.0958 s/iter. Eval: 0.9487 s/iter. Total: 2.0454 s/iter. ETA=0:08:51
[08/01 17:11:33] d2.evaluation.evaluator INFO: Inference done 278/535. Dataloading: 0.0007 s/iter. Inference: 1.0934 s/iter. Eval: 0.9485 s/iter. Total: 2.0428 s/iter. ETA=0:08:44
[08/01 17:11:38] d2.evaluation.evaluator INFO: Inference done 281/535. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.9484 s/iter. Total: 2.0401 s/iter. ETA=0:08:38
[08/01 17:11:44] d2.evaluation.evaluator INFO: Inference done 284/535. Dataloading: 0.0007 s/iter. Inference: 1.0887 s/iter. Eval: 0.9481 s/iter. Total: 2.0376 s/iter. ETA=0:08:31
[08/01 17:11:49] d2.evaluation.evaluator INFO: Inference done 287/535. Dataloading: 0.0007 s/iter. Inference: 1.0869 s/iter. Eval: 0.9480 s/iter. Total: 2.0357 s/iter. ETA=0:08:24
[08/01 17:11:55] d2.evaluation.evaluator INFO: Inference done 290/535. Dataloading: 0.0007 s/iter. Inference: 1.0848 s/iter. Eval: 0.9480 s/iter. Total: 2.0337 s/iter. ETA=0:08:18
[08/01 17:12:00] d2.evaluation.evaluator INFO: Inference done 293/535. Dataloading: 0.0007 s/iter. Inference: 1.0827 s/iter. Eval: 0.9476 s/iter. Total: 2.0311 s/iter. ETA=0:08:11
[08/01 17:12:06] d2.evaluation.evaluator INFO: Inference done 296/535. Dataloading: 0.0007 s/iter. Inference: 1.0805 s/iter. Eval: 0.9475 s/iter. Total: 2.0288 s/iter. ETA=0:08:04
[08/01 17:12:11] d2.evaluation.evaluator INFO: Inference done 299/535. Dataloading: 0.0007 s/iter. Inference: 1.0785 s/iter. Eval: 0.9474 s/iter. Total: 2.0268 s/iter. ETA=0:07:58
[08/01 17:12:17] d2.evaluation.evaluator INFO: Inference done 302/535. Dataloading: 0.0007 s/iter. Inference: 1.0768 s/iter. Eval: 0.9475 s/iter. Total: 2.0251 s/iter. ETA=0:07:51
[08/01 17:12:22] d2.evaluation.evaluator INFO: Inference done 305/535. Dataloading: 0.0007 s/iter. Inference: 1.0758 s/iter. Eval: 0.9475 s/iter. Total: 2.0242 s/iter. ETA=0:07:45
[08/01 17:12:28] d2.evaluation.evaluator INFO: Inference done 308/535. Dataloading: 0.0007 s/iter. Inference: 1.0740 s/iter. Eval: 0.9473 s/iter. Total: 2.0222 s/iter. ETA=0:07:39
[08/01 17:12:33] d2.evaluation.evaluator INFO: Inference done 311/535. Dataloading: 0.0007 s/iter. Inference: 1.0721 s/iter. Eval: 0.9471 s/iter. Total: 2.0201 s/iter. ETA=0:07:32
[08/01 17:12:39] d2.evaluation.evaluator INFO: Inference done 314/535. Dataloading: 0.0007 s/iter. Inference: 1.0697 s/iter. Eval: 0.9468 s/iter. Total: 2.0174 s/iter. ETA=0:07:25
[08/01 17:12:44] d2.evaluation.evaluator INFO: Inference done 317/535. Dataloading: 0.0007 s/iter. Inference: 1.0677 s/iter. Eval: 0.9468 s/iter. Total: 2.0153 s/iter. ETA=0:07:19
[08/01 17:12:50] d2.evaluation.evaluator INFO: Inference done 320/535. Dataloading: 0.0007 s/iter. Inference: 1.0664 s/iter. Eval: 0.9466 s/iter. Total: 2.0139 s/iter. ETA=0:07:12
[08/01 17:12:55] d2.evaluation.evaluator INFO: Inference done 323/535. Dataloading: 0.0007 s/iter. Inference: 1.0647 s/iter. Eval: 0.9464 s/iter. Total: 2.0119 s/iter. ETA=0:07:06
[08/01 17:13:00] d2.evaluation.evaluator INFO: Inference done 326/535. Dataloading: 0.0007 s/iter. Inference: 1.0629 s/iter. Eval: 0.9461 s/iter. Total: 2.0099 s/iter. ETA=0:07:00
[08/01 17:13:06] d2.evaluation.evaluator INFO: Inference done 329/535. Dataloading: 0.0007 s/iter. Inference: 1.0612 s/iter. Eval: 0.9460 s/iter. Total: 2.0080 s/iter. ETA=0:06:53
[08/01 17:13:11] d2.evaluation.evaluator INFO: Inference done 332/535. Dataloading: 0.0007 s/iter. Inference: 1.0596 s/iter. Eval: 0.9459 s/iter. Total: 2.0064 s/iter. ETA=0:06:47
[08/01 17:13:17] d2.evaluation.evaluator INFO: Inference done 335/535. Dataloading: 0.0007 s/iter. Inference: 1.0578 s/iter. Eval: 0.9456 s/iter. Total: 2.0043 s/iter. ETA=0:06:40
[08/01 17:13:22] d2.evaluation.evaluator INFO: Inference done 338/535. Dataloading: 0.0007 s/iter. Inference: 1.0565 s/iter. Eval: 0.9455 s/iter. Total: 2.0029 s/iter. ETA=0:06:34
[08/01 17:13:28] d2.evaluation.evaluator INFO: Inference done 341/535. Dataloading: 0.0007 s/iter. Inference: 1.0551 s/iter. Eval: 0.9454 s/iter. Total: 2.0013 s/iter. ETA=0:06:28
[08/01 17:13:33] d2.evaluation.evaluator INFO: Inference done 344/535. Dataloading: 0.0007 s/iter. Inference: 1.0532 s/iter. Eval: 0.9450 s/iter. Total: 1.9991 s/iter. ETA=0:06:21
[08/01 17:13:38] d2.evaluation.evaluator INFO: Inference done 347/535. Dataloading: 0.0007 s/iter. Inference: 1.0517 s/iter. Eval: 0.9449 s/iter. Total: 1.9975 s/iter. ETA=0:06:15
[08/01 17:13:44] d2.evaluation.evaluator INFO: Inference done 350/535. Dataloading: 0.0007 s/iter. Inference: 1.0502 s/iter. Eval: 0.9450 s/iter. Total: 1.9960 s/iter. ETA=0:06:09
[08/01 17:13:49] d2.evaluation.evaluator INFO: Inference done 353/535. Dataloading: 0.0007 s/iter. Inference: 1.0486 s/iter. Eval: 0.9447 s/iter. Total: 1.9941 s/iter. ETA=0:06:02
[08/01 17:13:55] d2.evaluation.evaluator INFO: Inference done 356/535. Dataloading: 0.0007 s/iter. Inference: 1.0473 s/iter. Eval: 0.9448 s/iter. Total: 1.9929 s/iter. ETA=0:05:56
[08/01 17:14:00] d2.evaluation.evaluator INFO: Inference done 359/535. Dataloading: 0.0007 s/iter. Inference: 1.0460 s/iter. Eval: 0.9448 s/iter. Total: 1.9917 s/iter. ETA=0:05:50
[08/01 17:14:06] d2.evaluation.evaluator INFO: Inference done 362/535. Dataloading: 0.0007 s/iter. Inference: 1.0443 s/iter. Eval: 0.9449 s/iter. Total: 1.9901 s/iter. ETA=0:05:44
[08/01 17:14:11] d2.evaluation.evaluator INFO: Inference done 365/535. Dataloading: 0.0007 s/iter. Inference: 1.0431 s/iter. Eval: 0.9447 s/iter. Total: 1.9887 s/iter. ETA=0:05:38
[08/01 17:14:16] d2.evaluation.evaluator INFO: Inference done 368/535. Dataloading: 0.0007 s/iter. Inference: 1.0416 s/iter. Eval: 0.9445 s/iter. Total: 1.9870 s/iter. ETA=0:05:31
[08/01 17:14:22] d2.evaluation.evaluator INFO: Inference done 371/535. Dataloading: 0.0007 s/iter. Inference: 1.0402 s/iter. Eval: 0.9444 s/iter. Total: 1.9855 s/iter. ETA=0:05:25
[08/01 17:14:27] d2.evaluation.evaluator INFO: Inference done 374/535. Dataloading: 0.0007 s/iter. Inference: 1.0390 s/iter. Eval: 0.9445 s/iter. Total: 1.9844 s/iter. ETA=0:05:19
[08/01 17:14:33] d2.evaluation.evaluator INFO: Inference done 377/535. Dataloading: 0.0007 s/iter. Inference: 1.0376 s/iter. Eval: 0.9443 s/iter. Total: 1.9827 s/iter. ETA=0:05:13
[08/01 17:14:38] d2.evaluation.evaluator INFO: Inference done 380/535. Dataloading: 0.0007 s/iter. Inference: 1.0365 s/iter. Eval: 0.9443 s/iter. Total: 1.9816 s/iter. ETA=0:05:07
[08/01 17:14:44] d2.evaluation.evaluator INFO: Inference done 383/535. Dataloading: 0.0007 s/iter. Inference: 1.0351 s/iter. Eval: 0.9440 s/iter. Total: 1.9800 s/iter. ETA=0:05:00
[08/01 17:14:49] d2.evaluation.evaluator INFO: Inference done 386/535. Dataloading: 0.0007 s/iter. Inference: 1.0342 s/iter. Eval: 0.9439 s/iter. Total: 1.9789 s/iter. ETA=0:04:54
[08/01 17:14:55] d2.evaluation.evaluator INFO: Inference done 389/535. Dataloading: 0.0007 s/iter. Inference: 1.0329 s/iter. Eval: 0.9439 s/iter. Total: 1.9777 s/iter. ETA=0:04:48
[08/01 17:15:00] d2.evaluation.evaluator INFO: Inference done 392/535. Dataloading: 0.0007 s/iter. Inference: 1.0318 s/iter. Eval: 0.9442 s/iter. Total: 1.9768 s/iter. ETA=0:04:42
[08/01 17:15:05] d2.evaluation.evaluator INFO: Inference done 395/535. Dataloading: 0.0007 s/iter. Inference: 1.0301 s/iter. Eval: 0.9442 s/iter. Total: 1.9752 s/iter. ETA=0:04:36
[08/01 17:15:11] d2.evaluation.evaluator INFO: Inference done 398/535. Dataloading: 0.0007 s/iter. Inference: 1.0291 s/iter. Eval: 0.9442 s/iter. Total: 1.9741 s/iter. ETA=0:04:30
[08/01 17:15:16] d2.evaluation.evaluator INFO: Inference done 401/535. Dataloading: 0.0007 s/iter. Inference: 1.0278 s/iter. Eval: 0.9439 s/iter. Total: 1.9726 s/iter. ETA=0:04:24
[08/01 17:15:22] d2.evaluation.evaluator INFO: Inference done 404/535. Dataloading: 0.0007 s/iter. Inference: 1.0266 s/iter. Eval: 0.9439 s/iter. Total: 1.9714 s/iter. ETA=0:04:18
[08/01 17:15:27] d2.evaluation.evaluator INFO: Inference done 407/535. Dataloading: 0.0007 s/iter. Inference: 1.0255 s/iter. Eval: 0.9437 s/iter. Total: 1.9701 s/iter. ETA=0:04:12
[08/01 17:15:33] d2.evaluation.evaluator INFO: Inference done 410/535. Dataloading: 0.0007 s/iter. Inference: 1.0246 s/iter. Eval: 0.9438 s/iter. Total: 1.9692 s/iter. ETA=0:04:06
[08/01 17:15:38] d2.evaluation.evaluator INFO: Inference done 413/535. Dataloading: 0.0007 s/iter. Inference: 1.0236 s/iter. Eval: 0.9440 s/iter. Total: 1.9685 s/iter. ETA=0:04:00
[08/01 17:15:44] d2.evaluation.evaluator INFO: Inference done 416/535. Dataloading: 0.0007 s/iter. Inference: 1.0228 s/iter. Eval: 0.9439 s/iter. Total: 1.9675 s/iter. ETA=0:03:54
[08/01 17:15:49] d2.evaluation.evaluator INFO: Inference done 419/535. Dataloading: 0.0007 s/iter. Inference: 1.0219 s/iter. Eval: 0.9438 s/iter. Total: 1.9665 s/iter. ETA=0:03:48
[08/01 17:15:55] d2.evaluation.evaluator INFO: Inference done 422/535. Dataloading: 0.0007 s/iter. Inference: 1.0207 s/iter. Eval: 0.9437 s/iter. Total: 1.9653 s/iter. ETA=0:03:42
[08/01 17:16:00] d2.evaluation.evaluator INFO: Inference done 425/535. Dataloading: 0.0007 s/iter. Inference: 1.0192 s/iter. Eval: 0.9439 s/iter. Total: 1.9640 s/iter. ETA=0:03:36
[08/01 17:16:06] d2.evaluation.evaluator INFO: Inference done 428/535. Dataloading: 0.0007 s/iter. Inference: 1.0182 s/iter. Eval: 0.9439 s/iter. Total: 1.9630 s/iter. ETA=0:03:30
[08/01 17:16:11] d2.evaluation.evaluator INFO: Inference done 431/535. Dataloading: 0.0007 s/iter. Inference: 1.0171 s/iter. Eval: 0.9440 s/iter. Total: 1.9619 s/iter. ETA=0:03:24
[08/01 17:16:16] d2.evaluation.evaluator INFO: Inference done 434/535. Dataloading: 0.0007 s/iter. Inference: 1.0161 s/iter. Eval: 0.9441 s/iter. Total: 1.9610 s/iter. ETA=0:03:18
[08/01 17:16:22] d2.evaluation.evaluator INFO: Inference done 437/535. Dataloading: 0.0007 s/iter. Inference: 1.0146 s/iter. Eval: 0.9440 s/iter. Total: 1.9595 s/iter. ETA=0:03:12
[08/01 17:16:27] d2.evaluation.evaluator INFO: Inference done 440/535. Dataloading: 0.0007 s/iter. Inference: 1.0137 s/iter. Eval: 0.9439 s/iter. Total: 1.9585 s/iter. ETA=0:03:06
[08/01 17:16:33] d2.evaluation.evaluator INFO: Inference done 443/535. Dataloading: 0.0007 s/iter. Inference: 1.0128 s/iter. Eval: 0.9439 s/iter. Total: 1.9575 s/iter. ETA=0:03:00
[08/01 17:16:38] d2.evaluation.evaluator INFO: Inference done 446/535. Dataloading: 0.0007 s/iter. Inference: 1.0120 s/iter. Eval: 0.9440 s/iter. Total: 1.9569 s/iter. ETA=0:02:54
[08/01 17:16:44] d2.evaluation.evaluator INFO: Inference done 449/535. Dataloading: 0.0007 s/iter. Inference: 1.0113 s/iter. Eval: 0.9440 s/iter. Total: 1.9562 s/iter. ETA=0:02:48
[08/01 17:16:49] d2.evaluation.evaluator INFO: Inference done 452/535. Dataloading: 0.0007 s/iter. Inference: 1.0105 s/iter. Eval: 0.9439 s/iter. Total: 1.9553 s/iter. ETA=0:02:42
[08/01 17:16:55] d2.evaluation.evaluator INFO: Inference done 455/535. Dataloading: 0.0007 s/iter. Inference: 1.0096 s/iter. Eval: 0.9440 s/iter. Total: 1.9545 s/iter. ETA=0:02:36
[08/01 17:17:00] d2.evaluation.evaluator INFO: Inference done 458/535. Dataloading: 0.0007 s/iter. Inference: 1.0087 s/iter. Eval: 0.9439 s/iter. Total: 1.9535 s/iter. ETA=0:02:30
[08/01 17:17:06] d2.evaluation.evaluator INFO: Inference done 461/535. Dataloading: 0.0008 s/iter. Inference: 1.0080 s/iter. Eval: 0.9439 s/iter. Total: 1.9528 s/iter. ETA=0:02:24
[08/01 17:17:11] d2.evaluation.evaluator INFO: Inference done 464/535. Dataloading: 0.0008 s/iter. Inference: 1.0072 s/iter. Eval: 0.9439 s/iter. Total: 1.9520 s/iter. ETA=0:02:18
[08/01 17:17:17] d2.evaluation.evaluator INFO: Inference done 467/535. Dataloading: 0.0008 s/iter. Inference: 1.0063 s/iter. Eval: 0.9439 s/iter. Total: 1.9511 s/iter. ETA=0:02:12
[08/01 17:17:22] d2.evaluation.evaluator INFO: Inference done 470/535. Dataloading: 0.0008 s/iter. Inference: 1.0055 s/iter. Eval: 0.9438 s/iter. Total: 1.9502 s/iter. ETA=0:02:06
[08/01 17:17:27] d2.evaluation.evaluator INFO: Inference done 473/535. Dataloading: 0.0008 s/iter. Inference: 1.0047 s/iter. Eval: 0.9437 s/iter. Total: 1.9493 s/iter. ETA=0:02:00
[08/01 17:17:33] d2.evaluation.evaluator INFO: Inference done 476/535. Dataloading: 0.0008 s/iter. Inference: 1.0039 s/iter. Eval: 0.9437 s/iter. Total: 1.9484 s/iter. ETA=0:01:54
[08/01 17:17:38] d2.evaluation.evaluator INFO: Inference done 479/535. Dataloading: 0.0008 s/iter. Inference: 1.0032 s/iter. Eval: 0.9437 s/iter. Total: 1.9477 s/iter. ETA=0:01:49
[08/01 17:17:44] d2.evaluation.evaluator INFO: Inference done 482/535. Dataloading: 0.0008 s/iter. Inference: 1.0028 s/iter. Eval: 0.9438 s/iter. Total: 1.9474 s/iter. ETA=0:01:43
[08/01 17:17:49] d2.evaluation.evaluator INFO: Inference done 485/535. Dataloading: 0.0008 s/iter. Inference: 1.0020 s/iter. Eval: 0.9436 s/iter. Total: 1.9465 s/iter. ETA=0:01:37
[08/01 17:17:55] d2.evaluation.evaluator INFO: Inference done 488/535. Dataloading: 0.0008 s/iter. Inference: 1.0014 s/iter. Eval: 0.9436 s/iter. Total: 1.9459 s/iter. ETA=0:01:31
[08/01 17:18:00] d2.evaluation.evaluator INFO: Inference done 491/535. Dataloading: 0.0008 s/iter. Inference: 1.0007 s/iter. Eval: 0.9435 s/iter. Total: 1.9450 s/iter. ETA=0:01:25
[08/01 17:18:06] d2.evaluation.evaluator INFO: Inference done 494/535. Dataloading: 0.0008 s/iter. Inference: 1.0001 s/iter. Eval: 0.9434 s/iter. Total: 1.9444 s/iter. ETA=0:01:19
[08/01 17:18:11] d2.evaluation.evaluator INFO: Inference done 497/535. Dataloading: 0.0008 s/iter. Inference: 0.9992 s/iter. Eval: 0.9435 s/iter. Total: 1.9436 s/iter. ETA=0:01:13
[08/01 17:18:17] d2.evaluation.evaluator INFO: Inference done 500/535. Dataloading: 0.0008 s/iter. Inference: 0.9985 s/iter. Eval: 0.9435 s/iter. Total: 1.9430 s/iter. ETA=0:01:08
[08/01 17:18:23] d2.evaluation.evaluator INFO: Inference done 503/535. Dataloading: 0.0008 s/iter. Inference: 0.9982 s/iter. Eval: 0.9435 s/iter. Total: 1.9425 s/iter. ETA=0:01:02
[08/01 17:18:28] d2.evaluation.evaluator INFO: Inference done 506/535. Dataloading: 0.0008 s/iter. Inference: 0.9976 s/iter. Eval: 0.9435 s/iter. Total: 1.9419 s/iter. ETA=0:00:56
[08/01 17:18:34] d2.evaluation.evaluator INFO: Inference done 509/535. Dataloading: 0.0008 s/iter. Inference: 0.9970 s/iter. Eval: 0.9433 s/iter. Total: 1.9412 s/iter. ETA=0:00:50
[08/01 17:18:39] d2.evaluation.evaluator INFO: Inference done 512/535. Dataloading: 0.0008 s/iter. Inference: 0.9962 s/iter. Eval: 0.9433 s/iter. Total: 1.9404 s/iter. ETA=0:00:44
[08/01 17:18:44] d2.evaluation.evaluator INFO: Inference done 515/535. Dataloading: 0.0008 s/iter. Inference: 0.9957 s/iter. Eval: 0.9433 s/iter. Total: 1.9399 s/iter. ETA=0:00:38
[08/01 17:18:50] d2.evaluation.evaluator INFO: Inference done 518/535. Dataloading: 0.0008 s/iter. Inference: 0.9949 s/iter. Eval: 0.9432 s/iter. Total: 1.9390 s/iter. ETA=0:00:32
[08/01 17:18:55] d2.evaluation.evaluator INFO: Inference done 521/535. Dataloading: 0.0008 s/iter. Inference: 0.9943 s/iter. Eval: 0.9431 s/iter. Total: 1.9382 s/iter. ETA=0:00:27
[08/01 17:19:01] d2.evaluation.evaluator INFO: Inference done 524/535. Dataloading: 0.0008 s/iter. Inference: 0.9935 s/iter. Eval: 0.9430 s/iter. Total: 1.9374 s/iter. ETA=0:00:21
[08/01 17:19:06] d2.evaluation.evaluator INFO: Inference done 527/535. Dataloading: 0.0008 s/iter. Inference: 0.9929 s/iter. Eval: 0.9431 s/iter. Total: 1.9369 s/iter. ETA=0:00:15
[08/01 17:19:12] d2.evaluation.evaluator INFO: Inference done 530/535. Dataloading: 0.0008 s/iter. Inference: 0.9923 s/iter. Eval: 0.9430 s/iter. Total: 1.9362 s/iter. ETA=0:00:09
[08/01 17:19:17] d2.evaluation.evaluator INFO: Inference done 533/535. Dataloading: 0.0008 s/iter. Inference: 0.9917 s/iter. Eval: 0.9429 s/iter. Total: 1.9355 s/iter. ETA=0:00:03
[08/01 17:19:21] d2.evaluation.evaluator INFO: Total inference time: 0:17:05.492944 (1.934892 s / iter per device, on 1 devices)
[08/01 17:19:21] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:08:45 (0.991087 s / iter per device, on 1 devices)
[08/01 17:19:21] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[08/01 17:19:21] d2.evaluation.coco_evaluation INFO: Saving results to ./R101_overlap/inference/coco_instances_results.json
[08/01 17:19:22] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[08/01 17:19:24] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 |  nan  | 0.000 |
[08/01 17:19:24] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 17:19:24] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| normal     | 0.000 | defect     | 0.000 |
[08/01 17:19:30] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl   |
|:------:|:------:|:------:|:------:|:-----:|:------:|
| 98.298 | 99.793 | 99.325 | 89.413 |  nan  | 98.298 |
[08/01 17:19:30] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 17:19:30] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| normal     | 98.889 | defect     | 97.706 |
[08/01 17:19:30] d2.engine.defaults INFO: Evaluation results for front2class_2017_val_overlap_panoptic in csv format:
[08/01 17:19:30] d2.evaluation.testing INFO: copypaste: Task: bbox
[08/01 17:19:30] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 17:19:30] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,nan,0.0000
[08/01 17:19:30] d2.evaluation.testing INFO: copypaste: Task: segm
[08/01 17:19:30] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 17:19:30] d2.evaluation.testing INFO: copypaste: 98.2978,99.7931,99.3249,89.4127,nan,98.2978
[08/01 17:19:30] d2.utils.events INFO:  eta: 6:50:46  iter: 4999  total_loss: 3.283  loss_ce: 0.0007288  loss_mask: 0.1288  loss_dice: 0.1836  loss_ce_0: 0.1297  loss_mask_0: 0.1269  loss_dice_0: 0.1854  loss_ce_1: 0.002163  loss_mask_1: 0.1272  loss_dice_1: 0.1837  loss_ce_2: 0.0007461  loss_mask_2: 0.1287  loss_dice_2: 0.1816  loss_ce_3: 0.0008593  loss_mask_3: 0.1286  loss_dice_3: 0.1815  loss_ce_4: 0.0007337  loss_mask_4: 0.128  loss_dice_4: 0.1835  loss_ce_5: 0.0006773  loss_mask_5: 0.1277  loss_dice_5: 0.1852  loss_ce_6: 0.0008418  loss_mask_6: 0.1221  loss_dice_6: 0.1802  loss_ce_7: 0.0007491  loss_mask_7: 0.1289  loss_dice_7: 0.1879  loss_ce_8: 0.0007366  loss_mask_8: 0.1293  loss_dice_8: 0.1835  time: 0.3790  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:19:30] fvcore.common.checkpoint INFO: Saving checkpoint to ./R101_overlap/model_best.pth
[08/01 17:19:31] d2.engine.hooks INFO: Saved first model at 3.55589 @ 4999 steps
[08/01 17:19:48] d2.utils.events INFO:  eta: 6:51:00  iter: 5019  total_loss: 3.292  loss_ce: 0.000404  loss_mask: 0.1254  loss_dice: 0.1881  loss_ce_0: 0.1305  loss_mask_0: 0.126  loss_dice_0: 0.1833  loss_ce_1: 0.00136  loss_mask_1: 0.1243  loss_dice_1: 0.1894  loss_ce_2: 0.0006509  loss_mask_2: 0.1288  loss_dice_2: 0.1901  loss_ce_3: 0.0004538  loss_mask_3: 0.1235  loss_dice_3: 0.1839  loss_ce_4: 0.0003136  loss_mask_4: 0.1242  loss_dice_4: 0.1864  loss_ce_5: 0.0004825  loss_mask_5: 0.1242  loss_dice_5: 0.1809  loss_ce_6: 0.0004299  loss_mask_6: 0.1219  loss_dice_6: 0.1863  loss_ce_7: 0.000405  loss_mask_7: 0.1257  loss_dice_7: 0.1831  loss_ce_8: 0.0005792  loss_mask_8: 0.1216  loss_dice_8: 0.1849  time: 0.3809  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:20:05] d2.utils.events INFO:  eta: 6:51:27  iter: 5039  total_loss: 3.24  loss_ce: 0.000285  loss_mask: 0.1244  loss_dice: 0.1771  loss_ce_0: 0.1336  loss_mask_0: 0.123  loss_dice_0: 0.1702  loss_ce_1: 0.0009743  loss_mask_1: 0.1251  loss_dice_1: 0.1701  loss_ce_2: 0.0003447  loss_mask_2: 0.1246  loss_dice_2: 0.1695  loss_ce_3: 0.0002448  loss_mask_3: 0.1243  loss_dice_3: 0.171  loss_ce_4: 0.0002567  loss_mask_4: 0.1239  loss_dice_4: 0.1679  loss_ce_5: 0.0002825  loss_mask_5: 0.1221  loss_dice_5: 0.1719  loss_ce_6: 0.0002668  loss_mask_6: 0.1254  loss_dice_6: 0.1739  loss_ce_7: 0.0003817  loss_mask_7: 0.1219  loss_dice_7: 0.1692  loss_ce_8: 0.0003689  loss_mask_8: 0.1262  loss_dice_8: 0.1757  time: 0.3828  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:20:22] d2.utils.events INFO:  eta: 6:51:36  iter: 5059  total_loss: 3.205  loss_ce: 0.000287  loss_mask: 0.126  loss_dice: 0.1729  loss_ce_0: 0.1311  loss_mask_0: 0.1285  loss_dice_0: 0.1849  loss_ce_1: 0.00062  loss_mask_1: 0.1248  loss_dice_1: 0.1804  loss_ce_2: 0.0002038  loss_mask_2: 0.1239  loss_dice_2: 0.18  loss_ce_3: 0.0002808  loss_mask_3: 0.1243  loss_dice_3: 0.1762  loss_ce_4: 0.0002256  loss_mask_4: 0.1269  loss_dice_4: 0.1765  loss_ce_5: 0.0001892  loss_mask_5: 0.1241  loss_dice_5: 0.1742  loss_ce_6: 0.0002966  loss_mask_6: 0.1257  loss_dice_6: 0.1785  loss_ce_7: 0.000251  loss_mask_7: 0.1244  loss_dice_7: 0.183  loss_ce_8: 0.0003757  loss_mask_8: 0.1288  loss_dice_8: 0.1787  time: 0.3847  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:20:39] d2.utils.events INFO:  eta: 6:51:19  iter: 5079  total_loss: 3.076  loss_ce: 0.0003315  loss_mask: 0.1243  loss_dice: 0.1704  loss_ce_0: 0.1303  loss_mask_0: 0.1249  loss_dice_0: 0.1782  loss_ce_1: 0.0006717  loss_mask_1: 0.125  loss_dice_1: 0.176  loss_ce_2: 0.0004385  loss_mask_2: 0.1232  loss_dice_2: 0.1745  loss_ce_3: 0.0002944  loss_mask_3: 0.1244  loss_dice_3: 0.1765  loss_ce_4: 0.0002953  loss_mask_4: 0.1225  loss_dice_4: 0.1819  loss_ce_5: 0.0004872  loss_mask_5: 0.121  loss_dice_5: 0.1716  loss_ce_6: 0.0003241  loss_mask_6: 0.1242  loss_dice_6: 0.173  loss_ce_7: 0.0003514  loss_mask_7: 0.1222  loss_dice_7: 0.1708  loss_ce_8: 0.0004451  loss_mask_8: 0.1216  loss_dice_8: 0.1729  time: 0.3864  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:20:56] d2.utils.events INFO:  eta: 6:51:03  iter: 5099  total_loss: 3.411  loss_ce: 0.0006018  loss_mask: 0.1211  loss_dice: 0.1774  loss_ce_0: 0.1308  loss_mask_0: 0.1229  loss_dice_0: 0.1855  loss_ce_1: 0.001411  loss_mask_1: 0.1231  loss_dice_1: 0.1847  loss_ce_2: 0.0005889  loss_mask_2: 0.1254  loss_dice_2: 0.1774  loss_ce_3: 0.0006165  loss_mask_3: 0.1211  loss_dice_3: 0.1774  loss_ce_4: 0.0005714  loss_mask_4: 0.1266  loss_dice_4: 0.1823  loss_ce_5: 0.0005306  loss_mask_5: 0.124  loss_dice_5: 0.1824  loss_ce_6: 0.0006337  loss_mask_6: 0.1218  loss_dice_6: 0.1802  loss_ce_7: 0.0006011  loss_mask_7: 0.125  loss_dice_7: 0.1786  loss_ce_8: 0.0005325  loss_mask_8: 0.1249  loss_dice_8: 0.1814  time: 0.3882  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:21:13] d2.utils.events INFO:  eta: 6:51:31  iter: 5119  total_loss: 3.435  loss_ce: 0.0003803  loss_mask: 0.1298  loss_dice: 0.1962  loss_ce_0: 0.1296  loss_mask_0: 0.1287  loss_dice_0: 0.2011  loss_ce_1: 0.0007498  loss_mask_1: 0.1298  loss_dice_1: 0.1941  loss_ce_2: 0.0005245  loss_mask_2: 0.1296  loss_dice_2: 0.1964  loss_ce_3: 0.0004635  loss_mask_3: 0.1317  loss_dice_3: 0.2041  loss_ce_4: 0.0005189  loss_mask_4: 0.1281  loss_dice_4: 0.1971  loss_ce_5: 0.0006089  loss_mask_5: 0.1326  loss_dice_5: 0.2031  loss_ce_6: 0.0005827  loss_mask_6: 0.1274  loss_dice_6: 0.1969  loss_ce_7: 0.0005107  loss_mask_7: 0.1268  loss_dice_7: 0.1992  loss_ce_8: 0.0004884  loss_mask_8: 0.1261  loss_dice_8: 0.1946  time: 0.3900  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:21:30] d2.utils.events INFO:  eta: 6:52:14  iter: 5139  total_loss: 3.189  loss_ce: 0.000456  loss_mask: 0.1235  loss_dice: 0.1773  loss_ce_0: 0.1311  loss_mask_0: 0.1213  loss_dice_0: 0.1757  loss_ce_1: 0.000823  loss_mask_1: 0.1237  loss_dice_1: 0.1742  loss_ce_2: 0.0005089  loss_mask_2: 0.1229  loss_dice_2: 0.1755  loss_ce_3: 0.0004021  loss_mask_3: 0.1225  loss_dice_3: 0.1766  loss_ce_4: 0.0004034  loss_mask_4: 0.1211  loss_dice_4: 0.1737  loss_ce_5: 0.0005163  loss_mask_5: 0.1198  loss_dice_5: 0.1756  loss_ce_6: 0.0005898  loss_mask_6: 0.1239  loss_dice_6: 0.1783  loss_ce_7: 0.0005857  loss_mask_7: 0.125  loss_dice_7: 0.1805  loss_ce_8: 0.0004405  loss_mask_8: 0.122  loss_dice_8: 0.1731  time: 0.3918  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:21:46] d2.utils.events INFO:  eta: 6:52:29  iter: 5159  total_loss: 3.295  loss_ce: 0.0002369  loss_mask: 0.1266  loss_dice: 0.184  loss_ce_0: 0.1304  loss_mask_0: 0.1314  loss_dice_0: 0.1856  loss_ce_1: 0.0003551  loss_mask_1: 0.1277  loss_dice_1: 0.1837  loss_ce_2: 0.0002229  loss_mask_2: 0.1278  loss_dice_2: 0.1857  loss_ce_3: 0.0001528  loss_mask_3: 0.1249  loss_dice_3: 0.1789  loss_ce_4: 0.0001355  loss_mask_4: 0.1231  loss_dice_4: 0.1848  loss_ce_5: 0.0001622  loss_mask_5: 0.1281  loss_dice_5: 0.1813  loss_ce_6: 0.0001955  loss_mask_6: 0.1229  loss_dice_6: 0.1811  loss_ce_7: 0.0001998  loss_mask_7: 0.125  loss_dice_7: 0.1848  loss_ce_8: 0.0002957  loss_mask_8: 0.1271  loss_dice_8: 0.1842  time: 0.3935  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:22:03] d2.utils.events INFO:  eta: 6:52:20  iter: 5179  total_loss: 3.394  loss_ce: 0.000285  loss_mask: 0.1367  loss_dice: 0.1983  loss_ce_0: 0.1296  loss_mask_0: 0.1306  loss_dice_0: 0.1903  loss_ce_1: 0.000376  loss_mask_1: 0.126  loss_dice_1: 0.186  loss_ce_2: 0.0001622  loss_mask_2: 0.1322  loss_dice_2: 0.1902  loss_ce_3: 0.0001973  loss_mask_3: 0.1361  loss_dice_3: 0.1982  loss_ce_4: 0.0002003  loss_mask_4: 0.1339  loss_dice_4: 0.1927  loss_ce_5: 0.0001745  loss_mask_5: 0.1342  loss_dice_5: 0.1958  loss_ce_6: 0.0002577  loss_mask_6: 0.1341  loss_dice_6: 0.1962  loss_ce_7: 0.0002681  loss_mask_7: 0.1341  loss_dice_7: 0.1926  loss_ce_8: 0.0003137  loss_mask_8: 0.1355  loss_dice_8: 0.192  time: 0.3953  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:22:20] d2.utils.events INFO:  eta: 6:52:05  iter: 5199  total_loss: 3.227  loss_ce: 0.0002636  loss_mask: 0.1311  loss_dice: 0.1821  loss_ce_0: 0.1285  loss_mask_0: 0.1297  loss_dice_0: 0.1795  loss_ce_1: 0.0004702  loss_mask_1: 0.1276  loss_dice_1: 0.175  loss_ce_2: 0.0002836  loss_mask_2: 0.1265  loss_dice_2: 0.1837  loss_ce_3: 0.0001754  loss_mask_3: 0.1255  loss_dice_3: 0.1813  loss_ce_4: 0.000212  loss_mask_4: 0.1287  loss_dice_4: 0.1829  loss_ce_5: 0.0002844  loss_mask_5: 0.1293  loss_dice_5: 0.1796  loss_ce_6: 0.0002472  loss_mask_6: 0.1284  loss_dice_6: 0.1825  loss_ce_7: 0.0002833  loss_mask_7: 0.1258  loss_dice_7: 0.1815  loss_ce_8: 0.000306  loss_mask_8: 0.1307  loss_dice_8: 0.1849  time: 0.3970  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:22:37] d2.utils.events INFO:  eta: 6:51:55  iter: 5219  total_loss: 3.159  loss_ce: 0.0002073  loss_mask: 0.1218  loss_dice: 0.1855  loss_ce_0: 0.129  loss_mask_0: 0.1231  loss_dice_0: 0.1878  loss_ce_1: 0.000439  loss_mask_1: 0.128  loss_dice_1: 0.1836  loss_ce_2: 0.0002891  loss_mask_2: 0.1268  loss_dice_2: 0.1884  loss_ce_3: 0.0002062  loss_mask_3: 0.1276  loss_dice_3: 0.1783  loss_ce_4: 0.0001943  loss_mask_4: 0.1292  loss_dice_4: 0.1855  loss_ce_5: 0.0002738  loss_mask_5: 0.1224  loss_dice_5: 0.1779  loss_ce_6: 0.0002386  loss_mask_6: 0.1262  loss_dice_6: 0.1808  loss_ce_7: 0.0002089  loss_mask_7: 0.1243  loss_dice_7: 0.1886  loss_ce_8: 0.0002503  loss_mask_8: 0.1181  loss_dice_8: 0.1851  time: 0.3988  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:22:54] d2.utils.events INFO:  eta: 6:51:39  iter: 5239  total_loss: 3.209  loss_ce: 0.0001705  loss_mask: 0.1297  loss_dice: 0.1858  loss_ce_0: 0.1251  loss_mask_0: 0.1248  loss_dice_0: 0.185  loss_ce_1: 0.0005161  loss_mask_1: 0.128  loss_dice_1: 0.1942  loss_ce_2: 0.0002788  loss_mask_2: 0.1295  loss_dice_2: 0.1881  loss_ce_3: 0.0001627  loss_mask_3: 0.1317  loss_dice_3: 0.1877  loss_ce_4: 0.0001405  loss_mask_4: 0.1307  loss_dice_4: 0.184  loss_ce_5: 0.000239  loss_mask_5: 0.1287  loss_dice_5: 0.1872  loss_ce_6: 0.0002029  loss_mask_6: 0.1298  loss_dice_6: 0.1845  loss_ce_7: 0.0001786  loss_mask_7: 0.1268  loss_dice_7: 0.1828  loss_ce_8: 0.0002746  loss_mask_8: 0.1279  loss_dice_8: 0.1913  time: 0.4005  data_time: 0.0018  lr: 0.0001  max_mem: 8444M
[08/01 17:23:12] d2.utils.events INFO:  eta: 6:51:26  iter: 5259  total_loss: 3.247  loss_ce: 0.0001842  loss_mask: 0.1261  loss_dice: 0.1813  loss_ce_0: 0.1283  loss_mask_0: 0.1218  loss_dice_0: 0.18  loss_ce_1: 0.0004375  loss_mask_1: 0.1266  loss_dice_1: 0.1801  loss_ce_2: 0.0002596  loss_mask_2: 0.1233  loss_dice_2: 0.1858  loss_ce_3: 0.0001448  loss_mask_3: 0.1226  loss_dice_3: 0.182  loss_ce_4: 0.0001583  loss_mask_4: 0.1199  loss_dice_4: 0.1834  loss_ce_5: 0.0002201  loss_mask_5: 0.1242  loss_dice_5: 0.1819  loss_ce_6: 0.0001676  loss_mask_6: 0.1228  loss_dice_6: 0.1803  loss_ce_7: 0.0001595  loss_mask_7: 0.1259  loss_dice_7: 0.1813  loss_ce_8: 0.0002335  loss_mask_8: 0.1246  loss_dice_8: 0.1867  time: 0.4023  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:23:29] d2.utils.events INFO:  eta: 6:51:25  iter: 5279  total_loss: 3.205  loss_ce: 0.0001916  loss_mask: 0.1244  loss_dice: 0.1805  loss_ce_0: 0.1252  loss_mask_0: 0.127  loss_dice_0: 0.182  loss_ce_1: 0.0003807  loss_mask_1: 0.1231  loss_dice_1: 0.1781  loss_ce_2: 0.0002655  loss_mask_2: 0.1241  loss_dice_2: 0.1792  loss_ce_3: 0.0001742  loss_mask_3: 0.1281  loss_dice_3: 0.1867  loss_ce_4: 0.0001627  loss_mask_4: 0.1318  loss_dice_4: 0.1874  loss_ce_5: 0.000245  loss_mask_5: 0.1279  loss_dice_5: 0.1794  loss_ce_6: 0.0001882  loss_mask_6: 0.1254  loss_dice_6: 0.1843  loss_ce_7: 0.0001998  loss_mask_7: 0.1291  loss_dice_7: 0.1863  loss_ce_8: 0.0002782  loss_mask_8: 0.1256  loss_dice_8: 0.1792  time: 0.4039  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:23:46] d2.utils.events INFO:  eta: 6:51:16  iter: 5299  total_loss: 3.245  loss_ce: 0.0002871  loss_mask: 0.1303  loss_dice: 0.1788  loss_ce_0: 0.133  loss_mask_0: 0.1222  loss_dice_0: 0.1749  loss_ce_1: 0.0005443  loss_mask_1: 0.1211  loss_dice_1: 0.1773  loss_ce_2: 0.00028  loss_mask_2: 0.1274  loss_dice_2: 0.1737  loss_ce_3: 0.0002609  loss_mask_3: 0.1266  loss_dice_3: 0.1755  loss_ce_4: 0.000253  loss_mask_4: 0.1247  loss_dice_4: 0.1725  loss_ce_5: 0.0002659  loss_mask_5: 0.125  loss_dice_5: 0.1752  loss_ce_6: 0.0002472  loss_mask_6: 0.1278  loss_dice_6: 0.1718  loss_ce_7: 0.0002581  loss_mask_7: 0.1234  loss_dice_7: 0.1759  loss_ce_8: 0.0002857  loss_mask_8: 0.1235  loss_dice_8: 0.1744  time: 0.4056  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:24:03] d2.utils.events INFO:  eta: 6:51:20  iter: 5319  total_loss: 3.136  loss_ce: 0.0001345  loss_mask: 0.1196  loss_dice: 0.1768  loss_ce_0: 0.1292  loss_mask_0: 0.1221  loss_dice_0: 0.1738  loss_ce_1: 0.0003706  loss_mask_1: 0.1206  loss_dice_1: 0.1795  loss_ce_2: 0.0001835  loss_mask_2: 0.1208  loss_dice_2: 0.1763  loss_ce_3: 0.0001279  loss_mask_3: 0.1197  loss_dice_3: 0.1785  loss_ce_4: 0.0001235  loss_mask_4: 0.1213  loss_dice_4: 0.1816  loss_ce_5: 0.0001585  loss_mask_5: 0.1231  loss_dice_5: 0.1805  loss_ce_6: 0.0001549  loss_mask_6: 0.1197  loss_dice_6: 0.1768  loss_ce_7: 0.0001438  loss_mask_7: 0.1236  loss_dice_7: 0.1726  loss_ce_8: 0.000262  loss_mask_8: 0.1235  loss_dice_8: 0.1799  time: 0.4073  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:24:20] d2.utils.events INFO:  eta: 6:51:09  iter: 5339  total_loss: 3.258  loss_ce: 0.0001908  loss_mask: 0.1269  loss_dice: 0.1886  loss_ce_0: 0.1315  loss_mask_0: 0.1226  loss_dice_0: 0.1817  loss_ce_1: 0.0002601  loss_mask_1: 0.1247  loss_dice_1: 0.18  loss_ce_2: 0.0001335  loss_mask_2: 0.1237  loss_dice_2: 0.1806  loss_ce_3: 0.0002093  loss_mask_3: 0.125  loss_dice_3: 0.182  loss_ce_4: 0.0001751  loss_mask_4: 0.1291  loss_dice_4: 0.1835  loss_ce_5: 0.0001214  loss_mask_5: 0.1263  loss_dice_5: 0.1847  loss_ce_6: 0.0002033  loss_mask_6: 0.1238  loss_dice_6: 0.1845  loss_ce_7: 0.000197  loss_mask_7: 0.1257  loss_dice_7: 0.1813  loss_ce_8: 0.0002375  loss_mask_8: 0.1216  loss_dice_8: 0.1817  time: 0.4090  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:24:37] d2.utils.events INFO:  eta: 6:50:52  iter: 5359  total_loss: 3.386  loss_ce: 0.000249  loss_mask: 0.1266  loss_dice: 0.1825  loss_ce_0: 0.1253  loss_mask_0: 0.1303  loss_dice_0: 0.1823  loss_ce_1: 0.0007638  loss_mask_1: 0.1272  loss_dice_1: 0.1798  loss_ce_2: 0.0002501  loss_mask_2: 0.1312  loss_dice_2: 0.1834  loss_ce_3: 0.0002865  loss_mask_3: 0.1253  loss_dice_3: 0.1781  loss_ce_4: 0.000303  loss_mask_4: 0.1284  loss_dice_4: 0.1779  loss_ce_5: 0.0002438  loss_mask_5: 0.1254  loss_dice_5: 0.1761  loss_ce_6: 0.0002632  loss_mask_6: 0.1279  loss_dice_6: 0.1841  loss_ce_7: 0.0003339  loss_mask_7: 0.1237  loss_dice_7: 0.183  loss_ce_8: 0.0003347  loss_mask_8: 0.1333  loss_dice_8: 0.1853  time: 0.4106  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:24:54] d2.utils.events INFO:  eta: 6:50:44  iter: 5379  total_loss: 3.208  loss_ce: 0.0001968  loss_mask: 0.121  loss_dice: 0.177  loss_ce_0: 0.1264  loss_mask_0: 0.1223  loss_dice_0: 0.1798  loss_ce_1: 0.0005378  loss_mask_1: 0.1219  loss_dice_1: 0.1821  loss_ce_2: 0.0002298  loss_mask_2: 0.1253  loss_dice_2: 0.1822  loss_ce_3: 0.0001625  loss_mask_3: 0.1266  loss_dice_3: 0.1816  loss_ce_4: 0.0001959  loss_mask_4: 0.1239  loss_dice_4: 0.181  loss_ce_5: 0.0002146  loss_mask_5: 0.1208  loss_dice_5: 0.1766  loss_ce_6: 0.0001783  loss_mask_6: 0.1225  loss_dice_6: 0.1787  loss_ce_7: 0.0002183  loss_mask_7: 0.1264  loss_dice_7: 0.1845  loss_ce_8: 0.0002876  loss_mask_8: 0.1228  loss_dice_8: 0.1848  time: 0.4123  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:25:11] d2.utils.events INFO:  eta: 6:50:36  iter: 5399  total_loss: 3.342  loss_ce: 0.00283  loss_mask: 0.1271  loss_dice: 0.1874  loss_ce_0: 0.1256  loss_mask_0: 0.1293  loss_dice_0: 0.1968  loss_ce_1: 0.0003647  loss_mask_1: 0.1324  loss_dice_1: 0.1859  loss_ce_2: 0.0002848  loss_mask_2: 0.131  loss_dice_2: 0.1879  loss_ce_3: 0.0003304  loss_mask_3: 0.1323  loss_dice_3: 0.1887  loss_ce_4: 0.0004581  loss_mask_4: 0.132  loss_dice_4: 0.1885  loss_ce_5: 0.000457  loss_mask_5: 0.1256  loss_dice_5: 0.1877  loss_ce_6: 0.0008513  loss_mask_6: 0.126  loss_dice_6: 0.1923  loss_ce_7: 0.0008785  loss_mask_7: 0.1288  loss_dice_7: 0.1897  loss_ce_8: 0.0005107  loss_mask_8: 0.1255  loss_dice_8: 0.1873  time: 0.4139  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:25:28] d2.utils.events INFO:  eta: 6:50:29  iter: 5419  total_loss: 3.281  loss_ce: 0.0002591  loss_mask: 0.127  loss_dice: 0.186  loss_ce_0: 0.124  loss_mask_0: 0.1282  loss_dice_0: 0.1899  loss_ce_1: 0.0003161  loss_mask_1: 0.1286  loss_dice_1: 0.1917  loss_ce_2: 0.0002024  loss_mask_2: 0.1226  loss_dice_2: 0.1818  loss_ce_3: 0.0002716  loss_mask_3: 0.1218  loss_dice_3: 0.1801  loss_ce_4: 0.0003274  loss_mask_4: 0.1301  loss_dice_4: 0.1835  loss_ce_5: 0.0003138  loss_mask_5: 0.1237  loss_dice_5: 0.1924  loss_ce_6: 0.0002638  loss_mask_6: 0.1275  loss_dice_6: 0.1969  loss_ce_7: 0.0002984  loss_mask_7: 0.1232  loss_dice_7: 0.1878  loss_ce_8: 0.0002045  loss_mask_8: 0.1247  loss_dice_8: 0.1811  time: 0.4155  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:25:45] d2.utils.events INFO:  eta: 6:50:12  iter: 5439  total_loss: 3.485  loss_ce: 0.0001465  loss_mask: 0.1364  loss_dice: 0.1966  loss_ce_0: 0.1336  loss_mask_0: 0.1371  loss_dice_0: 0.1918  loss_ce_1: 0.0004219  loss_mask_1: 0.1326  loss_dice_1: 0.1877  loss_ce_2: 0.0002032  loss_mask_2: 0.1326  loss_dice_2: 0.1926  loss_ce_3: 0.0001674  loss_mask_3: 0.1304  loss_dice_3: 0.1943  loss_ce_4: 0.0002733  loss_mask_4: 0.1351  loss_dice_4: 0.19  loss_ce_5: 0.0003481  loss_mask_5: 0.1369  loss_dice_5: 0.1901  loss_ce_6: 0.0004879  loss_mask_6: 0.1387  loss_dice_6: 0.2008  loss_ce_7: 0.0001944  loss_mask_7: 0.1406  loss_dice_7: 0.195  loss_ce_8: 0.0002058  loss_mask_8: 0.1356  loss_dice_8: 0.1914  time: 0.4171  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:26:02] d2.utils.events INFO:  eta: 6:50:07  iter: 5459  total_loss: 3.314  loss_ce: 0.0003692  loss_mask: 0.1326  loss_dice: 0.1754  loss_ce_0: 0.1263  loss_mask_0: 0.1318  loss_dice_0: 0.184  loss_ce_1: 0.0004396  loss_mask_1: 0.1322  loss_dice_1: 0.1831  loss_ce_2: 0.000269  loss_mask_2: 0.1286  loss_dice_2: 0.1806  loss_ce_3: 0.0003006  loss_mask_3: 0.1349  loss_dice_3: 0.1875  loss_ce_4: 0.0002639  loss_mask_4: 0.1317  loss_dice_4: 0.181  loss_ce_5: 0.0002173  loss_mask_5: 0.1317  loss_dice_5: 0.1782  loss_ce_6: 0.0002377  loss_mask_6: 0.1333  loss_dice_6: 0.1802  loss_ce_7: 0.0004184  loss_mask_7: 0.1349  loss_dice_7: 0.1852  loss_ce_8: 0.0005644  loss_mask_8: 0.1308  loss_dice_8: 0.189  time: 0.4187  data_time: 0.0017  lr: 0.0001  max_mem: 8444M
[08/01 17:26:19] d2.utils.events INFO:  eta: 6:49:50  iter: 5479  total_loss: 3.787  loss_ce: 0.0005043  loss_mask: 0.1342  loss_dice: 0.2203  loss_ce_0: 0.1346  loss_mask_0: 0.1347  loss_dice_0: 0.2162  loss_ce_1: 0.0004151  loss_mask_1: 0.1361  loss_dice_1: 0.2124  loss_ce_2: 0.0002523  loss_mask_2: 0.1419  loss_dice_2: 0.2139  loss_ce_3: 0.0002736  loss_mask_3: 0.1418  loss_dice_3: 0.2194  loss_ce_4: 0.000297  loss_mask_4: 0.1316  loss_dice_4: 0.2069  loss_ce_5: 0.0003364  loss_mask_5: 0.1397  loss_dice_5: 0.211  loss_ce_6: 0.0006865  loss_mask_6: 0.136  loss_dice_6: 0.2072  loss_ce_7: 0.0004892  loss_mask_7: 0.1351  loss_dice_7: 0.2071  loss_ce_8: 0.0005523  loss_mask_8: 0.1365  loss_dice_8: 0.2123  time: 0.4202  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:26:36] d2.utils.events INFO:  eta: 6:49:32  iter: 5499  total_loss: 3.536  loss_ce: 0.0004441  loss_mask: 0.1362  loss_dice: 0.1952  loss_ce_0: 0.1205  loss_mask_0: 0.1359  loss_dice_0: 0.1935  loss_ce_1: 0.0005245  loss_mask_1: 0.1363  loss_dice_1: 0.1886  loss_ce_2: 0.0002854  loss_mask_2: 0.1324  loss_dice_2: 0.1827  loss_ce_3: 0.000427  loss_mask_3: 0.1402  loss_dice_3: 0.1921  loss_ce_4: 0.0005217  loss_mask_4: 0.1345  loss_dice_4: 0.2008  loss_ce_5: 0.0003275  loss_mask_5: 0.1398  loss_dice_5: 0.193  loss_ce_6: 0.0004148  loss_mask_6: 0.1313  loss_dice_6: 0.1925  loss_ce_7: 0.0005953  loss_mask_7: 0.1362  loss_dice_7: 0.1959  loss_ce_8: 0.0007101  loss_mask_8: 0.138  loss_dice_8: 0.1917  time: 0.4218  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:26:53] d2.utils.events INFO:  eta: 6:49:11  iter: 5519  total_loss: 3.528  loss_ce: 0.0006875  loss_mask: 0.1305  loss_dice: 0.1957  loss_ce_0: 0.1275  loss_mask_0: 0.1324  loss_dice_0: 0.1998  loss_ce_1: 0.002881  loss_mask_1: 0.1277  loss_dice_1: 0.1968  loss_ce_2: 0.0007731  loss_mask_2: 0.1294  loss_dice_2: 0.192  loss_ce_3: 0.001186  loss_mask_3: 0.1314  loss_dice_3: 0.1973  loss_ce_4: 0.00103  loss_mask_4: 0.1241  loss_dice_4: 0.1943  loss_ce_5: 0.0005433  loss_mask_5: 0.1347  loss_dice_5: 0.1956  loss_ce_6: 0.001044  loss_mask_6: 0.1318  loss_dice_6: 0.1942  loss_ce_7: 0.001552  loss_mask_7: 0.1314  loss_dice_7: 0.1963  loss_ce_8: 0.0008048  loss_mask_8: 0.1276  loss_dice_8: 0.1962  time: 0.4233  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:27:10] d2.utils.events INFO:  eta: 6:49:12  iter: 5539  total_loss: 3.05  loss_ce: 0.0004727  loss_mask: 0.1195  loss_dice: 0.1759  loss_ce_0: 0.131  loss_mask_0: 0.1177  loss_dice_0: 0.1724  loss_ce_1: 0.0007224  loss_mask_1: 0.1152  loss_dice_1: 0.1754  loss_ce_2: 0.0003198  loss_mask_2: 0.1178  loss_dice_2: 0.1736  loss_ce_3: 0.0004688  loss_mask_3: 0.1188  loss_dice_3: 0.1698  loss_ce_4: 0.0004173  loss_mask_4: 0.1192  loss_dice_4: 0.1697  loss_ce_5: 0.0003417  loss_mask_5: 0.1181  loss_dice_5: 0.1805  loss_ce_6: 0.0006256  loss_mask_6: 0.1247  loss_dice_6: 0.1741  loss_ce_7: 0.0007757  loss_mask_7: 0.1183  loss_dice_7: 0.1699  loss_ce_8: 0.0005164  loss_mask_8: 0.1139  loss_dice_8: 0.1669  time: 0.4248  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:27:27] d2.utils.events INFO:  eta: 6:48:59  iter: 5559  total_loss: 3.432  loss_ce: 0.0002207  loss_mask: 0.1308  loss_dice: 0.2024  loss_ce_0: 0.1248  loss_mask_0: 0.1309  loss_dice_0: 0.2  loss_ce_1: 0.00033  loss_mask_1: 0.1334  loss_dice_1: 0.1972  loss_ce_2: 0.0001672  loss_mask_2: 0.1278  loss_dice_2: 0.1936  loss_ce_3: 0.0003069  loss_mask_3: 0.1326  loss_dice_3: 0.1965  loss_ce_4: 0.0003106  loss_mask_4: 0.1298  loss_dice_4: 0.1968  loss_ce_5: 0.0002453  loss_mask_5: 0.1281  loss_dice_5: 0.192  loss_ce_6: 0.0003045  loss_mask_6: 0.1361  loss_dice_6: 0.199  loss_ce_7: 0.0002789  loss_mask_7: 0.1291  loss_dice_7: 0.2027  loss_ce_8: 0.0001944  loss_mask_8: 0.1276  loss_dice_8: 0.1943  time: 0.4263  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 17:27:43] d2.utils.events INFO:  eta: 6:48:42  iter: 5579  total_loss: 3.281  loss_ce: 6.685e-05  loss_mask: 0.1286  loss_dice: 0.1913  loss_ce_0: 0.1275  loss_mask_0: 0.1275  loss_dice_0: 0.1998  loss_ce_1: 0.0002019  loss_mask_1: 0.1275  loss_dice_1: 0.1916  loss_ce_2: 0.0001195  loss_mask_2: 0.1272  loss_dice_2: 0.1933  loss_ce_3: 0.0001817  loss_mask_3: 0.1236  loss_dice_3: 0.1877  loss_ce_4: 0.0001832  loss_mask_4: 0.1297  loss_dice_4: 0.1885  loss_ce_5: 0.0001809  loss_mask_5: 0.1297  loss_dice_5: 0.2007  loss_ce_6: 0.0002127  loss_mask_6: 0.1286  loss_dice_6: 0.1912  loss_ce_7: 0.0001339  loss_mask_7: 0.1266  loss_dice_7: 0.1956  loss_ce_8: 7.423e-05  loss_mask_8: 0.1254  loss_dice_8: 0.1881  time: 0.4278  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:28:00] d2.utils.events INFO:  eta: 6:48:33  iter: 5599  total_loss: 3.524  loss_ce: 8.002e-05  loss_mask: 0.1236  loss_dice: 0.2053  loss_ce_0: 0.1205  loss_mask_0: 0.1258  loss_dice_0: 0.2049  loss_ce_1: 0.0002962  loss_mask_1: 0.1316  loss_dice_1: 0.2141  loss_ce_2: 0.0001261  loss_mask_2: 0.1279  loss_dice_2: 0.2079  loss_ce_3: 0.0001235  loss_mask_3: 0.1272  loss_dice_3: 0.2051  loss_ce_4: 0.0001462  loss_mask_4: 0.1282  loss_dice_4: 0.2121  loss_ce_5: 0.000155  loss_mask_5: 0.1282  loss_dice_5: 0.2064  loss_ce_6: 0.0001552  loss_mask_6: 0.1269  loss_dice_6: 0.2212  loss_ce_7: 7.829e-05  loss_mask_7: 0.1278  loss_dice_7: 0.2167  loss_ce_8: 6.587e-05  loss_mask_8: 0.1297  loss_dice_8: 0.2145  time: 0.4293  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:28:17] d2.utils.events INFO:  eta: 6:48:22  iter: 5619  total_loss: 3.234  loss_ce: 0.0002311  loss_mask: 0.1243  loss_dice: 0.1832  loss_ce_0: 0.1309  loss_mask_0: 0.1175  loss_dice_0: 0.1924  loss_ce_1: 0.0002685  loss_mask_1: 0.1222  loss_dice_1: 0.1893  loss_ce_2: 0.0001505  loss_mask_2: 0.1189  loss_dice_2: 0.1861  loss_ce_3: 0.0001847  loss_mask_3: 0.1223  loss_dice_3: 0.1847  loss_ce_4: 0.000204  loss_mask_4: 0.1205  loss_dice_4: 0.1884  loss_ce_5: 0.0001652  loss_mask_5: 0.1205  loss_dice_5: 0.185  loss_ce_6: 0.0002156  loss_mask_6: 0.1197  loss_dice_6: 0.1857  loss_ce_7: 0.0003285  loss_mask_7: 0.1216  loss_dice_7: 0.1889  loss_ce_8: 0.0002386  loss_mask_8: 0.1197  loss_dice_8: 0.1846  time: 0.4308  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:28:34] d2.utils.events INFO:  eta: 6:47:50  iter: 5639  total_loss: 3.338  loss_ce: 0.0002924  loss_mask: 0.123  loss_dice: 0.1903  loss_ce_0: 0.129  loss_mask_0: 0.127  loss_dice_0: 0.2007  loss_ce_1: 0.000281  loss_mask_1: 0.1229  loss_dice_1: 0.197  loss_ce_2: 0.0001991  loss_mask_2: 0.1257  loss_dice_2: 0.1893  loss_ce_3: 0.0001661  loss_mask_3: 0.1234  loss_dice_3: 0.1955  loss_ce_4: 0.0002445  loss_mask_4: 0.1267  loss_dice_4: 0.1927  loss_ce_5: 0.0002216  loss_mask_5: 0.1245  loss_dice_5: 0.1965  loss_ce_6: 0.0002523  loss_mask_6: 0.1246  loss_dice_6: 0.1947  loss_ce_7: 0.0003587  loss_mask_7: 0.13  loss_dice_7: 0.1963  loss_ce_8: 0.0002914  loss_mask_8: 0.1279  loss_dice_8: 0.1972  time: 0.4323  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:28:51] d2.utils.events INFO:  eta: 6:47:28  iter: 5659  total_loss: 3.24  loss_ce: 0.0001687  loss_mask: 0.129  loss_dice: 0.183  loss_ce_0: 0.1278  loss_mask_0: 0.1278  loss_dice_0: 0.1821  loss_ce_1: 0.0002765  loss_mask_1: 0.1253  loss_dice_1: 0.1787  loss_ce_2: 0.0002279  loss_mask_2: 0.1266  loss_dice_2: 0.1759  loss_ce_3: 0.0001494  loss_mask_3: 0.1272  loss_dice_3: 0.1788  loss_ce_4: 0.0001567  loss_mask_4: 0.1298  loss_dice_4: 0.1832  loss_ce_5: 0.0001899  loss_mask_5: 0.1307  loss_dice_5: 0.186  loss_ce_6: 0.0001792  loss_mask_6: 0.1263  loss_dice_6: 0.1805  loss_ce_7: 0.0002464  loss_mask_7: 0.1213  loss_dice_7: 0.1818  loss_ce_8: 0.0002466  loss_mask_8: 0.1282  loss_dice_8: 0.182  time: 0.4338  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:29:08] d2.utils.events INFO:  eta: 6:47:07  iter: 5679  total_loss: 3.775  loss_ce: 0.0001969  loss_mask: 0.1269  loss_dice: 0.2213  loss_ce_0: 0.1225  loss_mask_0: 0.1306  loss_dice_0: 0.2197  loss_ce_1: 0.0006052  loss_mask_1: 0.1323  loss_dice_1: 0.2263  loss_ce_2: 0.0001965  loss_mask_2: 0.1335  loss_dice_2: 0.2251  loss_ce_3: 0.0001447  loss_mask_3: 0.1292  loss_dice_3: 0.2316  loss_ce_4: 0.0001404  loss_mask_4: 0.1278  loss_dice_4: 0.2264  loss_ce_5: 0.000162  loss_mask_5: 0.1287  loss_dice_5: 0.2203  loss_ce_6: 0.0001817  loss_mask_6: 0.1296  loss_dice_6: 0.2287  loss_ce_7: 0.0002639  loss_mask_7: 0.1349  loss_dice_7: 0.2287  loss_ce_8: 0.0002558  loss_mask_8: 0.1321  loss_dice_8: 0.2202  time: 0.4352  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:29:25] d2.utils.events INFO:  eta: 6:47:18  iter: 5699  total_loss: 3.969  loss_ce: 0.001467  loss_mask: 0.1413  loss_dice: 0.2034  loss_ce_0: 0.1259  loss_mask_0: 0.1375  loss_dice_0: 0.2163  loss_ce_1: 0.001694  loss_mask_1: 0.1369  loss_dice_1: 0.199  loss_ce_2: 0.0004581  loss_mask_2: 0.1409  loss_dice_2: 0.2116  loss_ce_3: 0.00118  loss_mask_3: 0.133  loss_dice_3: 0.2148  loss_ce_4: 0.0006652  loss_mask_4: 0.1296  loss_dice_4: 0.2035  loss_ce_5: 0.0004755  loss_mask_5: 0.1397  loss_dice_5: 0.2102  loss_ce_6: 0.001322  loss_mask_6: 0.136  loss_dice_6: 0.2094  loss_ce_7: 0.000977  loss_mask_7: 0.1352  loss_dice_7: 0.2051  loss_ce_8: 0.0007087  loss_mask_8: 0.1351  loss_dice_8: 0.2065  time: 0.4366  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:29:42] d2.utils.events INFO:  eta: 6:47:25  iter: 5719  total_loss: 3.249  loss_ce: 0.0004909  loss_mask: 0.1203  loss_dice: 0.1854  loss_ce_0: 0.124  loss_mask_0: 0.123  loss_dice_0: 0.1957  loss_ce_1: 0.000879  loss_mask_1: 0.1246  loss_dice_1: 0.1879  loss_ce_2: 0.0002949  loss_mask_2: 0.124  loss_dice_2: 0.1773  loss_ce_3: 0.0003603  loss_mask_3: 0.1207  loss_dice_3: 0.1823  loss_ce_4: 0.0003781  loss_mask_4: 0.124  loss_dice_4: 0.1862  loss_ce_5: 0.0002524  loss_mask_5: 0.1237  loss_dice_5: 0.1813  loss_ce_6: 0.0003883  loss_mask_6: 0.1255  loss_dice_6: 0.1814  loss_ce_7: 0.000644  loss_mask_7: 0.1185  loss_dice_7: 0.1865  loss_ce_8: 0.000525  loss_mask_8: 0.1254  loss_dice_8: 0.1887  time: 0.4381  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:29:59] d2.utils.events INFO:  eta: 6:47:30  iter: 5739  total_loss: 3.041  loss_ce: 0.001482  loss_mask: 0.1218  loss_dice: 0.1698  loss_ce_0: 0.1213  loss_mask_0: 0.1173  loss_dice_0: 0.1696  loss_ce_1: 0.001525  loss_mask_1: 0.1198  loss_dice_1: 0.1649  loss_ce_2: 0.0005988  loss_mask_2: 0.1207  loss_dice_2: 0.1666  loss_ce_3: 0.001481  loss_mask_3: 0.1211  loss_dice_3: 0.1659  loss_ce_4: 0.0009586  loss_mask_4: 0.1194  loss_dice_4: 0.1702  loss_ce_5: 0.000425  loss_mask_5: 0.1242  loss_dice_5: 0.171  loss_ce_6: 0.0009155  loss_mask_6: 0.1204  loss_dice_6: 0.1671  loss_ce_7: 0.001493  loss_mask_7: 0.1204  loss_dice_7: 0.1687  loss_ce_8: 0.0009291  loss_mask_8: 0.1209  loss_dice_8: 0.1684  time: 0.4395  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:30:16] d2.utils.events INFO:  eta: 6:47:42  iter: 5759  total_loss: 3.485  loss_ce: 0.001497  loss_mask: 0.1264  loss_dice: 0.1829  loss_ce_0: 0.1315  loss_mask_0: 0.1268  loss_dice_0: 0.1933  loss_ce_1: 0.001214  loss_mask_1: 0.1273  loss_dice_1: 0.1932  loss_ce_2: 0.001703  loss_mask_2: 0.124  loss_dice_2: 0.1899  loss_ce_3: 0.001434  loss_mask_3: 0.1308  loss_dice_3: 0.1905  loss_ce_4: 0.001165  loss_mask_4: 0.1276  loss_dice_4: 0.1883  loss_ce_5: 0.001871  loss_mask_5: 0.1237  loss_dice_5: 0.1906  loss_ce_6: 0.0006738  loss_mask_6: 0.12  loss_dice_6: 0.1855  loss_ce_7: 0.001238  loss_mask_7: 0.1258  loss_dice_7: 0.19  loss_ce_8: 0.002524  loss_mask_8: 0.1258  loss_dice_8: 0.1963  time: 0.4409  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:30:33] d2.utils.events INFO:  eta: 6:47:51  iter: 5779  total_loss: 3.237  loss_ce: 0.001705  loss_mask: 0.1255  loss_dice: 0.1751  loss_ce_0: 0.1311  loss_mask_0: 0.1244  loss_dice_0: 0.1759  loss_ce_1: 0.002927  loss_mask_1: 0.1232  loss_dice_1: 0.1706  loss_ce_2: 0.003335  loss_mask_2: 0.1243  loss_dice_2: 0.1759  loss_ce_3: 0.003108  loss_mask_3: 0.126  loss_dice_3: 0.174  loss_ce_4: 0.003014  loss_mask_4: 0.1234  loss_dice_4: 0.1793  loss_ce_5: 0.003085  loss_mask_5: 0.1273  loss_dice_5: 0.176  loss_ce_6: 0.002491  loss_mask_6: 0.1263  loss_dice_6: 0.1784  loss_ce_7: 0.003265  loss_mask_7: 0.1231  loss_dice_7: 0.1772  loss_ce_8: 0.002085  loss_mask_8: 0.1251  loss_dice_8: 0.1734  time: 0.4424  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:30:50] d2.utils.events INFO:  eta: 6:48:04  iter: 5799  total_loss: 3.326  loss_ce: 0.000353  loss_mask: 0.1231  loss_dice: 0.1919  loss_ce_0: 0.1275  loss_mask_0: 0.1241  loss_dice_0: 0.1908  loss_ce_1: 0.0008815  loss_mask_1: 0.1252  loss_dice_1: 0.1953  loss_ce_2: 0.000404  loss_mask_2: 0.127  loss_dice_2: 0.1909  loss_ce_3: 0.001208  loss_mask_3: 0.1293  loss_dice_3: 0.1934  loss_ce_4: 0.0007442  loss_mask_4: 0.1245  loss_dice_4: 0.1894  loss_ce_5: 0.0002693  loss_mask_5: 0.1324  loss_dice_5: 0.1937  loss_ce_6: 0.0008424  loss_mask_6: 0.128  loss_dice_6: 0.1868  loss_ce_7: 0.0006275  loss_mask_7: 0.1279  loss_dice_7: 0.1876  loss_ce_8: 0.0007295  loss_mask_8: 0.1267  loss_dice_8: 0.1926  time: 0.4437  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:31:07] d2.utils.events INFO:  eta: 6:48:25  iter: 5819  total_loss: 3.114  loss_ce: 0.0001454  loss_mask: 0.1207  loss_dice: 0.1715  loss_ce_0: 0.1274  loss_mask_0: 0.123  loss_dice_0: 0.1725  loss_ce_1: 0.0005281  loss_mask_1: 0.1246  loss_dice_1: 0.1773  loss_ce_2: 0.000254  loss_mask_2: 0.1221  loss_dice_2: 0.1761  loss_ce_3: 0.0004316  loss_mask_3: 0.1262  loss_dice_3: 0.1713  loss_ce_4: 0.000345  loss_mask_4: 0.1276  loss_dice_4: 0.1749  loss_ce_5: 0.0001651  loss_mask_5: 0.1258  loss_dice_5: 0.1738  loss_ce_6: 0.0002947  loss_mask_6: 0.1212  loss_dice_6: 0.1717  loss_ce_7: 0.0003018  loss_mask_7: 0.1218  loss_dice_7: 0.1722  loss_ce_8: 0.0002935  loss_mask_8: 0.1234  loss_dice_8: 0.1733  time: 0.4451  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:31:24] d2.utils.events INFO:  eta: 6:48:16  iter: 5839  total_loss: 3.299  loss_ce: 0.0001712  loss_mask: 0.1255  loss_dice: 0.1898  loss_ce_0: 0.1239  loss_mask_0: 0.1233  loss_dice_0: 0.1956  loss_ce_1: 0.0004485  loss_mask_1: 0.1265  loss_dice_1: 0.1911  loss_ce_2: 0.0002222  loss_mask_2: 0.1287  loss_dice_2: 0.1968  loss_ce_3: 0.0004794  loss_mask_3: 0.127  loss_dice_3: 0.1967  loss_ce_4: 0.0003341  loss_mask_4: 0.1258  loss_dice_4: 0.1932  loss_ce_5: 0.000235  loss_mask_5: 0.1238  loss_dice_5: 0.1949  loss_ce_6: 0.0003609  loss_mask_6: 0.122  loss_dice_6: 0.1839  loss_ce_7: 0.0004637  loss_mask_7: 0.1282  loss_dice_7: 0.1993  loss_ce_8: 0.0002886  loss_mask_8: 0.1249  loss_dice_8: 0.1924  time: 0.4465  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 17:31:41] d2.utils.events INFO:  eta: 6:48:57  iter: 5859  total_loss: 3.225  loss_ce: 0.000126  loss_mask: 0.124  loss_dice: 0.1827  loss_ce_0: 0.1266  loss_mask_0: 0.1233  loss_dice_0: 0.1835  loss_ce_1: 0.0003648  loss_mask_1: 0.1205  loss_dice_1: 0.1759  loss_ce_2: 0.0002007  loss_mask_2: 0.124  loss_dice_2: 0.1809  loss_ce_3: 0.0005007  loss_mask_3: 0.1214  loss_dice_3: 0.18  loss_ce_4: 0.0003022  loss_mask_4: 0.1203  loss_dice_4: 0.1781  loss_ce_5: 0.0002183  loss_mask_5: 0.1263  loss_dice_5: 0.1799  loss_ce_6: 0.0003331  loss_mask_6: 0.1223  loss_dice_6: 0.1854  loss_ce_7: 0.0003715  loss_mask_7: 0.1234  loss_dice_7: 0.1794  loss_ce_8: 0.0002239  loss_mask_8: 0.1251  loss_dice_8: 0.1821  time: 0.4479  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:31:58] d2.utils.events INFO:  eta: 6:49:15  iter: 5879  total_loss: 3.085  loss_ce: 0.0001272  loss_mask: 0.1191  loss_dice: 0.175  loss_ce_0: 0.1304  loss_mask_0: 0.1159  loss_dice_0: 0.1694  loss_ce_1: 0.0003045  loss_mask_1: 0.1209  loss_dice_1: 0.1701  loss_ce_2: 0.0002046  loss_mask_2: 0.1184  loss_dice_2: 0.1763  loss_ce_3: 0.0003145  loss_mask_3: 0.1216  loss_dice_3: 0.1781  loss_ce_4: 0.0002359  loss_mask_4: 0.1158  loss_dice_4: 0.1759  loss_ce_5: 0.0001721  loss_mask_5: 0.1212  loss_dice_5: 0.1744  loss_ce_6: 0.0002507  loss_mask_6: 0.1249  loss_dice_6: 0.1793  loss_ce_7: 0.000348  loss_mask_7: 0.1169  loss_dice_7: 0.1754  loss_ce_8: 0.0001915  loss_mask_8: 0.1238  loss_dice_8: 0.1774  time: 0.4492  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:32:15] d2.utils.events INFO:  eta: 6:49:08  iter: 5899  total_loss: 3.168  loss_ce: 0.0002589  loss_mask: 0.1247  loss_dice: 0.1846  loss_ce_0: 0.1277  loss_mask_0: 0.1268  loss_dice_0: 0.1791  loss_ce_1: 0.00039  loss_mask_1: 0.1263  loss_dice_1: 0.1833  loss_ce_2: 0.0002242  loss_mask_2: 0.1256  loss_dice_2: 0.1791  loss_ce_3: 0.0003833  loss_mask_3: 0.1269  loss_dice_3: 0.1854  loss_ce_4: 0.0002999  loss_mask_4: 0.1237  loss_dice_4: 0.18  loss_ce_5: 0.0002045  loss_mask_5: 0.1227  loss_dice_5: 0.181  loss_ce_6: 0.0002972  loss_mask_6: 0.1263  loss_dice_6: 0.1811  loss_ce_7: 0.0003815  loss_mask_7: 0.1271  loss_dice_7: 0.1805  loss_ce_8: 0.0002091  loss_mask_8: 0.1234  loss_dice_8: 0.1828  time: 0.4506  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:32:32] d2.utils.events INFO:  eta: 6:49:13  iter: 5919  total_loss: 3.27  loss_ce: 0.0001002  loss_mask: 0.1234  loss_dice: 0.1873  loss_ce_0: 0.1277  loss_mask_0: 0.1198  loss_dice_0: 0.1929  loss_ce_1: 0.0003534  loss_mask_1: 0.1215  loss_dice_1: 0.1898  loss_ce_2: 0.0001678  loss_mask_2: 0.121  loss_dice_2: 0.1922  loss_ce_3: 0.0002202  loss_mask_3: 0.1239  loss_dice_3: 0.192  loss_ce_4: 0.0001786  loss_mask_4: 0.124  loss_dice_4: 0.1897  loss_ce_5: 0.0001617  loss_mask_5: 0.1216  loss_dice_5: 0.1875  loss_ce_6: 0.0002135  loss_mask_6: 0.1228  loss_dice_6: 0.1879  loss_ce_7: 0.000245  loss_mask_7: 0.1273  loss_dice_7: 0.1965  loss_ce_8: 0.0001612  loss_mask_8: 0.1245  loss_dice_8: 0.1907  time: 0.4519  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:32:49] d2.utils.events INFO:  eta: 6:49:10  iter: 5939  total_loss: 3.08  loss_ce: 0.0002061  loss_mask: 0.123  loss_dice: 0.1743  loss_ce_0: 0.1327  loss_mask_0: 0.1231  loss_dice_0: 0.1775  loss_ce_1: 0.0002293  loss_mask_1: 0.1231  loss_dice_1: 0.1776  loss_ce_2: 0.0002707  loss_mask_2: 0.1231  loss_dice_2: 0.1724  loss_ce_3: 0.0002876  loss_mask_3: 0.1209  loss_dice_3: 0.1717  loss_ce_4: 0.0002799  loss_mask_4: 0.1223  loss_dice_4: 0.1746  loss_ce_5: 0.0002915  loss_mask_5: 0.1197  loss_dice_5: 0.1716  loss_ce_6: 0.0002352  loss_mask_6: 0.1202  loss_dice_6: 0.1689  loss_ce_7: 0.0003161  loss_mask_7: 0.1214  loss_dice_7: 0.1753  loss_ce_8: 0.0002593  loss_mask_8: 0.1231  loss_dice_8: 0.1743  time: 0.4532  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:33:05] d2.utils.events INFO:  eta: 6:49:08  iter: 5959  total_loss: 3.189  loss_ce: 0.0002163  loss_mask: 0.1205  loss_dice: 0.1875  loss_ce_0: 0.1286  loss_mask_0: 0.1196  loss_dice_0: 0.175  loss_ce_1: 0.0003095  loss_mask_1: 0.123  loss_dice_1: 0.18  loss_ce_2: 0.0002511  loss_mask_2: 0.1203  loss_dice_2: 0.1785  loss_ce_3: 0.0002802  loss_mask_3: 0.1229  loss_dice_3: 0.1794  loss_ce_4: 0.0002516  loss_mask_4: 0.1208  loss_dice_4: 0.1738  loss_ce_5: 0.0002529  loss_mask_5: 0.1195  loss_dice_5: 0.1769  loss_ce_6: 0.0002605  loss_mask_6: 0.1194  loss_dice_6: 0.1783  loss_ce_7: 0.0003279  loss_mask_7: 0.1248  loss_dice_7: 0.1816  loss_ce_8: 0.0003007  loss_mask_8: 0.1221  loss_dice_8: 0.1758  time: 0.4545  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:33:22] d2.utils.events INFO:  eta: 6:49:23  iter: 5979  total_loss: 3.223  loss_ce: 7.94e-05  loss_mask: 0.1282  loss_dice: 0.182  loss_ce_0: 0.1292  loss_mask_0: 0.1248  loss_dice_0: 0.1828  loss_ce_1: 0.0001956  loss_mask_1: 0.1278  loss_dice_1: 0.1845  loss_ce_2: 0.0001648  loss_mask_2: 0.1302  loss_dice_2: 0.1864  loss_ce_3: 0.0001837  loss_mask_3: 0.1309  loss_dice_3: 0.1853  loss_ce_4: 0.0001428  loss_mask_4: 0.1316  loss_dice_4: 0.1854  loss_ce_5: 0.0001221  loss_mask_5: 0.1285  loss_dice_5: 0.1897  loss_ce_6: 0.0001474  loss_mask_6: 0.1294  loss_dice_6: 0.1826  loss_ce_7: 0.0001573  loss_mask_7: 0.1285  loss_dice_7: 0.1886  loss_ce_8: 0.000137  loss_mask_8: 0.128  loss_dice_8: 0.1906  time: 0.4558  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:33:39] d2.utils.events INFO:  eta: 6:49:20  iter: 5999  total_loss: 3.15  loss_ce: 0.0001626  loss_mask: 0.1187  loss_dice: 0.1829  loss_ce_0: 0.1287  loss_mask_0: 0.1171  loss_dice_0: 0.189  loss_ce_1: 0.0002758  loss_mask_1: 0.1197  loss_dice_1: 0.182  loss_ce_2: 0.0002064  loss_mask_2: 0.126  loss_dice_2: 0.1858  loss_ce_3: 0.0002414  loss_mask_3: 0.1197  loss_dice_3: 0.1801  loss_ce_4: 0.0001691  loss_mask_4: 0.1173  loss_dice_4: 0.1831  loss_ce_5: 0.000177  loss_mask_5: 0.1184  loss_dice_5: 0.1813  loss_ce_6: 0.0001966  loss_mask_6: 0.1211  loss_dice_6: 0.1821  loss_ce_7: 0.0001981  loss_mask_7: 0.1198  loss_dice_7: 0.1893  loss_ce_8: 0.0001894  loss_mask_8: 0.1161  loss_dice_8: 0.1795  time: 0.4571  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:33:56] d2.utils.events INFO:  eta: 6:48:54  iter: 6019  total_loss: 3.128  loss_ce: 7.341e-05  loss_mask: 0.1254  loss_dice: 0.1771  loss_ce_0: 0.1288  loss_mask_0: 0.1232  loss_dice_0: 0.1787  loss_ce_1: 0.0001911  loss_mask_1: 0.119  loss_dice_1: 0.1697  loss_ce_2: 0.0001254  loss_mask_2: 0.1238  loss_dice_2: 0.1778  loss_ce_3: 0.0001273  loss_mask_3: 0.1221  loss_dice_3: 0.1758  loss_ce_4: 0.0001035  loss_mask_4: 0.121  loss_dice_4: 0.1729  loss_ce_5: 8.961e-05  loss_mask_5: 0.1247  loss_dice_5: 0.1833  loss_ce_6: 0.0001247  loss_mask_6: 0.1231  loss_dice_6: 0.1757  loss_ce_7: 0.0001005  loss_mask_7: 0.1216  loss_dice_7: 0.1757  loss_ce_8: 9.261e-05  loss_mask_8: 0.1231  loss_dice_8: 0.1797  time: 0.4584  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:34:13] d2.utils.events INFO:  eta: 6:48:43  iter: 6039  total_loss: 3.4  loss_ce: 0.0001289  loss_mask: 0.1324  loss_dice: 0.1783  loss_ce_0: 0.1274  loss_mask_0: 0.1312  loss_dice_0: 0.1816  loss_ce_1: 0.0001789  loss_mask_1: 0.1327  loss_dice_1: 0.1839  loss_ce_2: 0.0001174  loss_mask_2: 0.1306  loss_dice_2: 0.1819  loss_ce_3: 0.0001323  loss_mask_3: 0.1378  loss_dice_3: 0.1841  loss_ce_4: 0.0001289  loss_mask_4: 0.1326  loss_dice_4: 0.1865  loss_ce_5: 9.816e-05  loss_mask_5: 0.1321  loss_dice_5: 0.1858  loss_ce_6: 0.0001406  loss_mask_6: 0.1316  loss_dice_6: 0.1856  loss_ce_7: 0.0001394  loss_mask_7: 0.1373  loss_dice_7: 0.183  loss_ce_8: 0.0001218  loss_mask_8: 0.134  loss_dice_8: 0.1827  time: 0.4597  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:34:30] d2.utils.events INFO:  eta: 6:48:20  iter: 6059  total_loss: 3.248  loss_ce: 0.0001969  loss_mask: 0.1238  loss_dice: 0.1866  loss_ce_0: 0.1282  loss_mask_0: 0.1189  loss_dice_0: 0.19  loss_ce_1: 0.0002111  loss_mask_1: 0.1236  loss_dice_1: 0.1942  loss_ce_2: 0.0002389  loss_mask_2: 0.1182  loss_dice_2: 0.1837  loss_ce_3: 0.0002122  loss_mask_3: 0.1253  loss_dice_3: 0.1894  loss_ce_4: 0.0001899  loss_mask_4: 0.1228  loss_dice_4: 0.1885  loss_ce_5: 0.0001589  loss_mask_5: 0.1208  loss_dice_5: 0.1845  loss_ce_6: 0.0001619  loss_mask_6: 0.1205  loss_dice_6: 0.193  loss_ce_7: 0.0001796  loss_mask_7: 0.1183  loss_dice_7: 0.1822  loss_ce_8: 0.000165  loss_mask_8: 0.1231  loss_dice_8: 0.1893  time: 0.4610  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:34:47] d2.utils.events INFO:  eta: 6:48:08  iter: 6079  total_loss: 3.178  loss_ce: 0.0001038  loss_mask: 0.1202  loss_dice: 0.1772  loss_ce_0: 0.127  loss_mask_0: 0.1209  loss_dice_0: 0.1822  loss_ce_1: 0.0001358  loss_mask_1: 0.12  loss_dice_1: 0.1804  loss_ce_2: 0.000111  loss_mask_2: 0.122  loss_dice_2: 0.1827  loss_ce_3: 0.0001402  loss_mask_3: 0.1226  loss_dice_3: 0.1832  loss_ce_4: 0.0001051  loss_mask_4: 0.1175  loss_dice_4: 0.1826  loss_ce_5: 8.357e-05  loss_mask_5: 0.1183  loss_dice_5: 0.1789  loss_ce_6: 0.0001197  loss_mask_6: 0.1262  loss_dice_6: 0.1806  loss_ce_7: 0.0001395  loss_mask_7: 0.1196  loss_dice_7: 0.1785  loss_ce_8: 0.0001097  loss_mask_8: 0.1226  loss_dice_8: 0.1823  time: 0.4622  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:35:04] d2.utils.events INFO:  eta: 6:47:57  iter: 6099  total_loss: 3.441  loss_ce: 0.0002822  loss_mask: 0.1337  loss_dice: 0.1901  loss_ce_0: 0.1262  loss_mask_0: 0.1305  loss_dice_0: 0.1973  loss_ce_1: 0.000288  loss_mask_1: 0.1317  loss_dice_1: 0.1911  loss_ce_2: 0.0002156  loss_mask_2: 0.1322  loss_dice_2: 0.1903  loss_ce_3: 0.0002583  loss_mask_3: 0.1351  loss_dice_3: 0.195  loss_ce_4: 0.000224  loss_mask_4: 0.1295  loss_dice_4: 0.1996  loss_ce_5: 0.0002376  loss_mask_5: 0.1326  loss_dice_5: 0.2001  loss_ce_6: 0.0002652  loss_mask_6: 0.1336  loss_dice_6: 0.2006  loss_ce_7: 0.0002976  loss_mask_7: 0.134  loss_dice_7: 0.1961  loss_ce_8: 0.0002397  loss_mask_8: 0.1381  loss_dice_8: 0.1965  time: 0.4635  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:35:21] d2.utils.events INFO:  eta: 6:47:46  iter: 6119  total_loss: 3.038  loss_ce: 0.0002627  loss_mask: 0.1174  loss_dice: 0.1777  loss_ce_0: 0.1253  loss_mask_0: 0.118  loss_dice_0: 0.176  loss_ce_1: 0.0002248  loss_mask_1: 0.1232  loss_dice_1: 0.1777  loss_ce_2: 0.0002007  loss_mask_2: 0.117  loss_dice_2: 0.1774  loss_ce_3: 0.0001639  loss_mask_3: 0.1146  loss_dice_3: 0.176  loss_ce_4: 0.0001358  loss_mask_4: 0.1182  loss_dice_4: 0.1751  loss_ce_5: 0.0002051  loss_mask_5: 0.1204  loss_dice_5: 0.1774  loss_ce_6: 0.0002063  loss_mask_6: 0.1139  loss_dice_6: 0.1703  loss_ce_7: 0.000274  loss_mask_7: 0.1189  loss_dice_7: 0.1773  loss_ce_8: 0.000436  loss_mask_8: 0.1176  loss_dice_8: 0.1758  time: 0.4648  data_time: 0.0018  lr: 0.0001  max_mem: 8444M
[08/01 17:35:38] d2.utils.events INFO:  eta: 6:47:26  iter: 6139  total_loss: 3.101  loss_ce: 0.0002467  loss_mask: 0.1196  loss_dice: 0.1766  loss_ce_0: 0.1269  loss_mask_0: 0.1204  loss_dice_0: 0.1753  loss_ce_1: 0.0002752  loss_mask_1: 0.1237  loss_dice_1: 0.1769  loss_ce_2: 0.0002032  loss_mask_2: 0.1223  loss_dice_2: 0.1709  loss_ce_3: 0.0003126  loss_mask_3: 0.1246  loss_dice_3: 0.1744  loss_ce_4: 0.0001829  loss_mask_4: 0.123  loss_dice_4: 0.1735  loss_ce_5: 0.0001934  loss_mask_5: 0.1233  loss_dice_5: 0.1743  loss_ce_6: 0.0002117  loss_mask_6: 0.1221  loss_dice_6: 0.1772  loss_ce_7: 0.000238  loss_mask_7: 0.1235  loss_dice_7: 0.1828  loss_ce_8: 0.0003194  loss_mask_8: 0.1195  loss_dice_8: 0.1714  time: 0.4660  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:35:55] d2.utils.events INFO:  eta: 6:47:32  iter: 6159  total_loss: 3.455  loss_ce: 0.0001305  loss_mask: 0.1306  loss_dice: 0.198  loss_ce_0: 0.1282  loss_mask_0: 0.1346  loss_dice_0: 0.1974  loss_ce_1: 0.0001951  loss_mask_1: 0.1259  loss_dice_1: 0.1941  loss_ce_2: 0.0001628  loss_mask_2: 0.1261  loss_dice_2: 0.1907  loss_ce_3: 0.0001158  loss_mask_3: 0.1271  loss_dice_3: 0.1889  loss_ce_4: 0.0001017  loss_mask_4: 0.1257  loss_dice_4: 0.1861  loss_ce_5: 0.0001334  loss_mask_5: 0.1274  loss_dice_5: 0.1987  loss_ce_6: 0.0001358  loss_mask_6: 0.1322  loss_dice_6: 0.1951  loss_ce_7: 0.0001283  loss_mask_7: 0.1303  loss_dice_7: 0.1924  loss_ce_8: 0.0002091  loss_mask_8: 0.1333  loss_dice_8: 0.195  time: 0.4673  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:36:12] d2.utils.events INFO:  eta: 6:46:58  iter: 6179  total_loss: 3.053  loss_ce: 0.0002258  loss_mask: 0.1184  loss_dice: 0.1729  loss_ce_0: 0.1265  loss_mask_0: 0.1224  loss_dice_0: 0.1807  loss_ce_1: 0.0002327  loss_mask_1: 0.1204  loss_dice_1: 0.175  loss_ce_2: 0.0002157  loss_mask_2: 0.1178  loss_dice_2: 0.1723  loss_ce_3: 0.0002548  loss_mask_3: 0.1145  loss_dice_3: 0.1707  loss_ce_4: 0.0001847  loss_mask_4: 0.1198  loss_dice_4: 0.175  loss_ce_5: 0.0002185  loss_mask_5: 0.1178  loss_dice_5: 0.1732  loss_ce_6: 0.0001802  loss_mask_6: 0.1153  loss_dice_6: 0.1727  loss_ce_7: 0.0002145  loss_mask_7: 0.1194  loss_dice_7: 0.1715  loss_ce_8: 0.0002241  loss_mask_8: 0.1144  loss_dice_8: 0.1751  time: 0.4685  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 17:36:29] d2.utils.events INFO:  eta: 6:46:41  iter: 6199  total_loss: 3.159  loss_ce: 0.0002202  loss_mask: 0.1235  loss_dice: 0.1788  loss_ce_0: 0.1244  loss_mask_0: 0.1228  loss_dice_0: 0.1814  loss_ce_1: 0.0002062  loss_mask_1: 0.1231  loss_dice_1: 0.1749  loss_ce_2: 0.0002059  loss_mask_2: 0.1233  loss_dice_2: 0.1751  loss_ce_3: 0.0002275  loss_mask_3: 0.1216  loss_dice_3: 0.1748  loss_ce_4: 0.0001866  loss_mask_4: 0.1232  loss_dice_4: 0.1727  loss_ce_5: 0.0002075  loss_mask_5: 0.1212  loss_dice_5: 0.1757  loss_ce_6: 0.0001924  loss_mask_6: 0.1191  loss_dice_6: 0.174  loss_ce_7: 0.0002612  loss_mask_7: 0.12  loss_dice_7: 0.1738  loss_ce_8: 0.0002532  loss_mask_8: 0.1212  loss_dice_8: 0.1783  time: 0.4697  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:36:46] d2.utils.events INFO:  eta: 6:46:21  iter: 6219  total_loss: 3.327  loss_ce: 0.0001528  loss_mask: 0.124  loss_dice: 0.195  loss_ce_0: 0.1223  loss_mask_0: 0.1272  loss_dice_0: 0.1942  loss_ce_1: 0.000219  loss_mask_1: 0.1301  loss_dice_1: 0.193  loss_ce_2: 0.0001867  loss_mask_2: 0.127  loss_dice_2: 0.1952  loss_ce_3: 0.0001505  loss_mask_3: 0.1298  loss_dice_3: 0.1967  loss_ce_4: 0.0001241  loss_mask_4: 0.127  loss_dice_4: 0.1927  loss_ce_5: 0.0001673  loss_mask_5: 0.1259  loss_dice_5: 0.1925  loss_ce_6: 0.0001571  loss_mask_6: 0.1289  loss_dice_6: 0.1903  loss_ce_7: 0.0001787  loss_mask_7: 0.1271  loss_dice_7: 0.1946  loss_ce_8: 0.0002061  loss_mask_8: 0.1265  loss_dice_8: 0.1958  time: 0.4709  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:37:03] d2.utils.events INFO:  eta: 6:46:04  iter: 6239  total_loss: 3.482  loss_ce: 0.0001603  loss_mask: 0.1345  loss_dice: 0.1922  loss_ce_0: 0.1231  loss_mask_0: 0.1347  loss_dice_0: 0.2059  loss_ce_1: 0.0001962  loss_mask_1: 0.1387  loss_dice_1: 0.1979  loss_ce_2: 0.000169  loss_mask_2: 0.1371  loss_dice_2: 0.1959  loss_ce_3: 0.0001746  loss_mask_3: 0.138  loss_dice_3: 0.1993  loss_ce_4: 0.000164  loss_mask_4: 0.135  loss_dice_4: 0.1937  loss_ce_5: 0.0001683  loss_mask_5: 0.1374  loss_dice_5: 0.1993  loss_ce_6: 0.0001497  loss_mask_6: 0.1364  loss_dice_6: 0.198  loss_ce_7: 0.000173  loss_mask_7: 0.1308  loss_dice_7: 0.2003  loss_ce_8: 0.0001775  loss_mask_8: 0.1361  loss_dice_8: 0.1993  time: 0.4721  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:37:20] d2.utils.events INFO:  eta: 6:45:43  iter: 6259  total_loss: 3.402  loss_ce: 9.106e-05  loss_mask: 0.1268  loss_dice: 0.1931  loss_ce_0: 0.1217  loss_mask_0: 0.1282  loss_dice_0: 0.1931  loss_ce_1: 0.0001509  loss_mask_1: 0.1278  loss_dice_1: 0.2091  loss_ce_2: 0.0001381  loss_mask_2: 0.1309  loss_dice_2: 0.1963  loss_ce_3: 0.000103  loss_mask_3: 0.1317  loss_dice_3: 0.1956  loss_ce_4: 0.0001198  loss_mask_4: 0.1329  loss_dice_4: 0.194  loss_ce_5: 0.000129  loss_mask_5: 0.1326  loss_dice_5: 0.2012  loss_ce_6: 0.0001046  loss_mask_6: 0.1372  loss_dice_6: 0.1991  loss_ce_7: 0.0001145  loss_mask_7: 0.1347  loss_dice_7: 0.1961  loss_ce_8: 0.000135  loss_mask_8: 0.1284  loss_dice_8: 0.1896  time: 0.4733  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:37:37] d2.utils.events INFO:  eta: 6:45:34  iter: 6279  total_loss: 3.181  loss_ce: 0.0001253  loss_mask: 0.1215  loss_dice: 0.1843  loss_ce_0: 0.1221  loss_mask_0: 0.1228  loss_dice_0: 0.1842  loss_ce_1: 0.00015  loss_mask_1: 0.121  loss_dice_1: 0.179  loss_ce_2: 0.0001875  loss_mask_2: 0.1238  loss_dice_2: 0.1836  loss_ce_3: 0.0001517  loss_mask_3: 0.1224  loss_dice_3: 0.1808  loss_ce_4: 0.0001374  loss_mask_4: 0.1195  loss_dice_4: 0.176  loss_ce_5: 0.0001455  loss_mask_5: 0.1214  loss_dice_5: 0.1848  loss_ce_6: 0.0001176  loss_mask_6: 0.1181  loss_dice_6: 0.1829  loss_ce_7: 0.0001444  loss_mask_7: 0.1225  loss_dice_7: 0.1785  loss_ce_8: 0.0001465  loss_mask_8: 0.1209  loss_dice_8: 0.1795  time: 0.4745  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:37:54] d2.utils.events INFO:  eta: 6:45:13  iter: 6299  total_loss: 3.058  loss_ce: 0.0001672  loss_mask: 0.1181  loss_dice: 0.1699  loss_ce_0: 0.1305  loss_mask_0: 0.1203  loss_dice_0: 0.1746  loss_ce_1: 0.0002143  loss_mask_1: 0.1183  loss_dice_1: 0.169  loss_ce_2: 0.0002652  loss_mask_2: 0.1243  loss_dice_2: 0.1751  loss_ce_3: 0.0001959  loss_mask_3: 0.1205  loss_dice_3: 0.1732  loss_ce_4: 0.0001205  loss_mask_4: 0.1203  loss_dice_4: 0.172  loss_ce_5: 0.0001374  loss_mask_5: 0.1246  loss_dice_5: 0.1753  loss_ce_6: 0.000159  loss_mask_6: 0.1189  loss_dice_6: 0.1731  loss_ce_7: 0.0001938  loss_mask_7: 0.1198  loss_dice_7: 0.171  loss_ce_8: 0.0001828  loss_mask_8: 0.1222  loss_dice_8: 0.1724  time: 0.4757  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:38:11] d2.utils.events INFO:  eta: 6:44:54  iter: 6319  total_loss: 3.525  loss_ce: 6.388e-05  loss_mask: 0.1297  loss_dice: 0.193  loss_ce_0: 0.1251  loss_mask_0: 0.1369  loss_dice_0: 0.2072  loss_ce_1: 0.0002521  loss_mask_1: 0.1343  loss_dice_1: 0.1952  loss_ce_2: 0.0001375  loss_mask_2: 0.1317  loss_dice_2: 0.1872  loss_ce_3: 9.452e-05  loss_mask_3: 0.1275  loss_dice_3: 0.1978  loss_ce_4: 7.129e-05  loss_mask_4: 0.134  loss_dice_4: 0.1953  loss_ce_5: 7.175e-05  loss_mask_5: 0.1289  loss_dice_5: 0.1966  loss_ce_6: 9.331e-05  loss_mask_6: 0.1285  loss_dice_6: 0.2002  loss_ce_7: 7.902e-05  loss_mask_7: 0.1287  loss_dice_7: 0.1984  loss_ce_8: 7.471e-05  loss_mask_8: 0.1345  loss_dice_8: 0.1952  time: 0.4769  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:38:27] d2.utils.events INFO:  eta: 6:44:23  iter: 6339  total_loss: 3.317  loss_ce: 7.783e-05  loss_mask: 0.1193  loss_dice: 0.1878  loss_ce_0: 0.1233  loss_mask_0: 0.1307  loss_dice_0: 0.1961  loss_ce_1: 0.0001552  loss_mask_1: 0.124  loss_dice_1: 0.1888  loss_ce_2: 0.0001233  loss_mask_2: 0.1246  loss_dice_2: 0.1928  loss_ce_3: 0.0001058  loss_mask_3: 0.1313  loss_dice_3: 0.191  loss_ce_4: 6.065e-05  loss_mask_4: 0.1287  loss_dice_4: 0.1963  loss_ce_5: 6.97e-05  loss_mask_5: 0.1277  loss_dice_5: 0.2003  loss_ce_6: 8.58e-05  loss_mask_6: 0.128  loss_dice_6: 0.1886  loss_ce_7: 9.163e-05  loss_mask_7: 0.1316  loss_dice_7: 0.195  loss_ce_8: 8.859e-05  loss_mask_8: 0.1293  loss_dice_8: 0.1932  time: 0.4780  data_time: 0.0017  lr: 0.0001  max_mem: 8444M
[08/01 17:38:44] d2.utils.events INFO:  eta: 6:43:57  iter: 6359  total_loss: 3.215  loss_ce: 0.0001683  loss_mask: 0.1221  loss_dice: 0.1852  loss_ce_0: 0.1257  loss_mask_0: 0.1209  loss_dice_0: 0.1853  loss_ce_1: 0.0001663  loss_mask_1: 0.1223  loss_dice_1: 0.1872  loss_ce_2: 0.0001704  loss_mask_2: 0.1226  loss_dice_2: 0.1872  loss_ce_3: 0.0001482  loss_mask_3: 0.1258  loss_dice_3: 0.1835  loss_ce_4: 0.0001763  loss_mask_4: 0.1249  loss_dice_4: 0.1875  loss_ce_5: 0.0001502  loss_mask_5: 0.1209  loss_dice_5: 0.1848  loss_ce_6: 0.0001255  loss_mask_6: 0.1238  loss_dice_6: 0.1871  loss_ce_7: 0.0001447  loss_mask_7: 0.1206  loss_dice_7: 0.1867  loss_ce_8: 0.0001847  loss_mask_8: 0.1212  loss_dice_8: 0.1789  time: 0.4792  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:39:01] d2.utils.events INFO:  eta: 6:43:25  iter: 6379  total_loss: 3.293  loss_ce: 0.0001138  loss_mask: 0.1293  loss_dice: 0.1919  loss_ce_0: 0.1196  loss_mask_0: 0.1259  loss_dice_0: 0.1866  loss_ce_1: 0.0001195  loss_mask_1: 0.1236  loss_dice_1: 0.1925  loss_ce_2: 0.0001382  loss_mask_2: 0.1274  loss_dice_2: 0.188  loss_ce_3: 9.31e-05  loss_mask_3: 0.1259  loss_dice_3: 0.1928  loss_ce_4: 9.507e-05  loss_mask_4: 0.1257  loss_dice_4: 0.1903  loss_ce_5: 0.0001134  loss_mask_5: 0.1282  loss_dice_5: 0.1984  loss_ce_6: 9.882e-05  loss_mask_6: 0.1257  loss_dice_6: 0.1876  loss_ce_7: 0.0001007  loss_mask_7: 0.1304  loss_dice_7: 0.1932  loss_ce_8: 0.0001432  loss_mask_8: 0.1286  loss_dice_8: 0.1925  time: 0.4803  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:39:18] d2.utils.events INFO:  eta: 6:43:04  iter: 6399  total_loss: 3.309  loss_ce: 5.172e-05  loss_mask: 0.1262  loss_dice: 0.1927  loss_ce_0: 0.13  loss_mask_0: 0.1208  loss_dice_0: 0.1864  loss_ce_1: 0.000104  loss_mask_1: 0.1217  loss_dice_1: 0.1935  loss_ce_2: 9.625e-05  loss_mask_2: 0.1221  loss_dice_2: 0.1853  loss_ce_3: 8.613e-05  loss_mask_3: 0.1234  loss_dice_3: 0.1997  loss_ce_4: 7.1e-05  loss_mask_4: 0.1221  loss_dice_4: 0.1935  loss_ce_5: 7.122e-05  loss_mask_5: 0.1238  loss_dice_5: 0.198  loss_ce_6: 7.787e-05  loss_mask_6: 0.1243  loss_dice_6: 0.1945  loss_ce_7: 8.853e-05  loss_mask_7: 0.1223  loss_dice_7: 0.2074  loss_ce_8: 7.119e-05  loss_mask_8: 0.1258  loss_dice_8: 0.1973  time: 0.4815  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:39:35] d2.utils.events INFO:  eta: 6:43:12  iter: 6419  total_loss: 3.201  loss_ce: 0.0001008  loss_mask: 0.1296  loss_dice: 0.1835  loss_ce_0: 0.1249  loss_mask_0: 0.1235  loss_dice_0: 0.1826  loss_ce_1: 0.0001137  loss_mask_1: 0.1241  loss_dice_1: 0.1828  loss_ce_2: 0.0001317  loss_mask_2: 0.1254  loss_dice_2: 0.182  loss_ce_3: 0.0001064  loss_mask_3: 0.1218  loss_dice_3: 0.1856  loss_ce_4: 8.644e-05  loss_mask_4: 0.1235  loss_dice_4: 0.1803  loss_ce_5: 0.0001026  loss_mask_5: 0.1263  loss_dice_5: 0.1811  loss_ce_6: 0.0001035  loss_mask_6: 0.1207  loss_dice_6: 0.176  loss_ce_7: 9.979e-05  loss_mask_7: 0.1252  loss_dice_7: 0.1772  loss_ce_8: 0.0001179  loss_mask_8: 0.122  loss_dice_8: 0.1839  time: 0.4826  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:39:52] d2.utils.events INFO:  eta: 6:42:55  iter: 6439  total_loss: 3.123  loss_ce: 0.0001086  loss_mask: 0.1226  loss_dice: 0.1731  loss_ce_0: 0.1181  loss_mask_0: 0.123  loss_dice_0: 0.1822  loss_ce_1: 0.000159  loss_mask_1: 0.1231  loss_dice_1: 0.1755  loss_ce_2: 0.0001168  loss_mask_2: 0.1229  loss_dice_2: 0.1725  loss_ce_3: 0.0001044  loss_mask_3: 0.1226  loss_dice_3: 0.1729  loss_ce_4: 0.0001005  loss_mask_4: 0.1228  loss_dice_4: 0.1732  loss_ce_5: 0.0001022  loss_mask_5: 0.1218  loss_dice_5: 0.1709  loss_ce_6: 8.547e-05  loss_mask_6: 0.1195  loss_dice_6: 0.1758  loss_ce_7: 9.029e-05  loss_mask_7: 0.1232  loss_dice_7: 0.177  loss_ce_8: 0.0001269  loss_mask_8: 0.1249  loss_dice_8: 0.173  time: 0.4837  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:40:09] d2.utils.events INFO:  eta: 6:42:41  iter: 6459  total_loss: 3.454  loss_ce: 0.0001459  loss_mask: 0.1377  loss_dice: 0.2015  loss_ce_0: 0.1314  loss_mask_0: 0.1295  loss_dice_0: 0.1966  loss_ce_1: 0.0001188  loss_mask_1: 0.1328  loss_dice_1: 0.1994  loss_ce_2: 0.0001483  loss_mask_2: 0.1362  loss_dice_2: 0.2018  loss_ce_3: 0.0001251  loss_mask_3: 0.1325  loss_dice_3: 0.1954  loss_ce_4: 0.0001392  loss_mask_4: 0.1331  loss_dice_4: 0.1974  loss_ce_5: 0.0001485  loss_mask_5: 0.1352  loss_dice_5: 0.1986  loss_ce_6: 0.0001162  loss_mask_6: 0.1335  loss_dice_6: 0.2011  loss_ce_7: 0.0001426  loss_mask_7: 0.1274  loss_dice_7: 0.2076  loss_ce_8: 0.0001569  loss_mask_8: 0.1382  loss_dice_8: 0.2011  time: 0.4849  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:40:26] d2.utils.events INFO:  eta: 6:42:24  iter: 6479  total_loss: 3.042  loss_ce: 0.0001236  loss_mask: 0.1208  loss_dice: 0.1739  loss_ce_0: 0.1266  loss_mask_0: 0.1227  loss_dice_0: 0.178  loss_ce_1: 0.000126  loss_mask_1: 0.1195  loss_dice_1: 0.1729  loss_ce_2: 0.0001292  loss_mask_2: 0.1222  loss_dice_2: 0.178  loss_ce_3: 0.0001748  loss_mask_3: 0.1203  loss_dice_3: 0.1761  loss_ce_4: 0.0001373  loss_mask_4: 0.1206  loss_dice_4: 0.177  loss_ce_5: 0.0001291  loss_mask_5: 0.1159  loss_dice_5: 0.1688  loss_ce_6: 0.0001513  loss_mask_6: 0.1141  loss_dice_6: 0.1733  loss_ce_7: 0.0001613  loss_mask_7: 0.1182  loss_dice_7: 0.1689  loss_ce_8: 0.0001508  loss_mask_8: 0.1199  loss_dice_8: 0.1738  time: 0.4860  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:40:43] d2.utils.events INFO:  eta: 6:42:08  iter: 6499  total_loss: 3.141  loss_ce: 0.0004253  loss_mask: 0.1192  loss_dice: 0.1807  loss_ce_0: 0.1261  loss_mask_0: 0.118  loss_dice_0: 0.1788  loss_ce_1: 0.0003311  loss_mask_1: 0.1217  loss_dice_1: 0.1803  loss_ce_2: 0.0003967  loss_mask_2: 0.1214  loss_dice_2: 0.1768  loss_ce_3: 0.0005512  loss_mask_3: 0.122  loss_dice_3: 0.1775  loss_ce_4: 0.0007384  loss_mask_4: 0.1207  loss_dice_4: 0.1825  loss_ce_5: 0.0004702  loss_mask_5: 0.1207  loss_dice_5: 0.1824  loss_ce_6: 0.0002513  loss_mask_6: 0.125  loss_dice_6: 0.1805  loss_ce_7: 0.0004786  loss_mask_7: 0.117  loss_dice_7: 0.1751  loss_ce_8: 0.0005688  loss_mask_8: 0.1159  loss_dice_8: 0.1812  time: 0.4871  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:41:00] d2.utils.events INFO:  eta: 6:41:51  iter: 6519  total_loss: 3.272  loss_ce: 0.00018  loss_mask: 0.1164  loss_dice: 0.1885  loss_ce_0: 0.1255  loss_mask_0: 0.1209  loss_dice_0: 0.1906  loss_ce_1: 0.0003955  loss_mask_1: 0.1189  loss_dice_1: 0.1853  loss_ce_2: 0.0003551  loss_mask_2: 0.1152  loss_dice_2: 0.1858  loss_ce_3: 0.0001804  loss_mask_3: 0.1208  loss_dice_3: 0.1886  loss_ce_4: 0.0002062  loss_mask_4: 0.1199  loss_dice_4: 0.1894  loss_ce_5: 0.0003951  loss_mask_5: 0.1196  loss_dice_5: 0.185  loss_ce_6: 0.0001454  loss_mask_6: 0.1199  loss_dice_6: 0.1872  loss_ce_7: 0.000248  loss_mask_7: 0.1226  loss_dice_7: 0.1851  loss_ce_8: 0.0003395  loss_mask_8: 0.1197  loss_dice_8: 0.184  time: 0.4882  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:41:17] d2.utils.events INFO:  eta: 6:41:34  iter: 6539  total_loss: 3.169  loss_ce: 0.000157  loss_mask: 0.1223  loss_dice: 0.1752  loss_ce_0: 0.1246  loss_mask_0: 0.1247  loss_dice_0: 0.1811  loss_ce_1: 0.0003518  loss_mask_1: 0.124  loss_dice_1: 0.1784  loss_ce_2: 0.0002446  loss_mask_2: 0.1219  loss_dice_2: 0.1822  loss_ce_3: 0.0001254  loss_mask_3: 0.1234  loss_dice_3: 0.1788  loss_ce_4: 0.0001361  loss_mask_4: 0.1212  loss_dice_4: 0.1757  loss_ce_5: 0.0002062  loss_mask_5: 0.1227  loss_dice_5: 0.1836  loss_ce_6: 0.0001144  loss_mask_6: 0.1258  loss_dice_6: 0.1805  loss_ce_7: 0.0001929  loss_mask_7: 0.1204  loss_dice_7: 0.1782  loss_ce_8: 0.0003063  loss_mask_8: 0.1249  loss_dice_8: 0.1812  time: 0.4893  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:41:34] d2.utils.events INFO:  eta: 6:41:17  iter: 6559  total_loss: 3.171  loss_ce: 0.0001255  loss_mask: 0.121  loss_dice: 0.1832  loss_ce_0: 0.1248  loss_mask_0: 0.1266  loss_dice_0: 0.188  loss_ce_1: 0.0003312  loss_mask_1: 0.1177  loss_dice_1: 0.1781  loss_ce_2: 0.0002481  loss_mask_2: 0.1205  loss_dice_2: 0.1791  loss_ce_3: 0.0001218  loss_mask_3: 0.1156  loss_dice_3: 0.175  loss_ce_4: 0.0001385  loss_mask_4: 0.1201  loss_dice_4: 0.178  loss_ce_5: 0.0002149  loss_mask_5: 0.1181  loss_dice_5: 0.1782  loss_ce_6: 0.0001115  loss_mask_6: 0.1237  loss_dice_6: 0.1767  loss_ce_7: 0.0001638  loss_mask_7: 0.1175  loss_dice_7: 0.1711  loss_ce_8: 0.0003194  loss_mask_8: 0.117  loss_dice_8: 0.1689  time: 0.4904  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:41:51] d2.utils.events INFO:  eta: 6:41:10  iter: 6579  total_loss: 3.146  loss_ce: 0.00012  loss_mask: 0.1247  loss_dice: 0.175  loss_ce_0: 0.1245  loss_mask_0: 0.1263  loss_dice_0: 0.1744  loss_ce_1: 0.0002195  loss_mask_1: 0.1242  loss_dice_1: 0.1778  loss_ce_2: 0.0002179  loss_mask_2: 0.122  loss_dice_2: 0.1736  loss_ce_3: 0.0001274  loss_mask_3: 0.1227  loss_dice_3: 0.1733  loss_ce_4: 0.0001202  loss_mask_4: 0.1234  loss_dice_4: 0.1733  loss_ce_5: 0.0001758  loss_mask_5: 0.1214  loss_dice_5: 0.1752  loss_ce_6: 0.0001104  loss_mask_6: 0.1206  loss_dice_6: 0.1708  loss_ce_7: 0.0001525  loss_mask_7: 0.1243  loss_dice_7: 0.1775  loss_ce_8: 0.0002199  loss_mask_8: 0.1276  loss_dice_8: 0.1765  time: 0.4915  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:42:08] d2.utils.events INFO:  eta: 6:40:46  iter: 6599  total_loss: 3.251  loss_ce: 9.675e-05  loss_mask: 0.1235  loss_dice: 0.188  loss_ce_0: 0.1216  loss_mask_0: 0.1206  loss_dice_0: 0.19  loss_ce_1: 0.0002776  loss_mask_1: 0.1173  loss_dice_1: 0.1823  loss_ce_2: 0.0001777  loss_mask_2: 0.1246  loss_dice_2: 0.1856  loss_ce_3: 7.583e-05  loss_mask_3: 0.1219  loss_dice_3: 0.1866  loss_ce_4: 9.548e-05  loss_mask_4: 0.1223  loss_dice_4: 0.1946  loss_ce_5: 0.0001232  loss_mask_5: 0.1216  loss_dice_5: 0.1864  loss_ce_6: 8.34e-05  loss_mask_6: 0.121  loss_dice_6: 0.1868  loss_ce_7: 0.00013  loss_mask_7: 0.1229  loss_dice_7: 0.1919  loss_ce_8: 0.000176  loss_mask_8: 0.1206  loss_dice_8: 0.185  time: 0.4926  data_time: 0.0018  lr: 0.0001  max_mem: 8444M
[08/01 17:42:25] d2.utils.events INFO:  eta: 6:40:26  iter: 6619  total_loss: 3.085  loss_ce: 0.0001828  loss_mask: 0.1199  loss_dice: 0.1713  loss_ce_0: 0.1347  loss_mask_0: 0.1212  loss_dice_0: 0.1709  loss_ce_1: 0.0004109  loss_mask_1: 0.1244  loss_dice_1: 0.1674  loss_ce_2: 0.0002711  loss_mask_2: 0.1217  loss_dice_2: 0.169  loss_ce_3: 0.0001446  loss_mask_3: 0.1212  loss_dice_3: 0.1751  loss_ce_4: 0.0001741  loss_mask_4: 0.1207  loss_dice_4: 0.1711  loss_ce_5: 0.0002159  loss_mask_5: 0.1176  loss_dice_5: 0.1702  loss_ce_6: 0.0001299  loss_mask_6: 0.1205  loss_dice_6: 0.1728  loss_ce_7: 0.0002457  loss_mask_7: 0.1222  loss_dice_7: 0.1751  loss_ce_8: 0.0002608  loss_mask_8: 0.12  loss_dice_8: 0.1704  time: 0.4937  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:42:42] d2.utils.events INFO:  eta: 6:40:09  iter: 6639  total_loss: 3.303  loss_ce: 0.001909  loss_mask: 0.121  loss_dice: 0.1812  loss_ce_0: 0.119  loss_mask_0: 0.1219  loss_dice_0: 0.1939  loss_ce_1: 0.001256  loss_mask_1: 0.1179  loss_dice_1: 0.1888  loss_ce_2: 0.001333  loss_mask_2: 0.118  loss_dice_2: 0.1865  loss_ce_3: 0.001281  loss_mask_3: 0.1221  loss_dice_3: 0.1911  loss_ce_4: 0.0008521  loss_mask_4: 0.1222  loss_dice_4: 0.1847  loss_ce_5: 0.001243  loss_mask_5: 0.1239  loss_dice_5: 0.1855  loss_ce_6: 0.0006156  loss_mask_6: 0.1207  loss_dice_6: 0.1916  loss_ce_7: 0.001637  loss_mask_7: 0.1184  loss_dice_7: 0.1891  loss_ce_8: 0.001269  loss_mask_8: 0.1218  loss_dice_8: 0.1851  time: 0.4947  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:42:59] d2.utils.events INFO:  eta: 6:39:52  iter: 6659  total_loss: 3.176  loss_ce: 0.0002951  loss_mask: 0.1263  loss_dice: 0.1815  loss_ce_0: 0.1256  loss_mask_0: 0.1247  loss_dice_0: 0.1821  loss_ce_1: 0.005633  loss_mask_1: 0.1218  loss_dice_1: 0.1856  loss_ce_2: 0.0004945  loss_mask_2: 0.1251  loss_dice_2: 0.1824  loss_ce_3: 0.0003729  loss_mask_3: 0.1247  loss_dice_3: 0.1854  loss_ce_4: 0.0003096  loss_mask_4: 0.1223  loss_dice_4: 0.1793  loss_ce_5: 0.0003913  loss_mask_5: 0.1191  loss_dice_5: 0.1746  loss_ce_6: 0.0002641  loss_mask_6: 0.1227  loss_dice_6: 0.1822  loss_ce_7: 0.0003928  loss_mask_7: 0.122  loss_dice_7: 0.1782  loss_ce_8: 0.0004243  loss_mask_8: 0.1205  loss_dice_8: 0.178  time: 0.4958  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:43:16] d2.utils.events INFO:  eta: 6:39:38  iter: 6679  total_loss: 3.059  loss_ce: 0.0002697  loss_mask: 0.1191  loss_dice: 0.1824  loss_ce_0: 0.119  loss_mask_0: 0.1175  loss_dice_0: 0.1765  loss_ce_1: 0.0003259  loss_mask_1: 0.1178  loss_dice_1: 0.1741  loss_ce_2: 0.0003956  loss_mask_2: 0.1152  loss_dice_2: 0.174  loss_ce_3: 0.0002785  loss_mask_3: 0.118  loss_dice_3: 0.1735  loss_ce_4: 0.0002536  loss_mask_4: 0.1194  loss_dice_4: 0.1793  loss_ce_5: 0.0003087  loss_mask_5: 0.1243  loss_dice_5: 0.1741  loss_ce_6: 0.0002203  loss_mask_6: 0.1217  loss_dice_6: 0.1774  loss_ce_7: 0.0003296  loss_mask_7: 0.1194  loss_dice_7: 0.1663  loss_ce_8: 0.0003554  loss_mask_8: 0.118  loss_dice_8: 0.1777  time: 0.4968  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:43:33] d2.utils.events INFO:  eta: 6:39:18  iter: 6699  total_loss: 3.436  loss_ce: 0.0002041  loss_mask: 0.1241  loss_dice: 0.1819  loss_ce_0: 0.1317  loss_mask_0: 0.128  loss_dice_0: 0.1853  loss_ce_1: 0.0002716  loss_mask_1: 0.1209  loss_dice_1: 0.185  loss_ce_2: 0.0002205  loss_mask_2: 0.1289  loss_dice_2: 0.1903  loss_ce_3: 0.0002069  loss_mask_3: 0.1263  loss_dice_3: 0.1836  loss_ce_4: 0.0001534  loss_mask_4: 0.1241  loss_dice_4: 0.1822  loss_ce_5: 0.000157  loss_mask_5: 0.1218  loss_dice_5: 0.1826  loss_ce_6: 0.0001598  loss_mask_6: 0.1253  loss_dice_6: 0.1858  loss_ce_7: 0.0001742  loss_mask_7: 0.1246  loss_dice_7: 0.1872  loss_ce_8: 0.0001786  loss_mask_8: 0.1222  loss_dice_8: 0.1889  time: 0.4979  data_time: 0.0018  lr: 0.0001  max_mem: 8444M
[08/01 17:43:50] d2.utils.events INFO:  eta: 6:39:01  iter: 6719  total_loss: 3.369  loss_ce: 0.000329  loss_mask: 0.1296  loss_dice: 0.1885  loss_ce_0: 0.1304  loss_mask_0: 0.1292  loss_dice_0: 0.1837  loss_ce_1: 0.0003829  loss_mask_1: 0.131  loss_dice_1: 0.1904  loss_ce_2: 0.0003371  loss_mask_2: 0.1278  loss_dice_2: 0.1841  loss_ce_3: 0.0003339  loss_mask_3: 0.1303  loss_dice_3: 0.1907  loss_ce_4: 0.0003074  loss_mask_4: 0.1334  loss_dice_4: 0.1937  loss_ce_5: 0.0002892  loss_mask_5: 0.1299  loss_dice_5: 0.1863  loss_ce_6: 0.0002268  loss_mask_6: 0.131  loss_dice_6: 0.1863  loss_ce_7: 0.0004352  loss_mask_7: 0.1324  loss_dice_7: 0.1872  loss_ce_8: 0.0003216  loss_mask_8: 0.1326  loss_dice_8: 0.1907  time: 0.4989  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:44:06] d2.utils.events INFO:  eta: 6:38:44  iter: 6739  total_loss: 3.103  loss_ce: 0.0002115  loss_mask: 0.1264  loss_dice: 0.1774  loss_ce_0: 0.126  loss_mask_0: 0.1213  loss_dice_0: 0.1739  loss_ce_1: 0.0003533  loss_mask_1: 0.1273  loss_dice_1: 0.1739  loss_ce_2: 0.0002412  loss_mask_2: 0.1254  loss_dice_2: 0.1738  loss_ce_3: 0.0003268  loss_mask_3: 0.1256  loss_dice_3: 0.1749  loss_ce_4: 0.000243  loss_mask_4: 0.1248  loss_dice_4: 0.1746  loss_ce_5: 0.0002501  loss_mask_5: 0.1293  loss_dice_5: 0.1777  loss_ce_6: 0.0002339  loss_mask_6: 0.1238  loss_dice_6: 0.1716  loss_ce_7: 0.0003736  loss_mask_7: 0.1277  loss_dice_7: 0.1763  loss_ce_8: 0.0003028  loss_mask_8: 0.1207  loss_dice_8: 0.1682  time: 0.4999  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:44:23] d2.utils.events INFO:  eta: 6:38:27  iter: 6759  total_loss: 3.202  loss_ce: 0.0002245  loss_mask: 0.1208  loss_dice: 0.1868  loss_ce_0: 0.1242  loss_mask_0: 0.1205  loss_dice_0: 0.1835  loss_ce_1: 0.0002479  loss_mask_1: 0.1208  loss_dice_1: 0.1821  loss_ce_2: 0.0002039  loss_mask_2: 0.1195  loss_dice_2: 0.1892  loss_ce_3: 0.0002117  loss_mask_3: 0.121  loss_dice_3: 0.1881  loss_ce_4: 0.0002038  loss_mask_4: 0.1202  loss_dice_4: 0.184  loss_ce_5: 0.0001929  loss_mask_5: 0.118  loss_dice_5: 0.1764  loss_ce_6: 0.0002177  loss_mask_6: 0.1209  loss_dice_6: 0.1792  loss_ce_7: 0.0003272  loss_mask_7: 0.1222  loss_dice_7: 0.1811  loss_ce_8: 0.0002404  loss_mask_8: 0.1235  loss_dice_8: 0.182  time: 0.5009  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:44:40] d2.utils.events INFO:  eta: 6:37:57  iter: 6779  total_loss: 3.042  loss_ce: 0.0001777  loss_mask: 0.1251  loss_dice: 0.1758  loss_ce_0: 0.1248  loss_mask_0: 0.1241  loss_dice_0: 0.1754  loss_ce_1: 0.0002421  loss_mask_1: 0.1267  loss_dice_1: 0.1777  loss_ce_2: 0.0002021  loss_mask_2: 0.1247  loss_dice_2: 0.1695  loss_ce_3: 0.0001656  loss_mask_3: 0.123  loss_dice_3: 0.1709  loss_ce_4: 0.0001787  loss_mask_4: 0.123  loss_dice_4: 0.1703  loss_ce_5: 0.0001952  loss_mask_5: 0.1256  loss_dice_5: 0.1739  loss_ce_6: 0.0001624  loss_mask_6: 0.1202  loss_dice_6: 0.1708  loss_ce_7: 0.0002277  loss_mask_7: 0.1233  loss_dice_7: 0.1767  loss_ce_8: 0.0002  loss_mask_8: 0.1263  loss_dice_8: 0.1749  time: 0.5020  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:44:57] d2.utils.events INFO:  eta: 6:37:54  iter: 6799  total_loss: 3.182  loss_ce: 0.0001538  loss_mask: 0.127  loss_dice: 0.1803  loss_ce_0: 0.1242  loss_mask_0: 0.1294  loss_dice_0: 0.1834  loss_ce_1: 0.0001837  loss_mask_1: 0.1271  loss_dice_1: 0.171  loss_ce_2: 0.0001567  loss_mask_2: 0.1247  loss_dice_2: 0.1811  loss_ce_3: 0.0001571  loss_mask_3: 0.126  loss_dice_3: 0.1767  loss_ce_4: 0.000154  loss_mask_4: 0.131  loss_dice_4: 0.1814  loss_ce_5: 0.0001471  loss_mask_5: 0.1299  loss_dice_5: 0.1817  loss_ce_6: 0.0001558  loss_mask_6: 0.1231  loss_dice_6: 0.1724  loss_ce_7: 0.0002102  loss_mask_7: 0.1307  loss_dice_7: 0.1814  loss_ce_8: 0.0001816  loss_mask_8: 0.126  loss_dice_8: 0.1731  time: 0.5030  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:45:14] d2.utils.events INFO:  eta: 6:37:29  iter: 6819  total_loss: 3.217  loss_ce: 0.000123  loss_mask: 0.1209  loss_dice: 0.1818  loss_ce_0: 0.1283  loss_mask_0: 0.1263  loss_dice_0: 0.1871  loss_ce_1: 0.0001629  loss_mask_1: 0.1272  loss_dice_1: 0.1775  loss_ce_2: 0.0001398  loss_mask_2: 0.1289  loss_dice_2: 0.18  loss_ce_3: 0.0001063  loss_mask_3: 0.123  loss_dice_3: 0.1792  loss_ce_4: 0.0001261  loss_mask_4: 0.1265  loss_dice_4: 0.189  loss_ce_5: 0.000141  loss_mask_5: 0.1243  loss_dice_5: 0.1768  loss_ce_6: 0.0001284  loss_mask_6: 0.1246  loss_dice_6: 0.1758  loss_ce_7: 0.0001678  loss_mask_7: 0.1265  loss_dice_7: 0.1822  loss_ce_8: 0.0001577  loss_mask_8: 0.126  loss_dice_8: 0.1877  time: 0.5040  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:45:31] d2.utils.events INFO:  eta: 6:37:12  iter: 6839  total_loss: 3.062  loss_ce: 0.0001373  loss_mask: 0.1175  loss_dice: 0.1706  loss_ce_0: 0.1258  loss_mask_0: 0.1205  loss_dice_0: 0.1758  loss_ce_1: 0.0002106  loss_mask_1: 0.1216  loss_dice_1: 0.1633  loss_ce_2: 0.0001428  loss_mask_2: 0.1191  loss_dice_2: 0.1702  loss_ce_3: 0.0001294  loss_mask_3: 0.124  loss_dice_3: 0.1773  loss_ce_4: 0.0001566  loss_mask_4: 0.1171  loss_dice_4: 0.1651  loss_ce_5: 0.0001507  loss_mask_5: 0.1171  loss_dice_5: 0.1755  loss_ce_6: 0.0001425  loss_mask_6: 0.1216  loss_dice_6: 0.1722  loss_ce_7: 0.0001943  loss_mask_7: 0.1167  loss_dice_7: 0.1723  loss_ce_8: 0.0001598  loss_mask_8: 0.1184  loss_dice_8: 0.173  time: 0.5050  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:45:48] d2.utils.events INFO:  eta: 6:36:50  iter: 6859  total_loss: 3.154  loss_ce: 0.0001271  loss_mask: 0.1229  loss_dice: 0.1771  loss_ce_0: 0.1267  loss_mask_0: 0.1253  loss_dice_0: 0.1829  loss_ce_1: 0.0001233  loss_mask_1: 0.1245  loss_dice_1: 0.1731  loss_ce_2: 0.0001246  loss_mask_2: 0.1254  loss_dice_2: 0.1872  loss_ce_3: 9.949e-05  loss_mask_3: 0.1215  loss_dice_3: 0.1862  loss_ce_4: 0.0001196  loss_mask_4: 0.122  loss_dice_4: 0.1774  loss_ce_5: 0.0001196  loss_mask_5: 0.1225  loss_dice_5: 0.1767  loss_ce_6: 0.0001351  loss_mask_6: 0.1228  loss_dice_6: 0.1839  loss_ce_7: 0.0001585  loss_mask_7: 0.1191  loss_dice_7: 0.1793  loss_ce_8: 0.0001419  loss_mask_8: 0.1204  loss_dice_8: 0.1783  time: 0.5060  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:46:05] d2.utils.events INFO:  eta: 6:36:15  iter: 6879  total_loss: 3.012  loss_ce: 0.0001101  loss_mask: 0.1176  loss_dice: 0.1798  loss_ce_0: 0.1277  loss_mask_0: 0.121  loss_dice_0: 0.1705  loss_ce_1: 4.782e-05  loss_mask_1: 0.1188  loss_dice_1: 0.1734  loss_ce_2: 0.0001126  loss_mask_2: 0.124  loss_dice_2: 0.177  loss_ce_3: 9.445e-05  loss_mask_3: 0.117  loss_dice_3: 0.1726  loss_ce_4: 0.0001023  loss_mask_4: 0.1235  loss_dice_4: 0.171  loss_ce_5: 0.0001068  loss_mask_5: 0.1181  loss_dice_5: 0.175  loss_ce_6: 0.0001213  loss_mask_6: 0.1119  loss_dice_6: 0.1694  loss_ce_7: 0.0001407  loss_mask_7: 0.1167  loss_dice_7: 0.1699  loss_ce_8: 0.0001132  loss_mask_8: 0.1189  loss_dice_8: 0.1728  time: 0.5070  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:46:22] d2.utils.events INFO:  eta: 6:35:57  iter: 6899  total_loss: 3.201  loss_ce: 0.0001191  loss_mask: 0.1296  loss_dice: 0.1718  loss_ce_0: 0.1268  loss_mask_0: 0.1248  loss_dice_0: 0.1707  loss_ce_1: 0.0001549  loss_mask_1: 0.1277  loss_dice_1: 0.1735  loss_ce_2: 0.0001408  loss_mask_2: 0.1231  loss_dice_2: 0.1783  loss_ce_3: 0.0001119  loss_mask_3: 0.1299  loss_dice_3: 0.1716  loss_ce_4: 0.0001209  loss_mask_4: 0.1321  loss_dice_4: 0.1758  loss_ce_5: 0.000138  loss_mask_5: 0.1293  loss_dice_5: 0.173  loss_ce_6: 0.0001248  loss_mask_6: 0.1281  loss_dice_6: 0.1755  loss_ce_7: 0.0001453  loss_mask_7: 0.1299  loss_dice_7: 0.1701  loss_ce_8: 0.0001335  loss_mask_8: 0.1303  loss_dice_8: 0.1716  time: 0.5080  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:46:39] d2.utils.events INFO:  eta: 6:35:39  iter: 6919  total_loss: 3.082  loss_ce: 0.0001116  loss_mask: 0.1172  loss_dice: 0.1761  loss_ce_0: 0.1265  loss_mask_0: 0.1206  loss_dice_0: 0.1865  loss_ce_1: 0.0001231  loss_mask_1: 0.1171  loss_dice_1: 0.1864  loss_ce_2: 0.0001124  loss_mask_2: 0.112  loss_dice_2: 0.1808  loss_ce_3: 8.418e-05  loss_mask_3: 0.1185  loss_dice_3: 0.18  loss_ce_4: 0.0001088  loss_mask_4: 0.1185  loss_dice_4: 0.1738  loss_ce_5: 0.000101  loss_mask_5: 0.1232  loss_dice_5: 0.185  loss_ce_6: 0.0001146  loss_mask_6: 0.1183  loss_dice_6: 0.1738  loss_ce_7: 0.0001349  loss_mask_7: 0.1197  loss_dice_7: 0.1753  loss_ce_8: 0.0001052  loss_mask_8: 0.1223  loss_dice_8: 0.1828  time: 0.5089  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:46:56] d2.utils.events INFO:  eta: 6:35:29  iter: 6939  total_loss: 3.229  loss_ce: 0.0001125  loss_mask: 0.123  loss_dice: 0.185  loss_ce_0: 0.1256  loss_mask_0: 0.1278  loss_dice_0: 0.1883  loss_ce_1: 0.0001392  loss_mask_1: 0.1242  loss_dice_1: 0.1836  loss_ce_2: 0.0001078  loss_mask_2: 0.1249  loss_dice_2: 0.1792  loss_ce_3: 7.809e-05  loss_mask_3: 0.1236  loss_dice_3: 0.1816  loss_ce_4: 0.0001076  loss_mask_4: 0.1247  loss_dice_4: 0.1822  loss_ce_5: 9.821e-05  loss_mask_5: 0.1241  loss_dice_5: 0.1807  loss_ce_6: 0.000112  loss_mask_6: 0.1205  loss_dice_6: 0.1747  loss_ce_7: 0.0001094  loss_mask_7: 0.1227  loss_dice_7: 0.1826  loss_ce_8: 0.0001167  loss_mask_8: 0.1282  loss_dice_8: 0.1824  time: 0.5099  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:47:13] d2.utils.events INFO:  eta: 6:35:25  iter: 6959  total_loss: 3.362  loss_ce: 0.0001079  loss_mask: 0.1321  loss_dice: 0.2024  loss_ce_0: 0.1257  loss_mask_0: 0.1323  loss_dice_0: 0.1997  loss_ce_1: 0.0001209  loss_mask_1: 0.1327  loss_dice_1: 0.1956  loss_ce_2: 0.000109  loss_mask_2: 0.1309  loss_dice_2: 0.1932  loss_ce_3: 8.862e-05  loss_mask_3: 0.1307  loss_dice_3: 0.1983  loss_ce_4: 0.0001295  loss_mask_4: 0.1283  loss_dice_4: 0.1954  loss_ce_5: 0.0001074  loss_mask_5: 0.1364  loss_dice_5: 0.1964  loss_ce_6: 0.0001179  loss_mask_6: 0.1316  loss_dice_6: 0.191  loss_ce_7: 0.0001229  loss_mask_7: 0.1352  loss_dice_7: 0.1957  loss_ce_8: 0.0001239  loss_mask_8: 0.132  loss_dice_8: 0.1904  time: 0.5109  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:47:30] d2.utils.events INFO:  eta: 6:35:08  iter: 6979  total_loss: 3.256  loss_ce: 8.583e-05  loss_mask: 0.131  loss_dice: 0.1828  loss_ce_0: 0.1257  loss_mask_0: 0.1293  loss_dice_0: 0.1813  loss_ce_1: 5.686e-05  loss_mask_1: 0.1297  loss_dice_1: 0.1787  loss_ce_2: 8.536e-05  loss_mask_2: 0.1282  loss_dice_2: 0.182  loss_ce_3: 6.377e-05  loss_mask_3: 0.1259  loss_dice_3: 0.1861  loss_ce_4: 8.532e-05  loss_mask_4: 0.1296  loss_dice_4: 0.1784  loss_ce_5: 8.384e-05  loss_mask_5: 0.1275  loss_dice_5: 0.1813  loss_ce_6: 9.625e-05  loss_mask_6: 0.1339  loss_dice_6: 0.1851  loss_ce_7: 0.0001055  loss_mask_7: 0.13  loss_dice_7: 0.1783  loss_ce_8: 7.637e-05  loss_mask_8: 0.1286  loss_dice_8: 0.1803  time: 0.5118  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:47:47] d2.utils.events INFO:  eta: 6:35:07  iter: 6999  total_loss: 3.193  loss_ce: 8.108e-05  loss_mask: 0.1255  loss_dice: 0.183  loss_ce_0: 0.124  loss_mask_0: 0.1248  loss_dice_0: 0.1825  loss_ce_1: 5.968e-05  loss_mask_1: 0.1262  loss_dice_1: 0.1858  loss_ce_2: 8.458e-05  loss_mask_2: 0.1213  loss_dice_2: 0.182  loss_ce_3: 6.661e-05  loss_mask_3: 0.1292  loss_dice_3: 0.187  loss_ce_4: 8.458e-05  loss_mask_4: 0.1279  loss_dice_4: 0.1866  loss_ce_5: 8.958e-05  loss_mask_5: 0.1254  loss_dice_5: 0.1797  loss_ce_6: 9.348e-05  loss_mask_6: 0.1258  loss_dice_6: 0.1829  loss_ce_7: 0.0001018  loss_mask_7: 0.1266  loss_dice_7: 0.1841  loss_ce_8: 8.952e-05  loss_mask_8: 0.125  loss_dice_8: 0.1806  time: 0.5128  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:48:04] d2.utils.events INFO:  eta: 6:34:50  iter: 7019  total_loss: 2.988  loss_ce: 8.291e-05  loss_mask: 0.1178  loss_dice: 0.1701  loss_ce_0: 0.1265  loss_mask_0: 0.1164  loss_dice_0: 0.1643  loss_ce_1: 0.0001074  loss_mask_1: 0.1161  loss_dice_1: 0.1624  loss_ce_2: 8.337e-05  loss_mask_2: 0.1187  loss_dice_2: 0.1623  loss_ce_3: 7.794e-05  loss_mask_3: 0.118  loss_dice_3: 0.1681  loss_ce_4: 9.442e-05  loss_mask_4: 0.1158  loss_dice_4: 0.1671  loss_ce_5: 9.161e-05  loss_mask_5: 0.1224  loss_dice_5: 0.1701  loss_ce_6: 9.152e-05  loss_mask_6: 0.1205  loss_dice_6: 0.1635  loss_ce_7: 0.0001109  loss_mask_7: 0.1184  loss_dice_7: 0.1673  loss_ce_8: 8.384e-05  loss_mask_8: 0.1248  loss_dice_8: 0.1734  time: 0.5138  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:48:21] d2.utils.events INFO:  eta: 6:34:27  iter: 7039  total_loss: 3.267  loss_ce: 7.422e-05  loss_mask: 0.1228  loss_dice: 0.1827  loss_ce_0: 0.1273  loss_mask_0: 0.126  loss_dice_0: 0.189  loss_ce_1: 7.235e-05  loss_mask_1: 0.1307  loss_dice_1: 0.1816  loss_ce_2: 7.166e-05  loss_mask_2: 0.1282  loss_dice_2: 0.1864  loss_ce_3: 6.135e-05  loss_mask_3: 0.1271  loss_dice_3: 0.187  loss_ce_4: 7.729e-05  loss_mask_4: 0.1288  loss_dice_4: 0.1858  loss_ce_5: 8.411e-05  loss_mask_5: 0.1255  loss_dice_5: 0.1749  loss_ce_6: 7.446e-05  loss_mask_6: 0.1289  loss_dice_6: 0.1895  loss_ce_7: 8.563e-05  loss_mask_7: 0.1295  loss_dice_7: 0.1859  loss_ce_8: 8.346e-05  loss_mask_8: 0.1255  loss_dice_8: 0.1794  time: 0.5147  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:48:38] d2.utils.events INFO:  eta: 6:34:06  iter: 7059  total_loss: 3.203  loss_ce: 6.776e-05  loss_mask: 0.1223  loss_dice: 0.1783  loss_ce_0: 0.1223  loss_mask_0: 0.121  loss_dice_0: 0.1895  loss_ce_1: 6.785e-05  loss_mask_1: 0.1181  loss_dice_1: 0.1823  loss_ce_2: 7.36e-05  loss_mask_2: 0.1259  loss_dice_2: 0.1904  loss_ce_3: 6.309e-05  loss_mask_3: 0.119  loss_dice_3: 0.1799  loss_ce_4: 7.096e-05  loss_mask_4: 0.1224  loss_dice_4: 0.1953  loss_ce_5: 8.261e-05  loss_mask_5: 0.119  loss_dice_5: 0.1823  loss_ce_6: 7.997e-05  loss_mask_6: 0.1198  loss_dice_6: 0.1867  loss_ce_7: 8.694e-05  loss_mask_7: 0.1194  loss_dice_7: 0.1895  loss_ce_8: 7.926e-05  loss_mask_8: 0.1179  loss_dice_8: 0.1828  time: 0.5156  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:48:54] d2.utils.events INFO:  eta: 6:33:30  iter: 7079  total_loss: 3.049  loss_ce: 6.08e-05  loss_mask: 0.1226  loss_dice: 0.1725  loss_ce_0: 0.1241  loss_mask_0: 0.1239  loss_dice_0: 0.171  loss_ce_1: 7.083e-05  loss_mask_1: 0.1247  loss_dice_1: 0.1695  loss_ce_2: 6.755e-05  loss_mask_2: 0.1201  loss_dice_2: 0.1721  loss_ce_3: 6.674e-05  loss_mask_3: 0.1224  loss_dice_3: 0.1728  loss_ce_4: 6.621e-05  loss_mask_4: 0.1237  loss_dice_4: 0.1668  loss_ce_5: 7.508e-05  loss_mask_5: 0.1255  loss_dice_5: 0.1729  loss_ce_6: 7.626e-05  loss_mask_6: 0.1208  loss_dice_6: 0.1688  loss_ce_7: 8.399e-05  loss_mask_7: 0.1247  loss_dice_7: 0.1657  loss_ce_8: 7.978e-05  loss_mask_8: 0.1179  loss_dice_8: 0.166  time: 0.5166  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:49:11] d2.utils.events INFO:  eta: 6:33:09  iter: 7099  total_loss: 3.09  loss_ce: 8.209e-05  loss_mask: 0.124  loss_dice: 0.1704  loss_ce_0: 0.1272  loss_mask_0: 0.1202  loss_dice_0: 0.1717  loss_ce_1: 5.156e-05  loss_mask_1: 0.125  loss_dice_1: 0.1692  loss_ce_2: 6.776e-05  loss_mask_2: 0.124  loss_dice_2: 0.1733  loss_ce_3: 6.832e-05  loss_mask_3: 0.1206  loss_dice_3: 0.169  loss_ce_4: 7.439e-05  loss_mask_4: 0.1226  loss_dice_4: 0.1687  loss_ce_5: 7.173e-05  loss_mask_5: 0.1218  loss_dice_5: 0.1717  loss_ce_6: 7.732e-05  loss_mask_6: 0.1182  loss_dice_6: 0.1715  loss_ce_7: 9.383e-05  loss_mask_7: 0.1222  loss_dice_7: 0.1691  loss_ce_8: 6.984e-05  loss_mask_8: 0.1209  loss_dice_8: 0.1728  time: 0.5175  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:49:28] d2.utils.events INFO:  eta: 6:32:48  iter: 7119  total_loss: 3.23  loss_ce: 5.744e-05  loss_mask: 0.1191  loss_dice: 0.1866  loss_ce_0: 0.1244  loss_mask_0: 0.1257  loss_dice_0: 0.1879  loss_ce_1: 5.41e-05  loss_mask_1: 0.1211  loss_dice_1: 0.1841  loss_ce_2: 6.366e-05  loss_mask_2: 0.1223  loss_dice_2: 0.183  loss_ce_3: 5.237e-05  loss_mask_3: 0.1199  loss_dice_3: 0.1802  loss_ce_4: 5.94e-05  loss_mask_4: 0.1203  loss_dice_4: 0.184  loss_ce_5: 6.672e-05  loss_mask_5: 0.1248  loss_dice_5: 0.1814  loss_ce_6: 6.811e-05  loss_mask_6: 0.118  loss_dice_6: 0.1807  loss_ce_7: 7.857e-05  loss_mask_7: 0.1208  loss_dice_7: 0.1812  loss_ce_8: 7.391e-05  loss_mask_8: 0.1247  loss_dice_8: 0.1856  time: 0.5184  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:49:45] d2.utils.events INFO:  eta: 6:32:30  iter: 7139  total_loss: 3.287  loss_ce: 6.412e-05  loss_mask: 0.118  loss_dice: 0.194  loss_ce_0: 0.1252  loss_mask_0: 0.1207  loss_dice_0: 0.1942  loss_ce_1: 4.476e-05  loss_mask_1: 0.1178  loss_dice_1: 0.1958  loss_ce_2: 6.672e-05  loss_mask_2: 0.1175  loss_dice_2: 0.1802  loss_ce_3: 4.894e-05  loss_mask_3: 0.1219  loss_dice_3: 0.1993  loss_ce_4: 6.711e-05  loss_mask_4: 0.1181  loss_dice_4: 0.1909  loss_ce_5: 6.924e-05  loss_mask_5: 0.1234  loss_dice_5: 0.1967  loss_ce_6: 6.574e-05  loss_mask_6: 0.1172  loss_dice_6: 0.1865  loss_ce_7: 8.258e-05  loss_mask_7: 0.1182  loss_dice_7: 0.1885  loss_ce_8: 6.782e-05  loss_mask_8: 0.125  loss_dice_8: 0.1988  time: 0.5193  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:50:02] d2.utils.events INFO:  eta: 6:32:02  iter: 7159  total_loss: 3.103  loss_ce: 6.143e-05  loss_mask: 0.1172  loss_dice: 0.1776  loss_ce_0: 0.1222  loss_mask_0: 0.1192  loss_dice_0: 0.1793  loss_ce_1: 5.942e-05  loss_mask_1: 0.123  loss_dice_1: 0.1749  loss_ce_2: 6.279e-05  loss_mask_2: 0.1247  loss_dice_2: 0.1772  loss_ce_3: 5.751e-05  loss_mask_3: 0.1201  loss_dice_3: 0.1747  loss_ce_4: 5.517e-05  loss_mask_4: 0.1232  loss_dice_4: 0.1782  loss_ce_5: 6.141e-05  loss_mask_5: 0.1217  loss_dice_5: 0.181  loss_ce_6: 6.594e-05  loss_mask_6: 0.1198  loss_dice_6: 0.1781  loss_ce_7: 7.86e-05  loss_mask_7: 0.1216  loss_dice_7: 0.1808  loss_ce_8: 7.206e-05  loss_mask_8: 0.1193  loss_dice_8: 0.1752  time: 0.5202  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:50:19] d2.utils.events INFO:  eta: 6:31:43  iter: 7179  total_loss: 3.133  loss_ce: 6.046e-05  loss_mask: 0.1235  loss_dice: 0.1784  loss_ce_0: 0.1258  loss_mask_0: 0.1203  loss_dice_0: 0.1768  loss_ce_1: 8.626e-05  loss_mask_1: 0.1226  loss_dice_1: 0.1803  loss_ce_2: 7.867e-05  loss_mask_2: 0.1196  loss_dice_2: 0.1701  loss_ce_3: 5.869e-05  loss_mask_3: 0.1228  loss_dice_3: 0.1713  loss_ce_4: 7.358e-05  loss_mask_4: 0.1241  loss_dice_4: 0.1801  loss_ce_5: 7.373e-05  loss_mask_5: 0.1259  loss_dice_5: 0.1795  loss_ce_6: 6.557e-05  loss_mask_6: 0.1214  loss_dice_6: 0.1728  loss_ce_7: 8.006e-05  loss_mask_7: 0.1217  loss_dice_7: 0.1778  loss_ce_8: 6.921e-05  loss_mask_8: 0.1272  loss_dice_8: 0.1755  time: 0.5211  data_time: 0.0018  lr: 0.0001  max_mem: 8444M
[08/01 17:50:36] d2.utils.events INFO:  eta: 6:31:26  iter: 7199  total_loss: 3.08  loss_ce: 4.632e-05  loss_mask: 0.117  loss_dice: 0.1769  loss_ce_0: 0.1286  loss_mask_0: 0.1206  loss_dice_0: 0.1784  loss_ce_1: 3.814e-05  loss_mask_1: 0.1176  loss_dice_1: 0.1694  loss_ce_2: 5.614e-05  loss_mask_2: 0.1198  loss_dice_2: 0.168  loss_ce_3: 3.713e-05  loss_mask_3: 0.1164  loss_dice_3: 0.1734  loss_ce_4: 5.595e-05  loss_mask_4: 0.1172  loss_dice_4: 0.1762  loss_ce_5: 4.726e-05  loss_mask_5: 0.112  loss_dice_5: 0.1747  loss_ce_6: 5.365e-05  loss_mask_6: 0.1168  loss_dice_6: 0.1647  loss_ce_7: 6.581e-05  loss_mask_7: 0.1154  loss_dice_7: 0.1716  loss_ce_8: 5.023e-05  loss_mask_8: 0.1165  loss_dice_8: 0.1679  time: 0.5220  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:50:53] d2.utils.events INFO:  eta: 6:30:55  iter: 7219  total_loss: 3.325  loss_ce: 5.423e-05  loss_mask: 0.1311  loss_dice: 0.2011  loss_ce_0: 0.1265  loss_mask_0: 0.1261  loss_dice_0: 0.1977  loss_ce_1: 3.762e-05  loss_mask_1: 0.1241  loss_dice_1: 0.1889  loss_ce_2: 5.956e-05  loss_mask_2: 0.128  loss_dice_2: 0.1936  loss_ce_3: 4.428e-05  loss_mask_3: 0.1248  loss_dice_3: 0.1965  loss_ce_4: 5.176e-05  loss_mask_4: 0.1258  loss_dice_4: 0.1936  loss_ce_5: 6.157e-05  loss_mask_5: 0.121  loss_dice_5: 0.1909  loss_ce_6: 6.052e-05  loss_mask_6: 0.1252  loss_dice_6: 0.1883  loss_ce_7: 7.026e-05  loss_mask_7: 0.1254  loss_dice_7: 0.1943  loss_ce_8: 6.468e-05  loss_mask_8: 0.1251  loss_dice_8: 0.1957  time: 0.5229  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:51:10] d2.utils.events INFO:  eta: 6:30:24  iter: 7239  total_loss: 3.035  loss_ce: 5.07e-05  loss_mask: 0.1136  loss_dice: 0.1734  loss_ce_0: 0.1252  loss_mask_0: 0.117  loss_dice_0: 0.1765  loss_ce_1: 3.01e-05  loss_mask_1: 0.1143  loss_dice_1: 0.1753  loss_ce_2: 4.995e-05  loss_mask_2: 0.1144  loss_dice_2: 0.1754  loss_ce_3: 3.388e-05  loss_mask_3: 0.1185  loss_dice_3: 0.1772  loss_ce_4: 4.721e-05  loss_mask_4: 0.1183  loss_dice_4: 0.175  loss_ce_5: 5.578e-05  loss_mask_5: 0.1169  loss_dice_5: 0.179  loss_ce_6: 5.583e-05  loss_mask_6: 0.114  loss_dice_6: 0.1824  loss_ce_7: 6.504e-05  loss_mask_7: 0.1144  loss_dice_7: 0.1792  loss_ce_8: 5.674e-05  loss_mask_8: 0.1136  loss_dice_8: 0.1788  time: 0.5238  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:51:27] d2.utils.events INFO:  eta: 6:29:57  iter: 7259  total_loss: 3.17  loss_ce: 5.16e-05  loss_mask: 0.1194  loss_dice: 0.185  loss_ce_0: 0.124  loss_mask_0: 0.1209  loss_dice_0: 0.2002  loss_ce_1: 3.995e-05  loss_mask_1: 0.1199  loss_dice_1: 0.19  loss_ce_2: 5.424e-05  loss_mask_2: 0.1184  loss_dice_2: 0.1829  loss_ce_3: 3.842e-05  loss_mask_3: 0.1212  loss_dice_3: 0.183  loss_ce_4: 5.035e-05  loss_mask_4: 0.1202  loss_dice_4: 0.1854  loss_ce_5: 4.896e-05  loss_mask_5: 0.1206  loss_dice_5: 0.1916  loss_ce_6: 5.553e-05  loss_mask_6: 0.121  loss_dice_6: 0.1837  loss_ce_7: 7.59e-05  loss_mask_7: 0.1187  loss_dice_7: 0.1852  loss_ce_8: 5.812e-05  loss_mask_8: 0.1223  loss_dice_8: 0.1922  time: 0.5247  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:51:44] d2.utils.events INFO:  eta: 6:29:27  iter: 7279  total_loss: 3.282  loss_ce: 4.392e-05  loss_mask: 0.1261  loss_dice: 0.1878  loss_ce_0: 0.1242  loss_mask_0: 0.1223  loss_dice_0: 0.1881  loss_ce_1: 3.027e-05  loss_mask_1: 0.1274  loss_dice_1: 0.1902  loss_ce_2: 4.568e-05  loss_mask_2: 0.1261  loss_dice_2: 0.1884  loss_ce_3: 3.026e-05  loss_mask_3: 0.126  loss_dice_3: 0.1855  loss_ce_4: 4.139e-05  loss_mask_4: 0.1254  loss_dice_4: 0.1828  loss_ce_5: 4.699e-05  loss_mask_5: 0.1227  loss_dice_5: 0.1852  loss_ce_6: 5.004e-05  loss_mask_6: 0.1243  loss_dice_6: 0.197  loss_ce_7: 5.829e-05  loss_mask_7: 0.1219  loss_dice_7: 0.1848  loss_ce_8: 5.132e-05  loss_mask_8: 0.1238  loss_dice_8: 0.187  time: 0.5256  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:52:01] d2.utils.events INFO:  eta: 6:28:58  iter: 7299  total_loss: 3.304  loss_ce: 5.484e-05  loss_mask: 0.1276  loss_dice: 0.1903  loss_ce_0: 0.1232  loss_mask_0: 0.1262  loss_dice_0: 0.1932  loss_ce_1: 7.279e-05  loss_mask_1: 0.1259  loss_dice_1: 0.1878  loss_ce_2: 5.86e-05  loss_mask_2: 0.1306  loss_dice_2: 0.1894  loss_ce_3: 5.188e-05  loss_mask_3: 0.1248  loss_dice_3: 0.1915  loss_ce_4: 5.639e-05  loss_mask_4: 0.1243  loss_dice_4: 0.1878  loss_ce_5: 5.736e-05  loss_mask_5: 0.1253  loss_dice_5: 0.1875  loss_ce_6: 6.57e-05  loss_mask_6: 0.1267  loss_dice_6: 0.1899  loss_ce_7: 7.377e-05  loss_mask_7: 0.1242  loss_dice_7: 0.1887  loss_ce_8: 6.36e-05  loss_mask_8: 0.1278  loss_dice_8: 0.1933  time: 0.5264  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:52:17] d2.utils.events INFO:  eta: 6:28:41  iter: 7319  total_loss: 3.357  loss_ce: 4.64e-05  loss_mask: 0.1223  loss_dice: 0.1912  loss_ce_0: 0.1228  loss_mask_0: 0.1285  loss_dice_0: 0.1954  loss_ce_1: 8.536e-05  loss_mask_1: 0.1201  loss_dice_1: 0.1906  loss_ce_2: 5.491e-05  loss_mask_2: 0.1236  loss_dice_2: 0.192  loss_ce_3: 3.262e-05  loss_mask_3: 0.1183  loss_dice_3: 0.1863  loss_ce_4: 4.452e-05  loss_mask_4: 0.1264  loss_dice_4: 0.1849  loss_ce_5: 4.81e-05  loss_mask_5: 0.1223  loss_dice_5: 0.1872  loss_ce_6: 4.744e-05  loss_mask_6: 0.1212  loss_dice_6: 0.1859  loss_ce_7: 6.293e-05  loss_mask_7: 0.1206  loss_dice_7: 0.1911  loss_ce_8: 5.608e-05  loss_mask_8: 0.1195  loss_dice_8: 0.1914  time: 0.5273  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:52:35] d2.utils.events INFO:  eta: 6:28:45  iter: 7339  total_loss: 3.151  loss_ce: 6.375e-05  loss_mask: 0.118  loss_dice: 0.18  loss_ce_0: 0.1229  loss_mask_0: 0.1205  loss_dice_0: 0.1795  loss_ce_1: 7.222e-05  loss_mask_1: 0.1243  loss_dice_1: 0.182  loss_ce_2: 5.894e-05  loss_mask_2: 0.1188  loss_dice_2: 0.179  loss_ce_3: 6.804e-05  loss_mask_3: 0.1223  loss_dice_3: 0.1762  loss_ce_4: 5.732e-05  loss_mask_4: 0.1213  loss_dice_4: 0.1726  loss_ce_5: 6.572e-05  loss_mask_5: 0.1214  loss_dice_5: 0.1773  loss_ce_6: 5.916e-05  loss_mask_6: 0.1211  loss_dice_6: 0.1798  loss_ce_7: 6.989e-05  loss_mask_7: 0.1209  loss_dice_7: 0.178  loss_ce_8: 6.639e-05  loss_mask_8: 0.1185  loss_dice_8: 0.179  time: 0.5282  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:52:51] d2.utils.events INFO:  eta: 6:28:36  iter: 7359  total_loss: 3.305  loss_ce: 4.445e-05  loss_mask: 0.1238  loss_dice: 0.1985  loss_ce_0: 0.1214  loss_mask_0: 0.1203  loss_dice_0: 0.1954  loss_ce_1: 7.006e-05  loss_mask_1: 0.121  loss_dice_1: 0.1906  loss_ce_2: 5.236e-05  loss_mask_2: 0.1227  loss_dice_2: 0.1943  loss_ce_3: 4.83e-05  loss_mask_3: 0.1233  loss_dice_3: 0.1867  loss_ce_4: 4.763e-05  loss_mask_4: 0.1233  loss_dice_4: 0.1913  loss_ce_5: 5.07e-05  loss_mask_5: 0.121  loss_dice_5: 0.1965  loss_ce_6: 5.432e-05  loss_mask_6: 0.126  loss_dice_6: 0.1965  loss_ce_7: 6.205e-05  loss_mask_7: 0.1207  loss_dice_7: 0.1902  loss_ce_8: 5.74e-05  loss_mask_8: 0.1211  loss_dice_8: 0.1976  time: 0.5291  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:53:08] d2.utils.events INFO:  eta: 6:28:16  iter: 7379  total_loss: 3.162  loss_ce: 4.255e-05  loss_mask: 0.1307  loss_dice: 0.1869  loss_ce_0: 0.1227  loss_mask_0: 0.1235  loss_dice_0: 0.1798  loss_ce_1: 4.805e-05  loss_mask_1: 0.1253  loss_dice_1: 0.1798  loss_ce_2: 5.104e-05  loss_mask_2: 0.1266  loss_dice_2: 0.1802  loss_ce_3: 3.369e-05  loss_mask_3: 0.1255  loss_dice_3: 0.1785  loss_ce_4: 3.871e-05  loss_mask_4: 0.1313  loss_dice_4: 0.1827  loss_ce_5: 4.576e-05  loss_mask_5: 0.1286  loss_dice_5: 0.1843  loss_ce_6: 4.65e-05  loss_mask_6: 0.1271  loss_dice_6: 0.1834  loss_ce_7: 4.693e-05  loss_mask_7: 0.1297  loss_dice_7: 0.1866  loss_ce_8: 5.33e-05  loss_mask_8: 0.1279  loss_dice_8: 0.1843  time: 0.5299  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:53:25] d2.utils.events INFO:  eta: 6:28:08  iter: 7399  total_loss: 3.184  loss_ce: 0.0001513  loss_mask: 0.1212  loss_dice: 0.1927  loss_ce_0: 0.1216  loss_mask_0: 0.1192  loss_dice_0: 0.189  loss_ce_1: 3.342e-05  loss_mask_1: 0.1255  loss_dice_1: 0.1912  loss_ce_2: 6.722e-05  loss_mask_2: 0.1196  loss_dice_2: 0.1804  loss_ce_3: 8.3e-05  loss_mask_3: 0.1167  loss_dice_3: 0.1839  loss_ce_4: 8.023e-05  loss_mask_4: 0.1198  loss_dice_4: 0.1898  loss_ce_5: 8.333e-05  loss_mask_5: 0.1176  loss_dice_5: 0.1862  loss_ce_6: 0.0001267  loss_mask_6: 0.1194  loss_dice_6: 0.1874  loss_ce_7: 0.0001301  loss_mask_7: 0.1222  loss_dice_7: 0.1887  loss_ce_8: 8.864e-05  loss_mask_8: 0.1241  loss_dice_8: 0.1887  time: 0.5308  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:53:42] d2.utils.events INFO:  eta: 6:27:51  iter: 7419  total_loss: 3.077  loss_ce: 0.0003926  loss_mask: 0.1237  loss_dice: 0.1711  loss_ce_0: 0.124  loss_mask_0: 0.1203  loss_dice_0: 0.1712  loss_ce_1: 0.000461  loss_mask_1: 0.1245  loss_dice_1: 0.1673  loss_ce_2: 0.0001229  loss_mask_2: 0.1234  loss_dice_2: 0.1658  loss_ce_3: 0.0003706  loss_mask_3: 0.1273  loss_dice_3: 0.1721  loss_ce_4: 0.0003114  loss_mask_4: 0.124  loss_dice_4: 0.171  loss_ce_5: 0.000267  loss_mask_5: 0.1252  loss_dice_5: 0.1697  loss_ce_6: 0.0003342  loss_mask_6: 0.1236  loss_dice_6: 0.1727  loss_ce_7: 0.0003562  loss_mask_7: 0.1223  loss_dice_7: 0.1654  loss_ce_8: 0.000275  loss_mask_8: 0.1272  loss_dice_8: 0.1681  time: 0.5317  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:54:00] d2.utils.events INFO:  eta: 6:27:38  iter: 7439  total_loss: 3.177  loss_ce: 0.0002054  loss_mask: 0.1235  loss_dice: 0.1801  loss_ce_0: 0.1172  loss_mask_0: 0.1225  loss_dice_0: 0.1823  loss_ce_1: 0.0001916  loss_mask_1: 0.1252  loss_dice_1: 0.1805  loss_ce_2: 0.0001019  loss_mask_2: 0.1269  loss_dice_2: 0.1825  loss_ce_3: 0.0001699  loss_mask_3: 0.122  loss_dice_3: 0.1821  loss_ce_4: 0.0002079  loss_mask_4: 0.1177  loss_dice_4: 0.1787  loss_ce_5: 0.0001129  loss_mask_5: 0.1273  loss_dice_5: 0.1792  loss_ce_6: 0.0002052  loss_mask_6: 0.1229  loss_dice_6: 0.1789  loss_ce_7: 0.0002231  loss_mask_7: 0.1224  loss_dice_7: 0.1739  loss_ce_8: 0.0001441  loss_mask_8: 0.1229  loss_dice_8: 0.1778  time: 0.5325  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:54:17] d2.utils.events INFO:  eta: 6:27:23  iter: 7459  total_loss: 2.953  loss_ce: 0.000151  loss_mask: 0.1161  loss_dice: 0.1662  loss_ce_0: 0.1255  loss_mask_0: 0.1159  loss_dice_0: 0.1664  loss_ce_1: 5.61e-05  loss_mask_1: 0.1201  loss_dice_1: 0.1667  loss_ce_2: 6.745e-05  loss_mask_2: 0.1138  loss_dice_2: 0.1691  loss_ce_3: 0.0001597  loss_mask_3: 0.1146  loss_dice_3: 0.1696  loss_ce_4: 0.0001331  loss_mask_4: 0.1176  loss_dice_4: 0.1773  loss_ce_5: 7.134e-05  loss_mask_5: 0.1164  loss_dice_5: 0.1694  loss_ce_6: 8.271e-05  loss_mask_6: 0.1176  loss_dice_6: 0.1708  loss_ce_7: 0.0001487  loss_mask_7: 0.1161  loss_dice_7: 0.1708  loss_ce_8: 7.779e-05  loss_mask_8: 0.116  loss_dice_8: 0.1738  time: 0.5334  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:54:34] d2.utils.events INFO:  eta: 6:27:08  iter: 7479  total_loss: 3.172  loss_ce: 0.0001115  loss_mask: 0.1212  loss_dice: 0.1774  loss_ce_0: 0.1266  loss_mask_0: 0.1206  loss_dice_0: 0.1764  loss_ce_1: 8.386e-05  loss_mask_1: 0.1193  loss_dice_1: 0.1789  loss_ce_2: 7.722e-05  loss_mask_2: 0.1192  loss_dice_2: 0.186  loss_ce_3: 0.0001339  loss_mask_3: 0.1278  loss_dice_3: 0.1828  loss_ce_4: 0.0001257  loss_mask_4: 0.1245  loss_dice_4: 0.1824  loss_ce_5: 6.973e-05  loss_mask_5: 0.1216  loss_dice_5: 0.1814  loss_ce_6: 6.66e-05  loss_mask_6: 0.123  loss_dice_6: 0.1795  loss_ce_7: 0.0001251  loss_mask_7: 0.1181  loss_dice_7: 0.1808  loss_ce_8: 8.618e-05  loss_mask_8: 0.1224  loss_dice_8: 0.1797  time: 0.5342  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:54:50] d2.utils.events INFO:  eta: 6:26:49  iter: 7499  total_loss: 2.971  loss_ce: 0.0001169  loss_mask: 0.1209  loss_dice: 0.1747  loss_ce_0: 0.1282  loss_mask_0: 0.1173  loss_dice_0: 0.1657  loss_ce_1: 0.0002257  loss_mask_1: 0.1149  loss_dice_1: 0.1676  loss_ce_2: 0.0001054  loss_mask_2: 0.1191  loss_dice_2: 0.1799  loss_ce_3: 0.000141  loss_mask_3: 0.1197  loss_dice_3: 0.1741  loss_ce_4: 0.0001341  loss_mask_4: 0.1192  loss_dice_4: 0.1692  loss_ce_5: 8.742e-05  loss_mask_5: 0.1171  loss_dice_5: 0.1695  loss_ce_6: 0.0001039  loss_mask_6: 0.1183  loss_dice_6: 0.1778  loss_ce_7: 0.0001357  loss_mask_7: 0.1137  loss_dice_7: 0.1614  loss_ce_8: 0.00011  loss_mask_8: 0.1212  loss_dice_8: 0.1781  time: 0.5350  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:55:07] d2.utils.events INFO:  eta: 6:26:32  iter: 7519  total_loss: 3.046  loss_ce: 9.796e-05  loss_mask: 0.1228  loss_dice: 0.168  loss_ce_0: 0.1192  loss_mask_0: 0.1236  loss_dice_0: 0.1715  loss_ce_1: 7.529e-05  loss_mask_1: 0.1225  loss_dice_1: 0.1753  loss_ce_2: 6.573e-05  loss_mask_2: 0.124  loss_dice_2: 0.1726  loss_ce_3: 8.25e-05  loss_mask_3: 0.1191  loss_dice_3: 0.1737  loss_ce_4: 9.238e-05  loss_mask_4: 0.124  loss_dice_4: 0.1774  loss_ce_5: 7.121e-05  loss_mask_5: 0.1176  loss_dice_5: 0.1674  loss_ce_6: 6.273e-05  loss_mask_6: 0.1228  loss_dice_6: 0.1713  loss_ce_7: 0.0001116  loss_mask_7: 0.1205  loss_dice_7: 0.1724  loss_ce_8: 8.047e-05  loss_mask_8: 0.1213  loss_dice_8: 0.1667  time: 0.5359  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:55:24] d2.utils.events INFO:  eta: 6:26:13  iter: 7539  total_loss: 3.308  loss_ce: 6.584e-05  loss_mask: 0.1258  loss_dice: 0.1825  loss_ce_0: 0.1161  loss_mask_0: 0.13  loss_dice_0: 0.1894  loss_ce_1: 2.133e-05  loss_mask_1: 0.128  loss_dice_1: 0.193  loss_ce_2: 4.12e-05  loss_mask_2: 0.1205  loss_dice_2: 0.1834  loss_ce_3: 4.382e-05  loss_mask_3: 0.1276  loss_dice_3: 0.1865  loss_ce_4: 3.755e-05  loss_mask_4: 0.1295  loss_dice_4: 0.1843  loss_ce_5: 3.92e-05  loss_mask_5: 0.1236  loss_dice_5: 0.1875  loss_ce_6: 3.851e-05  loss_mask_6: 0.1265  loss_dice_6: 0.1851  loss_ce_7: 5.152e-05  loss_mask_7: 0.1311  loss_dice_7: 0.1877  loss_ce_8: 3.922e-05  loss_mask_8: 0.1306  loss_dice_8: 0.1921  time: 0.5367  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:55:41] d2.utils.events INFO:  eta: 6:25:39  iter: 7559  total_loss: 3.079  loss_ce: 0.0001121  loss_mask: 0.1167  loss_dice: 0.1899  loss_ce_0: 0.1286  loss_mask_0: 0.1151  loss_dice_0: 0.19  loss_ce_1: 0.0001113  loss_mask_1: 0.1158  loss_dice_1: 0.1854  loss_ce_2: 9.701e-05  loss_mask_2: 0.117  loss_dice_2: 0.1861  loss_ce_3: 0.0001292  loss_mask_3: 0.1186  loss_dice_3: 0.1857  loss_ce_4: 0.0001412  loss_mask_4: 0.1127  loss_dice_4: 0.1857  loss_ce_5: 8.926e-05  loss_mask_5: 0.1151  loss_dice_5: 0.1838  loss_ce_6: 7.81e-05  loss_mask_6: 0.1133  loss_dice_6: 0.1808  loss_ce_7: 0.0001746  loss_mask_7: 0.1158  loss_dice_7: 0.1886  loss_ce_8: 0.0001193  loss_mask_8: 0.1201  loss_dice_8: 0.1862  time: 0.5375  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:55:58] d2.utils.events INFO:  eta: 6:25:17  iter: 7579  total_loss: 3.073  loss_ce: 0.0001654  loss_mask: 0.1214  loss_dice: 0.176  loss_ce_0: 0.1208  loss_mask_0: 0.1232  loss_dice_0: 0.1705  loss_ce_1: 0.0002199  loss_mask_1: 0.1226  loss_dice_1: 0.1709  loss_ce_2: 0.000142  loss_mask_2: 0.1182  loss_dice_2: 0.1691  loss_ce_3: 0.0002113  loss_mask_3: 0.1172  loss_dice_3: 0.1695  loss_ce_4: 0.0002517  loss_mask_4: 0.122  loss_dice_4: 0.1729  loss_ce_5: 0.0001477  loss_mask_5: 0.1242  loss_dice_5: 0.1718  loss_ce_6: 0.0001228  loss_mask_6: 0.118  loss_dice_6: 0.1721  loss_ce_7: 0.000244  loss_mask_7: 0.1199  loss_dice_7: 0.1719  loss_ce_8: 0.0001552  loss_mask_8: 0.1227  loss_dice_8: 0.1702  time: 0.5383  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:56:15] d2.utils.events INFO:  eta: 6:24:50  iter: 7599  total_loss: 3.016  loss_ce: 0.0001153  loss_mask: 0.1159  loss_dice: 0.1715  loss_ce_0: 0.1254  loss_mask_0: 0.1169  loss_dice_0: 0.1718  loss_ce_1: 9.828e-05  loss_mask_1: 0.1208  loss_dice_1: 0.1788  loss_ce_2: 8.206e-05  loss_mask_2: 0.117  loss_dice_2: 0.1727  loss_ce_3: 0.0001268  loss_mask_3: 0.1179  loss_dice_3: 0.1762  loss_ce_4: 0.0001007  loss_mask_4: 0.1185  loss_dice_4: 0.1722  loss_ce_5: 7.459e-05  loss_mask_5: 0.1166  loss_dice_5: 0.1732  loss_ce_6: 7.105e-05  loss_mask_6: 0.1207  loss_dice_6: 0.1767  loss_ce_7: 0.0001222  loss_mask_7: 0.1208  loss_dice_7: 0.1746  loss_ce_8: 9.076e-05  loss_mask_8: 0.1149  loss_dice_8: 0.17  time: 0.5391  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 17:56:32] d2.utils.events INFO:  eta: 6:24:22  iter: 7619  total_loss: 3.207  loss_ce: 0.0003075  loss_mask: 0.1229  loss_dice: 0.1782  loss_ce_0: 0.1279  loss_mask_0: 0.1236  loss_dice_0: 0.1833  loss_ce_1: 0.0003109  loss_mask_1: 0.1241  loss_dice_1: 0.1775  loss_ce_2: 0.0003597  loss_mask_2: 0.1234  loss_dice_2: 0.1801  loss_ce_3: 0.00026  loss_mask_3: 0.1242  loss_dice_3: 0.1754  loss_ce_4: 0.0002481  loss_mask_4: 0.1233  loss_dice_4: 0.1757  loss_ce_5: 0.0004064  loss_mask_5: 0.1245  loss_dice_5: 0.1769  loss_ce_6: 0.0003454  loss_mask_6: 0.1247  loss_dice_6: 0.1828  loss_ce_7: 0.0003321  loss_mask_7: 0.1219  loss_dice_7: 0.1764  loss_ce_8: 0.0003815  loss_mask_8: 0.1271  loss_dice_8: 0.1778  time: 0.5399  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:56:49] d2.utils.events INFO:  eta: 6:24:27  iter: 7639  total_loss: 3.165  loss_ce: 0.0001314  loss_mask: 0.1196  loss_dice: 0.1798  loss_ce_0: 0.1225  loss_mask_0: 0.1244  loss_dice_0: 0.1823  loss_ce_1: 0.000192  loss_mask_1: 0.1226  loss_dice_1: 0.1796  loss_ce_2: 8.618e-05  loss_mask_2: 0.1231  loss_dice_2: 0.1721  loss_ce_3: 0.0001479  loss_mask_3: 0.1204  loss_dice_3: 0.1813  loss_ce_4: 0.0001496  loss_mask_4: 0.1224  loss_dice_4: 0.1766  loss_ce_5: 8.365e-05  loss_mask_5: 0.1177  loss_dice_5: 0.1768  loss_ce_6: 9.124e-05  loss_mask_6: 0.1189  loss_dice_6: 0.1749  loss_ce_7: 0.000136  loss_mask_7: 0.1232  loss_dice_7: 0.1765  loss_ce_8: 0.0001031  loss_mask_8: 0.1224  loss_dice_8: 0.1814  time: 0.5407  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:57:05] d2.utils.events INFO:  eta: 6:24:00  iter: 7659  total_loss: 3.237  loss_ce: 9.818e-05  loss_mask: 0.121  loss_dice: 0.1962  loss_ce_0: 0.1215  loss_mask_0: 0.1204  loss_dice_0: 0.2013  loss_ce_1: 5.711e-05  loss_mask_1: 0.1228  loss_dice_1: 0.1936  loss_ce_2: 6.987e-05  loss_mask_2: 0.1275  loss_dice_2: 0.2008  loss_ce_3: 0.0001109  loss_mask_3: 0.1167  loss_dice_3: 0.1901  loss_ce_4: 0.0001099  loss_mask_4: 0.1203  loss_dice_4: 0.1904  loss_ce_5: 8.02e-05  loss_mask_5: 0.1202  loss_dice_5: 0.1947  loss_ce_6: 8.138e-05  loss_mask_6: 0.1215  loss_dice_6: 0.1879  loss_ce_7: 0.0001331  loss_mask_7: 0.1206  loss_dice_7: 0.1863  loss_ce_8: 0.0001009  loss_mask_8: 0.1208  loss_dice_8: 0.1955  time: 0.5415  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 17:57:23] d2.utils.events INFO:  eta: 6:23:58  iter: 7679  total_loss: 3.148  loss_ce: 0.0007254  loss_mask: 0.124  loss_dice: 0.1766  loss_ce_0: 0.1247  loss_mask_0: 0.1191  loss_dice_0: 0.1704  loss_ce_1: 0.0002996  loss_mask_1: 0.1203  loss_dice_1: 0.1755  loss_ce_2: 0.0004468  loss_mask_2: 0.1189  loss_dice_2: 0.1758  loss_ce_3: 0.000619  loss_mask_3: 0.1226  loss_dice_3: 0.1819  loss_ce_4: 0.000353  loss_mask_4: 0.1223  loss_dice_4: 0.1771  loss_ce_5: 0.0003271  loss_mask_5: 0.1223  loss_dice_5: 0.1735  loss_ce_6: 0.0003399  loss_mask_6: 0.1206  loss_dice_6: 0.1756  loss_ce_7: 0.0002259  loss_mask_7: 0.12  loss_dice_7: 0.1706  loss_ce_8: 0.0004741  loss_mask_8: 0.1168  loss_dice_8: 0.1707  time: 0.5423  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:57:40] d2.utils.events INFO:  eta: 6:23:28  iter: 7699  total_loss: 3.153  loss_ce: 0.0007707  loss_mask: 0.1212  loss_dice: 0.1801  loss_ce_0: 0.1216  loss_mask_0: 0.1228  loss_dice_0: 0.1841  loss_ce_1: 0.0004761  loss_mask_1: 0.1225  loss_dice_1: 0.1806  loss_ce_2: 0.0004897  loss_mask_2: 0.1234  loss_dice_2: 0.1793  loss_ce_3: 0.0004461  loss_mask_3: 0.1226  loss_dice_3: 0.177  loss_ce_4: 0.000447  loss_mask_4: 0.1227  loss_dice_4: 0.1785  loss_ce_5: 0.0003542  loss_mask_5: 0.1214  loss_dice_5: 0.1778  loss_ce_6: 0.0004742  loss_mask_6: 0.1214  loss_dice_6: 0.1811  loss_ce_7: 0.0004407  loss_mask_7: 0.1201  loss_dice_7: 0.1851  loss_ce_8: 0.0005565  loss_mask_8: 0.1222  loss_dice_8: 0.1787  time: 0.5431  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:57:57] d2.utils.events INFO:  eta: 6:23:33  iter: 7719  total_loss: 2.991  loss_ce: 0.0001806  loss_mask: 0.1177  loss_dice: 0.1743  loss_ce_0: 0.1276  loss_mask_0: 0.1194  loss_dice_0: 0.1686  loss_ce_1: 0.0002743  loss_mask_1: 0.1194  loss_dice_1: 0.1701  loss_ce_2: 0.0002305  loss_mask_2: 0.1187  loss_dice_2: 0.1707  loss_ce_3: 0.0002107  loss_mask_3: 0.1195  loss_dice_3: 0.1777  loss_ce_4: 0.0001903  loss_mask_4: 0.1167  loss_dice_4: 0.1721  loss_ce_5: 0.0002428  loss_mask_5: 0.1159  loss_dice_5: 0.1719  loss_ce_6: 0.0001513  loss_mask_6: 0.1179  loss_dice_6: 0.1727  loss_ce_7: 0.0001809  loss_mask_7: 0.1148  loss_dice_7: 0.1772  loss_ce_8: 0.0002259  loss_mask_8: 0.117  loss_dice_8: 0.1721  time: 0.5439  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:58:14] d2.utils.events INFO:  eta: 6:23:13  iter: 7739  total_loss: 3.178  loss_ce: 0.0001425  loss_mask: 0.1163  loss_dice: 0.18  loss_ce_0: 0.1256  loss_mask_0: 0.1261  loss_dice_0: 0.1866  loss_ce_1: 4.816e-05  loss_mask_1: 0.1217  loss_dice_1: 0.1831  loss_ce_2: 0.0001797  loss_mask_2: 0.1234  loss_dice_2: 0.1815  loss_ce_3: 0.0001709  loss_mask_3: 0.1242  loss_dice_3: 0.1777  loss_ce_4: 7.934e-05  loss_mask_4: 0.1197  loss_dice_4: 0.1837  loss_ce_5: 0.0001634  loss_mask_5: 0.1192  loss_dice_5: 0.177  loss_ce_6: 0.0001257  loss_mask_6: 0.1184  loss_dice_6: 0.1777  loss_ce_7: 6.281e-05  loss_mask_7: 0.1211  loss_dice_7: 0.1812  loss_ce_8: 0.0001755  loss_mask_8: 0.1181  loss_dice_8: 0.1814  time: 0.5447  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:58:30] d2.utils.events INFO:  eta: 6:22:59  iter: 7759  total_loss: 3.094  loss_ce: 0.0001095  loss_mask: 0.1212  loss_dice: 0.171  loss_ce_0: 0.1227  loss_mask_0: 0.1245  loss_dice_0: 0.1786  loss_ce_1: 9.414e-05  loss_mask_1: 0.124  loss_dice_1: 0.1695  loss_ce_2: 0.0001548  loss_mask_2: 0.1232  loss_dice_2: 0.1704  loss_ce_3: 0.0001279  loss_mask_3: 0.1225  loss_dice_3: 0.1772  loss_ce_4: 0.0001407  loss_mask_4: 0.1232  loss_dice_4: 0.1734  loss_ce_5: 0.00016  loss_mask_5: 0.1259  loss_dice_5: 0.1842  loss_ce_6: 0.000102  loss_mask_6: 0.1224  loss_dice_6: 0.1803  loss_ce_7: 8.024e-05  loss_mask_7: 0.125  loss_dice_7: 0.1797  loss_ce_8: 0.0001562  loss_mask_8: 0.1243  loss_dice_8: 0.179  time: 0.5454  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:58:47] d2.utils.events INFO:  eta: 6:22:48  iter: 7779  total_loss: 3.095  loss_ce: 0.0001481  loss_mask: 0.1184  loss_dice: 0.1721  loss_ce_0: 0.1216  loss_mask_0: 0.1177  loss_dice_0: 0.1826  loss_ce_1: 0.0001006  loss_mask_1: 0.1217  loss_dice_1: 0.1676  loss_ce_2: 0.0001471  loss_mask_2: 0.1183  loss_dice_2: 0.1623  loss_ce_3: 0.0001524  loss_mask_3: 0.1198  loss_dice_3: 0.17  loss_ce_4: 0.0001659  loss_mask_4: 0.1187  loss_dice_4: 0.1689  loss_ce_5: 0.0001448  loss_mask_5: 0.1239  loss_dice_5: 0.1724  loss_ce_6: 0.0001523  loss_mask_6: 0.1167  loss_dice_6: 0.1676  loss_ce_7: 9.621e-05  loss_mask_7: 0.1206  loss_dice_7: 0.1701  loss_ce_8: 0.0001491  loss_mask_8: 0.12  loss_dice_8: 0.1795  time: 0.5462  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:59:04] d2.utils.events INFO:  eta: 6:22:22  iter: 7799  total_loss: 3.069  loss_ce: 8.488e-05  loss_mask: 0.1177  loss_dice: 0.1734  loss_ce_0: 0.1182  loss_mask_0: 0.1187  loss_dice_0: 0.1733  loss_ce_1: 6.379e-05  loss_mask_1: 0.12  loss_dice_1: 0.1787  loss_ce_2: 0.0001221  loss_mask_2: 0.1202  loss_dice_2: 0.1835  loss_ce_3: 9.675e-05  loss_mask_3: 0.1189  loss_dice_3: 0.1775  loss_ce_4: 9.294e-05  loss_mask_4: 0.1193  loss_dice_4: 0.1764  loss_ce_5: 0.0001261  loss_mask_5: 0.1213  loss_dice_5: 0.1775  loss_ce_6: 8.625e-05  loss_mask_6: 0.1165  loss_dice_6: 0.1737  loss_ce_7: 6.053e-05  loss_mask_7: 0.1198  loss_dice_7: 0.1747  loss_ce_8: 0.0001297  loss_mask_8: 0.1159  loss_dice_8: 0.1781  time: 0.5470  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:59:21] d2.utils.events INFO:  eta: 6:22:19  iter: 7819  total_loss: 3.275  loss_ce: 0.0001274  loss_mask: 0.1248  loss_dice: 0.1861  loss_ce_0: 0.1165  loss_mask_0: 0.1234  loss_dice_0: 0.1936  loss_ce_1: 0.0001024  loss_mask_1: 0.1234  loss_dice_1: 0.1836  loss_ce_2: 0.0001227  loss_mask_2: 0.1273  loss_dice_2: 0.1842  loss_ce_3: 0.0001173  loss_mask_3: 0.1231  loss_dice_3: 0.1888  loss_ce_4: 0.0001361  loss_mask_4: 0.1236  loss_dice_4: 0.1844  loss_ce_5: 0.0001242  loss_mask_5: 0.1305  loss_dice_5: 0.194  loss_ce_6: 9.237e-05  loss_mask_6: 0.1253  loss_dice_6: 0.1874  loss_ce_7: 9.327e-05  loss_mask_7: 0.1233  loss_dice_7: 0.1842  loss_ce_8: 0.0001329  loss_mask_8: 0.1241  loss_dice_8: 0.1922  time: 0.5477  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 17:59:38] d2.utils.events INFO:  eta: 6:21:48  iter: 7839  total_loss: 3.188  loss_ce: 0.0001517  loss_mask: 0.1215  loss_dice: 0.1776  loss_ce_0: 0.1166  loss_mask_0: 0.1264  loss_dice_0: 0.1872  loss_ce_1: 0.0001774  loss_mask_1: 0.1225  loss_dice_1: 0.1811  loss_ce_2: 0.0001591  loss_mask_2: 0.1272  loss_dice_2: 0.1773  loss_ce_3: 0.0001307  loss_mask_3: 0.1187  loss_dice_3: 0.1793  loss_ce_4: 0.0001222  loss_mask_4: 0.1228  loss_dice_4: 0.18  loss_ce_5: 0.0001766  loss_mask_5: 0.1235  loss_dice_5: 0.1815  loss_ce_6: 0.0001667  loss_mask_6: 0.1237  loss_dice_6: 0.1834  loss_ce_7: 0.0001286  loss_mask_7: 0.126  loss_dice_7: 0.1772  loss_ce_8: 0.0001665  loss_mask_8: 0.1288  loss_dice_8: 0.184  time: 0.5485  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 17:59:55] d2.utils.events INFO:  eta: 6:21:03  iter: 7859  total_loss: 2.998  loss_ce: 0.0001557  loss_mask: 0.1126  loss_dice: 0.1661  loss_ce_0: 0.1347  loss_mask_0: 0.1162  loss_dice_0: 0.1756  loss_ce_1: 0.0001921  loss_mask_1: 0.1195  loss_dice_1: 0.174  loss_ce_2: 0.0001617  loss_mask_2: 0.116  loss_dice_2: 0.1759  loss_ce_3: 0.0001273  loss_mask_3: 0.1194  loss_dice_3: 0.1728  loss_ce_4: 0.0001177  loss_mask_4: 0.1129  loss_dice_4: 0.1654  loss_ce_5: 0.0001568  loss_mask_5: 0.1135  loss_dice_5: 0.1636  loss_ce_6: 0.0001539  loss_mask_6: 0.1141  loss_dice_6: 0.1765  loss_ce_7: 0.0001365  loss_mask_7: 0.1163  loss_dice_7: 0.1703  loss_ce_8: 0.0001593  loss_mask_8: 0.1222  loss_dice_8: 0.1825  time: 0.5492  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:00:12] d2.utils.events INFO:  eta: 6:20:43  iter: 7879  total_loss: 3.041  loss_ce: 0.0001306  loss_mask: 0.1187  loss_dice: 0.1734  loss_ce_0: 0.1305  loss_mask_0: 0.1194  loss_dice_0: 0.1755  loss_ce_1: 0.0001385  loss_mask_1: 0.1179  loss_dice_1: 0.17  loss_ce_2: 0.0001331  loss_mask_2: 0.1196  loss_dice_2: 0.1767  loss_ce_3: 0.0001316  loss_mask_3: 0.1186  loss_dice_3: 0.1748  loss_ce_4: 0.0001154  loss_mask_4: 0.119  loss_dice_4: 0.1704  loss_ce_5: 0.000108  loss_mask_5: 0.117  loss_dice_5: 0.1751  loss_ce_6: 8.77e-05  loss_mask_6: 0.1185  loss_dice_6: 0.1776  loss_ce_7: 0.0001161  loss_mask_7: 0.1219  loss_dice_7: 0.176  loss_ce_8: 0.0001457  loss_mask_8: 0.1184  loss_dice_8: 0.1769  time: 0.5500  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:00:29] d2.utils.events INFO:  eta: 6:20:58  iter: 7899  total_loss: 2.993  loss_ce: 0.0001014  loss_mask: 0.1203  loss_dice: 0.1669  loss_ce_0: 0.1257  loss_mask_0: 0.1232  loss_dice_0: 0.1676  loss_ce_1: 0.0001306  loss_mask_1: 0.1205  loss_dice_1: 0.1654  loss_ce_2: 0.000126  loss_mask_2: 0.1196  loss_dice_2: 0.1667  loss_ce_3: 9.939e-05  loss_mask_3: 0.122  loss_dice_3: 0.1675  loss_ce_4: 9.972e-05  loss_mask_4: 0.123  loss_dice_4: 0.1671  loss_ce_5: 9.64e-05  loss_mask_5: 0.1201  loss_dice_5: 0.167  loss_ce_6: 8.922e-05  loss_mask_6: 0.1174  loss_dice_6: 0.1599  loss_ce_7: 9.564e-05  loss_mask_7: 0.1181  loss_dice_7: 0.1663  loss_ce_8: 0.0001309  loss_mask_8: 0.119  loss_dice_8: 0.1634  time: 0.5507  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:00:45] d2.utils.events INFO:  eta: 6:20:16  iter: 7919  total_loss: 3.164  loss_ce: 9.496e-05  loss_mask: 0.1239  loss_dice: 0.1815  loss_ce_0: 0.12  loss_mask_0: 0.1221  loss_dice_0: 0.1826  loss_ce_1: 0.0001415  loss_mask_1: 0.125  loss_dice_1: 0.1781  loss_ce_2: 0.0001627  loss_mask_2: 0.1261  loss_dice_2: 0.1748  loss_ce_3: 0.0001063  loss_mask_3: 0.1205  loss_dice_3: 0.1716  loss_ce_4: 0.0001262  loss_mask_4: 0.1235  loss_dice_4: 0.1782  loss_ce_5: 0.0001265  loss_mask_5: 0.1237  loss_dice_5: 0.1777  loss_ce_6: 0.0001046  loss_mask_6: 0.1202  loss_dice_6: 0.179  loss_ce_7: 7.826e-05  loss_mask_7: 0.1216  loss_dice_7: 0.1769  loss_ce_8: 0.0001253  loss_mask_8: 0.1252  loss_dice_8: 0.1749  time: 0.5514  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:01:02] d2.utils.events INFO:  eta: 6:19:59  iter: 7939  total_loss: 3.192  loss_ce: 0.0001139  loss_mask: 0.1216  loss_dice: 0.1768  loss_ce_0: 0.1232  loss_mask_0: 0.1201  loss_dice_0: 0.1743  loss_ce_1: 0.0001947  loss_mask_1: 0.1212  loss_dice_1: 0.1715  loss_ce_2: 0.0001455  loss_mask_2: 0.1242  loss_dice_2: 0.1779  loss_ce_3: 0.0001157  loss_mask_3: 0.1235  loss_dice_3: 0.1786  loss_ce_4: 0.0001229  loss_mask_4: 0.1211  loss_dice_4: 0.1791  loss_ce_5: 0.0001218  loss_mask_5: 0.1232  loss_dice_5: 0.1791  loss_ce_6: 8.857e-05  loss_mask_6: 0.122  loss_dice_6: 0.1833  loss_ce_7: 0.0001106  loss_mask_7: 0.1208  loss_dice_7: 0.1785  loss_ce_8: 0.0001261  loss_mask_8: 0.1171  loss_dice_8: 0.1749  time: 0.5522  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:01:19] d2.utils.events INFO:  eta: 6:20:17  iter: 7959  total_loss: 3.103  loss_ce: 0.0001039  loss_mask: 0.116  loss_dice: 0.1744  loss_ce_0: 0.1251  loss_mask_0: 0.1188  loss_dice_0: 0.1822  loss_ce_1: 0.0001852  loss_mask_1: 0.1163  loss_dice_1: 0.182  loss_ce_2: 0.0001619  loss_mask_2: 0.1126  loss_dice_2: 0.1728  loss_ce_3: 0.0001272  loss_mask_3: 0.1177  loss_dice_3: 0.1761  loss_ce_4: 0.0001395  loss_mask_4: 0.1194  loss_dice_4: 0.1735  loss_ce_5: 0.0001177  loss_mask_5: 0.1154  loss_dice_5: 0.1708  loss_ce_6: 8.661e-05  loss_mask_6: 0.1161  loss_dice_6: 0.1757  loss_ce_7: 0.0001501  loss_mask_7: 0.1202  loss_dice_7: 0.1795  loss_ce_8: 0.0001221  loss_mask_8: 0.1176  loss_dice_8: 0.1725  time: 0.5530  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:01:37] d2.utils.events INFO:  eta: 6:20:04  iter: 7979  total_loss: 2.966  loss_ce: 0.0001008  loss_mask: 0.118  loss_dice: 0.168  loss_ce_0: 0.1293  loss_mask_0: 0.1161  loss_dice_0: 0.1696  loss_ce_1: 0.0002633  loss_mask_1: 0.1185  loss_dice_1: 0.1699  loss_ce_2: 0.0001431  loss_mask_2: 0.115  loss_dice_2: 0.1673  loss_ce_3: 0.0001114  loss_mask_3: 0.1164  loss_dice_3: 0.1657  loss_ce_4: 0.0001135  loss_mask_4: 0.1163  loss_dice_4: 0.1652  loss_ce_5: 0.0001092  loss_mask_5: 0.1195  loss_dice_5: 0.1678  loss_ce_6: 9.086e-05  loss_mask_6: 0.1152  loss_dice_6: 0.1713  loss_ce_7: 0.0001477  loss_mask_7: 0.1166  loss_dice_7: 0.1689  loss_ce_8: 0.0001146  loss_mask_8: 0.1143  loss_dice_8: 0.1651  time: 0.5537  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:01:54] d2.utils.events INFO:  eta: 6:19:40  iter: 7999  total_loss: 3.066  loss_ce: 0.0001001  loss_mask: 0.1234  loss_dice: 0.1691  loss_ce_0: 0.1244  loss_mask_0: 0.1178  loss_dice_0: 0.1731  loss_ce_1: 0.0001131  loss_mask_1: 0.1207  loss_dice_1: 0.1741  loss_ce_2: 0.0001165  loss_mask_2: 0.1195  loss_dice_2: 0.1744  loss_ce_3: 0.000118  loss_mask_3: 0.1223  loss_dice_3: 0.174  loss_ce_4: 0.0001083  loss_mask_4: 0.1229  loss_dice_4: 0.1773  loss_ce_5: 0.0001019  loss_mask_5: 0.1195  loss_dice_5: 0.1764  loss_ce_6: 9.046e-05  loss_mask_6: 0.1198  loss_dice_6: 0.1706  loss_ce_7: 0.0001757  loss_mask_7: 0.1188  loss_dice_7: 0.1753  loss_ce_8: 0.0001063  loss_mask_8: 0.1191  loss_dice_8: 0.1705  time: 0.5544  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:02:11] d2.utils.events INFO:  eta: 6:19:17  iter: 8019  total_loss: 3.422  loss_ce: 9.125e-05  loss_mask: 0.132  loss_dice: 0.2056  loss_ce_0: 0.1283  loss_mask_0: 0.1302  loss_dice_0: 0.2041  loss_ce_1: 5.766e-05  loss_mask_1: 0.1325  loss_dice_1: 0.2022  loss_ce_2: 9.968e-05  loss_mask_2: 0.1261  loss_dice_2: 0.1942  loss_ce_3: 8.716e-05  loss_mask_3: 0.1245  loss_dice_3: 0.1829  loss_ce_4: 9.317e-05  loss_mask_4: 0.1336  loss_dice_4: 0.1997  loss_ce_5: 9.368e-05  loss_mask_5: 0.1251  loss_dice_5: 0.2012  loss_ce_6: 7.92e-05  loss_mask_6: 0.1288  loss_dice_6: 0.2026  loss_ce_7: 0.0001192  loss_mask_7: 0.126  loss_dice_7: 0.1964  loss_ce_8: 0.0001033  loss_mask_8: 0.134  loss_dice_8: 0.2077  time: 0.5552  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:02:27] d2.utils.events INFO:  eta: 6:19:07  iter: 8039  total_loss: 3.204  loss_ce: 0.0001058  loss_mask: 0.1265  loss_dice: 0.1793  loss_ce_0: 0.1253  loss_mask_0: 0.1274  loss_dice_0: 0.1803  loss_ce_1: 9.894e-05  loss_mask_1: 0.1241  loss_dice_1: 0.1772  loss_ce_2: 0.0001084  loss_mask_2: 0.1267  loss_dice_2: 0.1816  loss_ce_3: 9.409e-05  loss_mask_3: 0.1215  loss_dice_3: 0.1776  loss_ce_4: 0.000105  loss_mask_4: 0.1244  loss_dice_4: 0.1762  loss_ce_5: 9.548e-05  loss_mask_5: 0.1215  loss_dice_5: 0.1765  loss_ce_6: 8.529e-05  loss_mask_6: 0.1222  loss_dice_6: 0.1844  loss_ce_7: 0.0001345  loss_mask_7: 0.122  loss_dice_7: 0.1758  loss_ce_8: 0.0001015  loss_mask_8: 0.1269  loss_dice_8: 0.1764  time: 0.5559  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:02:44] d2.utils.events INFO:  eta: 6:18:56  iter: 8059  total_loss: 3.207  loss_ce: 0.000106  loss_mask: 0.1255  loss_dice: 0.1868  loss_ce_0: 0.1205  loss_mask_0: 0.1251  loss_dice_0: 0.1911  loss_ce_1: 0.0003727  loss_mask_1: 0.131  loss_dice_1: 0.187  loss_ce_2: 0.0001851  loss_mask_2: 0.1269  loss_dice_2: 0.1861  loss_ce_3: 0.0006148  loss_mask_3: 0.1262  loss_dice_3: 0.187  loss_ce_4: 0.000128  loss_mask_4: 0.124  loss_dice_4: 0.1855  loss_ce_5: 0.0001504  loss_mask_5: 0.1273  loss_dice_5: 0.1858  loss_ce_6: 9.288e-05  loss_mask_6: 0.1269  loss_dice_6: 0.1918  loss_ce_7: 0.0001295  loss_mask_7: 0.121  loss_dice_7: 0.1829  loss_ce_8: 0.0001481  loss_mask_8: 0.1291  loss_dice_8: 0.1872  time: 0.5566  data_time: 0.0017  lr: 0.0001  max_mem: 8444M
[08/01 18:03:01] d2.utils.events INFO:  eta: 6:18:57  iter: 8079  total_loss: 3.017  loss_ce: 0.0001216  loss_mask: 0.1182  loss_dice: 0.1692  loss_ce_0: 0.1277  loss_mask_0: 0.1186  loss_dice_0: 0.1744  loss_ce_1: 0.0002102  loss_mask_1: 0.1178  loss_dice_1: 0.171  loss_ce_2: 0.0001388  loss_mask_2: 0.1198  loss_dice_2: 0.1755  loss_ce_3: 0.0001752  loss_mask_3: 0.1172  loss_dice_3: 0.1692  loss_ce_4: 0.0001356  loss_mask_4: 0.117  loss_dice_4: 0.1647  loss_ce_5: 0.0001559  loss_mask_5: 0.1211  loss_dice_5: 0.1657  loss_ce_6: 0.0001335  loss_mask_6: 0.1207  loss_dice_6: 0.1747  loss_ce_7: 0.0002761  loss_mask_7: 0.1201  loss_dice_7: 0.1693  loss_ce_8: 0.0001326  loss_mask_8: 0.1172  loss_dice_8: 0.161  time: 0.5573  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:03:18] d2.utils.events INFO:  eta: 6:18:36  iter: 8099  total_loss: 3.176  loss_ce: 0.0003352  loss_mask: 0.1222  loss_dice: 0.175  loss_ce_0: 0.123  loss_mask_0: 0.1233  loss_dice_0: 0.1776  loss_ce_1: 0.0007725  loss_mask_1: 0.1253  loss_dice_1: 0.1742  loss_ce_2: 0.0005142  loss_mask_2: 0.1276  loss_dice_2: 0.1738  loss_ce_3: 0.0001094  loss_mask_3: 0.1211  loss_dice_3: 0.1694  loss_ce_4: 0.00103  loss_mask_4: 0.1238  loss_dice_4: 0.1755  loss_ce_5: 0.0004503  loss_mask_5: 0.1225  loss_dice_5: 0.1698  loss_ce_6: 0.0003136  loss_mask_6: 0.125  loss_dice_6: 0.173  loss_ce_7: 0.001045  loss_mask_7: 0.1231  loss_dice_7: 0.1772  loss_ce_8: 0.0006134  loss_mask_8: 0.1241  loss_dice_8: 0.1746  time: 0.5580  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:03:35] d2.utils.events INFO:  eta: 6:18:19  iter: 8119  total_loss: 3.139  loss_ce: 0.0001706  loss_mask: 0.1218  loss_dice: 0.1766  loss_ce_0: 0.1227  loss_mask_0: 0.1229  loss_dice_0: 0.1735  loss_ce_1: 0.0002137  loss_mask_1: 0.1207  loss_dice_1: 0.1742  loss_ce_2: 0.0002828  loss_mask_2: 0.1236  loss_dice_2: 0.1775  loss_ce_3: 0.0001599  loss_mask_3: 0.1249  loss_dice_3: 0.1741  loss_ce_4: 0.0001608  loss_mask_4: 0.1228  loss_dice_4: 0.1751  loss_ce_5: 0.0003031  loss_mask_5: 0.1237  loss_dice_5: 0.177  loss_ce_6: 0.0003328  loss_mask_6: 0.1248  loss_dice_6: 0.179  loss_ce_7: 0.0001761  loss_mask_7: 0.1214  loss_dice_7: 0.1724  loss_ce_8: 0.0002207  loss_mask_8: 0.1185  loss_dice_8: 0.1732  time: 0.5587  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:03:52] d2.utils.events INFO:  eta: 6:18:09  iter: 8139  total_loss: 3.074  loss_ce: 0.0001667  loss_mask: 0.1244  loss_dice: 0.1739  loss_ce_0: 0.119  loss_mask_0: 0.1208  loss_dice_0: 0.1694  loss_ce_1: 0.000241  loss_mask_1: 0.1213  loss_dice_1: 0.1706  loss_ce_2: 0.0003374  loss_mask_2: 0.1188  loss_dice_2: 0.1672  loss_ce_3: 9.835e-05  loss_mask_3: 0.1219  loss_dice_3: 0.175  loss_ce_4: 0.0002237  loss_mask_4: 0.125  loss_dice_4: 0.1734  loss_ce_5: 0.0002379  loss_mask_5: 0.1203  loss_dice_5: 0.1704  loss_ce_6: 0.0002555  loss_mask_6: 0.1193  loss_dice_6: 0.1675  loss_ce_7: 0.0003224  loss_mask_7: 0.1244  loss_dice_7: 0.1714  loss_ce_8: 0.0004034  loss_mask_8: 0.128  loss_dice_8: 0.1774  time: 0.5595  data_time: 0.0020  lr: 0.0001  max_mem: 8444M
[08/01 18:04:09] d2.utils.events INFO:  eta: 6:17:56  iter: 8159  total_loss: 3.13  loss_ce: 0.0005065  loss_mask: 0.1209  loss_dice: 0.1748  loss_ce_0: 0.119  loss_mask_0: 0.1225  loss_dice_0: 0.1799  loss_ce_1: 0.0004897  loss_mask_1: 0.1223  loss_dice_1: 0.1761  loss_ce_2: 0.0007562  loss_mask_2: 0.1212  loss_dice_2: 0.1834  loss_ce_3: 0.0002051  loss_mask_3: 0.1229  loss_dice_3: 0.1832  loss_ce_4: 0.000826  loss_mask_4: 0.1199  loss_dice_4: 0.1804  loss_ce_5: 0.0006028  loss_mask_5: 0.1252  loss_dice_5: 0.1813  loss_ce_6: 0.0004712  loss_mask_6: 0.1225  loss_dice_6: 0.1816  loss_ce_7: 0.0009898  loss_mask_7: 0.1214  loss_dice_7: 0.1782  loss_ce_8: 0.0007916  loss_mask_8: 0.1233  loss_dice_8: 0.1796  time: 0.5602  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:04:26] d2.utils.events INFO:  eta: 6:17:42  iter: 8179  total_loss: 3.064  loss_ce: 0.0001278  loss_mask: 0.1225  loss_dice: 0.1808  loss_ce_0: 0.1238  loss_mask_0: 0.1177  loss_dice_0: 0.1822  loss_ce_1: 0.0001854  loss_mask_1: 0.1207  loss_dice_1: 0.1793  loss_ce_2: 0.0003167  loss_mask_2: 0.1261  loss_dice_2: 0.183  loss_ce_3: 0.0001249  loss_mask_3: 0.1241  loss_dice_3: 0.1805  loss_ce_4: 0.0001599  loss_mask_4: 0.1223  loss_dice_4: 0.1707  loss_ce_5: 0.0002229  loss_mask_5: 0.1222  loss_dice_5: 0.1849  loss_ce_6: 0.0002604  loss_mask_6: 0.1213  loss_dice_6: 0.1784  loss_ce_7: 0.000127  loss_mask_7: 0.116  loss_dice_7: 0.1761  loss_ce_8: 0.0001962  loss_mask_8: 0.1193  loss_dice_8: 0.1793  time: 0.5609  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:04:43] d2.utils.events INFO:  eta: 6:17:26  iter: 8199  total_loss: 3.021  loss_ce: 0.0001194  loss_mask: 0.1244  loss_dice: 0.1682  loss_ce_0: 0.1226  loss_mask_0: 0.1227  loss_dice_0: 0.1656  loss_ce_1: 0.0001374  loss_mask_1: 0.1211  loss_dice_1: 0.1638  loss_ce_2: 0.0001877  loss_mask_2: 0.1187  loss_dice_2: 0.1645  loss_ce_3: 8.826e-05  loss_mask_3: 0.1247  loss_dice_3: 0.1692  loss_ce_4: 7.069e-05  loss_mask_4: 0.1253  loss_dice_4: 0.1637  loss_ce_5: 9.969e-05  loss_mask_5: 0.1216  loss_dice_5: 0.1612  loss_ce_6: 7.758e-05  loss_mask_6: 0.1197  loss_dice_6: 0.1674  loss_ce_7: 8.54e-05  loss_mask_7: 0.1202  loss_dice_7: 0.1631  loss_ce_8: 0.0001569  loss_mask_8: 0.1222  loss_dice_8: 0.1706  time: 0.5616  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:05:00] d2.utils.events INFO:  eta: 6:17:16  iter: 8219  total_loss: 3.137  loss_ce: 0.0001985  loss_mask: 0.1159  loss_dice: 0.1789  loss_ce_0: 0.1236  loss_mask_0: 0.1171  loss_dice_0: 0.1819  loss_ce_1: 0.0002328  loss_mask_1: 0.1172  loss_dice_1: 0.1774  loss_ce_2: 0.0002639  loss_mask_2: 0.1174  loss_dice_2: 0.1754  loss_ce_3: 0.0001514  loss_mask_3: 0.1225  loss_dice_3: 0.1823  loss_ce_4: 0.0002227  loss_mask_4: 0.1216  loss_dice_4: 0.1768  loss_ce_5: 0.0001853  loss_mask_5: 0.1165  loss_dice_5: 0.174  loss_ce_6: 0.0001764  loss_mask_6: 0.1158  loss_dice_6: 0.1762  loss_ce_7: 9.256e-05  loss_mask_7: 0.1165  loss_dice_7: 0.1775  loss_ce_8: 0.0002202  loss_mask_8: 0.1175  loss_dice_8: 0.1814  time: 0.5623  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:05:17] d2.utils.events INFO:  eta: 6:17:05  iter: 8239  total_loss: 3.286  loss_ce: 0.0002573  loss_mask: 0.1178  loss_dice: 0.1815  loss_ce_0: 0.1214  loss_mask_0: 0.1191  loss_dice_0: 0.1908  loss_ce_1: 0.0002578  loss_mask_1: 0.1182  loss_dice_1: 0.1907  loss_ce_2: 0.00031  loss_mask_2: 0.1132  loss_dice_2: 0.1878  loss_ce_3: 0.0002389  loss_mask_3: 0.1148  loss_dice_3: 0.188  loss_ce_4: 0.0002596  loss_mask_4: 0.1199  loss_dice_4: 0.1869  loss_ce_5: 0.0002033  loss_mask_5: 0.116  loss_dice_5: 0.1836  loss_ce_6: 0.0001913  loss_mask_6: 0.1213  loss_dice_6: 0.1911  loss_ce_7: 0.0001178  loss_mask_7: 0.1141  loss_dice_7: 0.1858  loss_ce_8: 0.0002982  loss_mask_8: 0.1212  loss_dice_8: 0.1823  time: 0.5630  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:05:34] d2.utils.events INFO:  eta: 6:17:02  iter: 8259  total_loss: 3.151  loss_ce: 0.0002384  loss_mask: 0.1237  loss_dice: 0.1792  loss_ce_0: 0.1247  loss_mask_0: 0.1232  loss_dice_0: 0.1816  loss_ce_1: 0.0002717  loss_mask_1: 0.1204  loss_dice_1: 0.1737  loss_ce_2: 0.000414  loss_mask_2: 0.1202  loss_dice_2: 0.1758  loss_ce_3: 0.000332  loss_mask_3: 0.1179  loss_dice_3: 0.1768  loss_ce_4: 0.0001883  loss_mask_4: 0.1179  loss_dice_4: 0.1767  loss_ce_5: 0.0003473  loss_mask_5: 0.1188  loss_dice_5: 0.1734  loss_ce_6: 0.0002723  loss_mask_6: 0.1161  loss_dice_6: 0.1741  loss_ce_7: 9.409e-05  loss_mask_7: 0.118  loss_dice_7: 0.1771  loss_ce_8: 0.000445  loss_mask_8: 0.115  loss_dice_8: 0.1763  time: 0.5637  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:05:51] d2.utils.events INFO:  eta: 6:16:43  iter: 8279  total_loss: 3.054  loss_ce: 0.0005305  loss_mask: 0.1233  loss_dice: 0.1716  loss_ce_0: 0.1239  loss_mask_0: 0.1223  loss_dice_0: 0.1852  loss_ce_1: 0.0003  loss_mask_1: 0.1168  loss_dice_1: 0.1723  loss_ce_2: 0.0007855  loss_mask_2: 0.1201  loss_dice_2: 0.1701  loss_ce_3: 0.0006208  loss_mask_3: 0.1163  loss_dice_3: 0.1739  loss_ce_4: 0.0003662  loss_mask_4: 0.123  loss_dice_4: 0.1703  loss_ce_5: 0.0005972  loss_mask_5: 0.1239  loss_dice_5: 0.1749  loss_ce_6: 0.0003036  loss_mask_6: 0.1194  loss_dice_6: 0.1724  loss_ce_7: 0.0001985  loss_mask_7: 0.1198  loss_dice_7: 0.1716  loss_ce_8: 0.0005952  loss_mask_8: 0.1204  loss_dice_8: 0.1694  time: 0.5643  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:06:08] d2.utils.events INFO:  eta: 6:16:28  iter: 8299  total_loss: 3.172  loss_ce: 0.0002304  loss_mask: 0.128  loss_dice: 0.1843  loss_ce_0: 0.1232  loss_mask_0: 0.124  loss_dice_0: 0.1818  loss_ce_1: 0.0002928  loss_mask_1: 0.1227  loss_dice_1: 0.18  loss_ce_2: 0.0003065  loss_mask_2: 0.1216  loss_dice_2: 0.1722  loss_ce_3: 0.0002571  loss_mask_3: 0.1233  loss_dice_3: 0.18  loss_ce_4: 0.000328  loss_mask_4: 0.1229  loss_dice_4: 0.1812  loss_ce_5: 0.000275  loss_mask_5: 0.1262  loss_dice_5: 0.1785  loss_ce_6: 0.0002495  loss_mask_6: 0.1259  loss_dice_6: 0.1832  loss_ce_7: 0.0001766  loss_mask_7: 0.1241  loss_dice_7: 0.1824  loss_ce_8: 0.0003122  loss_mask_8: 0.1218  loss_dice_8: 0.1771  time: 0.5650  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:06:25] d2.utils.events INFO:  eta: 6:16:09  iter: 8319  total_loss: 3.292  loss_ce: 0.0002354  loss_mask: 0.1257  loss_dice: 0.19  loss_ce_0: 0.1237  loss_mask_0: 0.1223  loss_dice_0: 0.1833  loss_ce_1: 0.0002773  loss_mask_1: 0.1263  loss_dice_1: 0.1847  loss_ce_2: 0.0003851  loss_mask_2: 0.123  loss_dice_2: 0.1768  loss_ce_3: 0.0002434  loss_mask_3: 0.1251  loss_dice_3: 0.1822  loss_ce_4: 0.0002569  loss_mask_4: 0.1239  loss_dice_4: 0.1797  loss_ce_5: 0.0002522  loss_mask_5: 0.1272  loss_dice_5: 0.1891  loss_ce_6: 0.0002626  loss_mask_6: 0.1272  loss_dice_6: 0.1861  loss_ce_7: 0.0002049  loss_mask_7: 0.1306  loss_dice_7: 0.1874  loss_ce_8: 0.0003107  loss_mask_8: 0.1241  loss_dice_8: 0.1837  time: 0.5657  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:06:42] d2.utils.events INFO:  eta: 6:15:49  iter: 8339  total_loss: 3.109  loss_ce: 0.001141  loss_mask: 0.1141  loss_dice: 0.1772  loss_ce_0: 0.1259  loss_mask_0: 0.1202  loss_dice_0: 0.1851  loss_ce_1: 0.0007077  loss_mask_1: 0.1205  loss_dice_1: 0.1791  loss_ce_2: 0.001788  loss_mask_2: 0.1196  loss_dice_2: 0.181  loss_ce_3: 0.001699  loss_mask_3: 0.1141  loss_dice_3: 0.1728  loss_ce_4: 0.001685  loss_mask_4: 0.1181  loss_dice_4: 0.1791  loss_ce_5: 0.001239  loss_mask_5: 0.1119  loss_dice_5: 0.1748  loss_ce_6: 0.0003463  loss_mask_6: 0.1157  loss_dice_6: 0.1764  loss_ce_7: 0.001028  loss_mask_7: 0.1216  loss_dice_7: 0.1851  loss_ce_8: 0.001426  loss_mask_8: 0.1171  loss_dice_8: 0.1777  time: 0.5664  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:06:59] d2.utils.events INFO:  eta: 6:15:39  iter: 8359  total_loss: 3.167  loss_ce: 0.0005937  loss_mask: 0.122  loss_dice: 0.1818  loss_ce_0: 0.1234  loss_mask_0: 0.1246  loss_dice_0: 0.182  loss_ce_1: 0.0004993  loss_mask_1: 0.1181  loss_dice_1: 0.1733  loss_ce_2: 0.000625  loss_mask_2: 0.1287  loss_dice_2: 0.1795  loss_ce_3: 0.0003707  loss_mask_3: 0.1244  loss_dice_3: 0.1779  loss_ce_4: 0.0003842  loss_mask_4: 0.1234  loss_dice_4: 0.1838  loss_ce_5: 0.0003186  loss_mask_5: 0.1241  loss_dice_5: 0.1745  loss_ce_6: 0.0002639  loss_mask_6: 0.1187  loss_dice_6: 0.1756  loss_ce_7: 0.0005548  loss_mask_7: 0.1246  loss_dice_7: 0.1824  loss_ce_8: 0.0005115  loss_mask_8: 0.1245  loss_dice_8: 0.18  time: 0.5671  data_time: 0.0019  lr: 0.0001  max_mem: 8444M
[08/01 18:07:16] d2.utils.events INFO:  eta: 6:15:25  iter: 8379  total_loss: 3.332  loss_ce: 0.0003504  loss_mask: 0.1201  loss_dice: 0.1945  loss_ce_0: 0.1249  loss_mask_0: 0.12  loss_dice_0: 0.201  loss_ce_1: 0.0004446  loss_mask_1: 0.1223  loss_dice_1: 0.2013  loss_ce_2: 0.0003904  loss_mask_2: 0.1241  loss_dice_2: 0.1891  loss_ce_3: 0.0002363  loss_mask_3: 0.1221  loss_dice_3: 0.1962  loss_ce_4: 0.0002007  loss_mask_4: 0.1231  loss_dice_4: 0.1891  loss_ce_5: 0.0001916  loss_mask_5: 0.1226  loss_dice_5: 0.1889  loss_ce_6: 0.0001803  loss_mask_6: 0.1196  loss_dice_6: 0.1967  loss_ce_7: 0.0003095  loss_mask_7: 0.1249  loss_dice_7: 0.1937  loss_ce_8: 0.0002938  loss_mask_8: 0.1237  loss_dice_8: 0.1975  time: 0.5677  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 18:07:33] d2.utils.events INFO:  eta: 6:15:03  iter: 8399  total_loss: 3.261  loss_ce: 0.000223  loss_mask: 0.1237  loss_dice: 0.1788  loss_ce_0: 0.1244  loss_mask_0: 0.1215  loss_dice_0: 0.1862  loss_ce_1: 0.0002313  loss_mask_1: 0.1261  loss_dice_1: 0.1826  loss_ce_2: 0.0002793  loss_mask_2: 0.1228  loss_dice_2: 0.1818  loss_ce_3: 0.0001769  loss_mask_3: 0.1247  loss_dice_3: 0.183  loss_ce_4: 0.000153  loss_mask_4: 0.1217  loss_dice_4: 0.183  loss_ce_5: 0.0001387  loss_mask_5: 0.1264  loss_dice_5: 0.1898  loss_ce_6: 0.0001056  loss_mask_6: 0.1233  loss_dice_6: 0.181  loss_ce_7: 0.0001559  loss_mask_7: 0.1206  loss_dice_7: 0.1819  loss_ce_8: 0.0002326  loss_mask_8: 0.1238  loss_dice_8: 0.1811  time: 0.5684  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:07:50] d2.utils.events INFO:  eta: 6:14:46  iter: 8419  total_loss: 3.273  loss_ce: 0.0002464  loss_mask: 0.1214  loss_dice: 0.1948  loss_ce_0: 0.1227  loss_mask_0: 0.1231  loss_dice_0: 0.1869  loss_ce_1: 0.0002248  loss_mask_1: 0.1222  loss_dice_1: 0.1881  loss_ce_2: 0.000302  loss_mask_2: 0.1214  loss_dice_2: 0.1873  loss_ce_3: 0.0002022  loss_mask_3: 0.1234  loss_dice_3: 0.1827  loss_ce_4: 0.0001683  loss_mask_4: 0.1264  loss_dice_4: 0.1891  loss_ce_5: 0.0001706  loss_mask_5: 0.1194  loss_dice_5: 0.187  loss_ce_6: 0.0001839  loss_mask_6: 0.1197  loss_dice_6: 0.1872  loss_ce_7: 0.0001887  loss_mask_7: 0.123  loss_dice_7: 0.1844  loss_ce_8: 0.0002285  loss_mask_8: 0.1205  loss_dice_8: 0.1867  time: 0.5690  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:08:07] d2.utils.events INFO:  eta: 6:14:30  iter: 8439  total_loss: 3.224  loss_ce: 0.0002603  loss_mask: 0.1274  loss_dice: 0.1857  loss_ce_0: 0.1237  loss_mask_0: 0.1241  loss_dice_0: 0.1906  loss_ce_1: 0.0002114  loss_mask_1: 0.127  loss_dice_1: 0.1911  loss_ce_2: 0.0002298  loss_mask_2: 0.1235  loss_dice_2: 0.1835  loss_ce_3: 0.0001734  loss_mask_3: 0.123  loss_dice_3: 0.1816  loss_ce_4: 0.0001356  loss_mask_4: 0.1256  loss_dice_4: 0.1847  loss_ce_5: 0.0001344  loss_mask_5: 0.1223  loss_dice_5: 0.1838  loss_ce_6: 0.0001694  loss_mask_6: 0.1252  loss_dice_6: 0.1811  loss_ce_7: 0.0002537  loss_mask_7: 0.1259  loss_dice_7: 0.1821  loss_ce_8: 0.0002177  loss_mask_8: 0.1247  loss_dice_8: 0.1882  time: 0.5697  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:08:24] d2.utils.events INFO:  eta: 6:14:04  iter: 8459  total_loss: 3.092  loss_ce: 0.000267  loss_mask: 0.1215  loss_dice: 0.1764  loss_ce_0: 0.1206  loss_mask_0: 0.1281  loss_dice_0: 0.172  loss_ce_1: 0.0002662  loss_mask_1: 0.1244  loss_dice_1: 0.174  loss_ce_2: 0.0002529  loss_mask_2: 0.1258  loss_dice_2: 0.1753  loss_ce_3: 0.0001726  loss_mask_3: 0.125  loss_dice_3: 0.1764  loss_ce_4: 0.00013  loss_mask_4: 0.119  loss_dice_4: 0.1756  loss_ce_5: 0.0001322  loss_mask_5: 0.1232  loss_dice_5: 0.1725  loss_ce_6: 0.0001189  loss_mask_6: 0.1204  loss_dice_6: 0.1739  loss_ce_7: 0.000217  loss_mask_7: 0.1237  loss_dice_7: 0.1728  loss_ce_8: 0.0002164  loss_mask_8: 0.1211  loss_dice_8: 0.1735  time: 0.5703  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:08:40] d2.utils.events INFO:  eta: 6:13:45  iter: 8479  total_loss: 3.011  loss_ce: 0.0002322  loss_mask: 0.1203  loss_dice: 0.171  loss_ce_0: 0.1229  loss_mask_0: 0.1174  loss_dice_0: 0.1662  loss_ce_1: 0.000312  loss_mask_1: 0.1181  loss_dice_1: 0.1693  loss_ce_2: 0.0002578  loss_mask_2: 0.118  loss_dice_2: 0.1703  loss_ce_3: 0.0001747  loss_mask_3: 0.1172  loss_dice_3: 0.169  loss_ce_4: 0.0001268  loss_mask_4: 0.1179  loss_dice_4: 0.168  loss_ce_5: 0.0001279  loss_mask_5: 0.1167  loss_dice_5: 0.1652  loss_ce_6: 0.0001157  loss_mask_6: 0.1191  loss_dice_6: 0.1676  loss_ce_7: 0.0001787  loss_mask_7: 0.1204  loss_dice_7: 0.1714  loss_ce_8: 0.0002345  loss_mask_8: 0.1198  loss_dice_8: 0.1708  time: 0.5710  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:08:57] d2.utils.events INFO:  eta: 6:13:29  iter: 8499  total_loss: 3.001  loss_ce: 0.0002545  loss_mask: 0.1181  loss_dice: 0.1726  loss_ce_0: 0.1167  loss_mask_0: 0.1138  loss_dice_0: 0.1687  loss_ce_1: 0.000273  loss_mask_1: 0.1145  loss_dice_1: 0.171  loss_ce_2: 0.0002788  loss_mask_2: 0.1174  loss_dice_2: 0.168  loss_ce_3: 0.0001639  loss_mask_3: 0.1196  loss_dice_3: 0.1776  loss_ce_4: 0.0001349  loss_mask_4: 0.1169  loss_dice_4: 0.1708  loss_ce_5: 0.0001513  loss_mask_5: 0.1194  loss_dice_5: 0.1732  loss_ce_6: 0.0001653  loss_mask_6: 0.1217  loss_dice_6: 0.1715  loss_ce_7: 0.0002404  loss_mask_7: 0.1155  loss_dice_7: 0.1658  loss_ce_8: 0.0002229  loss_mask_8: 0.1173  loss_dice_8: 0.167  time: 0.5716  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:09:14] d2.utils.events INFO:  eta: 6:13:11  iter: 8519  total_loss: 3.054  loss_ce: 0.00015  loss_mask: 0.1206  loss_dice: 0.1688  loss_ce_0: 0.1183  loss_mask_0: 0.1213  loss_dice_0: 0.1738  loss_ce_1: 0.0001556  loss_mask_1: 0.125  loss_dice_1: 0.1724  loss_ce_2: 0.0002632  loss_mask_2: 0.1226  loss_dice_2: 0.1649  loss_ce_3: 0.0001792  loss_mask_3: 0.124  loss_dice_3: 0.1757  loss_ce_4: 0.0001354  loss_mask_4: 0.1223  loss_dice_4: 0.1712  loss_ce_5: 0.0002077  loss_mask_5: 0.1206  loss_dice_5: 0.1689  loss_ce_6: 8.513e-05  loss_mask_6: 0.1213  loss_dice_6: 0.1711  loss_ce_7: 0.0002051  loss_mask_7: 0.1203  loss_dice_7: 0.1664  loss_ce_8: 0.0002295  loss_mask_8: 0.1224  loss_dice_8: 0.1671  time: 0.5723  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:09:31] d2.utils.events INFO:  eta: 6:12:43  iter: 8539  total_loss: 3.185  loss_ce: 0.0002196  loss_mask: 0.1216  loss_dice: 0.1803  loss_ce_0: 0.1214  loss_mask_0: 0.1222  loss_dice_0: 0.184  loss_ce_1: 0.0003376  loss_mask_1: 0.1237  loss_dice_1: 0.1774  loss_ce_2: 0.0005394  loss_mask_2: 0.1191  loss_dice_2: 0.1779  loss_ce_3: 0.0001813  loss_mask_3: 0.1209  loss_dice_3: 0.1829  loss_ce_4: 0.0001302  loss_mask_4: 0.1212  loss_dice_4: 0.1755  loss_ce_5: 0.0002466  loss_mask_5: 0.1183  loss_dice_5: 0.1823  loss_ce_6: 0.000134  loss_mask_6: 0.1157  loss_dice_6: 0.1754  loss_ce_7: 0.0003463  loss_mask_7: 0.1206  loss_dice_7: 0.1841  loss_ce_8: 0.0005094  loss_mask_8: 0.1193  loss_dice_8: 0.1793  time: 0.5729  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:09:48] d2.utils.events INFO:  eta: 6:12:33  iter: 8559  total_loss: 2.973  loss_ce: 0.000197  loss_mask: 0.1124  loss_dice: 0.1678  loss_ce_0: 0.1168  loss_mask_0: 0.1132  loss_dice_0: 0.1757  loss_ce_1: 0.0003038  loss_mask_1: 0.1187  loss_dice_1: 0.174  loss_ce_2: 0.0003935  loss_mask_2: 0.117  loss_dice_2: 0.1703  loss_ce_3: 0.0001749  loss_mask_3: 0.1193  loss_dice_3: 0.1751  loss_ce_4: 0.0001379  loss_mask_4: 0.1179  loss_dice_4: 0.1671  loss_ce_5: 0.0002064  loss_mask_5: 0.1169  loss_dice_5: 0.173  loss_ce_6: 0.0001084  loss_mask_6: 0.1139  loss_dice_6: 0.175  loss_ce_7: 0.0002955  loss_mask_7: 0.1175  loss_dice_7: 0.1751  loss_ce_8: 0.0003662  loss_mask_8: 0.1146  loss_dice_8: 0.1746  time: 0.5735  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:10:05] d2.utils.events INFO:  eta: 6:12:20  iter: 8579  total_loss: 2.994  loss_ce: 0.0001682  loss_mask: 0.1148  loss_dice: 0.172  loss_ce_0: 0.1192  loss_mask_0: 0.1148  loss_dice_0: 0.1721  loss_ce_1: 0.0002037  loss_mask_1: 0.112  loss_dice_1: 0.1746  loss_ce_2: 0.0002847  loss_mask_2: 0.1169  loss_dice_2: 0.1725  loss_ce_3: 0.0001333  loss_mask_3: 0.1169  loss_dice_3: 0.18  loss_ce_4: 0.0001164  loss_mask_4: 0.1168  loss_dice_4: 0.177  loss_ce_5: 0.0001481  loss_mask_5: 0.1168  loss_dice_5: 0.1742  loss_ce_6: 9.097e-05  loss_mask_6: 0.1138  loss_dice_6: 0.1722  loss_ce_7: 0.0002573  loss_mask_7: 0.1122  loss_dice_7: 0.1738  loss_ce_8: 0.000295  loss_mask_8: 0.1174  loss_dice_8: 0.1782  time: 0.5742  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:10:22] d2.utils.events INFO:  eta: 6:12:06  iter: 8599  total_loss: 3.018  loss_ce: 0.0001426  loss_mask: 0.1193  loss_dice: 0.169  loss_ce_0: 0.1198  loss_mask_0: 0.1214  loss_dice_0: 0.1741  loss_ce_1: 0.0001688  loss_mask_1: 0.1177  loss_dice_1: 0.1734  loss_ce_2: 0.0002071  loss_mask_2: 0.1157  loss_dice_2: 0.1666  loss_ce_3: 0.0001171  loss_mask_3: 0.1153  loss_dice_3: 0.1691  loss_ce_4: 8.724e-05  loss_mask_4: 0.1181  loss_dice_4: 0.178  loss_ce_5: 0.0001184  loss_mask_5: 0.1155  loss_dice_5: 0.1711  loss_ce_6: 2.839e-05  loss_mask_6: 0.1091  loss_dice_6: 0.1625  loss_ce_7: 0.0001736  loss_mask_7: 0.1156  loss_dice_7: 0.1632  loss_ce_8: 0.0001917  loss_mask_8: 0.1145  loss_dice_8: 0.174  time: 0.5748  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:10:39] d2.utils.events INFO:  eta: 6:11:53  iter: 8619  total_loss: 3.003  loss_ce: 0.0001569  loss_mask: 0.1154  loss_dice: 0.1738  loss_ce_0: 0.1335  loss_mask_0: 0.117  loss_dice_0: 0.1707  loss_ce_1: 0.0001558  loss_mask_1: 0.1171  loss_dice_1: 0.1712  loss_ce_2: 0.0002343  loss_mask_2: 0.113  loss_dice_2: 0.1661  loss_ce_3: 0.0001504  loss_mask_3: 0.1148  loss_dice_3: 0.1733  loss_ce_4: 0.000129  loss_mask_4: 0.1165  loss_dice_4: 0.1692  loss_ce_5: 0.0001582  loss_mask_5: 0.1153  loss_dice_5: 0.1668  loss_ce_6: 0.0001103  loss_mask_6: 0.1164  loss_dice_6: 0.1663  loss_ce_7: 0.000187  loss_mask_7: 0.1151  loss_dice_7: 0.1656  loss_ce_8: 0.000244  loss_mask_8: 0.1174  loss_dice_8: 0.1717  time: 0.5754  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:10:56] d2.utils.events INFO:  eta: 6:11:32  iter: 8639  total_loss: 3.056  loss_ce: 0.0001568  loss_mask: 0.1211  loss_dice: 0.1752  loss_ce_0: 0.122  loss_mask_0: 0.1241  loss_dice_0: 0.1778  loss_ce_1: 0.0001932  loss_mask_1: 0.1218  loss_dice_1: 0.1729  loss_ce_2: 0.000189  loss_mask_2: 0.1213  loss_dice_2: 0.1734  loss_ce_3: 9.304e-05  loss_mask_3: 0.1236  loss_dice_3: 0.1721  loss_ce_4: 0.0001059  loss_mask_4: 0.1222  loss_dice_4: 0.1725  loss_ce_5: 0.0001058  loss_mask_5: 0.122  loss_dice_5: 0.1715  loss_ce_6: 9.518e-05  loss_mask_6: 0.1174  loss_dice_6: 0.1697  loss_ce_7: 0.0001747  loss_mask_7: 0.12  loss_dice_7: 0.1723  loss_ce_8: 0.0001888  loss_mask_8: 0.1211  loss_dice_8: 0.1682  time: 0.5760  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:11:13] d2.utils.events INFO:  eta: 6:11:13  iter: 8659  total_loss: 3.069  loss_ce: 0.000121  loss_mask: 0.1174  loss_dice: 0.1705  loss_ce_0: 0.1247  loss_mask_0: 0.1142  loss_dice_0: 0.1816  loss_ce_1: 0.0001335  loss_mask_1: 0.1158  loss_dice_1: 0.1767  loss_ce_2: 0.0001687  loss_mask_2: 0.1171  loss_dice_2: 0.1708  loss_ce_3: 0.0001133  loss_mask_3: 0.117  loss_dice_3: 0.1829  loss_ce_4: 0.0001177  loss_mask_4: 0.1193  loss_dice_4: 0.1801  loss_ce_5: 0.0001278  loss_mask_5: 0.1222  loss_dice_5: 0.1746  loss_ce_6: 0.0001092  loss_mask_6: 0.1202  loss_dice_6: 0.1803  loss_ce_7: 0.0001356  loss_mask_7: 0.1194  loss_dice_7: 0.1746  loss_ce_8: 0.0001535  loss_mask_8: 0.1191  loss_dice_8: 0.1776  time: 0.5767  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:11:29] d2.utils.events INFO:  eta: 6:10:55  iter: 8679  total_loss: 3.035  loss_ce: 0.0001015  loss_mask: 0.1189  loss_dice: 0.169  loss_ce_0: 0.1252  loss_mask_0: 0.1209  loss_dice_0: 0.182  loss_ce_1: 0.0001151  loss_mask_1: 0.1197  loss_dice_1: 0.1765  loss_ce_2: 0.0001475  loss_mask_2: 0.117  loss_dice_2: 0.1743  loss_ce_3: 8.894e-05  loss_mask_3: 0.1174  loss_dice_3: 0.1762  loss_ce_4: 8.629e-05  loss_mask_4: 0.1167  loss_dice_4: 0.174  loss_ce_5: 9.092e-05  loss_mask_5: 0.1168  loss_dice_5: 0.1763  loss_ce_6: 6.42e-05  loss_mask_6: 0.1187  loss_dice_6: 0.1743  loss_ce_7: 0.0001342  loss_mask_7: 0.1178  loss_dice_7: 0.1743  loss_ce_8: 0.000134  loss_mask_8: 0.115  loss_dice_8: 0.1742  time: 0.5773  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:11:46] d2.utils.events INFO:  eta: 6:10:39  iter: 8699  total_loss: 3.173  loss_ce: 9.585e-05  loss_mask: 0.1212  loss_dice: 0.1843  loss_ce_0: 0.1229  loss_mask_0: 0.1185  loss_dice_0: 0.1823  loss_ce_1: 0.0001319  loss_mask_1: 0.1228  loss_dice_1: 0.1865  loss_ce_2: 0.000146  loss_mask_2: 0.122  loss_dice_2: 0.1879  loss_ce_3: 0.0001204  loss_mask_3: 0.118  loss_dice_3: 0.1842  loss_ce_4: 0.0001082  loss_mask_4: 0.1217  loss_dice_4: 0.1786  loss_ce_5: 0.000114  loss_mask_5: 0.1183  loss_dice_5: 0.1783  loss_ce_6: 0.0001005  loss_mask_6: 0.1155  loss_dice_6: 0.1762  loss_ce_7: 0.0001262  loss_mask_7: 0.1172  loss_dice_7: 0.1805  loss_ce_8: 0.0001397  loss_mask_8: 0.1191  loss_dice_8: 0.1835  time: 0.5779  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:12:03] d2.utils.events INFO:  eta: 6:10:22  iter: 8719  total_loss: 3.375  loss_ce: 9.05e-05  loss_mask: 0.1335  loss_dice: 0.1938  loss_ce_0: 0.1226  loss_mask_0: 0.1275  loss_dice_0: 0.1904  loss_ce_1: 0.0001275  loss_mask_1: 0.1278  loss_dice_1: 0.1881  loss_ce_2: 0.0001279  loss_mask_2: 0.1281  loss_dice_2: 0.1882  loss_ce_3: 8.218e-05  loss_mask_3: 0.1289  loss_dice_3: 0.1921  loss_ce_4: 0.0001088  loss_mask_4: 0.1299  loss_dice_4: 0.1851  loss_ce_5: 8.747e-05  loss_mask_5: 0.1309  loss_dice_5: 0.192  loss_ce_6: 9.548e-05  loss_mask_6: 0.1319  loss_dice_6: 0.1871  loss_ce_7: 0.0001125  loss_mask_7: 0.1297  loss_dice_7: 0.1889  loss_ce_8: 0.0001593  loss_mask_8: 0.129  loss_dice_8: 0.1862  time: 0.5785  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:12:20] d2.utils.events INFO:  eta: 6:10:05  iter: 8739  total_loss: 3.081  loss_ce: 8.961e-05  loss_mask: 0.1141  loss_dice: 0.1764  loss_ce_0: 0.122  loss_mask_0: 0.1198  loss_dice_0: 0.1818  loss_ce_1: 0.0001228  loss_mask_1: 0.1153  loss_dice_1: 0.1798  loss_ce_2: 0.0001296  loss_mask_2: 0.115  loss_dice_2: 0.1759  loss_ce_3: 9.206e-05  loss_mask_3: 0.1133  loss_dice_3: 0.1736  loss_ce_4: 9.237e-05  loss_mask_4: 0.116  loss_dice_4: 0.1736  loss_ce_5: 8.772e-05  loss_mask_5: 0.1142  loss_dice_5: 0.1821  loss_ce_6: 8.632e-05  loss_mask_6: 0.1155  loss_dice_6: 0.1769  loss_ce_7: 0.0001188  loss_mask_7: 0.1184  loss_dice_7: 0.1845  loss_ce_8: 0.0001269  loss_mask_8: 0.118  loss_dice_8: 0.1801  time: 0.5791  data_time: 0.0018  lr: 0.0001  max_mem: 8444M
[08/01 18:12:37] d2.utils.events INFO:  eta: 6:09:48  iter: 8759  total_loss: 3.164  loss_ce: 0.0001  loss_mask: 0.1277  loss_dice: 0.1835  loss_ce_0: 0.1232  loss_mask_0: 0.1249  loss_dice_0: 0.1797  loss_ce_1: 0.0001442  loss_mask_1: 0.1259  loss_dice_1: 0.1863  loss_ce_2: 0.0001275  loss_mask_2: 0.1264  loss_dice_2: 0.1836  loss_ce_3: 8.438e-05  loss_mask_3: 0.1259  loss_dice_3: 0.1832  loss_ce_4: 9.801e-05  loss_mask_4: 0.1271  loss_dice_4: 0.1835  loss_ce_5: 8.33e-05  loss_mask_5: 0.1238  loss_dice_5: 0.1849  loss_ce_6: 8.801e-05  loss_mask_6: 0.1268  loss_dice_6: 0.1782  loss_ce_7: 0.0001211  loss_mask_7: 0.1252  loss_dice_7: 0.1804  loss_ce_8: 0.0001367  loss_mask_8: 0.1318  loss_dice_8: 0.1853  time: 0.5797  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 18:12:54] d2.utils.events INFO:  eta: 6:09:29  iter: 8779  total_loss: 3.302  loss_ce: 0.000115  loss_mask: 0.1211  loss_dice: 0.1764  loss_ce_0: 0.1216  loss_mask_0: 0.1248  loss_dice_0: 0.1867  loss_ce_1: 0.0001299  loss_mask_1: 0.1221  loss_dice_1: 0.1822  loss_ce_2: 0.0001195  loss_mask_2: 0.1192  loss_dice_2: 0.1806  loss_ce_3: 9.112e-05  loss_mask_3: 0.1235  loss_dice_3: 0.1773  loss_ce_4: 0.0001077  loss_mask_4: 0.1231  loss_dice_4: 0.1864  loss_ce_5: 9.71e-05  loss_mask_5: 0.1257  loss_dice_5: 0.1782  loss_ce_6: 9.513e-05  loss_mask_6: 0.1225  loss_dice_6: 0.1796  loss_ce_7: 0.0001151  loss_mask_7: 0.1198  loss_dice_7: 0.1835  loss_ce_8: 0.0001388  loss_mask_8: 0.1249  loss_dice_8: 0.1802  time: 0.5803  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:13:11] d2.utils.events INFO:  eta: 6:09:12  iter: 8799  total_loss: 3.093  loss_ce: 0.0001241  loss_mask: 0.1197  loss_dice: 0.1683  loss_ce_0: 0.1224  loss_mask_0: 0.1175  loss_dice_0: 0.1729  loss_ce_1: 0.0001647  loss_mask_1: 0.1199  loss_dice_1: 0.1684  loss_ce_2: 0.0001431  loss_mask_2: 0.123  loss_dice_2: 0.1718  loss_ce_3: 9.934e-05  loss_mask_3: 0.1182  loss_dice_3: 0.1714  loss_ce_4: 0.0001076  loss_mask_4: 0.1235  loss_dice_4: 0.1709  loss_ce_5: 0.0001131  loss_mask_5: 0.1241  loss_dice_5: 0.1718  loss_ce_6: 0.0001257  loss_mask_6: 0.1212  loss_dice_6: 0.1725  loss_ce_7: 0.0001253  loss_mask_7: 0.1221  loss_dice_7: 0.1729  loss_ce_8: 0.0001544  loss_mask_8: 0.1222  loss_dice_8: 0.165  time: 0.5810  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:13:28] d2.utils.events INFO:  eta: 6:08:49  iter: 8819  total_loss: 3.079  loss_ce: 0.0001645  loss_mask: 0.1192  loss_dice: 0.1734  loss_ce_0: 0.1263  loss_mask_0: 0.1211  loss_dice_0: 0.1761  loss_ce_1: 0.0001875  loss_mask_1: 0.125  loss_dice_1: 0.1737  loss_ce_2: 0.0002506  loss_mask_2: 0.1188  loss_dice_2: 0.1777  loss_ce_3: 0.0001213  loss_mask_3: 0.1195  loss_dice_3: 0.1781  loss_ce_4: 0.000138  loss_mask_4: 0.1191  loss_dice_4: 0.176  loss_ce_5: 0.000183  loss_mask_5: 0.1174  loss_dice_5: 0.1739  loss_ce_6: 0.0001324  loss_mask_6: 0.121  loss_dice_6: 0.1809  loss_ce_7: 0.0002329  loss_mask_7: 0.119  loss_dice_7: 0.1775  loss_ce_8: 0.0002541  loss_mask_8: 0.1236  loss_dice_8: 0.1739  time: 0.5815  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:13:45] d2.utils.events INFO:  eta: 6:08:40  iter: 8839  total_loss: 3.31  loss_ce: 3.068e-05  loss_mask: 0.1223  loss_dice: 0.1952  loss_ce_0: 0.1241  loss_mask_0: 0.1207  loss_dice_0: 0.1944  loss_ce_1: 0.0001944  loss_mask_1: 0.1165  loss_dice_1: 0.189  loss_ce_2: 3.599e-05  loss_mask_2: 0.1199  loss_dice_2: 0.1876  loss_ce_3: 3.813e-05  loss_mask_3: 0.1265  loss_dice_3: 0.1988  loss_ce_4: 8.479e-05  loss_mask_4: 0.1226  loss_dice_4: 0.1871  loss_ce_5: 2.508e-05  loss_mask_5: 0.1204  loss_dice_5: 0.1922  loss_ce_6: 4.076e-05  loss_mask_6: 0.1175  loss_dice_6: 0.1955  loss_ce_7: 4.018e-05  loss_mask_7: 0.1198  loss_dice_7: 0.1947  loss_ce_8: 4.312e-05  loss_mask_8: 0.1215  loss_dice_8: 0.1991  time: 0.5821  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:14:02] d2.utils.events INFO:  eta: 6:08:25  iter: 8859  total_loss: 3.193  loss_ce: 0.0001967  loss_mask: 0.1255  loss_dice: 0.1821  loss_ce_0: 0.1201  loss_mask_0: 0.1199  loss_dice_0: 0.1794  loss_ce_1: 0.0003107  loss_mask_1: 0.123  loss_dice_1: 0.1828  loss_ce_2: 0.0002706  loss_mask_2: 0.1252  loss_dice_2: 0.1853  loss_ce_3: 0.0001306  loss_mask_3: 0.1215  loss_dice_3: 0.1816  loss_ce_4: 0.0001667  loss_mask_4: 0.1248  loss_dice_4: 0.1814  loss_ce_5: 0.0001618  loss_mask_5: 0.124  loss_dice_5: 0.1855  loss_ce_6: 0.0001494  loss_mask_6: 0.1249  loss_dice_6: 0.1815  loss_ce_7: 0.0002623  loss_mask_7: 0.1237  loss_dice_7: 0.1796  loss_ce_8: 0.0003118  loss_mask_8: 0.1214  loss_dice_8: 0.1796  time: 0.5827  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:14:19] d2.utils.events INFO:  eta: 6:08:06  iter: 8879  total_loss: 3.417  loss_ce: 0.0001573  loss_mask: 0.1179  loss_dice: 0.1995  loss_ce_0: 0.1199  loss_mask_0: 0.1225  loss_dice_0: 0.2061  loss_ce_1: 0.0001839  loss_mask_1: 0.1235  loss_dice_1: 0.2073  loss_ce_2: 0.0002356  loss_mask_2: 0.1185  loss_dice_2: 0.2026  loss_ce_3: 0.0001139  loss_mask_3: 0.1228  loss_dice_3: 0.2056  loss_ce_4: 0.0001394  loss_mask_4: 0.1202  loss_dice_4: 0.2005  loss_ce_5: 0.0001633  loss_mask_5: 0.1209  loss_dice_5: 0.2003  loss_ce_6: 0.0001149  loss_mask_6: 0.121  loss_dice_6: 0.2065  loss_ce_7: 0.0001959  loss_mask_7: 0.1173  loss_dice_7: 0.1946  loss_ce_8: 0.0002159  loss_mask_8: 0.1213  loss_dice_8: 0.2055  time: 0.5833  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:14:36] d2.utils.events INFO:  eta: 6:07:44  iter: 8899  total_loss: 3.122  loss_ce: 0.0001571  loss_mask: 0.1151  loss_dice: 0.168  loss_ce_0: 0.1247  loss_mask_0: 0.1214  loss_dice_0: 0.1855  loss_ce_1: 0.0001786  loss_mask_1: 0.1208  loss_dice_1: 0.1806  loss_ce_2: 0.0002004  loss_mask_2: 0.1169  loss_dice_2: 0.176  loss_ce_3: 0.0001246  loss_mask_3: 0.1241  loss_dice_3: 0.1852  loss_ce_4: 0.0001401  loss_mask_4: 0.1158  loss_dice_4: 0.1722  loss_ce_5: 0.0001738  loss_mask_5: 0.1224  loss_dice_5: 0.1706  loss_ce_6: 0.0001415  loss_mask_6: 0.1175  loss_dice_6: 0.1749  loss_ce_7: 0.000205  loss_mask_7: 0.1182  loss_dice_7: 0.1806  loss_ce_8: 0.0002093  loss_mask_8: 0.1215  loss_dice_8: 0.1813  time: 0.5839  data_time: 0.0017  lr: 0.0001  max_mem: 8444M
[08/01 18:14:53] d2.utils.events INFO:  eta: 6:07:35  iter: 8919  total_loss: 3.292  loss_ce: 0.0001025  loss_mask: 0.1188  loss_dice: 0.192  loss_ce_0: 0.1246  loss_mask_0: 0.1216  loss_dice_0: 0.1987  loss_ce_1: 0.0001347  loss_mask_1: 0.1214  loss_dice_1: 0.1828  loss_ce_2: 0.0001401  loss_mask_2: 0.1201  loss_dice_2: 0.1916  loss_ce_3: 9.606e-05  loss_mask_3: 0.1227  loss_dice_3: 0.1953  loss_ce_4: 0.0001241  loss_mask_4: 0.1217  loss_dice_4: 0.1903  loss_ce_5: 9.025e-05  loss_mask_5: 0.1183  loss_dice_5: 0.1882  loss_ce_6: 9.161e-05  loss_mask_6: 0.1208  loss_dice_6: 0.1963  loss_ce_7: 0.0001341  loss_mask_7: 0.1218  loss_dice_7: 0.1912  loss_ce_8: 0.0001328  loss_mask_8: 0.1251  loss_dice_8: 0.1917  time: 0.5845  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:15:10] d2.utils.events INFO:  eta: 6:07:13  iter: 8939  total_loss: 3.121  loss_ce: 0.0001058  loss_mask: 0.1167  loss_dice: 0.1755  loss_ce_0: 0.1253  loss_mask_0: 0.1204  loss_dice_0: 0.1754  loss_ce_1: 0.0001438  loss_mask_1: 0.1221  loss_dice_1: 0.173  loss_ce_2: 0.000154  loss_mask_2: 0.1183  loss_dice_2: 0.175  loss_ce_3: 9.042e-05  loss_mask_3: 0.116  loss_dice_3: 0.1766  loss_ce_4: 0.000106  loss_mask_4: 0.1201  loss_dice_4: 0.1807  loss_ce_5: 8.966e-05  loss_mask_5: 0.1204  loss_dice_5: 0.1758  loss_ce_6: 8.805e-05  loss_mask_6: 0.1234  loss_dice_6: 0.1745  loss_ce_7: 0.0001327  loss_mask_7: 0.1151  loss_dice_7: 0.1811  loss_ce_8: 0.0001339  loss_mask_8: 0.1135  loss_dice_8: 0.1725  time: 0.5851  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:15:26] d2.utils.events INFO:  eta: 6:06:50  iter: 8959  total_loss: 3.248  loss_ce: 9.487e-05  loss_mask: 0.1209  loss_dice: 0.1875  loss_ce_0: 0.1217  loss_mask_0: 0.1216  loss_dice_0: 0.1912  loss_ce_1: 0.0001069  loss_mask_1: 0.1241  loss_dice_1: 0.1896  loss_ce_2: 0.0001489  loss_mask_2: 0.1224  loss_dice_2: 0.1916  loss_ce_3: 7.721e-05  loss_mask_3: 0.1196  loss_dice_3: 0.189  loss_ce_4: 0.0001101  loss_mask_4: 0.1232  loss_dice_4: 0.1888  loss_ce_5: 9.373e-05  loss_mask_5: 0.1252  loss_dice_5: 0.195  loss_ce_6: 9.667e-05  loss_mask_6: 0.1214  loss_dice_6: 0.1914  loss_ce_7: 0.0001303  loss_mask_7: 0.123  loss_dice_7: 0.1911  loss_ce_8: 0.0001383  loss_mask_8: 0.1257  loss_dice_8: 0.1927  time: 0.5857  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:15:43] d2.utils.events INFO:  eta: 6:06:34  iter: 8979  total_loss: 3.204  loss_ce: 8.635e-05  loss_mask: 0.1207  loss_dice: 0.1828  loss_ce_0: 0.1223  loss_mask_0: 0.1202  loss_dice_0: 0.1908  loss_ce_1: 0.0001299  loss_mask_1: 0.1206  loss_dice_1: 0.1881  loss_ce_2: 0.0001309  loss_mask_2: 0.1226  loss_dice_2: 0.1855  loss_ce_3: 8.033e-05  loss_mask_3: 0.123  loss_dice_3: 0.1906  loss_ce_4: 7.441e-05  loss_mask_4: 0.1233  loss_dice_4: 0.1862  loss_ce_5: 7.342e-05  loss_mask_5: 0.1215  loss_dice_5: 0.1786  loss_ce_6: 5.603e-05  loss_mask_6: 0.1207  loss_dice_6: 0.1865  loss_ce_7: 0.0001165  loss_mask_7: 0.1235  loss_dice_7: 0.1838  loss_ce_8: 0.0001122  loss_mask_8: 0.1241  loss_dice_8: 0.1844  time: 0.5862  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:16:00] d2.utils.events INFO:  eta: 6:06:17  iter: 8999  total_loss: 3.04  loss_ce: 8.81e-05  loss_mask: 0.1145  loss_dice: 0.1821  loss_ce_0: 0.1255  loss_mask_0: 0.1164  loss_dice_0: 0.1878  loss_ce_1: 0.0001204  loss_mask_1: 0.1137  loss_dice_1: 0.1807  loss_ce_2: 0.0001338  loss_mask_2: 0.1123  loss_dice_2: 0.1819  loss_ce_3: 9.719e-05  loss_mask_3: 0.1158  loss_dice_3: 0.1783  loss_ce_4: 9.752e-05  loss_mask_4: 0.116  loss_dice_4: 0.1806  loss_ce_5: 0.0001017  loss_mask_5: 0.1112  loss_dice_5: 0.177  loss_ce_6: 8.675e-05  loss_mask_6: 0.1153  loss_dice_6: 0.1821  loss_ce_7: 0.0001227  loss_mask_7: 0.1166  loss_dice_7: 0.1814  loss_ce_8: 0.0001291  loss_mask_8: 0.1148  loss_dice_8: 0.1758  time: 0.5868  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:16:17] d2.utils.events INFO:  eta: 6:06:01  iter: 9019  total_loss: 3.162  loss_ce: 7.856e-05  loss_mask: 0.1219  loss_dice: 0.1818  loss_ce_0: 0.125  loss_mask_0: 0.1227  loss_dice_0: 0.181  loss_ce_1: 0.000108  loss_mask_1: 0.1226  loss_dice_1: 0.1797  loss_ce_2: 0.0001072  loss_mask_2: 0.1204  loss_dice_2: 0.1759  loss_ce_3: 6.529e-05  loss_mask_3: 0.1236  loss_dice_3: 0.1838  loss_ce_4: 8.54e-05  loss_mask_4: 0.1245  loss_dice_4: 0.1748  loss_ce_5: 7.861e-05  loss_mask_5: 0.1269  loss_dice_5: 0.1772  loss_ce_6: 7.641e-05  loss_mask_6: 0.1261  loss_dice_6: 0.1782  loss_ce_7: 9.982e-05  loss_mask_7: 0.1188  loss_dice_7: 0.1749  loss_ce_8: 0.0001157  loss_mask_8: 0.1254  loss_dice_8: 0.1812  time: 0.5874  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:16:34] d2.utils.events INFO:  eta: 6:05:42  iter: 9039  total_loss: 3.068  loss_ce: 6.655e-05  loss_mask: 0.1191  loss_dice: 0.1742  loss_ce_0: 0.1284  loss_mask_0: 0.1156  loss_dice_0: 0.1725  loss_ce_1: 6.769e-05  loss_mask_1: 0.1171  loss_dice_1: 0.1699  loss_ce_2: 9.169e-05  loss_mask_2: 0.1185  loss_dice_2: 0.1726  loss_ce_3: 5.154e-05  loss_mask_3: 0.1166  loss_dice_3: 0.1724  loss_ce_4: 8.138e-05  loss_mask_4: 0.1212  loss_dice_4: 0.1753  loss_ce_5: 7.568e-05  loss_mask_5: 0.1166  loss_dice_5: 0.1745  loss_ce_6: 7.582e-05  loss_mask_6: 0.1179  loss_dice_6: 0.1705  loss_ce_7: 7.979e-05  loss_mask_7: 0.1225  loss_dice_7: 0.1769  loss_ce_8: 9.395e-05  loss_mask_8: 0.1195  loss_dice_8: 0.1693  time: 0.5880  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:16:51] d2.utils.events INFO:  eta: 6:05:27  iter: 9059  total_loss: 2.982  loss_ce: 6.443e-05  loss_mask: 0.1169  loss_dice: 0.1664  loss_ce_0: 0.1265  loss_mask_0: 0.1182  loss_dice_0: 0.1698  loss_ce_1: 8.608e-05  loss_mask_1: 0.1172  loss_dice_1: 0.1688  loss_ce_2: 8.8e-05  loss_mask_2: 0.1124  loss_dice_2: 0.1673  loss_ce_3: 5.509e-05  loss_mask_3: 0.1143  loss_dice_3: 0.1661  loss_ce_4: 4.628e-05  loss_mask_4: 0.1176  loss_dice_4: 0.1655  loss_ce_5: 4.788e-05  loss_mask_5: 0.1218  loss_dice_5: 0.1706  loss_ce_6: 3.312e-05  loss_mask_6: 0.1155  loss_dice_6: 0.1654  loss_ce_7: 7.887e-05  loss_mask_7: 0.1186  loss_dice_7: 0.1679  loss_ce_8: 8.396e-05  loss_mask_8: 0.1199  loss_dice_8: 0.1688  time: 0.5885  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:17:08] d2.utils.events INFO:  eta: 6:05:15  iter: 9079  total_loss: 2.83  loss_ce: 9.94e-05  loss_mask: 0.1088  loss_dice: 0.1617  loss_ce_0: 0.1223  loss_mask_0: 0.1099  loss_dice_0: 0.1668  loss_ce_1: 8.343e-05  loss_mask_1: 0.1107  loss_dice_1: 0.1611  loss_ce_2: 0.0001174  loss_mask_2: 0.1115  loss_dice_2: 0.1608  loss_ce_3: 9.714e-05  loss_mask_3: 0.1075  loss_dice_3: 0.1566  loss_ce_4: 9.528e-05  loss_mask_4: 0.1117  loss_dice_4: 0.166  loss_ce_5: 0.000107  loss_mask_5: 0.1118  loss_dice_5: 0.1598  loss_ce_6: 9.316e-05  loss_mask_6: 0.1127  loss_dice_6: 0.1608  loss_ce_7: 0.0001191  loss_mask_7: 0.1091  loss_dice_7: 0.1637  loss_ce_8: 0.0001184  loss_mask_8: 0.1117  loss_dice_8: 0.1606  time: 0.5891  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:17:25] d2.utils.events INFO:  eta: 6:05:02  iter: 9099  total_loss: 3.038  loss_ce: 0.0001114  loss_mask: 0.1212  loss_dice: 0.1753  loss_ce_0: 0.1308  loss_mask_0: 0.119  loss_dice_0: 0.1776  loss_ce_1: 0.0001197  loss_mask_1: 0.1185  loss_dice_1: 0.175  loss_ce_2: 0.0001207  loss_mask_2: 0.1207  loss_dice_2: 0.1754  loss_ce_3: 0.0001148  loss_mask_3: 0.1166  loss_dice_3: 0.1716  loss_ce_4: 0.0001283  loss_mask_4: 0.1201  loss_dice_4: 0.1727  loss_ce_5: 0.0001081  loss_mask_5: 0.1212  loss_dice_5: 0.1716  loss_ce_6: 0.0001001  loss_mask_6: 0.1202  loss_dice_6: 0.1696  loss_ce_7: 0.000143  loss_mask_7: 0.1162  loss_dice_7: 0.1723  loss_ce_8: 0.0001306  loss_mask_8: 0.1179  loss_dice_8: 0.1694  time: 0.5897  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:17:42] d2.utils.events INFO:  eta: 6:04:59  iter: 9119  total_loss: 3.463  loss_ce: 0.0003832  loss_mask: 0.1246  loss_dice: 0.1938  loss_ce_0: 0.1318  loss_mask_0: 0.1243  loss_dice_0: 0.1809  loss_ce_1: 0.0001173  loss_mask_1: 0.1215  loss_dice_1: 0.1852  loss_ce_2: 0.000147  loss_mask_2: 0.1215  loss_dice_2: 0.1903  loss_ce_3: 0.00025  loss_mask_3: 0.1218  loss_dice_3: 0.1808  loss_ce_4: 0.0001845  loss_mask_4: 0.124  loss_dice_4: 0.1831  loss_ce_5: 0.0002144  loss_mask_5: 0.1269  loss_dice_5: 0.1841  loss_ce_6: 0.0003508  loss_mask_6: 0.1239  loss_dice_6: 0.1784  loss_ce_7: 0.0004434  loss_mask_7: 0.1262  loss_dice_7: 0.1923  loss_ce_8: 0.0002241  loss_mask_8: 0.1239  loss_dice_8: 0.1791  time: 0.5902  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:17:59] d2.utils.events INFO:  eta: 6:04:45  iter: 9139  total_loss: 2.969  loss_ce: 0.0001908  loss_mask: 0.1143  loss_dice: 0.1643  loss_ce_0: 0.1262  loss_mask_0: 0.112  loss_dice_0: 0.1737  loss_ce_1: 0.0001288  loss_mask_1: 0.11  loss_dice_1: 0.1632  loss_ce_2: 0.0001737  loss_mask_2: 0.1178  loss_dice_2: 0.1694  loss_ce_3: 0.000174  loss_mask_3: 0.1142  loss_dice_3: 0.1706  loss_ce_4: 0.0001607  loss_mask_4: 0.1139  loss_dice_4: 0.1665  loss_ce_5: 0.0002149  loss_mask_5: 0.1154  loss_dice_5: 0.1697  loss_ce_6: 0.0001685  loss_mask_6: 0.1146  loss_dice_6: 0.1691  loss_ce_7: 0.0001808  loss_mask_7: 0.1113  loss_dice_7: 0.1646  loss_ce_8: 0.0001862  loss_mask_8: 0.1152  loss_dice_8: 0.1715  time: 0.5908  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:18:16] d2.utils.events INFO:  eta: 6:04:22  iter: 9159  total_loss: 3.133  loss_ce: 8.976e-05  loss_mask: 0.1183  loss_dice: 0.1838  loss_ce_0: 0.1228  loss_mask_0: 0.1193  loss_dice_0: 0.1898  loss_ce_1: 9.076e-05  loss_mask_1: 0.1141  loss_dice_1: 0.181  loss_ce_2: 9.429e-05  loss_mask_2: 0.1131  loss_dice_2: 0.1741  loss_ce_3: 9.08e-05  loss_mask_3: 0.1176  loss_dice_3: 0.1856  loss_ce_4: 8.224e-05  loss_mask_4: 0.1175  loss_dice_4: 0.1759  loss_ce_5: 9.875e-05  loss_mask_5: 0.1146  loss_dice_5: 0.1762  loss_ce_6: 7.554e-05  loss_mask_6: 0.1188  loss_dice_6: 0.1822  loss_ce_7: 9.804e-05  loss_mask_7: 0.1207  loss_dice_7: 0.1738  loss_ce_8: 0.0001067  loss_mask_8: 0.1149  loss_dice_8: 0.1761  time: 0.5914  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:18:33] d2.utils.events INFO:  eta: 6:03:54  iter: 9179  total_loss: 3.207  loss_ce: 0.0001299  loss_mask: 0.1204  loss_dice: 0.1866  loss_ce_0: 0.1258  loss_mask_0: 0.1253  loss_dice_0: 0.1852  loss_ce_1: 9.584e-05  loss_mask_1: 0.1244  loss_dice_1: 0.1861  loss_ce_2: 0.0001478  loss_mask_2: 0.125  loss_dice_2: 0.1806  loss_ce_3: 8.009e-05  loss_mask_3: 0.1255  loss_dice_3: 0.1891  loss_ce_4: 0.0001471  loss_mask_4: 0.1231  loss_dice_4: 0.1846  loss_ce_5: 0.0001697  loss_mask_5: 0.1187  loss_dice_5: 0.1792  loss_ce_6: 0.0001221  loss_mask_6: 0.1259  loss_dice_6: 0.1862  loss_ce_7: 0.0001354  loss_mask_7: 0.1245  loss_dice_7: 0.1951  loss_ce_8: 0.0001484  loss_mask_8: 0.123  loss_dice_8: 0.1832  time: 0.5919  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:18:50] d2.utils.events INFO:  eta: 6:03:43  iter: 9199  total_loss: 3.243  loss_ce: 8.501e-05  loss_mask: 0.121  loss_dice: 0.1823  loss_ce_0: 0.1237  loss_mask_0: 0.1211  loss_dice_0: 0.1846  loss_ce_1: 9.383e-05  loss_mask_1: 0.1189  loss_dice_1: 0.1843  loss_ce_2: 9.829e-05  loss_mask_2: 0.1244  loss_dice_2: 0.1889  loss_ce_3: 7.775e-05  loss_mask_3: 0.1224  loss_dice_3: 0.184  loss_ce_4: 0.0001038  loss_mask_4: 0.1263  loss_dice_4: 0.1886  loss_ce_5: 0.0001217  loss_mask_5: 0.1218  loss_dice_5: 0.1867  loss_ce_6: 9.715e-05  loss_mask_6: 0.1243  loss_dice_6: 0.1916  loss_ce_7: 0.0001043  loss_mask_7: 0.1215  loss_dice_7: 0.1865  loss_ce_8: 0.0001045  loss_mask_8: 0.1256  loss_dice_8: 0.1876  time: 0.5925  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:19:07] d2.utils.events INFO:  eta: 6:03:20  iter: 9219  total_loss: 3.289  loss_ce: 8.774e-05  loss_mask: 0.1285  loss_dice: 0.184  loss_ce_0: 0.1242  loss_mask_0: 0.1326  loss_dice_0: 0.1958  loss_ce_1: 0.0001279  loss_mask_1: 0.1281  loss_dice_1: 0.1841  loss_ce_2: 9.228e-05  loss_mask_2: 0.1276  loss_dice_2: 0.184  loss_ce_3: 6.565e-05  loss_mask_3: 0.1327  loss_dice_3: 0.1871  loss_ce_4: 0.0001055  loss_mask_4: 0.1278  loss_dice_4: 0.1844  loss_ce_5: 0.000115  loss_mask_5: 0.1282  loss_dice_5: 0.1828  loss_ce_6: 9.564e-05  loss_mask_6: 0.1255  loss_dice_6: 0.1872  loss_ce_7: 9.957e-05  loss_mask_7: 0.13  loss_dice_7: 0.1838  loss_ce_8: 9.567e-05  loss_mask_8: 0.1272  loss_dice_8: 0.1855  time: 0.5930  data_time: 0.0017  lr: 0.0001  max_mem: 8444M
[08/01 18:19:24] d2.utils.events INFO:  eta: 6:03:09  iter: 9239  total_loss: 2.893  loss_ce: 9.639e-05  loss_mask: 0.1162  loss_dice: 0.1672  loss_ce_0: 0.1237  loss_mask_0: 0.1114  loss_dice_0: 0.1615  loss_ce_1: 0.0001035  loss_mask_1: 0.1137  loss_dice_1: 0.1663  loss_ce_2: 0.000114  loss_mask_2: 0.1093  loss_dice_2: 0.166  loss_ce_3: 8.582e-05  loss_mask_3: 0.1145  loss_dice_3: 0.167  loss_ce_4: 0.0001159  loss_mask_4: 0.1131  loss_dice_4: 0.1658  loss_ce_5: 0.0001311  loss_mask_5: 0.1143  loss_dice_5: 0.1678  loss_ce_6: 0.0001032  loss_mask_6: 0.1098  loss_dice_6: 0.1639  loss_ce_7: 0.0001059  loss_mask_7: 0.1136  loss_dice_7: 0.1667  loss_ce_8: 0.0001086  loss_mask_8: 0.1145  loss_dice_8: 0.1696  time: 0.5936  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:19:41] d2.utils.events INFO:  eta: 6:02:45  iter: 9259  total_loss: 3.142  loss_ce: 8.017e-05  loss_mask: 0.1242  loss_dice: 0.1813  loss_ce_0: 0.1251  loss_mask_0: 0.1228  loss_dice_0: 0.1827  loss_ce_1: 5.941e-05  loss_mask_1: 0.1212  loss_dice_1: 0.1843  loss_ce_2: 6.147e-05  loss_mask_2: 0.1238  loss_dice_2: 0.1848  loss_ce_3: 5.527e-05  loss_mask_3: 0.1252  loss_dice_3: 0.1827  loss_ce_4: 3.937e-05  loss_mask_4: 0.1208  loss_dice_4: 0.1797  loss_ce_5: 3.678e-05  loss_mask_5: 0.1264  loss_dice_5: 0.1893  loss_ce_6: 2.144e-05  loss_mask_6: 0.1202  loss_dice_6: 0.183  loss_ce_7: 7.477e-05  loss_mask_7: 0.1232  loss_dice_7: 0.1793  loss_ce_8: 6.473e-05  loss_mask_8: 0.1232  loss_dice_8: 0.1781  time: 0.5941  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:19:58] d2.utils.events INFO:  eta: 6:02:23  iter: 9279  total_loss: 3.147  loss_ce: 0.0001256  loss_mask: 0.1206  loss_dice: 0.1806  loss_ce_0: 0.1221  loss_mask_0: 0.1221  loss_dice_0: 0.1798  loss_ce_1: 0.0001411  loss_mask_1: 0.1197  loss_dice_1: 0.1819  loss_ce_2: 0.0001513  loss_mask_2: 0.1198  loss_dice_2: 0.1757  loss_ce_3: 0.0001246  loss_mask_3: 0.1195  loss_dice_3: 0.1871  loss_ce_4: 0.0001549  loss_mask_4: 0.1233  loss_dice_4: 0.1783  loss_ce_5: 0.0001503  loss_mask_5: 0.121  loss_dice_5: 0.1801  loss_ce_6: 0.0001117  loss_mask_6: 0.12  loss_dice_6: 0.1767  loss_ce_7: 0.0001491  loss_mask_7: 0.1242  loss_dice_7: 0.1802  loss_ce_8: 0.0001299  loss_mask_8: 0.1226  loss_dice_8: 0.1784  time: 0.5947  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:20:14] d2.utils.events INFO:  eta: 6:02:06  iter: 9299  total_loss: 3.134  loss_ce: 0.0001207  loss_mask: 0.1179  loss_dice: 0.1732  loss_ce_0: 0.1225  loss_mask_0: 0.1209  loss_dice_0: 0.1813  loss_ce_1: 0.0001274  loss_mask_1: 0.1166  loss_dice_1: 0.1712  loss_ce_2: 0.0001407  loss_mask_2: 0.1213  loss_dice_2: 0.1806  loss_ce_3: 0.0001235  loss_mask_3: 0.1213  loss_dice_3: 0.1769  loss_ce_4: 0.0001387  loss_mask_4: 0.12  loss_dice_4: 0.1785  loss_ce_5: 0.0001409  loss_mask_5: 0.1193  loss_dice_5: 0.1775  loss_ce_6: 9.632e-05  loss_mask_6: 0.1187  loss_dice_6: 0.1725  loss_ce_7: 0.0001413  loss_mask_7: 0.1193  loss_dice_7: 0.1721  loss_ce_8: 0.0001222  loss_mask_8: 0.1233  loss_dice_8: 0.1784  time: 0.5952  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:20:31] d2.utils.events INFO:  eta: 6:01:40  iter: 9319  total_loss: 3.015  loss_ce: 0.0001182  loss_mask: 0.1195  loss_dice: 0.1697  loss_ce_0: 0.1286  loss_mask_0: 0.1197  loss_dice_0: 0.1775  loss_ce_1: 0.0001127  loss_mask_1: 0.1205  loss_dice_1: 0.1729  loss_ce_2: 0.000135  loss_mask_2: 0.1199  loss_dice_2: 0.1721  loss_ce_3: 0.0001144  loss_mask_3: 0.1162  loss_dice_3: 0.1716  loss_ce_4: 0.0001375  loss_mask_4: 0.1152  loss_dice_4: 0.1675  loss_ce_5: 0.0001327  loss_mask_5: 0.1196  loss_dice_5: 0.1674  loss_ce_6: 9.816e-05  loss_mask_6: 0.1206  loss_dice_6: 0.1666  loss_ce_7: 0.0001229  loss_mask_7: 0.1184  loss_dice_7: 0.1658  loss_ce_8: 0.000109  loss_mask_8: 0.1164  loss_dice_8: 0.1722  time: 0.5957  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:20:47] d2.utils.events INFO:  eta: 6:01:04  iter: 9339  total_loss: 2.941  loss_ce: 0.0001219  loss_mask: 0.1172  loss_dice: 0.1688  loss_ce_0: 0.1208  loss_mask_0: 0.1129  loss_dice_0: 0.1681  loss_ce_1: 0.0001378  loss_mask_1: 0.1192  loss_dice_1: 0.168  loss_ce_2: 0.0001405  loss_mask_2: 0.1177  loss_dice_2: 0.1628  loss_ce_3: 0.0001177  loss_mask_3: 0.1151  loss_dice_3: 0.1705  loss_ce_4: 0.0001243  loss_mask_4: 0.1196  loss_dice_4: 0.1718  loss_ce_5: 0.0001393  loss_mask_5: 0.1179  loss_dice_5: 0.1725  loss_ce_6: 0.0001247  loss_mask_6: 0.1182  loss_dice_6: 0.165  loss_ce_7: 0.0001183  loss_mask_7: 0.1186  loss_dice_7: 0.1705  loss_ce_8: 0.0001299  loss_mask_8: 0.1163  loss_dice_8: 0.1664  time: 0.5961  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 18:21:03] d2.utils.events INFO:  eta: 6:00:25  iter: 9359  total_loss: 3.097  loss_ce: 0.0001264  loss_mask: 0.1239  loss_dice: 0.1713  loss_ce_0: 0.1299  loss_mask_0: 0.1237  loss_dice_0: 0.175  loss_ce_1: 0.0001168  loss_mask_1: 0.1239  loss_dice_1: 0.1733  loss_ce_2: 0.000144  loss_mask_2: 0.12  loss_dice_2: 0.1709  loss_ce_3: 9.436e-05  loss_mask_3: 0.1183  loss_dice_3: 0.1755  loss_ce_4: 0.0001261  loss_mask_4: 0.1282  loss_dice_4: 0.1709  loss_ce_5: 0.0001606  loss_mask_5: 0.1178  loss_dice_5: 0.1686  loss_ce_6: 0.0001354  loss_mask_6: 0.123  loss_dice_6: 0.1701  loss_ce_7: 0.0001028  loss_mask_7: 0.1193  loss_dice_7: 0.1704  loss_ce_8: 0.0001561  loss_mask_8: 0.1226  loss_dice_8: 0.1711  time: 0.5965  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:21:18] d2.utils.events INFO:  eta: 5:59:54  iter: 9379  total_loss: 3.112  loss_ce: 0.0002026  loss_mask: 0.1179  loss_dice: 0.1754  loss_ce_0: 0.1261  loss_mask_0: 0.1185  loss_dice_0: 0.1865  loss_ce_1: 0.0001805  loss_mask_1: 0.1197  loss_dice_1: 0.1729  loss_ce_2: 0.0001841  loss_mask_2: 0.1171  loss_dice_2: 0.1753  loss_ce_3: 0.0001749  loss_mask_3: 0.1191  loss_dice_3: 0.1778  loss_ce_4: 0.0002454  loss_mask_4: 0.1201  loss_dice_4: 0.1799  loss_ce_5: 0.0002492  loss_mask_5: 0.1199  loss_dice_5: 0.1752  loss_ce_6: 0.000303  loss_mask_6: 0.1178  loss_dice_6: 0.1715  loss_ce_7: 0.0001796  loss_mask_7: 0.1213  loss_dice_7: 0.1821  loss_ce_8: 0.000212  loss_mask_8: 0.1198  loss_dice_8: 0.1724  time: 0.5969  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:21:34] d2.utils.events INFO:  eta: 5:58:59  iter: 9399  total_loss: 3.048  loss_ce: 0.0001713  loss_mask: 0.1144  loss_dice: 0.171  loss_ce_0: 0.1271  loss_mask_0: 0.1206  loss_dice_0: 0.1795  loss_ce_1: 0.0001295  loss_mask_1: 0.1223  loss_dice_1: 0.182  loss_ce_2: 0.0001428  loss_mask_2: 0.1157  loss_dice_2: 0.1735  loss_ce_3: 0.0001415  loss_mask_3: 0.1188  loss_dice_3: 0.1806  loss_ce_4: 0.0001375  loss_mask_4: 0.119  loss_dice_4: 0.1794  loss_ce_5: 0.0001915  loss_mask_5: 0.1184  loss_dice_5: 0.1751  loss_ce_6: 0.0001884  loss_mask_6: 0.1168  loss_dice_6: 0.1759  loss_ce_7: 0.0001516  loss_mask_7: 0.1199  loss_dice_7: 0.1798  loss_ce_8: 0.0002436  loss_mask_8: 0.1146  loss_dice_8: 0.1704  time: 0.5974  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:21:50] d2.utils.events INFO:  eta: 5:58:12  iter: 9419  total_loss: 3.113  loss_ce: 0.000122  loss_mask: 0.1189  loss_dice: 0.1764  loss_ce_0: 0.1255  loss_mask_0: 0.1224  loss_dice_0: 0.1858  loss_ce_1: 0.0001404  loss_mask_1: 0.1213  loss_dice_1: 0.1764  loss_ce_2: 0.0001297  loss_mask_2: 0.1179  loss_dice_2: 0.1769  loss_ce_3: 0.0001073  loss_mask_3: 0.1211  loss_dice_3: 0.1774  loss_ce_4: 0.0001147  loss_mask_4: 0.118  loss_dice_4: 0.1805  loss_ce_5: 0.0001323  loss_mask_5: 0.1236  loss_dice_5: 0.182  loss_ce_6: 0.0001149  loss_mask_6: 0.1189  loss_dice_6: 0.1817  loss_ce_7: 0.0001279  loss_mask_7: 0.1216  loss_dice_7: 0.1832  loss_ce_8: 0.0001604  loss_mask_8: 0.1194  loss_dice_8: 0.182  time: 0.5978  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:22:06] d2.utils.events INFO:  eta: 5:57:23  iter: 9439  total_loss: 3.175  loss_ce: 9.802e-05  loss_mask: 0.1207  loss_dice: 0.1759  loss_ce_0: 0.1234  loss_mask_0: 0.1254  loss_dice_0: 0.1797  loss_ce_1: 7.478e-05  loss_mask_1: 0.1223  loss_dice_1: 0.1784  loss_ce_2: 9.845e-05  loss_mask_2: 0.1186  loss_dice_2: 0.1745  loss_ce_3: 6.784e-05  loss_mask_3: 0.1232  loss_dice_3: 0.1789  loss_ce_4: 9.077e-05  loss_mask_4: 0.1242  loss_dice_4: 0.1755  loss_ce_5: 0.0001308  loss_mask_5: 0.1254  loss_dice_5: 0.1762  loss_ce_6: 9.126e-05  loss_mask_6: 0.1219  loss_dice_6: 0.1711  loss_ce_7: 8.562e-05  loss_mask_7: 0.1181  loss_dice_7: 0.1771  loss_ce_8: 0.0001686  loss_mask_8: 0.1224  loss_dice_8: 0.1766  time: 0.5982  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:22:22] d2.utils.events INFO:  eta: 5:56:55  iter: 9459  total_loss: 2.992  loss_ce: 6.492e-05  loss_mask: 0.1192  loss_dice: 0.1671  loss_ce_0: 0.1273  loss_mask_0: 0.1168  loss_dice_0: 0.1725  loss_ce_1: 0.0001119  loss_mask_1: 0.117  loss_dice_1: 0.1692  loss_ce_2: 9.744e-05  loss_mask_2: 0.1218  loss_dice_2: 0.1706  loss_ce_3: 6.97e-05  loss_mask_3: 0.1164  loss_dice_3: 0.1723  loss_ce_4: 7.452e-05  loss_mask_4: 0.1154  loss_dice_4: 0.1652  loss_ce_5: 5.616e-05  loss_mask_5: 0.1173  loss_dice_5: 0.1719  loss_ce_6: 5.187e-05  loss_mask_6: 0.1202  loss_dice_6: 0.1715  loss_ce_7: 4.745e-05  loss_mask_7: 0.1176  loss_dice_7: 0.166  loss_ce_8: 0.0001431  loss_mask_8: 0.115  loss_dice_8: 0.1764  time: 0.5986  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:22:38] d2.utils.events INFO:  eta: 5:56:15  iter: 9479  total_loss: 3.063  loss_ce: 5.207e-05  loss_mask: 0.1177  loss_dice: 0.1799  loss_ce_0: 0.1238  loss_mask_0: 0.1214  loss_dice_0: 0.1849  loss_ce_1: 3.933e-05  loss_mask_1: 0.1168  loss_dice_1: 0.1779  loss_ce_2: 4.269e-05  loss_mask_2: 0.1146  loss_dice_2: 0.1819  loss_ce_3: 3.407e-05  loss_mask_3: 0.1152  loss_dice_3: 0.1807  loss_ce_4: 2.669e-05  loss_mask_4: 0.1182  loss_dice_4: 0.175  loss_ce_5: 2.566e-05  loss_mask_5: 0.1199  loss_dice_5: 0.1823  loss_ce_6: 1.218e-05  loss_mask_6: 0.1156  loss_dice_6: 0.176  loss_ce_7: 4.04e-05  loss_mask_7: 0.1173  loss_dice_7: 0.1804  loss_ce_8: 5.626e-05  loss_mask_8: 0.1229  loss_dice_8: 0.1827  time: 0.5990  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:22:54] d2.utils.events INFO:  eta: 5:55:17  iter: 9499  total_loss: 3.027  loss_ce: 8.571e-05  loss_mask: 0.1202  loss_dice: 0.1732  loss_ce_0: 0.1219  loss_mask_0: 0.1141  loss_dice_0: 0.1711  loss_ce_1: 0.0001055  loss_mask_1: 0.1164  loss_dice_1: 0.1719  loss_ce_2: 0.0001141  loss_mask_2: 0.1216  loss_dice_2: 0.1783  loss_ce_3: 7.575e-05  loss_mask_3: 0.1197  loss_dice_3: 0.1724  loss_ce_4: 9.547e-05  loss_mask_4: 0.1164  loss_dice_4: 0.1736  loss_ce_5: 9.519e-05  loss_mask_5: 0.1171  loss_dice_5: 0.1697  loss_ce_6: 7.27e-05  loss_mask_6: 0.1113  loss_dice_6: 0.1687  loss_ce_7: 9.865e-05  loss_mask_7: 0.1159  loss_dice_7: 0.1737  loss_ce_8: 9.475e-05  loss_mask_8: 0.1172  loss_dice_8: 0.1745  time: 0.5994  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:23:09] d2.utils.events INFO:  eta: 5:54:11  iter: 9519  total_loss: 3.061  loss_ce: 9.15e-05  loss_mask: 0.1139  loss_dice: 0.1746  loss_ce_0: 0.1264  loss_mask_0: 0.1145  loss_dice_0: 0.1829  loss_ce_1: 8.791e-05  loss_mask_1: 0.1159  loss_dice_1: 0.1824  loss_ce_2: 9.814e-05  loss_mask_2: 0.115  loss_dice_2: 0.177  loss_ce_3: 7.564e-05  loss_mask_3: 0.1167  loss_dice_3: 0.1744  loss_ce_4: 8.943e-05  loss_mask_4: 0.1172  loss_dice_4: 0.1737  loss_ce_5: 0.000109  loss_mask_5: 0.1184  loss_dice_5: 0.1717  loss_ce_6: 8.602e-05  loss_mask_6: 0.118  loss_dice_6: 0.1734  loss_ce_7: 9.259e-05  loss_mask_7: 0.1177  loss_dice_7: 0.1742  loss_ce_8: 0.0001032  loss_mask_8: 0.1162  loss_dice_8: 0.1728  time: 0.5998  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:23:25] d2.utils.events INFO:  eta: 5:53:37  iter: 9539  total_loss: 3.052  loss_ce: 8.25e-05  loss_mask: 0.1192  loss_dice: 0.1721  loss_ce_0: 0.125  loss_mask_0: 0.1217  loss_dice_0: 0.1753  loss_ce_1: 7.503e-05  loss_mask_1: 0.123  loss_dice_1: 0.1775  loss_ce_2: 8.757e-05  loss_mask_2: 0.1247  loss_dice_2: 0.1763  loss_ce_3: 6.581e-05  loss_mask_3: 0.1216  loss_dice_3: 0.1802  loss_ce_4: 7.039e-05  loss_mask_4: 0.118  loss_dice_4: 0.1721  loss_ce_5: 9.264e-05  loss_mask_5: 0.1204  loss_dice_5: 0.174  loss_ce_6: 7.212e-05  loss_mask_6: 0.1204  loss_dice_6: 0.1753  loss_ce_7: 8.182e-05  loss_mask_7: 0.12  loss_dice_7: 0.1722  loss_ce_8: 9.24e-05  loss_mask_8: 0.1193  loss_dice_8: 0.1722  time: 0.6002  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:23:41] d2.utils.events INFO:  eta: 5:53:04  iter: 9559  total_loss: 3.008  loss_ce: 7.624e-05  loss_mask: 0.1196  loss_dice: 0.1702  loss_ce_0: 0.1238  loss_mask_0: 0.1195  loss_dice_0: 0.1726  loss_ce_1: 8.319e-05  loss_mask_1: 0.1152  loss_dice_1: 0.1703  loss_ce_2: 9.077e-05  loss_mask_2: 0.1236  loss_dice_2: 0.173  loss_ce_3: 6.124e-05  loss_mask_3: 0.1163  loss_dice_3: 0.1695  loss_ce_4: 7.68e-05  loss_mask_4: 0.1167  loss_dice_4: 0.171  loss_ce_5: 8.542e-05  loss_mask_5: 0.1203  loss_dice_5: 0.1724  loss_ce_6: 6.974e-05  loss_mask_6: 0.1222  loss_dice_6: 0.169  loss_ce_7: 8.102e-05  loss_mask_7: 0.1221  loss_dice_7: 0.1723  loss_ce_8: 8.301e-05  loss_mask_8: 0.1187  loss_dice_8: 0.1684  time: 0.6006  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:23:57] d2.utils.events INFO:  eta: 5:52:29  iter: 9579  total_loss: 3.116  loss_ce: 7.596e-05  loss_mask: 0.1203  loss_dice: 0.1785  loss_ce_0: 0.1228  loss_mask_0: 0.122  loss_dice_0: 0.1874  loss_ce_1: 7.276e-05  loss_mask_1: 0.121  loss_dice_1: 0.1829  loss_ce_2: 8.518e-05  loss_mask_2: 0.1193  loss_dice_2: 0.1769  loss_ce_3: 6.378e-05  loss_mask_3: 0.1228  loss_dice_3: 0.1785  loss_ce_4: 6.897e-05  loss_mask_4: 0.1214  loss_dice_4: 0.1819  loss_ce_5: 8.074e-05  loss_mask_5: 0.1222  loss_dice_5: 0.1769  loss_ce_6: 6.753e-05  loss_mask_6: 0.1233  loss_dice_6: 0.1882  loss_ce_7: 7.504e-05  loss_mask_7: 0.1249  loss_dice_7: 0.1798  loss_ce_8: 7.8e-05  loss_mask_8: 0.1214  loss_dice_8: 0.1881  time: 0.6010  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:24:13] d2.utils.events INFO:  eta: 5:51:28  iter: 9599  total_loss: 3.138  loss_ce: 7.451e-05  loss_mask: 0.1252  loss_dice: 0.1738  loss_ce_0: 0.1232  loss_mask_0: 0.1259  loss_dice_0: 0.1814  loss_ce_1: 6.253e-05  loss_mask_1: 0.1207  loss_dice_1: 0.1758  loss_ce_2: 8.232e-05  loss_mask_2: 0.1236  loss_dice_2: 0.1715  loss_ce_3: 7.634e-05  loss_mask_3: 0.1191  loss_dice_3: 0.1683  loss_ce_4: 8.976e-05  loss_mask_4: 0.1224  loss_dice_4: 0.1745  loss_ce_5: 9.219e-05  loss_mask_5: 0.1204  loss_dice_5: 0.1727  loss_ce_6: 7.362e-05  loss_mask_6: 0.1221  loss_dice_6: 0.1724  loss_ce_7: 7.09e-05  loss_mask_7: 0.1233  loss_dice_7: 0.1747  loss_ce_8: 8.34e-05  loss_mask_8: 0.1233  loss_dice_8: 0.1737  time: 0.6014  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 18:24:29] d2.utils.events INFO:  eta: 5:50:56  iter: 9619  total_loss: 3.308  loss_ce: 5.242e-05  loss_mask: 0.1243  loss_dice: 0.1903  loss_ce_0: 0.1266  loss_mask_0: 0.1227  loss_dice_0: 0.1998  loss_ce_1: 5.299e-05  loss_mask_1: 0.1213  loss_dice_1: 0.1912  loss_ce_2: 5.248e-05  loss_mask_2: 0.1258  loss_dice_2: 0.1839  loss_ce_3: 3.717e-05  loss_mask_3: 0.1236  loss_dice_3: 0.1861  loss_ce_4: 5.277e-05  loss_mask_4: 0.1222  loss_dice_4: 0.1783  loss_ce_5: 5.248e-05  loss_mask_5: 0.1201  loss_dice_5: 0.1908  loss_ce_6: 4.497e-05  loss_mask_6: 0.1249  loss_dice_6: 0.1878  loss_ce_7: 4.585e-05  loss_mask_7: 0.1224  loss_dice_7: 0.1836  loss_ce_8: 5.861e-05  loss_mask_8: 0.1212  loss_dice_8: 0.1849  time: 0.6018  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:24:44] d2.utils.events INFO:  eta: 5:50:12  iter: 9639  total_loss: 3.028  loss_ce: 4.274e-05  loss_mask: 0.1202  loss_dice: 0.1691  loss_ce_0: 0.1257  loss_mask_0: 0.1198  loss_dice_0: 0.1812  loss_ce_1: 4.985e-05  loss_mask_1: 0.1173  loss_dice_1: 0.172  loss_ce_2: 3.532e-05  loss_mask_2: 0.1209  loss_dice_2: 0.1768  loss_ce_3: 3.576e-05  loss_mask_3: 0.1146  loss_dice_3: 0.173  loss_ce_4: 3.881e-05  loss_mask_4: 0.1189  loss_dice_4: 0.1709  loss_ce_5: 3.286e-05  loss_mask_5: 0.1218  loss_dice_5: 0.1697  loss_ce_6: 2.692e-05  loss_mask_6: 0.1178  loss_dice_6: 0.1751  loss_ce_7: 3.349e-05  loss_mask_7: 0.1177  loss_dice_7: 0.1737  loss_ce_8: 4.795e-05  loss_mask_8: 0.1202  loss_dice_8: 0.1765  time: 0.6022  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:25:00] d2.utils.events INFO:  eta: 5:49:23  iter: 9659  total_loss: 3.139  loss_ce: 7.127e-05  loss_mask: 0.1165  loss_dice: 0.173  loss_ce_0: 0.1233  loss_mask_0: 0.1135  loss_dice_0: 0.1745  loss_ce_1: 7.908e-05  loss_mask_1: 0.117  loss_dice_1: 0.1729  loss_ce_2: 7.757e-05  loss_mask_2: 0.1158  loss_dice_2: 0.1718  loss_ce_3: 5.68e-05  loss_mask_3: 0.1177  loss_dice_3: 0.1751  loss_ce_4: 7.627e-05  loss_mask_4: 0.1215  loss_dice_4: 0.1767  loss_ce_5: 8.153e-05  loss_mask_5: 0.12  loss_dice_5: 0.1802  loss_ce_6: 6.342e-05  loss_mask_6: 0.1157  loss_dice_6: 0.1771  loss_ce_7: 7.351e-05  loss_mask_7: 0.1148  loss_dice_7: 0.1715  loss_ce_8: 8.196e-05  loss_mask_8: 0.114  loss_dice_8: 0.1725  time: 0.6026  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:25:16] d2.utils.events INFO:  eta: 5:48:32  iter: 9679  total_loss: 3.059  loss_ce: 5.759e-05  loss_mask: 0.1247  loss_dice: 0.1739  loss_ce_0: 0.1248  loss_mask_0: 0.1212  loss_dice_0: 0.1701  loss_ce_1: 5.745e-05  loss_mask_1: 0.1182  loss_dice_1: 0.1661  loss_ce_2: 6.536e-05  loss_mask_2: 0.1242  loss_dice_2: 0.1661  loss_ce_3: 4.188e-05  loss_mask_3: 0.1283  loss_dice_3: 0.1674  loss_ce_4: 6.116e-05  loss_mask_4: 0.1224  loss_dice_4: 0.1717  loss_ce_5: 7.967e-05  loss_mask_5: 0.1222  loss_dice_5: 0.1635  loss_ce_6: 5.826e-05  loss_mask_6: 0.1277  loss_dice_6: 0.1736  loss_ce_7: 5.727e-05  loss_mask_7: 0.1259  loss_dice_7: 0.1698  loss_ce_8: 8.315e-05  loss_mask_8: 0.1202  loss_dice_8: 0.1664  time: 0.6030  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:25:32] d2.utils.events INFO:  eta: 5:47:51  iter: 9699  total_loss: 3.112  loss_ce: 5.147e-05  loss_mask: 0.123  loss_dice: 0.18  loss_ce_0: 0.1229  loss_mask_0: 0.1197  loss_dice_0: 0.1715  loss_ce_1: 4.408e-05  loss_mask_1: 0.1218  loss_dice_1: 0.1747  loss_ce_2: 5.949e-05  loss_mask_2: 0.119  loss_dice_2: 0.178  loss_ce_3: 3.885e-05  loss_mask_3: 0.1214  loss_dice_3: 0.1831  loss_ce_4: 5.384e-05  loss_mask_4: 0.1201  loss_dice_4: 0.183  loss_ce_5: 7.059e-05  loss_mask_5: 0.1189  loss_dice_5: 0.1812  loss_ce_6: 5.118e-05  loss_mask_6: 0.1203  loss_dice_6: 0.1719  loss_ce_7: 4.986e-05  loss_mask_7: 0.1207  loss_dice_7: 0.1797  loss_ce_8: 7.046e-05  loss_mask_8: 0.1226  loss_dice_8: 0.1825  time: 0.6034  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:25:48] d2.utils.events INFO:  eta: 5:47:03  iter: 9719  total_loss: 3.185  loss_ce: 6.062e-05  loss_mask: 0.127  loss_dice: 0.1766  loss_ce_0: 0.1216  loss_mask_0: 0.1315  loss_dice_0: 0.1777  loss_ce_1: 5.121e-05  loss_mask_1: 0.1226  loss_dice_1: 0.1712  loss_ce_2: 6.543e-05  loss_mask_2: 0.1261  loss_dice_2: 0.1707  loss_ce_3: 5.135e-05  loss_mask_3: 0.1239  loss_dice_3: 0.1773  loss_ce_4: 5.971e-05  loss_mask_4: 0.1261  loss_dice_4: 0.1787  loss_ce_5: 7.328e-05  loss_mask_5: 0.1248  loss_dice_5: 0.1795  loss_ce_6: 5.91e-05  loss_mask_6: 0.128  loss_dice_6: 0.1805  loss_ce_7: 6.02e-05  loss_mask_7: 0.1309  loss_dice_7: 0.1773  loss_ce_8: 7.151e-05  loss_mask_8: 0.1276  loss_dice_8: 0.1765  time: 0.6037  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:26:04] d2.utils.events INFO:  eta: 5:46:32  iter: 9739  total_loss: 3.06  loss_ce: 6.359e-05  loss_mask: 0.1196  loss_dice: 0.1724  loss_ce_0: 0.1281  loss_mask_0: 0.1206  loss_dice_0: 0.178  loss_ce_1: 5.516e-05  loss_mask_1: 0.1195  loss_dice_1: 0.173  loss_ce_2: 6.728e-05  loss_mask_2: 0.1193  loss_dice_2: 0.1744  loss_ce_3: 5.275e-05  loss_mask_3: 0.1201  loss_dice_3: 0.1715  loss_ce_4: 5.725e-05  loss_mask_4: 0.1175  loss_dice_4: 0.1707  loss_ce_5: 6.563e-05  loss_mask_5: 0.1188  loss_dice_5: 0.1735  loss_ce_6: 5.126e-05  loss_mask_6: 0.1203  loss_dice_6: 0.1732  loss_ce_7: 5.863e-05  loss_mask_7: 0.12  loss_dice_7: 0.1738  loss_ce_8: 6.751e-05  loss_mask_8: 0.1211  loss_dice_8: 0.1735  time: 0.6041  data_time: 0.0017  lr: 0.0001  max_mem: 8444M
[08/01 18:26:20] d2.utils.events INFO:  eta: 5:45:26  iter: 9759  total_loss: 3.086  loss_ce: 5.18e-05  loss_mask: 0.1233  loss_dice: 0.1814  loss_ce_0: 0.1245  loss_mask_0: 0.1204  loss_dice_0: 0.1812  loss_ce_1: 3.977e-05  loss_mask_1: 0.1199  loss_dice_1: 0.1839  loss_ce_2: 5.912e-05  loss_mask_2: 0.1201  loss_dice_2: 0.1799  loss_ce_3: 4.724e-05  loss_mask_3: 0.1216  loss_dice_3: 0.1824  loss_ce_4: 5.348e-05  loss_mask_4: 0.1188  loss_dice_4: 0.1862  loss_ce_5: 6.368e-05  loss_mask_5: 0.1181  loss_dice_5: 0.1741  loss_ce_6: 4.834e-05  loss_mask_6: 0.1223  loss_dice_6: 0.1744  loss_ce_7: 5.26e-05  loss_mask_7: 0.1242  loss_dice_7: 0.1785  loss_ce_8: 6.297e-05  loss_mask_8: 0.121  loss_dice_8: 0.1723  time: 0.6045  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:26:35] d2.utils.events INFO:  eta: 5:44:44  iter: 9779  total_loss: 3.145  loss_ce: 3.184e-05  loss_mask: 0.1188  loss_dice: 0.1772  loss_ce_0: 0.1281  loss_mask_0: 0.117  loss_dice_0: 0.1879  loss_ce_1: 2.267e-05  loss_mask_1: 0.1168  loss_dice_1: 0.1854  loss_ce_2: 3.3e-05  loss_mask_2: 0.1196  loss_dice_2: 0.1792  loss_ce_3: 2.397e-05  loss_mask_3: 0.1174  loss_dice_3: 0.1845  loss_ce_4: 2.716e-05  loss_mask_4: 0.1206  loss_dice_4: 0.181  loss_ce_5: 2.371e-05  loss_mask_5: 0.1202  loss_dice_5: 0.1797  loss_ce_6: 2.302e-05  loss_mask_6: 0.1176  loss_dice_6: 0.1746  loss_ce_7: 2.597e-05  loss_mask_7: 0.122  loss_dice_7: 0.1798  loss_ce_8: 3.643e-05  loss_mask_8: 0.1177  loss_dice_8: 0.1763  time: 0.6049  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:26:51] d2.utils.events INFO:  eta: 5:43:53  iter: 9799  total_loss: 3.22  loss_ce: 5.46e-05  loss_mask: 0.1221  loss_dice: 0.1919  loss_ce_0: 0.1255  loss_mask_0: 0.1217  loss_dice_0: 0.1973  loss_ce_1: 7.374e-05  loss_mask_1: 0.1185  loss_dice_1: 0.1861  loss_ce_2: 6.204e-05  loss_mask_2: 0.12  loss_dice_2: 0.1791  loss_ce_3: 4.56e-05  loss_mask_3: 0.1221  loss_dice_3: 0.1878  loss_ce_4: 5.797e-05  loss_mask_4: 0.1218  loss_dice_4: 0.188  loss_ce_5: 7.115e-05  loss_mask_5: 0.1208  loss_dice_5: 0.187  loss_ce_6: 5.132e-05  loss_mask_6: 0.1211  loss_dice_6: 0.1985  loss_ce_7: 5.754e-05  loss_mask_7: 0.1197  loss_dice_7: 0.1898  loss_ce_8: 6.708e-05  loss_mask_8: 0.121  loss_dice_8: 0.1826  time: 0.6053  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:27:07] d2.utils.events INFO:  eta: 5:42:56  iter: 9819  total_loss: 3.039  loss_ce: 5.666e-05  loss_mask: 0.1185  loss_dice: 0.1722  loss_ce_0: 0.1247  loss_mask_0: 0.1182  loss_dice_0: 0.1761  loss_ce_1: 5.991e-05  loss_mask_1: 0.1141  loss_dice_1: 0.1761  loss_ce_2: 6.383e-05  loss_mask_2: 0.117  loss_dice_2: 0.1779  loss_ce_3: 4.832e-05  loss_mask_3: 0.1157  loss_dice_3: 0.175  loss_ce_4: 5.52e-05  loss_mask_4: 0.113  loss_dice_4: 0.1698  loss_ce_5: 6.256e-05  loss_mask_5: 0.1143  loss_dice_5: 0.1757  loss_ce_6: 4.657e-05  loss_mask_6: 0.1165  loss_dice_6: 0.1754  loss_ce_7: 6.142e-05  loss_mask_7: 0.1129  loss_dice_7: 0.1722  loss_ce_8: 6.037e-05  loss_mask_8: 0.114  loss_dice_8: 0.1745  time: 0.6057  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:27:23] d2.utils.events INFO:  eta: 5:42:29  iter: 9839  total_loss: 3.343  loss_ce: 7.42e-05  loss_mask: 0.1228  loss_dice: 0.1979  loss_ce_0: 0.1243  loss_mask_0: 0.1231  loss_dice_0: 0.2109  loss_ce_1: 6.944e-05  loss_mask_1: 0.1223  loss_dice_1: 0.2003  loss_ce_2: 6.641e-05  loss_mask_2: 0.1224  loss_dice_2: 0.1953  loss_ce_3: 7.51e-05  loss_mask_3: 0.123  loss_dice_3: 0.189  loss_ce_4: 6.448e-05  loss_mask_4: 0.1236  loss_dice_4: 0.1951  loss_ce_5: 7.35e-05  loss_mask_5: 0.1235  loss_dice_5: 0.191  loss_ce_6: 2.885e-05  loss_mask_6: 0.1227  loss_dice_6: 0.1916  loss_ce_7: 6.731e-05  loss_mask_7: 0.1261  loss_dice_7: 0.1913  loss_ce_8: 8.327e-05  loss_mask_8: 0.1256  loss_dice_8: 0.1899  time: 0.6060  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:27:39] d2.utils.events INFO:  eta: 5:41:52  iter: 9859  total_loss: 2.896  loss_ce: 0.0004035  loss_mask: 0.1138  loss_dice: 0.1588  loss_ce_0: 0.1234  loss_mask_0: 0.1174  loss_dice_0: 0.1652  loss_ce_1: 0.000428  loss_mask_1: 0.1147  loss_dice_1: 0.1632  loss_ce_2: 0.0002421  loss_mask_2: 0.1131  loss_dice_2: 0.1621  loss_ce_3: 0.0001579  loss_mask_3: 0.1158  loss_dice_3: 0.1602  loss_ce_4: 0.0002135  loss_mask_4: 0.1148  loss_dice_4: 0.1554  loss_ce_5: 0.0001844  loss_mask_5: 0.1106  loss_dice_5: 0.1565  loss_ce_6: 8.418e-05  loss_mask_6: 0.1165  loss_dice_6: 0.16  loss_ce_7: 0.0002013  loss_mask_7: 0.1121  loss_dice_7: 0.1626  loss_ce_8: 0.00026  loss_mask_8: 0.1145  loss_dice_8: 0.1629  time: 0.6064  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 18:27:55] d2.utils.events INFO:  eta: 5:40:55  iter: 9879  total_loss: 3.392  loss_ce: 0.0006438  loss_mask: 0.1272  loss_dice: 0.1841  loss_ce_0: 0.1297  loss_mask_0: 0.1269  loss_dice_0: 0.1845  loss_ce_1: 0.002259  loss_mask_1: 0.1243  loss_dice_1: 0.177  loss_ce_2: 0.001004  loss_mask_2: 0.1277  loss_dice_2: 0.178  loss_ce_3: 0.00111  loss_mask_3: 0.1247  loss_dice_3: 0.1808  loss_ce_4: 0.001032  loss_mask_4: 0.1232  loss_dice_4: 0.1859  loss_ce_5: 0.0007789  loss_mask_5: 0.1279  loss_dice_5: 0.1861  loss_ce_6: 0.00155  loss_mask_6: 0.1294  loss_dice_6: 0.1824  loss_ce_7: 0.001202  loss_mask_7: 0.1269  loss_dice_7: 0.1807  loss_ce_8: 0.0005505  loss_mask_8: 0.1278  loss_dice_8: 0.1913  time: 0.6068  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:28:11] d2.utils.events INFO:  eta: 5:39:49  iter: 9899  total_loss: 3.87  loss_ce: 0.005779  loss_mask: 0.1243  loss_dice: 0.1851  loss_ce_0: 0.1229  loss_mask_0: 0.1249  loss_dice_0: 0.1981  loss_ce_1: 0.008018  loss_mask_1: 0.1309  loss_dice_1: 0.1976  loss_ce_2: 0.0009355  loss_mask_2: 0.1266  loss_dice_2: 0.2068  loss_ce_3: 0.005922  loss_mask_3: 0.1279  loss_dice_3: 0.2034  loss_ce_4: 0.01356  loss_mask_4: 0.1288  loss_dice_4: 0.1986  loss_ce_5: 0.003439  loss_mask_5: 0.121  loss_dice_5: 0.1943  loss_ce_6: 0.01702  loss_mask_6: 0.1262  loss_dice_6: 0.1943  loss_ce_7: 0.0112  loss_mask_7: 0.1231  loss_dice_7: 0.1926  loss_ce_8: 0.005201  loss_mask_8: 0.1261  loss_dice_8: 0.192  time: 0.6072  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:28:27] d2.utils.events INFO:  eta: 5:39:08  iter: 9919  total_loss: 3.392  loss_ce: 0.009262  loss_mask: 0.121  loss_dice: 0.1789  loss_ce_0: 0.1255  loss_mask_0: 0.1237  loss_dice_0: 0.1921  loss_ce_1: 0.002668  loss_mask_1: 0.1206  loss_dice_1: 0.188  loss_ce_2: 0.0003544  loss_mask_2: 0.1209  loss_dice_2: 0.1927  loss_ce_3: 0.001001  loss_mask_3: 0.1267  loss_dice_3: 0.1884  loss_ce_4: 0.001132  loss_mask_4: 0.1217  loss_dice_4: 0.1972  loss_ce_5: 0.0003865  loss_mask_5: 0.1194  loss_dice_5: 0.1925  loss_ce_6: 0.003278  loss_mask_6: 0.1229  loss_dice_6: 0.1972  loss_ce_7: 0.002004  loss_mask_7: 0.1181  loss_dice_7: 0.1837  loss_ce_8: 0.001518  loss_mask_8: 0.1263  loss_dice_8: 0.1923  time: 0.6076  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:28:43] d2.utils.events INFO:  eta: 5:38:24  iter: 9939  total_loss: 3.071  loss_ce: 0.0042  loss_mask: 0.1214  loss_dice: 0.1693  loss_ce_0: 0.1209  loss_mask_0: 0.1177  loss_dice_0: 0.1687  loss_ce_1: 0.001364  loss_mask_1: 0.1234  loss_dice_1: 0.1679  loss_ce_2: 0.0003099  loss_mask_2: 0.1217  loss_dice_2: 0.172  loss_ce_3: 0.0004166  loss_mask_3: 0.1217  loss_dice_3: 0.17  loss_ce_4: 0.0007348  loss_mask_4: 0.1245  loss_dice_4: 0.1762  loss_ce_5: 0.0004655  loss_mask_5: 0.1201  loss_dice_5: 0.1769  loss_ce_6: 0.0004752  loss_mask_6: 0.1259  loss_dice_6: 0.1679  loss_ce_7: 0.0007012  loss_mask_7: 0.1195  loss_dice_7: 0.1708  loss_ce_8: 0.004306  loss_mask_8: 0.1239  loss_dice_8: 0.1703  time: 0.6079  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:28:58] d2.utils.events INFO:  eta: 5:37:44  iter: 9959  total_loss: 3.45  loss_ce: 0.001081  loss_mask: 0.127  loss_dice: 0.1868  loss_ce_0: 0.1241  loss_mask_0: 0.1259  loss_dice_0: 0.1859  loss_ce_1: 0.02587  loss_mask_1: 0.123  loss_dice_1: 0.183  loss_ce_2: 0.001072  loss_mask_2: 0.1233  loss_dice_2: 0.1807  loss_ce_3: 0.001404  loss_mask_3: 0.1242  loss_dice_3: 0.1799  loss_ce_4: 0.001494  loss_mask_4: 0.1239  loss_dice_4: 0.186  loss_ce_5: 0.0007323  loss_mask_5: 0.1287  loss_dice_5: 0.1799  loss_ce_6: 0.0008427  loss_mask_6: 0.1233  loss_dice_6: 0.1844  loss_ce_7: 0.0004024  loss_mask_7: 0.1234  loss_dice_7: 0.1854  loss_ce_8: 0.000836  loss_mask_8: 0.1245  loss_dice_8: 0.177  time: 0.6083  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:29:14] d2.utils.events INFO:  eta: 5:36:53  iter: 9979  total_loss: 3.422  loss_ce: 0.0009339  loss_mask: 0.1239  loss_dice: 0.1849  loss_ce_0: 0.1246  loss_mask_0: 0.1212  loss_dice_0: 0.1871  loss_ce_1: 0.0108  loss_mask_1: 0.1303  loss_dice_1: 0.186  loss_ce_2: 0.006518  loss_mask_2: 0.13  loss_dice_2: 0.1855  loss_ce_3: 0.009398  loss_mask_3: 0.1241  loss_dice_3: 0.1841  loss_ce_4: 0.006701  loss_mask_4: 0.1252  loss_dice_4: 0.189  loss_ce_5: 0.001401  loss_mask_5: 0.1226  loss_dice_5: 0.1811  loss_ce_6: 0.001577  loss_mask_6: 0.1212  loss_dice_6: 0.1821  loss_ce_7: 0.001108  loss_mask_7: 0.1237  loss_dice_7: 0.1814  loss_ce_8: 0.0005912  loss_mask_8: 0.1205  loss_dice_8: 0.178  time: 0.6087  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:29:30] fvcore.common.checkpoint INFO: Saving checkpoint to ./R101_overlap/model_0009999.pth
[08/01 18:29:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(256, 256), max_size=256, sample_style='choice')]
[08/01 18:29:30] d2.data.common INFO: Serializing 535 elements to byte tensors and concatenating them all ...
[08/01 18:29:30] d2.data.common INFO: Serialized dataset takes 0.22 MiB
[08/01 18:29:30] d2.evaluation.evaluator INFO: Start inference on 535 batches
[08/01 18:29:54] d2.evaluation.evaluator INFO: Inference done 11/535. Dataloading: 0.0005 s/iter. Inference: 1.1901 s/iter. Eval: 0.9699 s/iter. Total: 2.1606 s/iter. ETA=0:18:52
[08/01 18:30:01] d2.evaluation.evaluator INFO: Inference done 14/535. Dataloading: 0.0006 s/iter. Inference: 1.1906 s/iter. Eval: 0.9712 s/iter. Total: 2.1624 s/iter. ETA=0:18:46
[08/01 18:30:07] d2.evaluation.evaluator INFO: Inference done 17/535. Dataloading: 0.0006 s/iter. Inference: 1.1983 s/iter. Eval: 0.9678 s/iter. Total: 2.1668 s/iter. ETA=0:18:42
[08/01 18:30:14] d2.evaluation.evaluator INFO: Inference done 20/535. Dataloading: 0.0006 s/iter. Inference: 1.1975 s/iter. Eval: 0.9670 s/iter. Total: 2.1652 s/iter. ETA=0:18:35
[08/01 18:30:20] d2.evaluation.evaluator INFO: Inference done 23/535. Dataloading: 0.0007 s/iter. Inference: 1.1984 s/iter. Eval: 0.9633 s/iter. Total: 2.1624 s/iter. ETA=0:18:27
[08/01 18:30:27] d2.evaluation.evaluator INFO: Inference done 26/535. Dataloading: 0.0007 s/iter. Inference: 1.1978 s/iter. Eval: 0.9621 s/iter. Total: 2.1607 s/iter. ETA=0:18:19
[08/01 18:30:33] d2.evaluation.evaluator INFO: Inference done 29/535. Dataloading: 0.0007 s/iter. Inference: 1.1977 s/iter. Eval: 0.9609 s/iter. Total: 2.1595 s/iter. ETA=0:18:12
[08/01 18:30:40] d2.evaluation.evaluator INFO: Inference done 32/535. Dataloading: 0.0007 s/iter. Inference: 1.1972 s/iter. Eval: 0.9586 s/iter. Total: 2.1565 s/iter. ETA=0:18:04
[08/01 18:30:46] d2.evaluation.evaluator INFO: Inference done 35/535. Dataloading: 0.0007 s/iter. Inference: 1.1957 s/iter. Eval: 0.9580 s/iter. Total: 2.1545 s/iter. ETA=0:17:57
[08/01 18:30:52] d2.evaluation.evaluator INFO: Inference done 38/535. Dataloading: 0.0007 s/iter. Inference: 1.1955 s/iter. Eval: 0.9557 s/iter. Total: 2.1520 s/iter. ETA=0:17:49
[08/01 18:30:59] d2.evaluation.evaluator INFO: Inference done 41/535. Dataloading: 0.0007 s/iter. Inference: 1.1955 s/iter. Eval: 0.9564 s/iter. Total: 2.1527 s/iter. ETA=0:17:43
[08/01 18:31:05] d2.evaluation.evaluator INFO: Inference done 44/535. Dataloading: 0.0007 s/iter. Inference: 1.1945 s/iter. Eval: 0.9554 s/iter. Total: 2.1507 s/iter. ETA=0:17:36
[08/01 18:31:12] d2.evaluation.evaluator INFO: Inference done 47/535. Dataloading: 0.0007 s/iter. Inference: 1.1939 s/iter. Eval: 0.9548 s/iter. Total: 2.1495 s/iter. ETA=0:17:28
[08/01 18:31:18] d2.evaluation.evaluator INFO: Inference done 50/535. Dataloading: 0.0007 s/iter. Inference: 1.1939 s/iter. Eval: 0.9545 s/iter. Total: 2.1491 s/iter. ETA=0:17:22
[08/01 18:31:25] d2.evaluation.evaluator INFO: Inference done 53/535. Dataloading: 0.0007 s/iter. Inference: 1.1960 s/iter. Eval: 0.9544 s/iter. Total: 2.1512 s/iter. ETA=0:17:16
[08/01 18:31:31] d2.evaluation.evaluator INFO: Inference done 56/535. Dataloading: 0.0007 s/iter. Inference: 1.1943 s/iter. Eval: 0.9542 s/iter. Total: 2.1492 s/iter. ETA=0:17:09
[08/01 18:31:38] d2.evaluation.evaluator INFO: Inference done 59/535. Dataloading: 0.0008 s/iter. Inference: 1.1947 s/iter. Eval: 0.9541 s/iter. Total: 2.1497 s/iter. ETA=0:17:03
[08/01 18:31:44] d2.evaluation.evaluator INFO: Inference done 62/535. Dataloading: 0.0008 s/iter. Inference: 1.1972 s/iter. Eval: 0.9536 s/iter. Total: 2.1517 s/iter. ETA=0:16:57
[08/01 18:31:51] d2.evaluation.evaluator INFO: Inference done 65/535. Dataloading: 0.0008 s/iter. Inference: 1.1980 s/iter. Eval: 0.9544 s/iter. Total: 2.1533 s/iter. ETA=0:16:52
[08/01 18:31:57] d2.evaluation.evaluator INFO: Inference done 68/535. Dataloading: 0.0008 s/iter. Inference: 1.1980 s/iter. Eval: 0.9539 s/iter. Total: 2.1528 s/iter. ETA=0:16:45
[08/01 18:32:03] d2.evaluation.evaluator INFO: Inference done 71/535. Dataloading: 0.0008 s/iter. Inference: 1.1947 s/iter. Eval: 0.9546 s/iter. Total: 2.1502 s/iter. ETA=0:16:37
[08/01 18:32:10] d2.evaluation.evaluator INFO: Inference done 74/535. Dataloading: 0.0008 s/iter. Inference: 1.1953 s/iter. Eval: 0.9547 s/iter. Total: 2.1509 s/iter. ETA=0:16:31
[08/01 18:32:17] d2.evaluation.evaluator INFO: Inference done 77/535. Dataloading: 0.0008 s/iter. Inference: 1.1963 s/iter. Eval: 0.9561 s/iter. Total: 2.1533 s/iter. ETA=0:16:26
[08/01 18:32:23] d2.evaluation.evaluator INFO: Inference done 80/535. Dataloading: 0.0008 s/iter. Inference: 1.1964 s/iter. Eval: 0.9567 s/iter. Total: 2.1539 s/iter. ETA=0:16:20
[08/01 18:32:30] d2.evaluation.evaluator INFO: Inference done 83/535. Dataloading: 0.0008 s/iter. Inference: 1.1963 s/iter. Eval: 0.9573 s/iter. Total: 2.1545 s/iter. ETA=0:16:13
[08/01 18:32:36] d2.evaluation.evaluator INFO: Inference done 86/535. Dataloading: 0.0008 s/iter. Inference: 1.1966 s/iter. Eval: 0.9569 s/iter. Total: 2.1544 s/iter. ETA=0:16:07
[08/01 18:32:43] d2.evaluation.evaluator INFO: Inference done 89/535. Dataloading: 0.0008 s/iter. Inference: 1.1977 s/iter. Eval: 0.9569 s/iter. Total: 2.1555 s/iter. ETA=0:16:01
[08/01 18:32:49] d2.evaluation.evaluator INFO: Inference done 92/535. Dataloading: 0.0008 s/iter. Inference: 1.1975 s/iter. Eval: 0.9563 s/iter. Total: 2.1547 s/iter. ETA=0:15:54
[08/01 18:32:56] d2.evaluation.evaluator INFO: Inference done 95/535. Dataloading: 0.0008 s/iter. Inference: 1.1972 s/iter. Eval: 0.9582 s/iter. Total: 2.1564 s/iter. ETA=0:15:48
[08/01 18:33:02] d2.evaluation.evaluator INFO: Inference done 98/535. Dataloading: 0.0008 s/iter. Inference: 1.1975 s/iter. Eval: 0.9585 s/iter. Total: 2.1569 s/iter. ETA=0:15:42
[08/01 18:33:09] d2.evaluation.evaluator INFO: Inference done 101/535. Dataloading: 0.0008 s/iter. Inference: 1.1962 s/iter. Eval: 0.9596 s/iter. Total: 2.1566 s/iter. ETA=0:15:35
[08/01 18:33:15] d2.evaluation.evaluator INFO: Inference done 104/535. Dataloading: 0.0008 s/iter. Inference: 1.1949 s/iter. Eval: 0.9596 s/iter. Total: 2.1554 s/iter. ETA=0:15:28
[08/01 18:33:21] d2.evaluation.evaluator INFO: Inference done 107/535. Dataloading: 0.0008 s/iter. Inference: 1.1952 s/iter. Eval: 0.9601 s/iter. Total: 2.1562 s/iter. ETA=0:15:22
[08/01 18:33:28] d2.evaluation.evaluator INFO: Inference done 110/535. Dataloading: 0.0008 s/iter. Inference: 1.1950 s/iter. Eval: 0.9600 s/iter. Total: 2.1559 s/iter. ETA=0:15:16
[08/01 18:33:34] d2.evaluation.evaluator INFO: Inference done 113/535. Dataloading: 0.0008 s/iter. Inference: 1.1953 s/iter. Eval: 0.9604 s/iter. Total: 2.1565 s/iter. ETA=0:15:10
[08/01 18:33:41] d2.evaluation.evaluator INFO: Inference done 116/535. Dataloading: 0.0008 s/iter. Inference: 1.1955 s/iter. Eval: 0.9609 s/iter. Total: 2.1573 s/iter. ETA=0:15:03
[08/01 18:33:48] d2.evaluation.evaluator INFO: Inference done 119/535. Dataloading: 0.0008 s/iter. Inference: 1.1964 s/iter. Eval: 0.9609 s/iter. Total: 2.1582 s/iter. ETA=0:14:57
[08/01 18:33:54] d2.evaluation.evaluator INFO: Inference done 122/535. Dataloading: 0.0008 s/iter. Inference: 1.1965 s/iter. Eval: 0.9610 s/iter. Total: 2.1584 s/iter. ETA=0:14:51
[08/01 18:34:00] d2.evaluation.evaluator INFO: Inference done 125/535. Dataloading: 0.0008 s/iter. Inference: 1.1962 s/iter. Eval: 0.9608 s/iter. Total: 2.1578 s/iter. ETA=0:14:44
[08/01 18:34:07] d2.evaluation.evaluator INFO: Inference done 128/535. Dataloading: 0.0008 s/iter. Inference: 1.1959 s/iter. Eval: 0.9612 s/iter. Total: 2.1579 s/iter. ETA=0:14:38
[08/01 18:34:13] d2.evaluation.evaluator INFO: Inference done 131/535. Dataloading: 0.0008 s/iter. Inference: 1.1956 s/iter. Eval: 0.9614 s/iter. Total: 2.1578 s/iter. ETA=0:14:31
[08/01 18:34:20] d2.evaluation.evaluator INFO: Inference done 134/535. Dataloading: 0.0008 s/iter. Inference: 1.1959 s/iter. Eval: 0.9618 s/iter. Total: 2.1585 s/iter. ETA=0:14:25
[08/01 18:34:26] d2.evaluation.evaluator INFO: Inference done 137/535. Dataloading: 0.0008 s/iter. Inference: 1.1951 s/iter. Eval: 0.9622 s/iter. Total: 2.1582 s/iter. ETA=0:14:18
[08/01 18:34:33] d2.evaluation.evaluator INFO: Inference done 140/535. Dataloading: 0.0008 s/iter. Inference: 1.1951 s/iter. Eval: 0.9627 s/iter. Total: 2.1587 s/iter. ETA=0:14:12
[08/01 18:34:39] d2.evaluation.evaluator INFO: Inference done 143/535. Dataloading: 0.0008 s/iter. Inference: 1.1953 s/iter. Eval: 0.9630 s/iter. Total: 2.1592 s/iter. ETA=0:14:06
[08/01 18:34:46] d2.evaluation.evaluator INFO: Inference done 146/535. Dataloading: 0.0008 s/iter. Inference: 1.1950 s/iter. Eval: 0.9630 s/iter. Total: 2.1589 s/iter. ETA=0:13:59
[08/01 18:34:52] d2.evaluation.evaluator INFO: Inference done 149/535. Dataloading: 0.0008 s/iter. Inference: 1.1937 s/iter. Eval: 0.9631 s/iter. Total: 2.1578 s/iter. ETA=0:13:52
[08/01 18:34:59] d2.evaluation.evaluator INFO: Inference done 152/535. Dataloading: 0.0008 s/iter. Inference: 1.1941 s/iter. Eval: 0.9633 s/iter. Total: 2.1583 s/iter. ETA=0:13:46
[08/01 18:35:05] d2.evaluation.evaluator INFO: Inference done 155/535. Dataloading: 0.0008 s/iter. Inference: 1.1936 s/iter. Eval: 0.9638 s/iter. Total: 2.1583 s/iter. ETA=0:13:40
[08/01 18:35:12] d2.evaluation.evaluator INFO: Inference done 158/535. Dataloading: 0.0008 s/iter. Inference: 1.1922 s/iter. Eval: 0.9651 s/iter. Total: 2.1583 s/iter. ETA=0:13:33
[08/01 18:35:18] d2.evaluation.evaluator INFO: Inference done 161/535. Dataloading: 0.0008 s/iter. Inference: 1.1936 s/iter. Eval: 0.9647 s/iter. Total: 2.1592 s/iter. ETA=0:13:27
[08/01 18:35:25] d2.evaluation.evaluator INFO: Inference done 164/535. Dataloading: 0.0008 s/iter. Inference: 1.1958 s/iter. Eval: 0.9643 s/iter. Total: 2.1610 s/iter. ETA=0:13:21
[08/01 18:35:32] d2.evaluation.evaluator INFO: Inference done 167/535. Dataloading: 0.0008 s/iter. Inference: 1.1971 s/iter. Eval: 0.9639 s/iter. Total: 2.1620 s/iter. ETA=0:13:15
[08/01 18:35:38] d2.evaluation.evaluator INFO: Inference done 170/535. Dataloading: 0.0008 s/iter. Inference: 1.1989 s/iter. Eval: 0.9631 s/iter. Total: 2.1629 s/iter. ETA=0:13:09
[08/01 18:35:45] d2.evaluation.evaluator INFO: Inference done 173/535. Dataloading: 0.0008 s/iter. Inference: 1.2006 s/iter. Eval: 0.9626 s/iter. Total: 2.1641 s/iter. ETA=0:13:03
[08/01 18:35:52] d2.evaluation.evaluator INFO: Inference done 176/535. Dataloading: 0.0008 s/iter. Inference: 1.2019 s/iter. Eval: 0.9627 s/iter. Total: 2.1655 s/iter. ETA=0:12:57
[08/01 18:35:59] d2.evaluation.evaluator INFO: Inference done 179/535. Dataloading: 0.0008 s/iter. Inference: 1.2043 s/iter. Eval: 0.9623 s/iter. Total: 2.1676 s/iter. ETA=0:12:51
[08/01 18:36:05] d2.evaluation.evaluator INFO: Inference done 182/535. Dataloading: 0.0008 s/iter. Inference: 1.2058 s/iter. Eval: 0.9621 s/iter. Total: 2.1688 s/iter. ETA=0:12:45
[08/01 18:36:12] d2.evaluation.evaluator INFO: Inference done 185/535. Dataloading: 0.0008 s/iter. Inference: 1.2073 s/iter. Eval: 0.9615 s/iter. Total: 2.1697 s/iter. ETA=0:12:39
[08/01 18:36:19] d2.evaluation.evaluator INFO: Inference done 188/535. Dataloading: 0.0008 s/iter. Inference: 1.2088 s/iter. Eval: 0.9617 s/iter. Total: 2.1714 s/iter. ETA=0:12:33
[08/01 18:36:26] d2.evaluation.evaluator INFO: Inference done 191/535. Dataloading: 0.0008 s/iter. Inference: 1.2106 s/iter. Eval: 0.9618 s/iter. Total: 2.1733 s/iter. ETA=0:12:27
[08/01 18:36:32] d2.evaluation.evaluator INFO: Inference done 194/535. Dataloading: 0.0008 s/iter. Inference: 1.2116 s/iter. Eval: 0.9616 s/iter. Total: 2.1741 s/iter. ETA=0:12:21
[08/01 18:36:39] d2.evaluation.evaluator INFO: Inference done 197/535. Dataloading: 0.0008 s/iter. Inference: 1.2131 s/iter. Eval: 0.9614 s/iter. Total: 2.1754 s/iter. ETA=0:12:15
[08/01 18:36:46] d2.evaluation.evaluator INFO: Inference done 200/535. Dataloading: 0.0008 s/iter. Inference: 1.2142 s/iter. Eval: 0.9612 s/iter. Total: 2.1763 s/iter. ETA=0:12:09
[08/01 18:36:53] d2.evaluation.evaluator INFO: Inference done 203/535. Dataloading: 0.0008 s/iter. Inference: 1.2156 s/iter. Eval: 0.9606 s/iter. Total: 2.1771 s/iter. ETA=0:12:02
[08/01 18:36:59] d2.evaluation.evaluator INFO: Inference done 206/535. Dataloading: 0.0008 s/iter. Inference: 1.2169 s/iter. Eval: 0.9604 s/iter. Total: 2.1782 s/iter. ETA=0:11:56
[08/01 18:37:06] d2.evaluation.evaluator INFO: Inference done 209/535. Dataloading: 0.0008 s/iter. Inference: 1.2177 s/iter. Eval: 0.9603 s/iter. Total: 2.1790 s/iter. ETA=0:11:50
[08/01 18:37:13] d2.evaluation.evaluator INFO: Inference done 212/535. Dataloading: 0.0008 s/iter. Inference: 1.2187 s/iter. Eval: 0.9598 s/iter. Total: 2.1794 s/iter. ETA=0:11:43
[08/01 18:37:19] d2.evaluation.evaluator INFO: Inference done 215/535. Dataloading: 0.0008 s/iter. Inference: 1.2196 s/iter. Eval: 0.9599 s/iter. Total: 2.1804 s/iter. ETA=0:11:37
[08/01 18:37:26] d2.evaluation.evaluator INFO: Inference done 218/535. Dataloading: 0.0008 s/iter. Inference: 1.2206 s/iter. Eval: 0.9595 s/iter. Total: 2.1810 s/iter. ETA=0:11:31
[08/01 18:37:33] d2.evaluation.evaluator INFO: Inference done 221/535. Dataloading: 0.0008 s/iter. Inference: 1.2218 s/iter. Eval: 0.9593 s/iter. Total: 2.1819 s/iter. ETA=0:11:25
[08/01 18:37:39] d2.evaluation.evaluator INFO: Inference done 224/535. Dataloading: 0.0008 s/iter. Inference: 1.2225 s/iter. Eval: 0.9589 s/iter. Total: 2.1823 s/iter. ETA=0:11:18
[08/01 18:37:46] d2.evaluation.evaluator INFO: Inference done 227/535. Dataloading: 0.0008 s/iter. Inference: 1.2231 s/iter. Eval: 0.9585 s/iter. Total: 2.1825 s/iter. ETA=0:11:12
[08/01 18:37:53] d2.evaluation.evaluator INFO: Inference done 230/535. Dataloading: 0.0008 s/iter. Inference: 1.2238 s/iter. Eval: 0.9583 s/iter. Total: 2.1830 s/iter. ETA=0:11:05
[08/01 18:37:59] d2.evaluation.evaluator INFO: Inference done 233/535. Dataloading: 0.0008 s/iter. Inference: 1.2244 s/iter. Eval: 0.9578 s/iter. Total: 2.1832 s/iter. ETA=0:10:59
[08/01 18:38:06] d2.evaluation.evaluator INFO: Inference done 236/535. Dataloading: 0.0008 s/iter. Inference: 1.2257 s/iter. Eval: 0.9577 s/iter. Total: 2.1843 s/iter. ETA=0:10:53
[08/01 18:38:13] d2.evaluation.evaluator INFO: Inference done 239/535. Dataloading: 0.0008 s/iter. Inference: 1.2265 s/iter. Eval: 0.9575 s/iter. Total: 2.1848 s/iter. ETA=0:10:46
[08/01 18:38:19] d2.evaluation.evaluator INFO: Inference done 242/535. Dataloading: 0.0008 s/iter. Inference: 1.2271 s/iter. Eval: 0.9576 s/iter. Total: 2.1857 s/iter. ETA=0:10:40
[08/01 18:38:26] d2.evaluation.evaluator INFO: Inference done 245/535. Dataloading: 0.0008 s/iter. Inference: 1.2274 s/iter. Eval: 0.9575 s/iter. Total: 2.1858 s/iter. ETA=0:10:33
[08/01 18:38:33] d2.evaluation.evaluator INFO: Inference done 248/535. Dataloading: 0.0008 s/iter. Inference: 1.2280 s/iter. Eval: 0.9578 s/iter. Total: 2.1867 s/iter. ETA=0:10:27
[08/01 18:38:40] d2.evaluation.evaluator INFO: Inference done 251/535. Dataloading: 0.0008 s/iter. Inference: 1.2290 s/iter. Eval: 0.9575 s/iter. Total: 2.1874 s/iter. ETA=0:10:21
[08/01 18:38:46] d2.evaluation.evaluator INFO: Inference done 254/535. Dataloading: 0.0008 s/iter. Inference: 1.2295 s/iter. Eval: 0.9572 s/iter. Total: 2.1876 s/iter. ETA=0:10:14
[08/01 18:38:53] d2.evaluation.evaluator INFO: Inference done 257/535. Dataloading: 0.0008 s/iter. Inference: 1.2303 s/iter. Eval: 0.9572 s/iter. Total: 2.1884 s/iter. ETA=0:10:08
[08/01 18:38:59] d2.evaluation.evaluator INFO: Inference done 260/535. Dataloading: 0.0008 s/iter. Inference: 1.2305 s/iter. Eval: 0.9569 s/iter. Total: 2.1883 s/iter. ETA=0:10:01
[08/01 18:39:06] d2.evaluation.evaluator INFO: Inference done 263/535. Dataloading: 0.0008 s/iter. Inference: 1.2315 s/iter. Eval: 0.9566 s/iter. Total: 2.1890 s/iter. ETA=0:09:55
[08/01 18:39:13] d2.evaluation.evaluator INFO: Inference done 266/535. Dataloading: 0.0008 s/iter. Inference: 1.2323 s/iter. Eval: 0.9566 s/iter. Total: 2.1897 s/iter. ETA=0:09:49
[08/01 18:39:20] d2.evaluation.evaluator INFO: Inference done 269/535. Dataloading: 0.0008 s/iter. Inference: 1.2332 s/iter. Eval: 0.9564 s/iter. Total: 2.1906 s/iter. ETA=0:09:42
[08/01 18:39:26] d2.evaluation.evaluator INFO: Inference done 272/535. Dataloading: 0.0008 s/iter. Inference: 1.2337 s/iter. Eval: 0.9565 s/iter. Total: 2.1911 s/iter. ETA=0:09:36
[08/01 18:39:33] d2.evaluation.evaluator INFO: Inference done 275/535. Dataloading: 0.0008 s/iter. Inference: 1.2348 s/iter. Eval: 0.9561 s/iter. Total: 2.1919 s/iter. ETA=0:09:29
[08/01 18:39:40] d2.evaluation.evaluator INFO: Inference done 278/535. Dataloading: 0.0008 s/iter. Inference: 1.2358 s/iter. Eval: 0.9558 s/iter. Total: 2.1925 s/iter. ETA=0:09:23
[08/01 18:39:47] d2.evaluation.evaluator INFO: Inference done 281/535. Dataloading: 0.0008 s/iter. Inference: 1.2362 s/iter. Eval: 0.9556 s/iter. Total: 2.1927 s/iter. ETA=0:09:16
[08/01 18:39:53] d2.evaluation.evaluator INFO: Inference done 284/535. Dataloading: 0.0008 s/iter. Inference: 1.2366 s/iter. Eval: 0.9554 s/iter. Total: 2.1929 s/iter. ETA=0:09:10
[08/01 18:40:00] d2.evaluation.evaluator INFO: Inference done 287/535. Dataloading: 0.0008 s/iter. Inference: 1.2371 s/iter. Eval: 0.9553 s/iter. Total: 2.1934 s/iter. ETA=0:09:03
[08/01 18:40:07] d2.evaluation.evaluator INFO: Inference done 290/535. Dataloading: 0.0008 s/iter. Inference: 1.2378 s/iter. Eval: 0.9551 s/iter. Total: 2.1938 s/iter. ETA=0:08:57
[08/01 18:40:13] d2.evaluation.evaluator INFO: Inference done 293/535. Dataloading: 0.0008 s/iter. Inference: 1.2382 s/iter. Eval: 0.9551 s/iter. Total: 2.1942 s/iter. ETA=0:08:50
[08/01 18:40:20] d2.evaluation.evaluator INFO: Inference done 296/535. Dataloading: 0.0008 s/iter. Inference: 1.2388 s/iter. Eval: 0.9549 s/iter. Total: 2.1947 s/iter. ETA=0:08:44
[08/01 18:40:27] d2.evaluation.evaluator INFO: Inference done 299/535. Dataloading: 0.0008 s/iter. Inference: 1.2394 s/iter. Eval: 0.9546 s/iter. Total: 2.1949 s/iter. ETA=0:08:37
[08/01 18:40:33] d2.evaluation.evaluator INFO: Inference done 302/535. Dataloading: 0.0008 s/iter. Inference: 1.2398 s/iter. Eval: 0.9544 s/iter. Total: 2.1951 s/iter. ETA=0:08:31
[08/01 18:40:40] d2.evaluation.evaluator INFO: Inference done 305/535. Dataloading: 0.0008 s/iter. Inference: 1.2405 s/iter. Eval: 0.9541 s/iter. Total: 2.1955 s/iter. ETA=0:08:24
[08/01 18:40:47] d2.evaluation.evaluator INFO: Inference done 308/535. Dataloading: 0.0008 s/iter. Inference: 1.2409 s/iter. Eval: 0.9538 s/iter. Total: 2.1957 s/iter. ETA=0:08:18
[08/01 18:40:53] d2.evaluation.evaluator INFO: Inference done 311/535. Dataloading: 0.0008 s/iter. Inference: 1.2412 s/iter. Eval: 0.9536 s/iter. Total: 2.1958 s/iter. ETA=0:08:11
[08/01 18:41:00] d2.evaluation.evaluator INFO: Inference done 314/535. Dataloading: 0.0008 s/iter. Inference: 1.2416 s/iter. Eval: 0.9536 s/iter. Total: 2.1961 s/iter. ETA=0:08:05
[08/01 18:41:07] d2.evaluation.evaluator INFO: Inference done 317/535. Dataloading: 0.0008 s/iter. Inference: 1.2418 s/iter. Eval: 0.9536 s/iter. Total: 2.1963 s/iter. ETA=0:07:58
[08/01 18:41:13] d2.evaluation.evaluator INFO: Inference done 320/535. Dataloading: 0.0008 s/iter. Inference: 1.2422 s/iter. Eval: 0.9533 s/iter. Total: 2.1964 s/iter. ETA=0:07:52
[08/01 18:41:20] d2.evaluation.evaluator INFO: Inference done 323/535. Dataloading: 0.0008 s/iter. Inference: 1.2426 s/iter. Eval: 0.9530 s/iter. Total: 2.1965 s/iter. ETA=0:07:45
[08/01 18:41:27] d2.evaluation.evaluator INFO: Inference done 326/535. Dataloading: 0.0008 s/iter. Inference: 1.2429 s/iter. Eval: 0.9528 s/iter. Total: 2.1967 s/iter. ETA=0:07:39
[08/01 18:41:33] d2.evaluation.evaluator INFO: Inference done 329/535. Dataloading: 0.0008 s/iter. Inference: 1.2436 s/iter. Eval: 0.9527 s/iter. Total: 2.1972 s/iter. ETA=0:07:32
[08/01 18:41:40] d2.evaluation.evaluator INFO: Inference done 332/535. Dataloading: 0.0008 s/iter. Inference: 1.2438 s/iter. Eval: 0.9527 s/iter. Total: 2.1974 s/iter. ETA=0:07:26
[08/01 18:41:47] d2.evaluation.evaluator INFO: Inference done 335/535. Dataloading: 0.0008 s/iter. Inference: 1.2443 s/iter. Eval: 0.9525 s/iter. Total: 2.1977 s/iter. ETA=0:07:19
[08/01 18:41:53] d2.evaluation.evaluator INFO: Inference done 338/535. Dataloading: 0.0008 s/iter. Inference: 1.2448 s/iter. Eval: 0.9522 s/iter. Total: 2.1979 s/iter. ETA=0:07:12
[08/01 18:42:00] d2.evaluation.evaluator INFO: Inference done 341/535. Dataloading: 0.0008 s/iter. Inference: 1.2455 s/iter. Eval: 0.9520 s/iter. Total: 2.1984 s/iter. ETA=0:07:06
[08/01 18:42:07] d2.evaluation.evaluator INFO: Inference done 344/535. Dataloading: 0.0008 s/iter. Inference: 1.2461 s/iter. Eval: 0.9517 s/iter. Total: 2.1987 s/iter. ETA=0:06:59
[08/01 18:42:14] d2.evaluation.evaluator INFO: Inference done 347/535. Dataloading: 0.0008 s/iter. Inference: 1.2463 s/iter. Eval: 0.9517 s/iter. Total: 2.1990 s/iter. ETA=0:06:53
[08/01 18:42:20] d2.evaluation.evaluator INFO: Inference done 350/535. Dataloading: 0.0008 s/iter. Inference: 1.2467 s/iter. Eval: 0.9516 s/iter. Total: 2.1992 s/iter. ETA=0:06:46
[08/01 18:42:27] d2.evaluation.evaluator INFO: Inference done 353/535. Dataloading: 0.0008 s/iter. Inference: 1.2470 s/iter. Eval: 0.9515 s/iter. Total: 2.1995 s/iter. ETA=0:06:40
[08/01 18:42:34] d2.evaluation.evaluator INFO: Inference done 356/535. Dataloading: 0.0008 s/iter. Inference: 1.2475 s/iter. Eval: 0.9513 s/iter. Total: 2.1997 s/iter. ETA=0:06:33
[08/01 18:42:40] d2.evaluation.evaluator INFO: Inference done 359/535. Dataloading: 0.0008 s/iter. Inference: 1.2478 s/iter. Eval: 0.9513 s/iter. Total: 2.2000 s/iter. ETA=0:06:27
[08/01 18:42:47] d2.evaluation.evaluator INFO: Inference done 362/535. Dataloading: 0.0008 s/iter. Inference: 1.2482 s/iter. Eval: 0.9510 s/iter. Total: 2.2002 s/iter. ETA=0:06:20
[08/01 18:42:54] d2.evaluation.evaluator INFO: Inference done 365/535. Dataloading: 0.0008 s/iter. Inference: 1.2486 s/iter. Eval: 0.9512 s/iter. Total: 2.2007 s/iter. ETA=0:06:14
[08/01 18:43:01] d2.evaluation.evaluator INFO: Inference done 368/535. Dataloading: 0.0008 s/iter. Inference: 1.2492 s/iter. Eval: 0.9510 s/iter. Total: 2.2012 s/iter. ETA=0:06:07
[08/01 18:43:07] d2.evaluation.evaluator INFO: Inference done 371/535. Dataloading: 0.0008 s/iter. Inference: 1.2499 s/iter. Eval: 0.9508 s/iter. Total: 2.2016 s/iter. ETA=0:06:01
[08/01 18:43:14] d2.evaluation.evaluator INFO: Inference done 374/535. Dataloading: 0.0008 s/iter. Inference: 1.2503 s/iter. Eval: 0.9507 s/iter. Total: 2.2018 s/iter. ETA=0:05:54
[08/01 18:43:21] d2.evaluation.evaluator INFO: Inference done 377/535. Dataloading: 0.0008 s/iter. Inference: 1.2506 s/iter. Eval: 0.9505 s/iter. Total: 2.2020 s/iter. ETA=0:05:47
[08/01 18:43:27] d2.evaluation.evaluator INFO: Inference done 380/535. Dataloading: 0.0008 s/iter. Inference: 1.2506 s/iter. Eval: 0.9507 s/iter. Total: 2.2022 s/iter. ETA=0:05:41
[08/01 18:43:34] d2.evaluation.evaluator INFO: Inference done 383/535. Dataloading: 0.0008 s/iter. Inference: 1.2510 s/iter. Eval: 0.9506 s/iter. Total: 2.2025 s/iter. ETA=0:05:34
[08/01 18:43:41] d2.evaluation.evaluator INFO: Inference done 386/535. Dataloading: 0.0008 s/iter. Inference: 1.2514 s/iter. Eval: 0.9505 s/iter. Total: 2.2028 s/iter. ETA=0:05:28
[08/01 18:43:47] d2.evaluation.evaluator INFO: Inference done 389/535. Dataloading: 0.0008 s/iter. Inference: 1.2518 s/iter. Eval: 0.9505 s/iter. Total: 2.2032 s/iter. ETA=0:05:21
[08/01 18:43:54] d2.evaluation.evaluator INFO: Inference done 392/535. Dataloading: 0.0008 s/iter. Inference: 1.2520 s/iter. Eval: 0.9505 s/iter. Total: 2.2034 s/iter. ETA=0:05:15
[08/01 18:44:01] d2.evaluation.evaluator INFO: Inference done 395/535. Dataloading: 0.0008 s/iter. Inference: 1.2521 s/iter. Eval: 0.9504 s/iter. Total: 2.2033 s/iter. ETA=0:05:08
[08/01 18:44:08] d2.evaluation.evaluator INFO: Inference done 398/535. Dataloading: 0.0008 s/iter. Inference: 1.2526 s/iter. Eval: 0.9503 s/iter. Total: 2.2038 s/iter. ETA=0:05:01
[08/01 18:44:14] d2.evaluation.evaluator INFO: Inference done 401/535. Dataloading: 0.0008 s/iter. Inference: 1.2527 s/iter. Eval: 0.9503 s/iter. Total: 2.2039 s/iter. ETA=0:04:55
[08/01 18:44:21] d2.evaluation.evaluator INFO: Inference done 404/535. Dataloading: 0.0008 s/iter. Inference: 1.2532 s/iter. Eval: 0.9502 s/iter. Total: 2.2043 s/iter. ETA=0:04:48
[08/01 18:44:28] d2.evaluation.evaluator INFO: Inference done 407/535. Dataloading: 0.0008 s/iter. Inference: 1.2534 s/iter. Eval: 0.9500 s/iter. Total: 2.2043 s/iter. ETA=0:04:42
[08/01 18:44:34] d2.evaluation.evaluator INFO: Inference done 410/535. Dataloading: 0.0008 s/iter. Inference: 1.2536 s/iter. Eval: 0.9500 s/iter. Total: 2.2045 s/iter. ETA=0:04:35
[08/01 18:44:41] d2.evaluation.evaluator INFO: Inference done 413/535. Dataloading: 0.0008 s/iter. Inference: 1.2536 s/iter. Eval: 0.9498 s/iter. Total: 2.2043 s/iter. ETA=0:04:28
[08/01 18:44:48] d2.evaluation.evaluator INFO: Inference done 416/535. Dataloading: 0.0008 s/iter. Inference: 1.2540 s/iter. Eval: 0.9498 s/iter. Total: 2.2047 s/iter. ETA=0:04:22
[08/01 18:44:54] d2.evaluation.evaluator INFO: Inference done 419/535. Dataloading: 0.0008 s/iter. Inference: 1.2545 s/iter. Eval: 0.9497 s/iter. Total: 2.2050 s/iter. ETA=0:04:15
[08/01 18:45:01] d2.evaluation.evaluator INFO: Inference done 422/535. Dataloading: 0.0008 s/iter. Inference: 1.2546 s/iter. Eval: 0.9498 s/iter. Total: 2.2052 s/iter. ETA=0:04:09
[08/01 18:45:08] d2.evaluation.evaluator INFO: Inference done 425/535. Dataloading: 0.0008 s/iter. Inference: 1.2547 s/iter. Eval: 0.9498 s/iter. Total: 2.2054 s/iter. ETA=0:04:02
[08/01 18:45:14] d2.evaluation.evaluator INFO: Inference done 428/535. Dataloading: 0.0008 s/iter. Inference: 1.2547 s/iter. Eval: 0.9498 s/iter. Total: 2.2054 s/iter. ETA=0:03:55
[08/01 18:45:21] d2.evaluation.evaluator INFO: Inference done 431/535. Dataloading: 0.0008 s/iter. Inference: 1.2553 s/iter. Eval: 0.9498 s/iter. Total: 2.2060 s/iter. ETA=0:03:49
[08/01 18:45:28] d2.evaluation.evaluator INFO: Inference done 434/535. Dataloading: 0.0008 s/iter. Inference: 1.2554 s/iter. Eval: 0.9498 s/iter. Total: 2.2060 s/iter. ETA=0:03:42
[08/01 18:45:34] d2.evaluation.evaluator INFO: Inference done 437/535. Dataloading: 0.0008 s/iter. Inference: 1.2555 s/iter. Eval: 0.9496 s/iter. Total: 2.2060 s/iter. ETA=0:03:36
[08/01 18:45:41] d2.evaluation.evaluator INFO: Inference done 440/535. Dataloading: 0.0008 s/iter. Inference: 1.2557 s/iter. Eval: 0.9494 s/iter. Total: 2.2060 s/iter. ETA=0:03:29
[08/01 18:45:48] d2.evaluation.evaluator INFO: Inference done 443/535. Dataloading: 0.0008 s/iter. Inference: 1.2557 s/iter. Eval: 0.9493 s/iter. Total: 2.2060 s/iter. ETA=0:03:22
[08/01 18:45:54] d2.evaluation.evaluator INFO: Inference done 446/535. Dataloading: 0.0008 s/iter. Inference: 1.2561 s/iter. Eval: 0.9492 s/iter. Total: 2.2061 s/iter. ETA=0:03:16
[08/01 18:46:01] d2.evaluation.evaluator INFO: Inference done 449/535. Dataloading: 0.0008 s/iter. Inference: 1.2564 s/iter. Eval: 0.9492 s/iter. Total: 2.2065 s/iter. ETA=0:03:09
[08/01 18:46:08] d2.evaluation.evaluator INFO: Inference done 452/535. Dataloading: 0.0008 s/iter. Inference: 1.2569 s/iter. Eval: 0.9492 s/iter. Total: 2.2070 s/iter. ETA=0:03:03
[08/01 18:46:15] d2.evaluation.evaluator INFO: Inference done 455/535. Dataloading: 0.0008 s/iter. Inference: 1.2570 s/iter. Eval: 0.9491 s/iter. Total: 2.2070 s/iter. ETA=0:02:56
[08/01 18:46:21] d2.evaluation.evaluator INFO: Inference done 458/535. Dataloading: 0.0008 s/iter. Inference: 1.2571 s/iter. Eval: 0.9491 s/iter. Total: 2.2071 s/iter. ETA=0:02:49
[08/01 18:46:28] d2.evaluation.evaluator INFO: Inference done 461/535. Dataloading: 0.0008 s/iter. Inference: 1.2573 s/iter. Eval: 0.9491 s/iter. Total: 2.2073 s/iter. ETA=0:02:43
[08/01 18:46:35] d2.evaluation.evaluator INFO: Inference done 464/535. Dataloading: 0.0008 s/iter. Inference: 1.2574 s/iter. Eval: 0.9489 s/iter. Total: 2.2073 s/iter. ETA=0:02:36
[08/01 18:46:41] d2.evaluation.evaluator INFO: Inference done 467/535. Dataloading: 0.0008 s/iter. Inference: 1.2575 s/iter. Eval: 0.9488 s/iter. Total: 2.2072 s/iter. ETA=0:02:30
[08/01 18:46:48] d2.evaluation.evaluator INFO: Inference done 470/535. Dataloading: 0.0008 s/iter. Inference: 1.2577 s/iter. Eval: 0.9486 s/iter. Total: 2.2072 s/iter. ETA=0:02:23
[08/01 18:46:54] d2.evaluation.evaluator INFO: Inference done 473/535. Dataloading: 0.0008 s/iter. Inference: 1.2578 s/iter. Eval: 0.9484 s/iter. Total: 2.2071 s/iter. ETA=0:02:16
[08/01 18:47:01] d2.evaluation.evaluator INFO: Inference done 476/535. Dataloading: 0.0008 s/iter. Inference: 1.2579 s/iter. Eval: 0.9483 s/iter. Total: 2.2071 s/iter. ETA=0:02:10
[08/01 18:47:08] d2.evaluation.evaluator INFO: Inference done 479/535. Dataloading: 0.0008 s/iter. Inference: 1.2583 s/iter. Eval: 0.9481 s/iter. Total: 2.2073 s/iter. ETA=0:02:03
[08/01 18:47:14] d2.evaluation.evaluator INFO: Inference done 482/535. Dataloading: 0.0008 s/iter. Inference: 1.2586 s/iter. Eval: 0.9479 s/iter. Total: 2.2074 s/iter. ETA=0:01:56
[08/01 18:47:21] d2.evaluation.evaluator INFO: Inference done 485/535. Dataloading: 0.0008 s/iter. Inference: 1.2587 s/iter. Eval: 0.9479 s/iter. Total: 2.2075 s/iter. ETA=0:01:50
[08/01 18:47:28] d2.evaluation.evaluator INFO: Inference done 488/535. Dataloading: 0.0008 s/iter. Inference: 1.2588 s/iter. Eval: 0.9478 s/iter. Total: 2.2075 s/iter. ETA=0:01:43
[08/01 18:47:34] d2.evaluation.evaluator INFO: Inference done 491/535. Dataloading: 0.0008 s/iter. Inference: 1.2590 s/iter. Eval: 0.9477 s/iter. Total: 2.2077 s/iter. ETA=0:01:37
[08/01 18:47:41] d2.evaluation.evaluator INFO: Inference done 494/535. Dataloading: 0.0008 s/iter. Inference: 1.2592 s/iter. Eval: 0.9476 s/iter. Total: 2.2077 s/iter. ETA=0:01:30
[08/01 18:47:48] d2.evaluation.evaluator INFO: Inference done 497/535. Dataloading: 0.0008 s/iter. Inference: 1.2598 s/iter. Eval: 0.9475 s/iter. Total: 2.2082 s/iter. ETA=0:01:23
[08/01 18:47:55] d2.evaluation.evaluator INFO: Inference done 500/535. Dataloading: 0.0008 s/iter. Inference: 1.2600 s/iter. Eval: 0.9476 s/iter. Total: 2.2085 s/iter. ETA=0:01:17
[08/01 18:48:01] d2.evaluation.evaluator INFO: Inference done 503/535. Dataloading: 0.0008 s/iter. Inference: 1.2603 s/iter. Eval: 0.9477 s/iter. Total: 2.2088 s/iter. ETA=0:01:10
[08/01 18:48:08] d2.evaluation.evaluator INFO: Inference done 506/535. Dataloading: 0.0008 s/iter. Inference: 1.2605 s/iter. Eval: 0.9477 s/iter. Total: 2.2090 s/iter. ETA=0:01:04
[08/01 18:48:15] d2.evaluation.evaluator INFO: Inference done 509/535. Dataloading: 0.0008 s/iter. Inference: 1.2607 s/iter. Eval: 0.9478 s/iter. Total: 2.2095 s/iter. ETA=0:00:57
[08/01 18:48:22] d2.evaluation.evaluator INFO: Inference done 512/535. Dataloading: 0.0008 s/iter. Inference: 1.2609 s/iter. Eval: 0.9477 s/iter. Total: 2.2096 s/iter. ETA=0:00:50
[08/01 18:48:28] d2.evaluation.evaluator INFO: Inference done 515/535. Dataloading: 0.0008 s/iter. Inference: 1.2612 s/iter. Eval: 0.9476 s/iter. Total: 2.2097 s/iter. ETA=0:00:44
[08/01 18:48:35] d2.evaluation.evaluator INFO: Inference done 518/535. Dataloading: 0.0008 s/iter. Inference: 1.2613 s/iter. Eval: 0.9476 s/iter. Total: 2.2098 s/iter. ETA=0:00:37
[08/01 18:48:42] d2.evaluation.evaluator INFO: Inference done 521/535. Dataloading: 0.0008 s/iter. Inference: 1.2613 s/iter. Eval: 0.9476 s/iter. Total: 2.2098 s/iter. ETA=0:00:30
[08/01 18:48:48] d2.evaluation.evaluator INFO: Inference done 524/535. Dataloading: 0.0008 s/iter. Inference: 1.2611 s/iter. Eval: 0.9478 s/iter. Total: 2.2098 s/iter. ETA=0:00:24
[08/01 18:48:55] d2.evaluation.evaluator INFO: Inference done 527/535. Dataloading: 0.0008 s/iter. Inference: 1.2612 s/iter. Eval: 0.9477 s/iter. Total: 2.2098 s/iter. ETA=0:00:17
[08/01 18:49:02] d2.evaluation.evaluator INFO: Inference done 530/535. Dataloading: 0.0008 s/iter. Inference: 1.2613 s/iter. Eval: 0.9476 s/iter. Total: 2.2099 s/iter. ETA=0:00:11
[08/01 18:49:08] d2.evaluation.evaluator INFO: Inference done 533/535. Dataloading: 0.0008 s/iter. Inference: 1.2616 s/iter. Eval: 0.9475 s/iter. Total: 2.2100 s/iter. ETA=0:00:04
[08/01 18:49:13] d2.evaluation.evaluator INFO: Total inference time: 0:19:31.436406 (2.210257 s / iter per device, on 1 devices)
[08/01 18:49:13] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:11:08 (1.261687 s / iter per device, on 1 devices)
[08/01 18:49:14] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[08/01 18:49:14] d2.evaluation.coco_evaluation INFO: Saving results to ./R101_overlap/inference/coco_instances_results.json
[08/01 18:49:14] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[08/01 18:49:16] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 |  nan  | 0.000 |
[08/01 18:49:16] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 18:49:16] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| normal     | 0.000 | defect     | 0.000 |
[08/01 18:49:23] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl   |
|:------:|:------:|:------:|:------:|:-----:|:------:|
| 93.288 | 95.308 | 94.303 | 86.210 |  nan  | 93.288 |
[08/01 18:49:23] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 18:49:23] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| normal     | 96.604 | defect     | 89.973 |
[08/01 18:49:23] d2.engine.defaults INFO: Evaluation results for front2class_2017_val_overlap_panoptic in csv format:
[08/01 18:49:23] d2.evaluation.testing INFO: copypaste: Task: bbox
[08/01 18:49:23] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 18:49:23] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,nan,0.0000
[08/01 18:49:23] d2.evaluation.testing INFO: copypaste: Task: segm
[08/01 18:49:23] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 18:49:23] d2.evaluation.testing INFO: copypaste: 93.2884,95.3077,94.3034,86.2102,nan,93.2884
[08/01 18:49:23] d2.utils.events INFO:  eta: 5:36:18  iter: 9999  total_loss: 3.26  loss_ce: 0.0006518  loss_mask: 0.1263  loss_dice: 0.1826  loss_ce_0: 0.1291  loss_mask_0: 0.1316  loss_dice_0: 0.1841  loss_ce_1: 0.005099  loss_mask_1: 0.1358  loss_dice_1: 0.1755  loss_ce_2: 0.0006863  loss_mask_2: 0.1304  loss_dice_2: 0.1735  loss_ce_3: 0.0006489  loss_mask_3: 0.1251  loss_dice_3: 0.1853  loss_ce_4: 0.000794  loss_mask_4: 0.1231  loss_dice_4: 0.1748  loss_ce_5: 0.0006183  loss_mask_5: 0.1255  loss_dice_5: 0.1785  loss_ce_6: 0.0009389  loss_mask_6: 0.1289  loss_dice_6: 0.1736  loss_ce_7: 0.0005877  loss_mask_7: 0.1198  loss_dice_7: 0.1761  loss_ce_8: 0.0003784  loss_mask_8: 0.1275  loss_dice_8: 0.1809  time: 0.6090  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:49:23] fvcore.common.checkpoint INFO: Saving checkpoint to ./R101_overlap/model_best.pth
[08/01 18:49:23] d2.engine.hooks INFO: Saved best model as latest eval score for total_loss is3.09764, better than last best score 3.55589 @ iteration 4999.
[08/01 18:49:40] d2.utils.events INFO:  eta: 5:36:02  iter: 10019  total_loss: 3.298  loss_ce: 0.0003369  loss_mask: 0.12  loss_dice: 0.1753  loss_ce_0: 0.1214  loss_mask_0: 0.1222  loss_dice_0: 0.1851  loss_ce_1: 0.002836  loss_mask_1: 0.1293  loss_dice_1: 0.1806  loss_ce_2: 0.0007652  loss_mask_2: 0.1266  loss_dice_2: 0.1844  loss_ce_3: 0.001391  loss_mask_3: 0.1209  loss_dice_3: 0.1854  loss_ce_4: 0.001988  loss_mask_4: 0.1178  loss_dice_4: 0.1835  loss_ce_5: 0.000488  loss_mask_5: 0.1245  loss_dice_5: 0.1762  loss_ce_6: 0.0005713  loss_mask_6: 0.1234  loss_dice_6: 0.1847  loss_ce_7: 0.0004299  loss_mask_7: 0.1231  loss_dice_7: 0.1824  loss_ce_8: 0.000337  loss_mask_8: 0.1271  loss_dice_8: 0.1814  time: 0.6095  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:49:57] d2.utils.events INFO:  eta: 5:35:49  iter: 10039  total_loss: 2.959  loss_ce: 0.0002571  loss_mask: 0.1168  loss_dice: 0.1689  loss_ce_0: 0.1266  loss_mask_0: 0.1119  loss_dice_0: 0.1681  loss_ce_1: 0.0006269  loss_mask_1: 0.1163  loss_dice_1: 0.1685  loss_ce_2: 0.0002839  loss_mask_2: 0.111  loss_dice_2: 0.1647  loss_ce_3: 0.0003436  loss_mask_3: 0.1191  loss_dice_3: 0.1666  loss_ce_4: 0.0002289  loss_mask_4: 0.1163  loss_dice_4: 0.1702  loss_ce_5: 0.0002556  loss_mask_5: 0.1157  loss_dice_5: 0.1662  loss_ce_6: 0.0002955  loss_mask_6: 0.1117  loss_dice_6: 0.1676  loss_ce_7: 0.0002959  loss_mask_7: 0.1165  loss_dice_7: 0.1681  loss_ce_8: 0.0002971  loss_mask_8: 0.1155  loss_dice_8: 0.1637  time: 0.6100  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:50:14] d2.utils.events INFO:  eta: 5:35:30  iter: 10059  total_loss: 3.15  loss_ce: 0.0001844  loss_mask: 0.1225  loss_dice: 0.1793  loss_ce_0: 0.1305  loss_mask_0: 0.1232  loss_dice_0: 0.1862  loss_ce_1: 0.0008249  loss_mask_1: 0.1214  loss_dice_1: 0.1819  loss_ce_2: 0.0002039  loss_mask_2: 0.1222  loss_dice_2: 0.1781  loss_ce_3: 0.0001848  loss_mask_3: 0.1245  loss_dice_3: 0.1782  loss_ce_4: 0.0001538  loss_mask_4: 0.1244  loss_dice_4: 0.1785  loss_ce_5: 0.0002389  loss_mask_5: 0.1217  loss_dice_5: 0.176  loss_ce_6: 0.0002149  loss_mask_6: 0.1242  loss_dice_6: 0.1824  loss_ce_7: 0.0001218  loss_mask_7: 0.1225  loss_dice_7: 0.1821  loss_ce_8: 0.0001368  loss_mask_8: 0.1183  loss_dice_8: 0.179  time: 0.6104  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:50:31] d2.utils.events INFO:  eta: 5:35:12  iter: 10079  total_loss: 3.189  loss_ce: 0.0002122  loss_mask: 0.1223  loss_dice: 0.1874  loss_ce_0: 0.1242  loss_mask_0: 0.1301  loss_dice_0: 0.1859  loss_ce_1: 0.0004589  loss_mask_1: 0.1227  loss_dice_1: 0.1842  loss_ce_2: 0.0002008  loss_mask_2: 0.1244  loss_dice_2: 0.1907  loss_ce_3: 0.0002406  loss_mask_3: 0.1242  loss_dice_3: 0.189  loss_ce_4: 0.0001492  loss_mask_4: 0.1232  loss_dice_4: 0.1914  loss_ce_5: 0.0002156  loss_mask_5: 0.1246  loss_dice_5: 0.1829  loss_ce_6: 0.0002109  loss_mask_6: 0.1192  loss_dice_6: 0.189  loss_ce_7: 0.000185  loss_mask_7: 0.1236  loss_dice_7: 0.1881  loss_ce_8: 0.0002496  loss_mask_8: 0.1247  loss_dice_8: 0.1944  time: 0.6109  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:50:48] d2.utils.events INFO:  eta: 5:34:56  iter: 10099  total_loss: 3.059  loss_ce: 0.0001222  loss_mask: 0.1196  loss_dice: 0.1721  loss_ce_0: 0.1228  loss_mask_0: 0.1205  loss_dice_0: 0.1683  loss_ce_1: 0.0003976  loss_mask_1: 0.1189  loss_dice_1: 0.1731  loss_ce_2: 0.0001926  loss_mask_2: 0.1184  loss_dice_2: 0.1723  loss_ce_3: 0.0001852  loss_mask_3: 0.1202  loss_dice_3: 0.1718  loss_ce_4: 0.000118  loss_mask_4: 0.1224  loss_dice_4: 0.1772  loss_ce_5: 0.0001842  loss_mask_5: 0.1188  loss_dice_5: 0.1717  loss_ce_6: 0.0001662  loss_mask_6: 0.121  loss_dice_6: 0.1736  loss_ce_7: 0.0001382  loss_mask_7: 0.121  loss_dice_7: 0.1765  loss_ce_8: 0.000154  loss_mask_8: 0.1196  loss_dice_8: 0.1743  time: 0.6113  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:51:05] d2.utils.events INFO:  eta: 5:34:40  iter: 10119  total_loss: 3.337  loss_ce: 0.0001505  loss_mask: 0.1284  loss_dice: 0.19  loss_ce_0: 0.1199  loss_mask_0: 0.1288  loss_dice_0: 0.1932  loss_ce_1: 0.0004878  loss_mask_1: 0.1307  loss_dice_1: 0.1909  loss_ce_2: 0.0001812  loss_mask_2: 0.1277  loss_dice_2: 0.1865  loss_ce_3: 0.0001546  loss_mask_3: 0.1278  loss_dice_3: 0.1878  loss_ce_4: 0.0001003  loss_mask_4: 0.1309  loss_dice_4: 0.1899  loss_ce_5: 0.0001715  loss_mask_5: 0.1271  loss_dice_5: 0.1909  loss_ce_6: 0.0001733  loss_mask_6: 0.1262  loss_dice_6: 0.197  loss_ce_7: 0.0001599  loss_mask_7: 0.1276  loss_dice_7: 0.1885  loss_ce_8: 0.0002108  loss_mask_8: 0.124  loss_dice_8: 0.1912  time: 0.6118  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:51:22] d2.utils.events INFO:  eta: 5:34:22  iter: 10139  total_loss: 3.005  loss_ce: 0.0001116  loss_mask: 0.1199  loss_dice: 0.1649  loss_ce_0: 0.1212  loss_mask_0: 0.118  loss_dice_0: 0.1703  loss_ce_1: 0.0003416  loss_mask_1: 0.115  loss_dice_1: 0.1733  loss_ce_2: 0.0001717  loss_mask_2: 0.1139  loss_dice_2: 0.1688  loss_ce_3: 0.0001306  loss_mask_3: 0.1191  loss_dice_3: 0.1662  loss_ce_4: 0.0001068  loss_mask_4: 0.1177  loss_dice_4: 0.1672  loss_ce_5: 0.0001453  loss_mask_5: 0.1187  loss_dice_5: 0.1713  loss_ce_6: 0.0001333  loss_mask_6: 0.1141  loss_dice_6: 0.1616  loss_ce_7: 0.0001442  loss_mask_7: 0.118  loss_dice_7: 0.1695  loss_ce_8: 0.0001751  loss_mask_8: 0.1188  loss_dice_8: 0.1678  time: 0.6123  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:51:39] d2.utils.events INFO:  eta: 5:33:59  iter: 10159  total_loss: 3.415  loss_ce: 8.972e-05  loss_mask: 0.1288  loss_dice: 0.1956  loss_ce_0: 0.1236  loss_mask_0: 0.1263  loss_dice_0: 0.1933  loss_ce_1: 0.0002397  loss_mask_1: 0.1296  loss_dice_1: 0.1929  loss_ce_2: 0.0001535  loss_mask_2: 0.1327  loss_dice_2: 0.1933  loss_ce_3: 0.000132  loss_mask_3: 0.1251  loss_dice_3: 0.1902  loss_ce_4: 8.301e-05  loss_mask_4: 0.1281  loss_dice_4: 0.2004  loss_ce_5: 0.0001207  loss_mask_5: 0.1276  loss_dice_5: 0.1952  loss_ce_6: 0.0001193  loss_mask_6: 0.1277  loss_dice_6: 0.1945  loss_ce_7: 0.0001271  loss_mask_7: 0.1263  loss_dice_7: 0.1902  loss_ce_8: 0.0001561  loss_mask_8: 0.1285  loss_dice_8: 0.1913  time: 0.6127  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:51:56] d2.utils.events INFO:  eta: 5:33:46  iter: 10179  total_loss: 3.113  loss_ce: 7.946e-05  loss_mask: 0.1175  loss_dice: 0.1754  loss_ce_0: 0.1199  loss_mask_0: 0.1226  loss_dice_0: 0.1745  loss_ce_1: 0.0002509  loss_mask_1: 0.1207  loss_dice_1: 0.1808  loss_ce_2: 0.0001415  loss_mask_2: 0.1186  loss_dice_2: 0.1723  loss_ce_3: 0.0001144  loss_mask_3: 0.1188  loss_dice_3: 0.1775  loss_ce_4: 7.437e-05  loss_mask_4: 0.1198  loss_dice_4: 0.1727  loss_ce_5: 0.0001262  loss_mask_5: 0.1182  loss_dice_5: 0.1706  loss_ce_6: 0.0001084  loss_mask_6: 0.1217  loss_dice_6: 0.1704  loss_ce_7: 0.0001107  loss_mask_7: 0.1186  loss_dice_7: 0.1798  loss_ce_8: 0.0001444  loss_mask_8: 0.1187  loss_dice_8: 0.1726  time: 0.6132  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:52:13] d2.utils.events INFO:  eta: 5:33:30  iter: 10199  total_loss: 3.167  loss_ce: 0.0001304  loss_mask: 0.1216  loss_dice: 0.1787  loss_ce_0: 0.1303  loss_mask_0: 0.1224  loss_dice_0: 0.1806  loss_ce_1: 0.0002786  loss_mask_1: 0.1214  loss_dice_1: 0.1827  loss_ce_2: 0.000142  loss_mask_2: 0.1213  loss_dice_2: 0.1778  loss_ce_3: 0.0001068  loss_mask_3: 0.1208  loss_dice_3: 0.1864  loss_ce_4: 9.27e-05  loss_mask_4: 0.1227  loss_dice_4: 0.181  loss_ce_5: 0.0001182  loss_mask_5: 0.1191  loss_dice_5: 0.1776  loss_ce_6: 0.0001186  loss_mask_6: 0.1191  loss_dice_6: 0.185  loss_ce_7: 0.0001017  loss_mask_7: 0.1184  loss_dice_7: 0.1821  loss_ce_8: 0.000159  loss_mask_8: 0.1178  loss_dice_8: 0.1762  time: 0.6136  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:52:30] d2.utils.events INFO:  eta: 5:33:17  iter: 10219  total_loss: 3.414  loss_ce: 0.0001353  loss_mask: 0.1195  loss_dice: 0.2015  loss_ce_0: 0.1143  loss_mask_0: 0.1221  loss_dice_0: 0.1951  loss_ce_1: 0.0003426  loss_mask_1: 0.1223  loss_dice_1: 0.2008  loss_ce_2: 0.0001471  loss_mask_2: 0.1216  loss_dice_2: 0.1987  loss_ce_3: 0.0001096  loss_mask_3: 0.1208  loss_dice_3: 0.1976  loss_ce_4: 7.192e-05  loss_mask_4: 0.122  loss_dice_4: 0.1931  loss_ce_5: 0.0001533  loss_mask_5: 0.1208  loss_dice_5: 0.1941  loss_ce_6: 0.0001317  loss_mask_6: 0.1239  loss_dice_6: 0.203  loss_ce_7: 0.0001194  loss_mask_7: 0.1187  loss_dice_7: 0.1986  loss_ce_8: 0.0001741  loss_mask_8: 0.1241  loss_dice_8: 0.1973  time: 0.6141  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:52:47] d2.utils.events INFO:  eta: 5:33:03  iter: 10239  total_loss: 3.075  loss_ce: 8.62e-05  loss_mask: 0.1208  loss_dice: 0.1756  loss_ce_0: 0.1248  loss_mask_0: 0.1204  loss_dice_0: 0.1772  loss_ce_1: 0.0002564  loss_mask_1: 0.1194  loss_dice_1: 0.1769  loss_ce_2: 0.0001279  loss_mask_2: 0.1182  loss_dice_2: 0.1764  loss_ce_3: 0.0001046  loss_mask_3: 0.1173  loss_dice_3: 0.1762  loss_ce_4: 7.378e-05  loss_mask_4: 0.1187  loss_dice_4: 0.1794  loss_ce_5: 0.0001197  loss_mask_5: 0.1182  loss_dice_5: 0.1757  loss_ce_6: 0.000106  loss_mask_6: 0.1187  loss_dice_6: 0.1691  loss_ce_7: 9.283e-05  loss_mask_7: 0.1223  loss_dice_7: 0.1784  loss_ce_8: 0.0001206  loss_mask_8: 0.1227  loss_dice_8: 0.1749  time: 0.6145  data_time: 0.0017  lr: 0.0001  max_mem: 8444M
[08/01 18:53:03] d2.utils.events INFO:  eta: 5:32:44  iter: 10259  total_loss: 3.103  loss_ce: 8.399e-05  loss_mask: 0.1177  loss_dice: 0.1679  loss_ce_0: 0.1284  loss_mask_0: 0.1222  loss_dice_0: 0.1716  loss_ce_1: 0.0001739  loss_mask_1: 0.1211  loss_dice_1: 0.1717  loss_ce_2: 0.0001283  loss_mask_2: 0.1226  loss_dice_2: 0.1666  loss_ce_3: 0.0001064  loss_mask_3: 0.1211  loss_dice_3: 0.1733  loss_ce_4: 8.694e-05  loss_mask_4: 0.1193  loss_dice_4: 0.1719  loss_ce_5: 9.671e-05  loss_mask_5: 0.125  loss_dice_5: 0.1653  loss_ce_6: 0.0001045  loss_mask_6: 0.1269  loss_dice_6: 0.1761  loss_ce_7: 9.048e-05  loss_mask_7: 0.1225  loss_dice_7: 0.1753  loss_ce_8: 0.0001221  loss_mask_8: 0.1217  loss_dice_8: 0.167  time: 0.6150  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:53:20] d2.utils.events INFO:  eta: 5:32:29  iter: 10279  total_loss: 3.042  loss_ce: 9.544e-05  loss_mask: 0.1223  loss_dice: 0.1726  loss_ce_0: 0.1212  loss_mask_0: 0.1203  loss_dice_0: 0.1719  loss_ce_1: 0.0002384  loss_mask_1: 0.12  loss_dice_1: 0.1698  loss_ce_2: 0.0001383  loss_mask_2: 0.1162  loss_dice_2: 0.1711  loss_ce_3: 9.839e-05  loss_mask_3: 0.1166  loss_dice_3: 0.174  loss_ce_4: 8.768e-05  loss_mask_4: 0.1175  loss_dice_4: 0.1717  loss_ce_5: 0.0001078  loss_mask_5: 0.1169  loss_dice_5: 0.1715  loss_ce_6: 9.794e-05  loss_mask_6: 0.1171  loss_dice_6: 0.1709  loss_ce_7: 7.63e-05  loss_mask_7: 0.1156  loss_dice_7: 0.1686  loss_ce_8: 0.0001068  loss_mask_8: 0.1197  loss_dice_8: 0.1731  time: 0.6154  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 18:53:37] d2.utils.events INFO:  eta: 5:32:01  iter: 10299  total_loss: 3.03  loss_ce: 0.000104  loss_mask: 0.1142  loss_dice: 0.1689  loss_ce_0: 0.1217  loss_mask_0: 0.1177  loss_dice_0: 0.1716  loss_ce_1: 0.0002311  loss_mask_1: 0.1161  loss_dice_1: 0.1724  loss_ce_2: 0.0001418  loss_mask_2: 0.1139  loss_dice_2: 0.1683  loss_ce_3: 9.707e-05  loss_mask_3: 0.1127  loss_dice_3: 0.1745  loss_ce_4: 7.709e-05  loss_mask_4: 0.1169  loss_dice_4: 0.1679  loss_ce_5: 0.0001103  loss_mask_5: 0.1149  loss_dice_5: 0.1657  loss_ce_6: 0.0001051  loss_mask_6: 0.1156  loss_dice_6: 0.1693  loss_ce_7: 8.583e-05  loss_mask_7: 0.1178  loss_dice_7: 0.1758  loss_ce_8: 0.0001195  loss_mask_8: 0.1153  loss_dice_8: 0.1767  time: 0.6159  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:53:54] d2.utils.events INFO:  eta: 5:31:54  iter: 10319  total_loss: 3.004  loss_ce: 7.369e-05  loss_mask: 0.1166  loss_dice: 0.1771  loss_ce_0: 0.1198  loss_mask_0: 0.1158  loss_dice_0: 0.1765  loss_ce_1: 0.0001667  loss_mask_1: 0.1161  loss_dice_1: 0.1729  loss_ce_2: 0.0001126  loss_mask_2: 0.1165  loss_dice_2: 0.1722  loss_ce_3: 8.689e-05  loss_mask_3: 0.114  loss_dice_3: 0.1712  loss_ce_4: 7.212e-05  loss_mask_4: 0.1156  loss_dice_4: 0.169  loss_ce_5: 9.532e-05  loss_mask_5: 0.1157  loss_dice_5: 0.1719  loss_ce_6: 9.589e-05  loss_mask_6: 0.1151  loss_dice_6: 0.1774  loss_ce_7: 8.273e-05  loss_mask_7: 0.1132  loss_dice_7: 0.1737  loss_ce_8: 0.0001115  loss_mask_8: 0.1188  loss_dice_8: 0.1734  time: 0.6163  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:54:11] d2.utils.events INFO:  eta: 5:32:00  iter: 10339  total_loss: 3.075  loss_ce: 8.352e-05  loss_mask: 0.1132  loss_dice: 0.1721  loss_ce_0: 0.1251  loss_mask_0: 0.1198  loss_dice_0: 0.1748  loss_ce_1: 0.0001767  loss_mask_1: 0.118  loss_dice_1: 0.1744  loss_ce_2: 0.0001331  loss_mask_2: 0.1164  loss_dice_2: 0.1744  loss_ce_3: 0.000105  loss_mask_3: 0.1155  loss_dice_3: 0.1782  loss_ce_4: 6.478e-05  loss_mask_4: 0.1182  loss_dice_4: 0.175  loss_ce_5: 0.0001111  loss_mask_5: 0.1186  loss_dice_5: 0.1785  loss_ce_6: 0.0001013  loss_mask_6: 0.1161  loss_dice_6: 0.1737  loss_ce_7: 7.523e-05  loss_mask_7: 0.1133  loss_dice_7: 0.1713  loss_ce_8: 0.0001194  loss_mask_8: 0.1215  loss_dice_8: 0.1774  time: 0.6167  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:54:28] d2.utils.events INFO:  eta: 5:32:10  iter: 10359  total_loss: 2.977  loss_ce: 6.262e-05  loss_mask: 0.1187  loss_dice: 0.1707  loss_ce_0: 0.1196  loss_mask_0: 0.118  loss_dice_0: 0.1783  loss_ce_1: 0.0002842  loss_mask_1: 0.1165  loss_dice_1: 0.1642  loss_ce_2: 0.0001234  loss_mask_2: 0.1136  loss_dice_2: 0.1707  loss_ce_3: 0.0001093  loss_mask_3: 0.119  loss_dice_3: 0.1699  loss_ce_4: 6.104e-05  loss_mask_4: 0.1172  loss_dice_4: 0.1688  loss_ce_5: 9.284e-05  loss_mask_5: 0.1172  loss_dice_5: 0.169  loss_ce_6: 9.395e-05  loss_mask_6: 0.1191  loss_dice_6: 0.1632  loss_ce_7: 6.036e-05  loss_mask_7: 0.1183  loss_dice_7: 0.1652  loss_ce_8: 8.13e-05  loss_mask_8: 0.1179  loss_dice_8: 0.1666  time: 0.6172  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:54:45] d2.utils.events INFO:  eta: 5:32:35  iter: 10379  total_loss: 3.091  loss_ce: 9.607e-05  loss_mask: 0.1155  loss_dice: 0.1766  loss_ce_0: 0.1219  loss_mask_0: 0.1166  loss_dice_0: 0.1818  loss_ce_1: 0.0002277  loss_mask_1: 0.1213  loss_dice_1: 0.1825  loss_ce_2: 0.0001109  loss_mask_2: 0.1181  loss_dice_2: 0.176  loss_ce_3: 7.37e-05  loss_mask_3: 0.1167  loss_dice_3: 0.1784  loss_ce_4: 5.291e-05  loss_mask_4: 0.1196  loss_dice_4: 0.1866  loss_ce_5: 8.653e-05  loss_mask_5: 0.1184  loss_dice_5: 0.1825  loss_ce_6: 7.389e-05  loss_mask_6: 0.1175  loss_dice_6: 0.1806  loss_ce_7: 7.2e-05  loss_mask_7: 0.1153  loss_dice_7: 0.1769  loss_ce_8: 0.0001263  loss_mask_8: 0.1166  loss_dice_8: 0.1789  time: 0.6176  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:55:02] d2.utils.events INFO:  eta: 5:32:38  iter: 10399  total_loss: 3.146  loss_ce: 8.4e-05  loss_mask: 0.1317  loss_dice: 0.1747  loss_ce_0: 0.1231  loss_mask_0: 0.1299  loss_dice_0: 0.1772  loss_ce_1: 0.0003245  loss_mask_1: 0.1253  loss_dice_1: 0.1779  loss_ce_2: 8.508e-05  loss_mask_2: 0.125  loss_dice_2: 0.1724  loss_ce_3: 6.324e-05  loss_mask_3: 0.1267  loss_dice_3: 0.1813  loss_ce_4: 4.856e-05  loss_mask_4: 0.1237  loss_dice_4: 0.1726  loss_ce_5: 8.129e-05  loss_mask_5: 0.1293  loss_dice_5: 0.1785  loss_ce_6: 7.16e-05  loss_mask_6: 0.1265  loss_dice_6: 0.1754  loss_ce_7: 6.941e-05  loss_mask_7: 0.1264  loss_dice_7: 0.1732  loss_ce_8: 0.0001223  loss_mask_8: 0.126  loss_dice_8: 0.178  time: 0.6181  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:55:18] d2.utils.events INFO:  eta: 5:33:04  iter: 10419  total_loss: 3.089  loss_ce: 5.312e-05  loss_mask: 0.1184  loss_dice: 0.1778  loss_ce_0: 0.1191  loss_mask_0: 0.1231  loss_dice_0: 0.184  loss_ce_1: 0.0001442  loss_mask_1: 0.122  loss_dice_1: 0.1778  loss_ce_2: 0.0001068  loss_mask_2: 0.1214  loss_dice_2: 0.1768  loss_ce_3: 7.767e-05  loss_mask_3: 0.1238  loss_dice_3: 0.1842  loss_ce_4: 5.419e-05  loss_mask_4: 0.1208  loss_dice_4: 0.1728  loss_ce_5: 8.308e-05  loss_mask_5: 0.1223  loss_dice_5: 0.1764  loss_ce_6: 8.11e-05  loss_mask_6: 0.121  loss_dice_6: 0.1759  loss_ce_7: 6.316e-05  loss_mask_7: 0.1242  loss_dice_7: 0.1765  loss_ce_8: 9.76e-05  loss_mask_8: 0.123  loss_dice_8: 0.1762  time: 0.6185  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:55:35] d2.utils.events INFO:  eta: 5:33:30  iter: 10439  total_loss: 3.025  loss_ce: 5.905e-05  loss_mask: 0.118  loss_dice: 0.1727  loss_ce_0: 0.1197  loss_mask_0: 0.1167  loss_dice_0: 0.1772  loss_ce_1: 0.0001585  loss_mask_1: 0.1133  loss_dice_1: 0.1733  loss_ce_2: 9.988e-05  loss_mask_2: 0.1159  loss_dice_2: 0.1736  loss_ce_3: 8.166e-05  loss_mask_3: 0.1132  loss_dice_3: 0.1737  loss_ce_4: 5.613e-05  loss_mask_4: 0.1181  loss_dice_4: 0.17  loss_ce_5: 8.581e-05  loss_mask_5: 0.1175  loss_dice_5: 0.1732  loss_ce_6: 7.435e-05  loss_mask_6: 0.1139  loss_dice_6: 0.1734  loss_ce_7: 6.384e-05  loss_mask_7: 0.1148  loss_dice_7: 0.1708  loss_ce_8: 9.512e-05  loss_mask_8: 0.1125  loss_dice_8: 0.171  time: 0.6189  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:55:52] d2.utils.events INFO:  eta: 5:33:45  iter: 10459  total_loss: 3.204  loss_ce: 4.998e-05  loss_mask: 0.1285  loss_dice: 0.1856  loss_ce_0: 0.1245  loss_mask_0: 0.125  loss_dice_0: 0.1864  loss_ce_1: 0.0001331  loss_mask_1: 0.1249  loss_dice_1: 0.1805  loss_ce_2: 0.0001032  loss_mask_2: 0.1283  loss_dice_2: 0.1844  loss_ce_3: 8.386e-05  loss_mask_3: 0.1244  loss_dice_3: 0.182  loss_ce_4: 5.249e-05  loss_mask_4: 0.125  loss_dice_4: 0.1815  loss_ce_5: 7.262e-05  loss_mask_5: 0.1238  loss_dice_5: 0.1784  loss_ce_6: 7.316e-05  loss_mask_6: 0.123  loss_dice_6: 0.1754  loss_ce_7: 5.769e-05  loss_mask_7: 0.1254  loss_dice_7: 0.1799  loss_ce_8: 9.311e-05  loss_mask_8: 0.1276  loss_dice_8: 0.1861  time: 0.6194  data_time: 0.0017  lr: 0.0001  max_mem: 8444M
[08/01 18:56:10] d2.utils.events INFO:  eta: 5:33:50  iter: 10479  total_loss: 2.98  loss_ce: 4.716e-05  loss_mask: 0.1263  loss_dice: 0.1693  loss_ce_0: 0.1227  loss_mask_0: 0.1198  loss_dice_0: 0.1676  loss_ce_1: 0.0001498  loss_mask_1: 0.12  loss_dice_1: 0.1717  loss_ce_2: 8.99e-05  loss_mask_2: 0.1211  loss_dice_2: 0.1679  loss_ce_3: 7.696e-05  loss_mask_3: 0.1181  loss_dice_3: 0.1662  loss_ce_4: 4.833e-05  loss_mask_4: 0.1219  loss_dice_4: 0.1714  loss_ce_5: 7.593e-05  loss_mask_5: 0.1212  loss_dice_5: 0.1699  loss_ce_6: 6.603e-05  loss_mask_6: 0.1176  loss_dice_6: 0.1682  loss_ce_7: 4.809e-05  loss_mask_7: 0.1208  loss_dice_7: 0.168  loss_ce_8: 5.804e-05  loss_mask_8: 0.1161  loss_dice_8: 0.1699  time: 0.6198  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 18:56:27] d2.utils.events INFO:  eta: 5:34:19  iter: 10499  total_loss: 3.335  loss_ce: 3.518e-05  loss_mask: 0.13  loss_dice: 0.2007  loss_ce_0: 0.1272  loss_mask_0: 0.1266  loss_dice_0: 0.2123  loss_ce_1: 0.0001723  loss_mask_1: 0.1231  loss_dice_1: 0.1936  loss_ce_2: 8.487e-05  loss_mask_2: 0.1254  loss_dice_2: 0.1975  loss_ce_3: 6.315e-05  loss_mask_3: 0.1281  loss_dice_3: 0.1931  loss_ce_4: 3.476e-05  loss_mask_4: 0.124  loss_dice_4: 0.1954  loss_ce_5: 7.745e-05  loss_mask_5: 0.1293  loss_dice_5: 0.1905  loss_ce_6: 5.791e-05  loss_mask_6: 0.1249  loss_dice_6: 0.1968  loss_ce_7: 4.03e-05  loss_mask_7: 0.1246  loss_dice_7: 0.194  loss_ce_8: 5.205e-05  loss_mask_8: 0.1263  loss_dice_8: 0.2036  time: 0.6203  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:56:44] d2.utils.events INFO:  eta: 5:34:30  iter: 10519  total_loss: 3.375  loss_ce: 4.56e-05  loss_mask: 0.1298  loss_dice: 0.1989  loss_ce_0: 0.1206  loss_mask_0: 0.1287  loss_dice_0: 0.1954  loss_ce_1: 0.0001411  loss_mask_1: 0.1259  loss_dice_1: 0.1993  loss_ce_2: 0.0001034  loss_mask_2: 0.1265  loss_dice_2: 0.1973  loss_ce_3: 6.926e-05  loss_mask_3: 0.132  loss_dice_3: 0.2006  loss_ce_4: 4.518e-05  loss_mask_4: 0.1279  loss_dice_4: 0.1926  loss_ce_5: 6.788e-05  loss_mask_5: 0.1265  loss_dice_5: 0.194  loss_ce_6: 6.307e-05  loss_mask_6: 0.1276  loss_dice_6: 0.1964  loss_ce_7: 5.475e-05  loss_mask_7: 0.1272  loss_dice_7: 0.1978  loss_ce_8: 7.428e-05  loss_mask_8: 0.1281  loss_dice_8: 0.2013  time: 0.6207  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:57:01] d2.utils.events INFO:  eta: 5:34:23  iter: 10539  total_loss: 3.206  loss_ce: 4.297e-05  loss_mask: 0.1248  loss_dice: 0.1792  loss_ce_0: 0.1172  loss_mask_0: 0.1244  loss_dice_0: 0.1846  loss_ce_1: 0.0001469  loss_mask_1: 0.1256  loss_dice_1: 0.1771  loss_ce_2: 8.208e-05  loss_mask_2: 0.1262  loss_dice_2: 0.1818  loss_ce_3: 6.772e-05  loss_mask_3: 0.128  loss_dice_3: 0.1814  loss_ce_4: 3.992e-05  loss_mask_4: 0.1227  loss_dice_4: 0.1786  loss_ce_5: 7.133e-05  loss_mask_5: 0.1272  loss_dice_5: 0.1817  loss_ce_6: 5.13e-05  loss_mask_6: 0.1216  loss_dice_6: 0.1822  loss_ce_7: 4.353e-05  loss_mask_7: 0.1245  loss_dice_7: 0.1794  loss_ce_8: 5.443e-05  loss_mask_8: 0.127  loss_dice_8: 0.1881  time: 0.6211  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:57:18] d2.utils.events INFO:  eta: 5:34:25  iter: 10559  total_loss: 3.291  loss_ce: 4.723e-05  loss_mask: 0.1185  loss_dice: 0.1928  loss_ce_0: 0.1311  loss_mask_0: 0.1222  loss_dice_0: 0.1999  loss_ce_1: 0.0001033  loss_mask_1: 0.118  loss_dice_1: 0.1895  loss_ce_2: 7.851e-05  loss_mask_2: 0.1201  loss_dice_2: 0.1886  loss_ce_3: 6.218e-05  loss_mask_3: 0.1183  loss_dice_3: 0.1999  loss_ce_4: 5.436e-05  loss_mask_4: 0.1206  loss_dice_4: 0.1992  loss_ce_5: 6.698e-05  loss_mask_5: 0.1206  loss_dice_5: 0.1913  loss_ce_6: 5.987e-05  loss_mask_6: 0.1188  loss_dice_6: 0.1838  loss_ce_7: 4.903e-05  loss_mask_7: 0.1169  loss_dice_7: 0.1855  loss_ce_8: 6.454e-05  loss_mask_8: 0.1207  loss_dice_8: 0.1972  time: 0.6216  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:57:35] d2.utils.events INFO:  eta: 5:34:44  iter: 10579  total_loss: 3.104  loss_ce: 0.0005504  loss_mask: 0.1187  loss_dice: 0.1741  loss_ce_0: 0.1266  loss_mask_0: 0.1144  loss_dice_0: 0.1796  loss_ce_1: 0.0001485  loss_mask_1: 0.1128  loss_dice_1: 0.1826  loss_ce_2: 0.0001753  loss_mask_2: 0.1135  loss_dice_2: 0.1805  loss_ce_3: 0.0001524  loss_mask_3: 0.1128  loss_dice_3: 0.1769  loss_ce_4: 0.0004017  loss_mask_4: 0.1153  loss_dice_4: 0.1787  loss_ce_5: 0.0006946  loss_mask_5: 0.1144  loss_dice_5: 0.1776  loss_ce_6: 0.001011  loss_mask_6: 0.1128  loss_dice_6: 0.1693  loss_ce_7: 0.0003265  loss_mask_7: 0.115  loss_dice_7: 0.1783  loss_ce_8: 0.0002221  loss_mask_8: 0.1154  loss_dice_8: 0.1804  time: 0.6220  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:57:52] d2.utils.events INFO:  eta: 5:34:58  iter: 10599  total_loss: 3.18  loss_ce: 0.001021  loss_mask: 0.1164  loss_dice: 0.1839  loss_ce_0: 0.1175  loss_mask_0: 0.1178  loss_dice_0: 0.1854  loss_ce_1: 0.0002949  loss_mask_1: 0.1155  loss_dice_1: 0.1827  loss_ce_2: 0.0005684  loss_mask_2: 0.1137  loss_dice_2: 0.1817  loss_ce_3: 0.0007856  loss_mask_3: 0.1167  loss_dice_3: 0.189  loss_ce_4: 0.0005275  loss_mask_4: 0.1193  loss_dice_4: 0.1822  loss_ce_5: 0.0004685  loss_mask_5: 0.1225  loss_dice_5: 0.1823  loss_ce_6: 0.001353  loss_mask_6: 0.1164  loss_dice_6: 0.1833  loss_ce_7: 0.0005751  loss_mask_7: 0.117  loss_dice_7: 0.18  loss_ce_8: 0.0005522  loss_mask_8: 0.1182  loss_dice_8: 0.1817  time: 0.6224  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:58:09] d2.utils.events INFO:  eta: 5:35:23  iter: 10619  total_loss: 3.137  loss_ce: 0.0008194  loss_mask: 0.123  loss_dice: 0.1751  loss_ce_0: 0.1221  loss_mask_0: 0.1228  loss_dice_0: 0.178  loss_ce_1: 0.0003874  loss_mask_1: 0.1244  loss_dice_1: 0.1785  loss_ce_2: 0.0003772  loss_mask_2: 0.1209  loss_dice_2: 0.1793  loss_ce_3: 0.00062  loss_mask_3: 0.1212  loss_dice_3: 0.1782  loss_ce_4: 0.000896  loss_mask_4: 0.1225  loss_dice_4: 0.178  loss_ce_5: 0.0005496  loss_mask_5: 0.1197  loss_dice_5: 0.174  loss_ce_6: 0.0003496  loss_mask_6: 0.1221  loss_dice_6: 0.1757  loss_ce_7: 0.0008821  loss_mask_7: 0.1201  loss_dice_7: 0.1755  loss_ce_8: 0.0008469  loss_mask_8: 0.1222  loss_dice_8: 0.1768  time: 0.6229  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:58:26] d2.utils.events INFO:  eta: 5:36:01  iter: 10639  total_loss: 3.2  loss_ce: 0.0004493  loss_mask: 0.1175  loss_dice: 0.1746  loss_ce_0: 0.1245  loss_mask_0: 0.1141  loss_dice_0: 0.1729  loss_ce_1: 0.0003785  loss_mask_1: 0.1161  loss_dice_1: 0.1794  loss_ce_2: 0.000407  loss_mask_2: 0.1224  loss_dice_2: 0.1799  loss_ce_3: 0.0005053  loss_mask_3: 0.1209  loss_dice_3: 0.1821  loss_ce_4: 0.0004185  loss_mask_4: 0.1185  loss_dice_4: 0.1802  loss_ce_5: 0.0004348  loss_mask_5: 0.1198  loss_dice_5: 0.178  loss_ce_6: 0.000243  loss_mask_6: 0.1143  loss_dice_6: 0.1758  loss_ce_7: 0.0003865  loss_mask_7: 0.1192  loss_dice_7: 0.1739  loss_ce_8: 0.0005635  loss_mask_8: 0.1202  loss_dice_8: 0.1843  time: 0.6233  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:58:43] d2.utils.events INFO:  eta: 5:36:13  iter: 10659  total_loss: 3.165  loss_ce: 0.0005004  loss_mask: 0.1219  loss_dice: 0.1814  loss_ce_0: 0.127  loss_mask_0: 0.1214  loss_dice_0: 0.174  loss_ce_1: 0.0007321  loss_mask_1: 0.1221  loss_dice_1: 0.1834  loss_ce_2: 0.0008834  loss_mask_2: 0.1231  loss_dice_2: 0.1786  loss_ce_3: 0.0005405  loss_mask_3: 0.1247  loss_dice_3: 0.177  loss_ce_4: 0.0006606  loss_mask_4: 0.1206  loss_dice_4: 0.1793  loss_ce_5: 0.0008083  loss_mask_5: 0.1204  loss_dice_5: 0.1807  loss_ce_6: 0.0002084  loss_mask_6: 0.1243  loss_dice_6: 0.1854  loss_ce_7: 0.0005306  loss_mask_7: 0.1225  loss_dice_7: 0.1747  loss_ce_8: 0.0009361  loss_mask_8: 0.1232  loss_dice_8: 0.1819  time: 0.6237  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:59:00] d2.utils.events INFO:  eta: 5:36:29  iter: 10679  total_loss: 3.138  loss_ce: 0.0003067  loss_mask: 0.1224  loss_dice: 0.1812  loss_ce_0: 0.1211  loss_mask_0: 0.1188  loss_dice_0: 0.1819  loss_ce_1: 0.0003716  loss_mask_1: 0.1186  loss_dice_1: 0.1774  loss_ce_2: 0.0003009  loss_mask_2: 0.1155  loss_dice_2: 0.1729  loss_ce_3: 0.0003015  loss_mask_3: 0.1214  loss_dice_3: 0.1795  loss_ce_4: 0.0002708  loss_mask_4: 0.1242  loss_dice_4: 0.1852  loss_ce_5: 0.0003959  loss_mask_5: 0.12  loss_dice_5: 0.1711  loss_ce_6: 0.0001788  loss_mask_6: 0.1185  loss_dice_6: 0.1798  loss_ce_7: 0.0002846  loss_mask_7: 0.1228  loss_dice_7: 0.177  loss_ce_8: 0.0004299  loss_mask_8: 0.1204  loss_dice_8: 0.1841  time: 0.6242  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 18:59:17] d2.utils.events INFO:  eta: 5:36:40  iter: 10699  total_loss: 3.119  loss_ce: 0.0002678  loss_mask: 0.1228  loss_dice: 0.1852  loss_ce_0: 0.121  loss_mask_0: 0.114  loss_dice_0: 0.1766  loss_ce_1: 0.0003867  loss_mask_1: 0.1189  loss_dice_1: 0.1785  loss_ce_2: 0.0004039  loss_mask_2: 0.1183  loss_dice_2: 0.1787  loss_ce_3: 0.0002784  loss_mask_3: 0.1176  loss_dice_3: 0.1756  loss_ce_4: 0.0002619  loss_mask_4: 0.1217  loss_dice_4: 0.1767  loss_ce_5: 0.0003365  loss_mask_5: 0.1174  loss_dice_5: 0.181  loss_ce_6: 0.0001577  loss_mask_6: 0.1176  loss_dice_6: 0.1863  loss_ce_7: 0.0002948  loss_mask_7: 0.114  loss_dice_7: 0.1778  loss_ce_8: 0.0004279  loss_mask_8: 0.1168  loss_dice_8: 0.1772  time: 0.6246  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:59:34] d2.utils.events INFO:  eta: 5:37:19  iter: 10719  total_loss: 3.065  loss_ce: 0.000197  loss_mask: 0.1182  loss_dice: 0.1725  loss_ce_0: 0.1233  loss_mask_0: 0.1222  loss_dice_0: 0.1769  loss_ce_1: 0.0002  loss_mask_1: 0.1198  loss_dice_1: 0.1755  loss_ce_2: 0.0002082  loss_mask_2: 0.1137  loss_dice_2: 0.175  loss_ce_3: 0.0001541  loss_mask_3: 0.1213  loss_dice_3: 0.1751  loss_ce_4: 0.0001601  loss_mask_4: 0.1202  loss_dice_4: 0.1755  loss_ce_5: 0.0001096  loss_mask_5: 0.1188  loss_dice_5: 0.1725  loss_ce_6: 0.0001268  loss_mask_6: 0.1165  loss_dice_6: 0.1719  loss_ce_7: 0.0001821  loss_mask_7: 0.121  loss_dice_7: 0.174  loss_ce_8: 0.0001811  loss_mask_8: 0.1188  loss_dice_8: 0.1769  time: 0.6250  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 18:59:51] d2.utils.events INFO:  eta: 5:37:26  iter: 10739  total_loss: 3.038  loss_ce: 0.0001888  loss_mask: 0.1235  loss_dice: 0.1751  loss_ce_0: 0.1244  loss_mask_0: 0.1173  loss_dice_0: 0.171  loss_ce_1: 0.0002182  loss_mask_1: 0.1228  loss_dice_1: 0.1782  loss_ce_2: 0.0002401  loss_mask_2: 0.1181  loss_dice_2: 0.1711  loss_ce_3: 0.0001973  loss_mask_3: 0.1244  loss_dice_3: 0.1777  loss_ce_4: 0.0001781  loss_mask_4: 0.1205  loss_dice_4: 0.1768  loss_ce_5: 0.0002413  loss_mask_5: 0.1215  loss_dice_5: 0.1713  loss_ce_6: 0.0001567  loss_mask_6: 0.1234  loss_dice_6: 0.17  loss_ce_7: 0.0001884  loss_mask_7: 0.1221  loss_dice_7: 0.1703  loss_ce_8: 0.000251  loss_mask_8: 0.1221  loss_dice_8: 0.1738  time: 0.6254  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:00:08] d2.utils.events INFO:  eta: 5:37:25  iter: 10759  total_loss: 2.994  loss_ce: 0.0001239  loss_mask: 0.1155  loss_dice: 0.168  loss_ce_0: 0.122  loss_mask_0: 0.1155  loss_dice_0: 0.1699  loss_ce_1: 0.0001255  loss_mask_1: 0.1165  loss_dice_1: 0.1666  loss_ce_2: 0.0001238  loss_mask_2: 0.1167  loss_dice_2: 0.1737  loss_ce_3: 0.0001575  loss_mask_3: 0.1177  loss_dice_3: 0.1749  loss_ce_4: 0.0001268  loss_mask_4: 0.1176  loss_dice_4: 0.1695  loss_ce_5: 8.066e-05  loss_mask_5: 0.1148  loss_dice_5: 0.1719  loss_ce_6: 0.0001296  loss_mask_6: 0.1176  loss_dice_6: 0.1695  loss_ce_7: 0.0001454  loss_mask_7: 0.1142  loss_dice_7: 0.1702  loss_ce_8: 0.0001492  loss_mask_8: 0.1155  loss_dice_8: 0.167  time: 0.6259  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:00:25] d2.utils.events INFO:  eta: 5:37:52  iter: 10779  total_loss: 3.056  loss_ce: 0.0001246  loss_mask: 0.1187  loss_dice: 0.1771  loss_ce_0: 0.1244  loss_mask_0: 0.1184  loss_dice_0: 0.1762  loss_ce_1: 0.0001901  loss_mask_1: 0.1181  loss_dice_1: 0.1792  loss_ce_2: 0.0001553  loss_mask_2: 0.1195  loss_dice_2: 0.1807  loss_ce_3: 0.0001336  loss_mask_3: 0.1165  loss_dice_3: 0.1746  loss_ce_4: 0.0001168  loss_mask_4: 0.1203  loss_dice_4: 0.1812  loss_ce_5: 0.0001753  loss_mask_5: 0.1162  loss_dice_5: 0.1706  loss_ce_6: 0.0001072  loss_mask_6: 0.1166  loss_dice_6: 0.1738  loss_ce_7: 0.0001401  loss_mask_7: 0.1193  loss_dice_7: 0.1816  loss_ce_8: 0.0002097  loss_mask_8: 0.1187  loss_dice_8: 0.1819  time: 0.6263  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:00:42] d2.utils.events INFO:  eta: 5:38:13  iter: 10799  total_loss: 2.999  loss_ce: 0.0001078  loss_mask: 0.1192  loss_dice: 0.1596  loss_ce_0: 0.1245  loss_mask_0: 0.1182  loss_dice_0: 0.1614  loss_ce_1: 0.0001255  loss_mask_1: 0.1174  loss_dice_1: 0.1614  loss_ce_2: 0.0001258  loss_mask_2: 0.1182  loss_dice_2: 0.1642  loss_ce_3: 0.0001199  loss_mask_3: 0.1167  loss_dice_3: 0.1607  loss_ce_4: 0.0001098  loss_mask_4: 0.115  loss_dice_4: 0.1695  loss_ce_5: 7.098e-05  loss_mask_5: 0.1206  loss_dice_5: 0.1622  loss_ce_6: 0.00011  loss_mask_6: 0.1172  loss_dice_6: 0.1559  loss_ce_7: 0.0001129  loss_mask_7: 0.1167  loss_dice_7: 0.1647  loss_ce_8: 0.0001219  loss_mask_8: 0.1153  loss_dice_8: 0.1692  time: 0.6267  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:01:00] d2.utils.events INFO:  eta: 5:38:23  iter: 10819  total_loss: 3.116  loss_ce: 0.000123  loss_mask: 0.1197  loss_dice: 0.1781  loss_ce_0: 0.1209  loss_mask_0: 0.1186  loss_dice_0: 0.1853  loss_ce_1: 0.0001669  loss_mask_1: 0.1218  loss_dice_1: 0.1821  loss_ce_2: 0.0001526  loss_mask_2: 0.1165  loss_dice_2: 0.185  loss_ce_3: 0.0001101  loss_mask_3: 0.122  loss_dice_3: 0.1845  loss_ce_4: 9.934e-05  loss_mask_4: 0.1211  loss_dice_4: 0.1836  loss_ce_5: 0.000165  loss_mask_5: 0.1193  loss_dice_5: 0.185  loss_ce_6: 0.000106  loss_mask_6: 0.1204  loss_dice_6: 0.1825  loss_ce_7: 0.0001305  loss_mask_7: 0.1213  loss_dice_7: 0.183  loss_ce_8: 0.0001792  loss_mask_8: 0.1211  loss_dice_8: 0.1861  time: 0.6271  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:01:17] d2.utils.events INFO:  eta: 5:38:28  iter: 10839  total_loss: 3.054  loss_ce: 0.0001241  loss_mask: 0.1161  loss_dice: 0.1756  loss_ce_0: 0.1285  loss_mask_0: 0.1168  loss_dice_0: 0.181  loss_ce_1: 0.000274  loss_mask_1: 0.1149  loss_dice_1: 0.1721  loss_ce_2: 0.000246  loss_mask_2: 0.117  loss_dice_2: 0.1731  loss_ce_3: 0.0001388  loss_mask_3: 0.1176  loss_dice_3: 0.1749  loss_ce_4: 0.0001936  loss_mask_4: 0.1176  loss_dice_4: 0.1753  loss_ce_5: 0.0001819  loss_mask_5: 0.1167  loss_dice_5: 0.173  loss_ce_6: 0.0001333  loss_mask_6: 0.1151  loss_dice_6: 0.1726  loss_ce_7: 0.0001837  loss_mask_7: 0.1169  loss_dice_7: 0.1771  loss_ce_8: 0.0002311  loss_mask_8: 0.1169  loss_dice_8: 0.1756  time: 0.6275  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:01:33] d2.utils.events INFO:  eta: 5:38:30  iter: 10859  total_loss: 3.172  loss_ce: 0.0002304  loss_mask: 0.1193  loss_dice: 0.1772  loss_ce_0: 0.1256  loss_mask_0: 0.119  loss_dice_0: 0.1866  loss_ce_1: 0.0004833  loss_mask_1: 0.1188  loss_dice_1: 0.1759  loss_ce_2: 0.0002906  loss_mask_2: 0.1196  loss_dice_2: 0.1836  loss_ce_3: 0.000215  loss_mask_3: 0.1213  loss_dice_3: 0.1787  loss_ce_4: 0.0002502  loss_mask_4: 0.1216  loss_dice_4: 0.1822  loss_ce_5: 0.0002566  loss_mask_5: 0.1232  loss_dice_5: 0.1783  loss_ce_6: 0.000148  loss_mask_6: 0.1208  loss_dice_6: 0.1758  loss_ce_7: 0.0002582  loss_mask_7: 0.1202  loss_dice_7: 0.1802  loss_ce_8: 0.0003004  loss_mask_8: 0.1184  loss_dice_8: 0.1746  time: 0.6279  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:01:50] d2.utils.events INFO:  eta: 5:38:42  iter: 10879  total_loss: 3.124  loss_ce: 0.0001563  loss_mask: 0.1157  loss_dice: 0.1803  loss_ce_0: 0.1263  loss_mask_0: 0.1191  loss_dice_0: 0.1865  loss_ce_1: 0.0003755  loss_mask_1: 0.1202  loss_dice_1: 0.1792  loss_ce_2: 0.0003275  loss_mask_2: 0.1134  loss_dice_2: 0.1762  loss_ce_3: 0.0003322  loss_mask_3: 0.122  loss_dice_3: 0.1833  loss_ce_4: 0.0002513  loss_mask_4: 0.1204  loss_dice_4: 0.1807  loss_ce_5: 0.0002167  loss_mask_5: 0.1205  loss_dice_5: 0.179  loss_ce_6: 0.0001386  loss_mask_6: 0.117  loss_dice_6: 0.1785  loss_ce_7: 0.0001992  loss_mask_7: 0.1221  loss_dice_7: 0.1839  loss_ce_8: 0.0002904  loss_mask_8: 0.1186  loss_dice_8: 0.1773  time: 0.6283  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:02:08] d2.utils.events INFO:  eta: 5:38:53  iter: 10899  total_loss: 3.319  loss_ce: 0.0001925  loss_mask: 0.1255  loss_dice: 0.1979  loss_ce_0: 0.1216  loss_mask_0: 0.1182  loss_dice_0: 0.1923  loss_ce_1: 0.0005244  loss_mask_1: 0.1217  loss_dice_1: 0.1916  loss_ce_2: 0.00032  loss_mask_2: 0.1241  loss_dice_2: 0.1928  loss_ce_3: 0.0004065  loss_mask_3: 0.1213  loss_dice_3: 0.192  loss_ce_4: 0.000411  loss_mask_4: 0.123  loss_dice_4: 0.1974  loss_ce_5: 0.0002927  loss_mask_5: 0.1215  loss_dice_5: 0.1876  loss_ce_6: 0.0002345  loss_mask_6: 0.1216  loss_dice_6: 0.192  loss_ce_7: 0.0002637  loss_mask_7: 0.1248  loss_dice_7: 0.1934  loss_ce_8: 0.0003481  loss_mask_8: 0.125  loss_dice_8: 0.1937  time: 0.6287  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:02:25] d2.utils.events INFO:  eta: 5:39:07  iter: 10919  total_loss: 3.139  loss_ce: 0.00167  loss_mask: 0.1222  loss_dice: 0.1729  loss_ce_0: 0.1205  loss_mask_0: 0.1206  loss_dice_0: 0.1804  loss_ce_1: 0.0009408  loss_mask_1: 0.1185  loss_dice_1: 0.173  loss_ce_2: 0.0008319  loss_mask_2: 0.1182  loss_dice_2: 0.1688  loss_ce_3: 0.001755  loss_mask_3: 0.1201  loss_dice_3: 0.1774  loss_ce_4: 0.0009284  loss_mask_4: 0.1203  loss_dice_4: 0.176  loss_ce_5: 0.001582  loss_mask_5: 0.1208  loss_dice_5: 0.1704  loss_ce_6: 0.00144  loss_mask_6: 0.1213  loss_dice_6: 0.1744  loss_ce_7: 0.002092  loss_mask_7: 0.1245  loss_dice_7: 0.178  loss_ce_8: 0.001392  loss_mask_8: 0.123  loss_dice_8: 0.1679  time: 0.6292  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:02:41] d2.utils.events INFO:  eta: 5:39:04  iter: 10939  total_loss: 3.179  loss_ce: 0.0003554  loss_mask: 0.1205  loss_dice: 0.1828  loss_ce_0: 0.1209  loss_mask_0: 0.1177  loss_dice_0: 0.1816  loss_ce_1: 0.0004388  loss_mask_1: 0.1172  loss_dice_1: 0.1861  loss_ce_2: 0.0004099  loss_mask_2: 0.1166  loss_dice_2: 0.181  loss_ce_3: 0.0001626  loss_mask_3: 0.117  loss_dice_3: 0.1865  loss_ce_4: 0.0002577  loss_mask_4: 0.1194  loss_dice_4: 0.1884  loss_ce_5: 0.00078  loss_mask_5: 0.1228  loss_dice_5: 0.1833  loss_ce_6: 0.0006417  loss_mask_6: 0.117  loss_dice_6: 0.1831  loss_ce_7: 0.0008007  loss_mask_7: 0.1187  loss_dice_7: 0.1833  loss_ce_8: 0.000724  loss_mask_8: 0.1174  loss_dice_8: 0.1808  time: 0.6295  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:02:59] d2.utils.events INFO:  eta: 5:39:13  iter: 10959  total_loss: 3.153  loss_ce: 0.0003176  loss_mask: 0.1222  loss_dice: 0.1725  loss_ce_0: 0.1227  loss_mask_0: 0.1259  loss_dice_0: 0.173  loss_ce_1: 0.0007042  loss_mask_1: 0.121  loss_dice_1: 0.1651  loss_ce_2: 0.0004243  loss_mask_2: 0.1248  loss_dice_2: 0.1738  loss_ce_3: 0.0001747  loss_mask_3: 0.1286  loss_dice_3: 0.1756  loss_ce_4: 0.0002996  loss_mask_4: 0.1199  loss_dice_4: 0.1666  loss_ce_5: 0.000655  loss_mask_5: 0.1223  loss_dice_5: 0.1709  loss_ce_6: 0.0004859  loss_mask_6: 0.123  loss_dice_6: 0.1777  loss_ce_7: 0.0006135  loss_mask_7: 0.1235  loss_dice_7: 0.1735  loss_ce_8: 0.0005122  loss_mask_8: 0.1157  loss_dice_8: 0.1679  time: 0.6300  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:03:16] d2.utils.events INFO:  eta: 5:39:04  iter: 10979  total_loss: 3.155  loss_ce: 0.0002315  loss_mask: 0.1189  loss_dice: 0.1827  loss_ce_0: 0.1193  loss_mask_0: 0.1209  loss_dice_0: 0.1822  loss_ce_1: 0.0005006  loss_mask_1: 0.121  loss_dice_1: 0.1831  loss_ce_2: 0.0003181  loss_mask_2: 0.1145  loss_dice_2: 0.1789  loss_ce_3: 0.0001717  loss_mask_3: 0.1193  loss_dice_3: 0.1779  loss_ce_4: 0.0002134  loss_mask_4: 0.1197  loss_dice_4: 0.18  loss_ce_5: 0.0004066  loss_mask_5: 0.1191  loss_dice_5: 0.1776  loss_ce_6: 0.0003143  loss_mask_6: 0.1179  loss_dice_6: 0.1853  loss_ce_7: 0.0004164  loss_mask_7: 0.1233  loss_dice_7: 0.1808  loss_ce_8: 0.0003835  loss_mask_8: 0.1186  loss_dice_8: 0.1826  time: 0.6303  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:03:32] d2.utils.events INFO:  eta: 5:38:58  iter: 10999  total_loss: 3.143  loss_ce: 0.0001743  loss_mask: 0.1201  loss_dice: 0.1729  loss_ce_0: 0.1182  loss_mask_0: 0.1216  loss_dice_0: 0.1766  loss_ce_1: 0.0003141  loss_mask_1: 0.122  loss_dice_1: 0.1742  loss_ce_2: 0.00031  loss_mask_2: 0.1254  loss_dice_2: 0.1809  loss_ce_3: 0.0001526  loss_mask_3: 0.1227  loss_dice_3: 0.1739  loss_ce_4: 0.0002315  loss_mask_4: 0.1207  loss_dice_4: 0.1813  loss_ce_5: 0.0003308  loss_mask_5: 0.1217  loss_dice_5: 0.1779  loss_ce_6: 0.0002634  loss_mask_6: 0.1204  loss_dice_6: 0.1751  loss_ce_7: 0.0003042  loss_mask_7: 0.1215  loss_dice_7: 0.1753  loss_ce_8: 0.0002829  loss_mask_8: 0.1218  loss_dice_8: 0.1755  time: 0.6307  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:03:49] d2.utils.events INFO:  eta: 5:38:38  iter: 11019  total_loss: 3.206  loss_ce: 0.0002134  loss_mask: 0.123  loss_dice: 0.1862  loss_ce_0: 0.1165  loss_mask_0: 0.1264  loss_dice_0: 0.1811  loss_ce_1: 0.00039  loss_mask_1: 0.1258  loss_dice_1: 0.1855  loss_ce_2: 0.0002767  loss_mask_2: 0.1222  loss_dice_2: 0.1811  loss_ce_3: 0.0001489  loss_mask_3: 0.1238  loss_dice_3: 0.1809  loss_ce_4: 0.0001697  loss_mask_4: 0.1232  loss_dice_4: 0.1806  loss_ce_5: 0.0003329  loss_mask_5: 0.1236  loss_dice_5: 0.1817  loss_ce_6: 0.0002679  loss_mask_6: 0.1244  loss_dice_6: 0.1765  loss_ce_7: 0.000289  loss_mask_7: 0.1223  loss_dice_7: 0.1853  loss_ce_8: 0.0003104  loss_mask_8: 0.1207  loss_dice_8: 0.1805  time: 0.6311  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:04:06] d2.utils.events INFO:  eta: 5:38:15  iter: 11039  total_loss: 2.961  loss_ce: 0.0003124  loss_mask: 0.1085  loss_dice: 0.1775  loss_ce_0: 0.1169  loss_mask_0: 0.1154  loss_dice_0: 0.1687  loss_ce_1: 0.0003354  loss_mask_1: 0.1103  loss_dice_1: 0.1729  loss_ce_2: 0.0003658  loss_mask_2: 0.1166  loss_dice_2: 0.1744  loss_ce_3: 0.0001525  loss_mask_3: 0.113  loss_dice_3: 0.1876  loss_ce_4: 0.00021  loss_mask_4: 0.1143  loss_dice_4: 0.1743  loss_ce_5: 0.0003112  loss_mask_5: 0.1186  loss_dice_5: 0.1818  loss_ce_6: 0.0002708  loss_mask_6: 0.1162  loss_dice_6: 0.1834  loss_ce_7: 0.0002728  loss_mask_7: 0.1172  loss_dice_7: 0.1795  loss_ce_8: 0.0002909  loss_mask_8: 0.1126  loss_dice_8: 0.1778  time: 0.6315  data_time: 0.0017  lr: 0.0001  max_mem: 8444M
[08/01 19:04:23] d2.utils.events INFO:  eta: 5:37:55  iter: 11059  total_loss: 3.134  loss_ce: 0.0001323  loss_mask: 0.1188  loss_dice: 0.1704  loss_ce_0: 0.1181  loss_mask_0: 0.1198  loss_dice_0: 0.1718  loss_ce_1: 0.0002974  loss_mask_1: 0.1153  loss_dice_1: 0.1692  loss_ce_2: 0.0002292  loss_mask_2: 0.1206  loss_dice_2: 0.1639  loss_ce_3: 0.0001389  loss_mask_3: 0.119  loss_dice_3: 0.1781  loss_ce_4: 0.0001567  loss_mask_4: 0.1172  loss_dice_4: 0.175  loss_ce_5: 0.0002343  loss_mask_5: 0.1234  loss_dice_5: 0.18  loss_ce_6: 0.0001903  loss_mask_6: 0.1165  loss_dice_6: 0.1753  loss_ce_7: 0.0001871  loss_mask_7: 0.119  loss_dice_7: 0.1706  loss_ce_8: 0.0002136  loss_mask_8: 0.1158  loss_dice_8: 0.1738  time: 0.6319  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:04:40] d2.utils.events INFO:  eta: 5:37:38  iter: 11079  total_loss: 3.248  loss_ce: 0.0002447  loss_mask: 0.1172  loss_dice: 0.1855  loss_ce_0: 0.1178  loss_mask_0: 0.1186  loss_dice_0: 0.1921  loss_ce_1: 0.0002458  loss_mask_1: 0.1214  loss_dice_1: 0.1881  loss_ce_2: 0.0002568  loss_mask_2: 0.1211  loss_dice_2: 0.1897  loss_ce_3: 0.0001424  loss_mask_3: 0.118  loss_dice_3: 0.1939  loss_ce_4: 0.000171  loss_mask_4: 0.1205  loss_dice_4: 0.1854  loss_ce_5: 0.0001807  loss_mask_5: 0.1152  loss_dice_5: 0.1889  loss_ce_6: 0.0001499  loss_mask_6: 0.1208  loss_dice_6: 0.1846  loss_ce_7: 0.0002086  loss_mask_7: 0.1195  loss_dice_7: 0.1889  loss_ce_8: 0.0002185  loss_mask_8: 0.1185  loss_dice_8: 0.1931  time: 0.6323  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:04:57] d2.utils.events INFO:  eta: 5:37:20  iter: 11099  total_loss: 3.123  loss_ce: 0.0002862  loss_mask: 0.1145  loss_dice: 0.1799  loss_ce_0: 0.1299  loss_mask_0: 0.1165  loss_dice_0: 0.1806  loss_ce_1: 0.0002711  loss_mask_1: 0.1153  loss_dice_1: 0.1854  loss_ce_2: 0.0003139  loss_mask_2: 0.1129  loss_dice_2: 0.1811  loss_ce_3: 0.0001616  loss_mask_3: 0.1129  loss_dice_3: 0.1831  loss_ce_4: 0.0002046  loss_mask_4: 0.1133  loss_dice_4: 0.1808  loss_ce_5: 0.0002855  loss_mask_5: 0.114  loss_dice_5: 0.1778  loss_ce_6: 0.0002457  loss_mask_6: 0.1123  loss_dice_6: 0.1774  loss_ce_7: 0.0002906  loss_mask_7: 0.1139  loss_dice_7: 0.1823  loss_ce_8: 0.000313  loss_mask_8: 0.1149  loss_dice_8: 0.1774  time: 0.6327  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:05:14] d2.utils.events INFO:  eta: 5:37:08  iter: 11119  total_loss: 3.134  loss_ce: 0.0002031  loss_mask: 0.1181  loss_dice: 0.1784  loss_ce_0: 0.1169  loss_mask_0: 0.1205  loss_dice_0: 0.1893  loss_ce_1: 0.0002266  loss_mask_1: 0.12  loss_dice_1: 0.1746  loss_ce_2: 0.0002471  loss_mask_2: 0.1213  loss_dice_2: 0.1824  loss_ce_3: 0.0001295  loss_mask_3: 0.1224  loss_dice_3: 0.1806  loss_ce_4: 0.0001671  loss_mask_4: 0.1173  loss_dice_4: 0.1783  loss_ce_5: 0.0002177  loss_mask_5: 0.1231  loss_dice_5: 0.1794  loss_ce_6: 0.0001715  loss_mask_6: 0.1217  loss_dice_6: 0.1835  loss_ce_7: 0.0002081  loss_mask_7: 0.1238  loss_dice_7: 0.1778  loss_ce_8: 0.0002344  loss_mask_8: 0.1182  loss_dice_8: 0.1767  time: 0.6331  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:05:31] d2.utils.events INFO:  eta: 5:36:55  iter: 11139  total_loss: 3.095  loss_ce: 0.0001496  loss_mask: 0.1151  loss_dice: 0.1744  loss_ce_0: 0.116  loss_mask_0: 0.1174  loss_dice_0: 0.182  loss_ce_1: 0.0001724  loss_mask_1: 0.1172  loss_dice_1: 0.178  loss_ce_2: 0.0001873  loss_mask_2: 0.1221  loss_dice_2: 0.1736  loss_ce_3: 0.0001293  loss_mask_3: 0.1185  loss_dice_3: 0.1768  loss_ce_4: 0.0001249  loss_mask_4: 0.1152  loss_dice_4: 0.1795  loss_ce_5: 0.0001874  loss_mask_5: 0.1137  loss_dice_5: 0.1761  loss_ce_6: 0.000156  loss_mask_6: 0.1158  loss_dice_6: 0.177  loss_ce_7: 0.0001463  loss_mask_7: 0.1167  loss_dice_7: 0.1777  loss_ce_8: 0.0001753  loss_mask_8: 0.1187  loss_dice_8: 0.1795  time: 0.6334  data_time: 0.0017  lr: 0.0001  max_mem: 8444M
[08/01 19:05:48] d2.utils.events INFO:  eta: 5:36:42  iter: 11159  total_loss: 2.955  loss_ce: 0.0001716  loss_mask: 0.1167  loss_dice: 0.1808  loss_ce_0: 0.1163  loss_mask_0: 0.1149  loss_dice_0: 0.1669  loss_ce_1: 0.0001641  loss_mask_1: 0.116  loss_dice_1: 0.1756  loss_ce_2: 0.0002141  loss_mask_2: 0.1152  loss_dice_2: 0.168  loss_ce_3: 0.0001047  loss_mask_3: 0.1138  loss_dice_3: 0.1702  loss_ce_4: 0.0001495  loss_mask_4: 0.1158  loss_dice_4: 0.1667  loss_ce_5: 0.000199  loss_mask_5: 0.1118  loss_dice_5: 0.1646  loss_ce_6: 0.000164  loss_mask_6: 0.1167  loss_dice_6: 0.173  loss_ce_7: 0.0001937  loss_mask_7: 0.1166  loss_dice_7: 0.1746  loss_ce_8: 0.0001873  loss_mask_8: 0.116  loss_dice_8: 0.172  time: 0.6338  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:06:05] d2.utils.events INFO:  eta: 5:36:23  iter: 11179  total_loss: 2.958  loss_ce: 0.0001475  loss_mask: 0.1161  loss_dice: 0.1703  loss_ce_0: 0.1287  loss_mask_0: 0.1162  loss_dice_0: 0.1638  loss_ce_1: 0.0001659  loss_mask_1: 0.1145  loss_dice_1: 0.168  loss_ce_2: 0.0001968  loss_mask_2: 0.1172  loss_dice_2: 0.1714  loss_ce_3: 0.0001077  loss_mask_3: 0.1186  loss_dice_3: 0.1711  loss_ce_4: 0.0001388  loss_mask_4: 0.1139  loss_dice_4: 0.1652  loss_ce_5: 0.000153  loss_mask_5: 0.1199  loss_dice_5: 0.1631  loss_ce_6: 0.0001201  loss_mask_6: 0.1179  loss_dice_6: 0.166  loss_ce_7: 0.0001709  loss_mask_7: 0.1162  loss_dice_7: 0.1659  loss_ce_8: 0.0001648  loss_mask_8: 0.1174  loss_dice_8: 0.1672  time: 0.6342  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:06:22] d2.utils.events INFO:  eta: 5:36:16  iter: 11199  total_loss: 2.907  loss_ce: 0.000139  loss_mask: 0.1194  loss_dice: 0.1707  loss_ce_0: 0.1214  loss_mask_0: 0.1158  loss_dice_0: 0.1619  loss_ce_1: 0.0001336  loss_mask_1: 0.1138  loss_dice_1: 0.1606  loss_ce_2: 0.0001916  loss_mask_2: 0.1162  loss_dice_2: 0.1626  loss_ce_3: 0.000103  loss_mask_3: 0.1176  loss_dice_3: 0.1652  loss_ce_4: 0.0001352  loss_mask_4: 0.1113  loss_dice_4: 0.1607  loss_ce_5: 0.000124  loss_mask_5: 0.1129  loss_dice_5: 0.1607  loss_ce_6: 0.0001082  loss_mask_6: 0.1138  loss_dice_6: 0.1537  loss_ce_7: 0.000147  loss_mask_7: 0.1194  loss_dice_7: 0.1607  loss_ce_8: 0.0001494  loss_mask_8: 0.1161  loss_dice_8: 0.1635  time: 0.6346  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:06:39] d2.utils.events INFO:  eta: 5:36:04  iter: 11219  total_loss: 3.124  loss_ce: 0.0001303  loss_mask: 0.1183  loss_dice: 0.1804  loss_ce_0: 0.1139  loss_mask_0: 0.1189  loss_dice_0: 0.1774  loss_ce_1: 0.0001598  loss_mask_1: 0.1144  loss_dice_1: 0.1749  loss_ce_2: 0.0002088  loss_mask_2: 0.1182  loss_dice_2: 0.1795  loss_ce_3: 0.0001121  loss_mask_3: 0.1187  loss_dice_3: 0.1718  loss_ce_4: 0.0001523  loss_mask_4: 0.1155  loss_dice_4: 0.1749  loss_ce_5: 0.0001621  loss_mask_5: 0.1156  loss_dice_5: 0.1792  loss_ce_6: 0.0001508  loss_mask_6: 0.1229  loss_dice_6: 0.1813  loss_ce_7: 0.0001364  loss_mask_7: 0.1158  loss_dice_7: 0.1849  loss_ce_8: 0.0001635  loss_mask_8: 0.118  loss_dice_8: 0.1754  time: 0.6350  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:06:56] d2.utils.events INFO:  eta: 5:35:53  iter: 11239  total_loss: 3.04  loss_ce: 0.0002403  loss_mask: 0.119  loss_dice: 0.1696  loss_ce_0: 0.1246  loss_mask_0: 0.1207  loss_dice_0: 0.1682  loss_ce_1: 0.0001688  loss_mask_1: 0.1188  loss_dice_1: 0.1643  loss_ce_2: 0.000191  loss_mask_2: 0.1197  loss_dice_2: 0.1702  loss_ce_3: 0.0001424  loss_mask_3: 0.1187  loss_dice_3: 0.1671  loss_ce_4: 0.0001403  loss_mask_4: 0.1214  loss_dice_4: 0.1686  loss_ce_5: 0.0002085  loss_mask_5: 0.12  loss_dice_5: 0.1692  loss_ce_6: 0.0001964  loss_mask_6: 0.1208  loss_dice_6: 0.171  loss_ce_7: 0.0001799  loss_mask_7: 0.1203  loss_dice_7: 0.1672  loss_ce_8: 0.0002279  loss_mask_8: 0.1182  loss_dice_8: 0.1677  time: 0.6354  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:07:13] d2.utils.events INFO:  eta: 5:35:36  iter: 11259  total_loss: 3.118  loss_ce: 0.0002298  loss_mask: 0.1232  loss_dice: 0.1808  loss_ce_0: 0.1272  loss_mask_0: 0.1201  loss_dice_0: 0.1771  loss_ce_1: 0.00036  loss_mask_1: 0.1188  loss_dice_1: 0.1798  loss_ce_2: 0.0002218  loss_mask_2: 0.1191  loss_dice_2: 0.1787  loss_ce_3: 0.0001677  loss_mask_3: 0.1183  loss_dice_3: 0.1811  loss_ce_4: 0.0002221  loss_mask_4: 0.1187  loss_dice_4: 0.1781  loss_ce_5: 0.0002223  loss_mask_5: 0.1202  loss_dice_5: 0.1808  loss_ce_6: 0.0002863  loss_mask_6: 0.1231  loss_dice_6: 0.1823  loss_ce_7: 0.0001886  loss_mask_7: 0.1168  loss_dice_7: 0.1788  loss_ce_8: 0.000249  loss_mask_8: 0.1168  loss_dice_8: 0.1815  time: 0.6357  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:07:30] d2.utils.events INFO:  eta: 5:35:13  iter: 11279  total_loss: 3.172  loss_ce: 0.0001951  loss_mask: 0.1265  loss_dice: 0.1831  loss_ce_0: 0.1219  loss_mask_0: 0.1228  loss_dice_0: 0.1783  loss_ce_1: 0.000341  loss_mask_1: 0.1276  loss_dice_1: 0.1882  loss_ce_2: 0.0003187  loss_mask_2: 0.1223  loss_dice_2: 0.1798  loss_ce_3: 0.0001569  loss_mask_3: 0.1181  loss_dice_3: 0.1796  loss_ce_4: 0.0002618  loss_mask_4: 0.1207  loss_dice_4: 0.1759  loss_ce_5: 0.000219  loss_mask_5: 0.1214  loss_dice_5: 0.1897  loss_ce_6: 0.0001743  loss_mask_6: 0.1185  loss_dice_6: 0.1849  loss_ce_7: 0.0003724  loss_mask_7: 0.1156  loss_dice_7: 0.1733  loss_ce_8: 0.0004416  loss_mask_8: 0.1225  loss_dice_8: 0.1826  time: 0.6361  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:07:47] d2.utils.events INFO:  eta: 5:34:51  iter: 11299  total_loss: 3.071  loss_ce: 0.0001702  loss_mask: 0.1147  loss_dice: 0.1687  loss_ce_0: 0.1269  loss_mask_0: 0.1146  loss_dice_0: 0.1749  loss_ce_1: 0.0001956  loss_mask_1: 0.1128  loss_dice_1: 0.1792  loss_ce_2: 0.0002076  loss_mask_2: 0.1187  loss_dice_2: 0.1749  loss_ce_3: 0.0001192  loss_mask_3: 0.116  loss_dice_3: 0.1772  loss_ce_4: 0.0002041  loss_mask_4: 0.1202  loss_dice_4: 0.1739  loss_ce_5: 0.0001873  loss_mask_5: 0.1142  loss_dice_5: 0.1752  loss_ce_6: 0.0001145  loss_mask_6: 0.1168  loss_dice_6: 0.1777  loss_ce_7: 0.0001586  loss_mask_7: 0.1188  loss_dice_7: 0.1794  loss_ce_8: 0.0002055  loss_mask_8: 0.115  loss_dice_8: 0.1747  time: 0.6365  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:08:04] d2.utils.events INFO:  eta: 5:34:28  iter: 11319  total_loss: 3.055  loss_ce: 0.0001562  loss_mask: 0.1149  loss_dice: 0.1742  loss_ce_0: 0.1285  loss_mask_0: 0.1137  loss_dice_0: 0.1812  loss_ce_1: 0.0002156  loss_mask_1: 0.1171  loss_dice_1: 0.1713  loss_ce_2: 0.0002536  loss_mask_2: 0.117  loss_dice_2: 0.1694  loss_ce_3: 0.0001122  loss_mask_3: 0.1156  loss_dice_3: 0.1723  loss_ce_4: 0.0001779  loss_mask_4: 0.1127  loss_dice_4: 0.1677  loss_ce_5: 0.0001798  loss_mask_5: 0.116  loss_dice_5: 0.1697  loss_ce_6: 0.0001573  loss_mask_6: 0.1141  loss_dice_6: 0.1756  loss_ce_7: 0.0002178  loss_mask_7: 0.1154  loss_dice_7: 0.1687  loss_ce_8: 0.0002792  loss_mask_8: 0.1107  loss_dice_8: 0.1697  time: 0.6368  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:08:21] d2.utils.events INFO:  eta: 5:34:28  iter: 11339  total_loss: 3.136  loss_ce: 0.0001418  loss_mask: 0.1265  loss_dice: 0.1843  loss_ce_0: 0.1207  loss_mask_0: 0.12  loss_dice_0: 0.1784  loss_ce_1: 0.0002502  loss_mask_1: 0.1264  loss_dice_1: 0.1875  loss_ce_2: 0.0002296  loss_mask_2: 0.123  loss_dice_2: 0.1794  loss_ce_3: 0.0001379  loss_mask_3: 0.1176  loss_dice_3: 0.1799  loss_ce_4: 0.0001806  loss_mask_4: 0.1272  loss_dice_4: 0.1776  loss_ce_5: 0.0001731  loss_mask_5: 0.1206  loss_dice_5: 0.1761  loss_ce_6: 0.0001553  loss_mask_6: 0.1218  loss_dice_6: 0.1802  loss_ce_7: 0.0002404  loss_mask_7: 0.1232  loss_dice_7: 0.1876  loss_ce_8: 0.000285  loss_mask_8: 0.1211  loss_dice_8: 0.1829  time: 0.6372  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:08:38] d2.utils.events INFO:  eta: 5:34:14  iter: 11359  total_loss: 3.25  loss_ce: 0.0001516  loss_mask: 0.1218  loss_dice: 0.1899  loss_ce_0: 0.1258  loss_mask_0: 0.1203  loss_dice_0: 0.1907  loss_ce_1: 0.0001638  loss_mask_1: 0.1225  loss_dice_1: 0.1896  loss_ce_2: 0.0002286  loss_mask_2: 0.1229  loss_dice_2: 0.1885  loss_ce_3: 0.0001532  loss_mask_3: 0.121  loss_dice_3: 0.1925  loss_ce_4: 0.0001845  loss_mask_4: 0.1208  loss_dice_4: 0.1872  loss_ce_5: 0.0001504  loss_mask_5: 0.1269  loss_dice_5: 0.1857  loss_ce_6: 0.0001406  loss_mask_6: 0.1234  loss_dice_6: 0.1911  loss_ce_7: 0.0002053  loss_mask_7: 0.12  loss_dice_7: 0.1891  loss_ce_8: 0.0002357  loss_mask_8: 0.1241  loss_dice_8: 0.1951  time: 0.6376  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:08:55] d2.utils.events INFO:  eta: 5:34:01  iter: 11379  total_loss: 3.37  loss_ce: 0.0001311  loss_mask: 0.1136  loss_dice: 0.1961  loss_ce_0: 0.1251  loss_mask_0: 0.1188  loss_dice_0: 0.1972  loss_ce_1: 0.0001987  loss_mask_1: 0.1211  loss_dice_1: 0.1998  loss_ce_2: 0.000209  loss_mask_2: 0.1199  loss_dice_2: 0.1945  loss_ce_3: 0.0001439  loss_mask_3: 0.1219  loss_dice_3: 0.1967  loss_ce_4: 0.0001625  loss_mask_4: 0.1183  loss_dice_4: 0.1924  loss_ce_5: 0.0001466  loss_mask_5: 0.1219  loss_dice_5: 0.1995  loss_ce_6: 0.0001328  loss_mask_6: 0.1172  loss_dice_6: 0.1918  loss_ce_7: 0.0001692  loss_mask_7: 0.1149  loss_dice_7: 0.1969  loss_ce_8: 0.0001852  loss_mask_8: 0.1258  loss_dice_8: 0.1959  time: 0.6380  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:09:12] d2.utils.events INFO:  eta: 5:33:53  iter: 11399  total_loss: 3.005  loss_ce: 0.0001145  loss_mask: 0.1144  loss_dice: 0.1708  loss_ce_0: 0.1263  loss_mask_0: 0.1168  loss_dice_0: 0.1733  loss_ce_1: 0.000175  loss_mask_1: 0.1124  loss_dice_1: 0.1744  loss_ce_2: 0.0001942  loss_mask_2: 0.1117  loss_dice_2: 0.1744  loss_ce_3: 8.755e-05  loss_mask_3: 0.112  loss_dice_3: 0.1725  loss_ce_4: 0.0001372  loss_mask_4: 0.1117  loss_dice_4: 0.1735  loss_ce_5: 0.0001492  loss_mask_5: 0.1146  loss_dice_5: 0.1751  loss_ce_6: 0.0001279  loss_mask_6: 0.1149  loss_dice_6: 0.1746  loss_ce_7: 0.0001664  loss_mask_7: 0.1117  loss_dice_7: 0.1741  loss_ce_8: 0.0001807  loss_mask_8: 0.1154  loss_dice_8: 0.1756  time: 0.6383  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:09:28] d2.utils.events INFO:  eta: 5:33:30  iter: 11419  total_loss: 3.017  loss_ce: 0.000105  loss_mask: 0.1169  loss_dice: 0.1692  loss_ce_0: 0.1224  loss_mask_0: 0.1168  loss_dice_0: 0.1768  loss_ce_1: 0.0001665  loss_mask_1: 0.1164  loss_dice_1: 0.1658  loss_ce_2: 0.0002084  loss_mask_2: 0.1183  loss_dice_2: 0.1707  loss_ce_3: 8.462e-05  loss_mask_3: 0.1183  loss_dice_3: 0.1691  loss_ce_4: 0.0001225  loss_mask_4: 0.1211  loss_dice_4: 0.1755  loss_ce_5: 0.000145  loss_mask_5: 0.1156  loss_dice_5: 0.1712  loss_ce_6: 0.0001226  loss_mask_6: 0.1208  loss_dice_6: 0.17  loss_ce_7: 0.0001594  loss_mask_7: 0.117  loss_dice_7: 0.1727  loss_ce_8: 0.0001825  loss_mask_8: 0.1166  loss_dice_8: 0.1746  time: 0.6387  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:09:45] d2.utils.events INFO:  eta: 5:33:13  iter: 11439  total_loss: 3.074  loss_ce: 0.0001066  loss_mask: 0.121  loss_dice: 0.17  loss_ce_0: 0.1224  loss_mask_0: 0.1211  loss_dice_0: 0.1748  loss_ce_1: 0.000176  loss_mask_1: 0.1261  loss_dice_1: 0.1737  loss_ce_2: 0.0001742  loss_mask_2: 0.1207  loss_dice_2: 0.1739  loss_ce_3: 8.345e-05  loss_mask_3: 0.1208  loss_dice_3: 0.1713  loss_ce_4: 0.0001187  loss_mask_4: 0.1214  loss_dice_4: 0.1673  loss_ce_5: 0.0001388  loss_mask_5: 0.1205  loss_dice_5: 0.1735  loss_ce_6: 0.0001055  loss_mask_6: 0.124  loss_dice_6: 0.1724  loss_ce_7: 0.0001491  loss_mask_7: 0.1184  loss_dice_7: 0.1709  loss_ce_8: 0.000151  loss_mask_8: 0.1226  loss_dice_8: 0.173  time: 0.6391  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:10:02] d2.utils.events INFO:  eta: 5:32:47  iter: 11459  total_loss: 2.973  loss_ce: 9.93e-05  loss_mask: 0.121  loss_dice: 0.1661  loss_ce_0: 0.1227  loss_mask_0: 0.1262  loss_dice_0: 0.1675  loss_ce_1: 0.0001595  loss_mask_1: 0.1186  loss_dice_1: 0.1673  loss_ce_2: 0.0001806  loss_mask_2: 0.1228  loss_dice_2: 0.1664  loss_ce_3: 8.617e-05  loss_mask_3: 0.1251  loss_dice_3: 0.1689  loss_ce_4: 0.0001085  loss_mask_4: 0.121  loss_dice_4: 0.1691  loss_ce_5: 0.0001272  loss_mask_5: 0.1202  loss_dice_5: 0.1704  loss_ce_6: 0.0001205  loss_mask_6: 0.1209  loss_dice_6: 0.1722  loss_ce_7: 0.0001302  loss_mask_7: 0.1263  loss_dice_7: 0.1709  loss_ce_8: 0.0001634  loss_mask_8: 0.1183  loss_dice_8: 0.1685  time: 0.6394  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:10:19] d2.utils.events INFO:  eta: 5:32:23  iter: 11479  total_loss: 3.219  loss_ce: 9.013e-05  loss_mask: 0.1206  loss_dice: 0.1898  loss_ce_0: 0.125  loss_mask_0: 0.1188  loss_dice_0: 0.1833  loss_ce_1: 0.0001546  loss_mask_1: 0.1184  loss_dice_1: 0.1834  loss_ce_2: 0.000143  loss_mask_2: 0.1191  loss_dice_2: 0.187  loss_ce_3: 7.722e-05  loss_mask_3: 0.1217  loss_dice_3: 0.1831  loss_ce_4: 0.0001058  loss_mask_4: 0.1164  loss_dice_4: 0.1804  loss_ce_5: 0.0001095  loss_mask_5: 0.1243  loss_dice_5: 0.1899  loss_ce_6: 0.0001106  loss_mask_6: 0.1176  loss_dice_6: 0.1903  loss_ce_7: 0.0001232  loss_mask_7: 0.1179  loss_dice_7: 0.1875  loss_ce_8: 0.0001474  loss_mask_8: 0.1168  loss_dice_8: 0.1903  time: 0.6398  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:10:36] d2.utils.events INFO:  eta: 5:32:01  iter: 11499  total_loss: 2.974  loss_ce: 9.005e-05  loss_mask: 0.1185  loss_dice: 0.1674  loss_ce_0: 0.115  loss_mask_0: 0.1182  loss_dice_0: 0.1694  loss_ce_1: 0.0001568  loss_mask_1: 0.1173  loss_dice_1: 0.168  loss_ce_2: 0.0001504  loss_mask_2: 0.1226  loss_dice_2: 0.1767  loss_ce_3: 8.517e-05  loss_mask_3: 0.1166  loss_dice_3: 0.1678  loss_ce_4: 0.0001001  loss_mask_4: 0.1199  loss_dice_4: 0.1701  loss_ce_5: 0.0001205  loss_mask_5: 0.1189  loss_dice_5: 0.1639  loss_ce_6: 0.0001043  loss_mask_6: 0.1195  loss_dice_6: 0.173  loss_ce_7: 0.0001173  loss_mask_7: 0.1163  loss_dice_7: 0.1644  loss_ce_8: 0.0001497  loss_mask_8: 0.1162  loss_dice_8: 0.1681  time: 0.6401  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:10:53] d2.utils.events INFO:  eta: 5:31:50  iter: 11519  total_loss: 3.107  loss_ce: 8.28e-05  loss_mask: 0.1171  loss_dice: 0.1767  loss_ce_0: 0.1303  loss_mask_0: 0.1172  loss_dice_0: 0.1785  loss_ce_1: 0.0001336  loss_mask_1: 0.1171  loss_dice_1: 0.1781  loss_ce_2: 0.0001258  loss_mask_2: 0.1191  loss_dice_2: 0.1756  loss_ce_3: 6.403e-05  loss_mask_3: 0.1125  loss_dice_3: 0.1713  loss_ce_4: 9.407e-05  loss_mask_4: 0.1165  loss_dice_4: 0.1718  loss_ce_5: 9.213e-05  loss_mask_5: 0.1193  loss_dice_5: 0.1788  loss_ce_6: 9.847e-05  loss_mask_6: 0.1163  loss_dice_6: 0.1778  loss_ce_7: 0.000112  loss_mask_7: 0.1169  loss_dice_7: 0.1709  loss_ce_8: 0.0001157  loss_mask_8: 0.1195  loss_dice_8: 0.1836  time: 0.6405  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:11:10] d2.utils.events INFO:  eta: 5:31:21  iter: 11539  total_loss: 2.97  loss_ce: 7.442e-05  loss_mask: 0.1153  loss_dice: 0.1662  loss_ce_0: 0.1288  loss_mask_0: 0.114  loss_dice_0: 0.1665  loss_ce_1: 0.000135  loss_mask_1: 0.1194  loss_dice_1: 0.1667  loss_ce_2: 0.000118  loss_mask_2: 0.1168  loss_dice_2: 0.1692  loss_ce_3: 6.873e-05  loss_mask_3: 0.1202  loss_dice_3: 0.1677  loss_ce_4: 0.0001015  loss_mask_4: 0.1132  loss_dice_4: 0.1631  loss_ce_5: 9.001e-05  loss_mask_5: 0.1194  loss_dice_5: 0.1689  loss_ce_6: 9.262e-05  loss_mask_6: 0.1172  loss_dice_6: 0.1686  loss_ce_7: 0.0001036  loss_mask_7: 0.1157  loss_dice_7: 0.1641  loss_ce_8: 0.0001119  loss_mask_8: 0.1141  loss_dice_8: 0.1623  time: 0.6408  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:11:27] d2.utils.events INFO:  eta: 5:31:00  iter: 11559  total_loss: 2.963  loss_ce: 7.961e-05  loss_mask: 0.1166  loss_dice: 0.1748  loss_ce_0: 0.1297  loss_mask_0: 0.1181  loss_dice_0: 0.1656  loss_ce_1: 0.0001208  loss_mask_1: 0.119  loss_dice_1: 0.1737  loss_ce_2: 0.0001232  loss_mask_2: 0.1178  loss_dice_2: 0.1658  loss_ce_3: 6.541e-05  loss_mask_3: 0.119  loss_dice_3: 0.1704  loss_ce_4: 9.407e-05  loss_mask_4: 0.1185  loss_dice_4: 0.168  loss_ce_5: 0.0001117  loss_mask_5: 0.1135  loss_dice_5: 0.1703  loss_ce_6: 7.784e-05  loss_mask_6: 0.1204  loss_dice_6: 0.1732  loss_ce_7: 9.726e-05  loss_mask_7: 0.1194  loss_dice_7: 0.1729  loss_ce_8: 0.0001064  loss_mask_8: 0.1213  loss_dice_8: 0.1678  time: 0.6412  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 19:11:44] d2.utils.events INFO:  eta: 5:30:52  iter: 11579  total_loss: 3.032  loss_ce: 7.562e-05  loss_mask: 0.1155  loss_dice: 0.1735  loss_ce_0: 0.125  loss_mask_0: 0.1176  loss_dice_0: 0.1757  loss_ce_1: 0.0001159  loss_mask_1: 0.1107  loss_dice_1: 0.1726  loss_ce_2: 0.0001185  loss_mask_2: 0.1124  loss_dice_2: 0.1724  loss_ce_3: 6.212e-05  loss_mask_3: 0.1159  loss_dice_3: 0.174  loss_ce_4: 8.887e-05  loss_mask_4: 0.1148  loss_dice_4: 0.1789  loss_ce_5: 9.159e-05  loss_mask_5: 0.1169  loss_dice_5: 0.1801  loss_ce_6: 8.563e-05  loss_mask_6: 0.1176  loss_dice_6: 0.1739  loss_ce_7: 9.484e-05  loss_mask_7: 0.1141  loss_dice_7: 0.1745  loss_ce_8: 0.0001011  loss_mask_8: 0.1178  loss_dice_8: 0.1775  time: 0.6416  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:12:01] d2.utils.events INFO:  eta: 5:30:21  iter: 11599  total_loss: 3.136  loss_ce: 6.399e-05  loss_mask: 0.1288  loss_dice: 0.1795  loss_ce_0: 0.1217  loss_mask_0: 0.1231  loss_dice_0: 0.1733  loss_ce_1: 0.0001211  loss_mask_1: 0.1213  loss_dice_1: 0.1726  loss_ce_2: 0.0001299  loss_mask_2: 0.1311  loss_dice_2: 0.1761  loss_ce_3: 6.645e-05  loss_mask_3: 0.1202  loss_dice_3: 0.1756  loss_ce_4: 8.252e-05  loss_mask_4: 0.1233  loss_dice_4: 0.1778  loss_ce_5: 0.0001056  loss_mask_5: 0.1229  loss_dice_5: 0.174  loss_ce_6: 9.068e-05  loss_mask_6: 0.126  loss_dice_6: 0.1701  loss_ce_7: 9.327e-05  loss_mask_7: 0.1268  loss_dice_7: 0.1736  loss_ce_8: 0.0001273  loss_mask_8: 0.1261  loss_dice_8: 0.179  time: 0.6419  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:12:18] d2.utils.events INFO:  eta: 5:30:00  iter: 11619  total_loss: 3.149  loss_ce: 7.218e-05  loss_mask: 0.1191  loss_dice: 0.1731  loss_ce_0: 0.122  loss_mask_0: 0.1213  loss_dice_0: 0.1793  loss_ce_1: 0.0001216  loss_mask_1: 0.1185  loss_dice_1: 0.1778  loss_ce_2: 0.0001236  loss_mask_2: 0.1223  loss_dice_2: 0.1804  loss_ce_3: 6.501e-05  loss_mask_3: 0.1221  loss_dice_3: 0.1805  loss_ce_4: 8.146e-05  loss_mask_4: 0.1179  loss_dice_4: 0.1758  loss_ce_5: 9.517e-05  loss_mask_5: 0.12  loss_dice_5: 0.1736  loss_ce_6: 8.226e-05  loss_mask_6: 0.1223  loss_dice_6: 0.182  loss_ce_7: 9.635e-05  loss_mask_7: 0.1228  loss_dice_7: 0.1769  loss_ce_8: 0.0001333  loss_mask_8: 0.1239  loss_dice_8: 0.1853  time: 0.6423  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:12:35] d2.utils.events INFO:  eta: 5:29:47  iter: 11639  total_loss: 3.108  loss_ce: 7.47e-05  loss_mask: 0.1204  loss_dice: 0.1796  loss_ce_0: 0.1263  loss_mask_0: 0.1146  loss_dice_0: 0.1817  loss_ce_1: 0.0001097  loss_mask_1: 0.1127  loss_dice_1: 0.1842  loss_ce_2: 0.0001108  loss_mask_2: 0.116  loss_dice_2: 0.1736  loss_ce_3: 6.094e-05  loss_mask_3: 0.1127  loss_dice_3: 0.1831  loss_ce_4: 7.668e-05  loss_mask_4: 0.1158  loss_dice_4: 0.1761  loss_ce_5: 8.14e-05  loss_mask_5: 0.1169  loss_dice_5: 0.1801  loss_ce_6: 5.86e-05  loss_mask_6: 0.1156  loss_dice_6: 0.1862  loss_ce_7: 8.673e-05  loss_mask_7: 0.1156  loss_dice_7: 0.1777  loss_ce_8: 9.133e-05  loss_mask_8: 0.1121  loss_dice_8: 0.1817  time: 0.6426  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:12:52] d2.utils.events INFO:  eta: 5:29:26  iter: 11659  total_loss: 3.167  loss_ce: 7.405e-05  loss_mask: 0.1194  loss_dice: 0.1804  loss_ce_0: 0.1229  loss_mask_0: 0.1226  loss_dice_0: 0.1815  loss_ce_1: 0.0001167  loss_mask_1: 0.1197  loss_dice_1: 0.1831  loss_ce_2: 0.0001187  loss_mask_2: 0.1213  loss_dice_2: 0.1859  loss_ce_3: 6.169e-05  loss_mask_3: 0.1233  loss_dice_3: 0.1812  loss_ce_4: 7.571e-05  loss_mask_4: 0.1246  loss_dice_4: 0.1867  loss_ce_5: 9.061e-05  loss_mask_5: 0.1189  loss_dice_5: 0.1717  loss_ce_6: 7.882e-05  loss_mask_6: 0.1238  loss_dice_6: 0.1777  loss_ce_7: 8.799e-05  loss_mask_7: 0.12  loss_dice_7: 0.1761  loss_ce_8: 0.0001071  loss_mask_8: 0.1193  loss_dice_8: 0.1742  time: 0.6430  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:13:08] d2.utils.events INFO:  eta: 5:29:10  iter: 11679  total_loss: 2.985  loss_ce: 9.127e-05  loss_mask: 0.12  loss_dice: 0.1674  loss_ce_0: 0.1212  loss_mask_0: 0.1184  loss_dice_0: 0.177  loss_ce_1: 8.819e-05  loss_mask_1: 0.1145  loss_dice_1: 0.1671  loss_ce_2: 8.796e-05  loss_mask_2: 0.1162  loss_dice_2: 0.1655  loss_ce_3: 5.31e-05  loss_mask_3: 0.1184  loss_dice_3: 0.1674  loss_ce_4: 7.04e-05  loss_mask_4: 0.1151  loss_dice_4: 0.166  loss_ce_5: 6.742e-05  loss_mask_5: 0.1139  loss_dice_5: 0.1666  loss_ce_6: 5.847e-05  loss_mask_6: 0.1112  loss_dice_6: 0.1626  loss_ce_7: 8.48e-05  loss_mask_7: 0.1145  loss_dice_7: 0.1632  loss_ce_8: 8.761e-05  loss_mask_8: 0.1168  loss_dice_8: 0.1734  time: 0.6433  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:13:25] d2.utils.events INFO:  eta: 5:28:49  iter: 11699  total_loss: 3.057  loss_ce: 7.032e-05  loss_mask: 0.1156  loss_dice: 0.1687  loss_ce_0: 0.1316  loss_mask_0: 0.1142  loss_dice_0: 0.173  loss_ce_1: 9.517e-05  loss_mask_1: 0.1144  loss_dice_1: 0.1711  loss_ce_2: 8.434e-05  loss_mask_2: 0.1174  loss_dice_2: 0.1721  loss_ce_3: 6.604e-05  loss_mask_3: 0.1178  loss_dice_3: 0.1774  loss_ce_4: 7.613e-05  loss_mask_4: 0.1133  loss_dice_4: 0.1729  loss_ce_5: 6.772e-05  loss_mask_5: 0.116  loss_dice_5: 0.1677  loss_ce_6: 7.49e-05  loss_mask_6: 0.1207  loss_dice_6: 0.1752  loss_ce_7: 7.893e-05  loss_mask_7: 0.1192  loss_dice_7: 0.1757  loss_ce_8: 8.9e-05  loss_mask_8: 0.119  loss_dice_8: 0.175  time: 0.6436  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 19:13:42] d2.utils.events INFO:  eta: 5:28:27  iter: 11719  total_loss: 3.053  loss_ce: 5.979e-05  loss_mask: 0.1201  loss_dice: 0.1696  loss_ce_0: 0.1218  loss_mask_0: 0.1211  loss_dice_0: 0.172  loss_ce_1: 0.0001088  loss_mask_1: 0.1207  loss_dice_1: 0.1775  loss_ce_2: 0.0001053  loss_mask_2: 0.1168  loss_dice_2: 0.1723  loss_ce_3: 5.473e-05  loss_mask_3: 0.1207  loss_dice_3: 0.1743  loss_ce_4: 7.843e-05  loss_mask_4: 0.1215  loss_dice_4: 0.1818  loss_ce_5: 7.676e-05  loss_mask_5: 0.1186  loss_dice_5: 0.1732  loss_ce_6: 7.025e-05  loss_mask_6: 0.1199  loss_dice_6: 0.1778  loss_ce_7: 7.609e-05  loss_mask_7: 0.1184  loss_dice_7: 0.1792  loss_ce_8: 9.477e-05  loss_mask_8: 0.1224  loss_dice_8: 0.1836  time: 0.6440  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:13:59] d2.utils.events INFO:  eta: 5:28:07  iter: 11739  total_loss: 2.923  loss_ce: 6.155e-05  loss_mask: 0.1151  loss_dice: 0.1687  loss_ce_0: 0.125  loss_mask_0: 0.1146  loss_dice_0: 0.17  loss_ce_1: 9.951e-05  loss_mask_1: 0.114  loss_dice_1: 0.1643  loss_ce_2: 9.228e-05  loss_mask_2: 0.1147  loss_dice_2: 0.1664  loss_ce_3: 6.139e-05  loss_mask_3: 0.1172  loss_dice_3: 0.1662  loss_ce_4: 8.208e-05  loss_mask_4: 0.116  loss_dice_4: 0.1655  loss_ce_5: 7.165e-05  loss_mask_5: 0.1179  loss_dice_5: 0.1674  loss_ce_6: 7.608e-05  loss_mask_6: 0.1187  loss_dice_6: 0.1692  loss_ce_7: 8.286e-05  loss_mask_7: 0.1148  loss_dice_7: 0.1646  loss_ce_8: 9.91e-05  loss_mask_8: 0.1157  loss_dice_8: 0.1743  time: 0.6443  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:14:16] d2.utils.events INFO:  eta: 5:27:46  iter: 11759  total_loss: 2.98  loss_ce: 6.198e-05  loss_mask: 0.1202  loss_dice: 0.1701  loss_ce_0: 0.1232  loss_mask_0: 0.1221  loss_dice_0: 0.1748  loss_ce_1: 9.802e-05  loss_mask_1: 0.1213  loss_dice_1: 0.17  loss_ce_2: 9.837e-05  loss_mask_2: 0.1231  loss_dice_2: 0.1719  loss_ce_3: 4.918e-05  loss_mask_3: 0.1235  loss_dice_3: 0.1752  loss_ce_4: 7.03e-05  loss_mask_4: 0.1212  loss_dice_4: 0.174  loss_ce_5: 7.376e-05  loss_mask_5: 0.1224  loss_dice_5: 0.1723  loss_ce_6: 6.782e-05  loss_mask_6: 0.1208  loss_dice_6: 0.1718  loss_ce_7: 7.328e-05  loss_mask_7: 0.1235  loss_dice_7: 0.1733  loss_ce_8: 9.032e-05  loss_mask_8: 0.1217  loss_dice_8: 0.1728  time: 0.6447  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:14:33] d2.utils.events INFO:  eta: 5:27:21  iter: 11779  total_loss: 2.915  loss_ce: 5.415e-05  loss_mask: 0.1125  loss_dice: 0.1619  loss_ce_0: 0.1248  loss_mask_0: 0.1096  loss_dice_0: 0.1583  loss_ce_1: 8.125e-05  loss_mask_1: 0.1129  loss_dice_1: 0.1577  loss_ce_2: 7.514e-05  loss_mask_2: 0.1111  loss_dice_2: 0.1616  loss_ce_3: 4.107e-05  loss_mask_3: 0.1144  loss_dice_3: 0.1636  loss_ce_4: 6.625e-05  loss_mask_4: 0.1128  loss_dice_4: 0.1646  loss_ce_5: 6.185e-05  loss_mask_5: 0.1144  loss_dice_5: 0.1674  loss_ce_6: 5.074e-05  loss_mask_6: 0.115  loss_dice_6: 0.1634  loss_ce_7: 6.959e-05  loss_mask_7: 0.1117  loss_dice_7: 0.1628  loss_ce_8: 7.679e-05  loss_mask_8: 0.1151  loss_dice_8: 0.1712  time: 0.6450  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:14:50] d2.utils.events INFO:  eta: 5:27:05  iter: 11799  total_loss: 3  loss_ce: 5.316e-05  loss_mask: 0.1161  loss_dice: 0.1653  loss_ce_0: 0.1204  loss_mask_0: 0.1185  loss_dice_0: 0.1689  loss_ce_1: 9.323e-05  loss_mask_1: 0.1184  loss_dice_1: 0.1666  loss_ce_2: 8.922e-05  loss_mask_2: 0.1208  loss_dice_2: 0.1676  loss_ce_3: 5.536e-05  loss_mask_3: 0.1177  loss_dice_3: 0.1684  loss_ce_4: 6.943e-05  loss_mask_4: 0.1129  loss_dice_4: 0.165  loss_ce_5: 7.979e-05  loss_mask_5: 0.1227  loss_dice_5: 0.1661  loss_ce_6: 6.233e-05  loss_mask_6: 0.1147  loss_dice_6: 0.1649  loss_ce_7: 6.889e-05  loss_mask_7: 0.1196  loss_dice_7: 0.1719  loss_ce_8: 7.9e-05  loss_mask_8: 0.1216  loss_dice_8: 0.1681  time: 0.6453  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:15:07] d2.utils.events INFO:  eta: 5:26:47  iter: 11819  total_loss: 2.933  loss_ce: 5.671e-05  loss_mask: 0.1168  loss_dice: 0.1624  loss_ce_0: 0.1184  loss_mask_0: 0.1148  loss_dice_0: 0.175  loss_ce_1: 9.257e-05  loss_mask_1: 0.1196  loss_dice_1: 0.1703  loss_ce_2: 9.086e-05  loss_mask_2: 0.1141  loss_dice_2: 0.1635  loss_ce_3: 4.87e-05  loss_mask_3: 0.1161  loss_dice_3: 0.1701  loss_ce_4: 6.85e-05  loss_mask_4: 0.1115  loss_dice_4: 0.1644  loss_ce_5: 7.28e-05  loss_mask_5: 0.1147  loss_dice_5: 0.1657  loss_ce_6: 6.569e-05  loss_mask_6: 0.1198  loss_dice_6: 0.168  loss_ce_7: 6.612e-05  loss_mask_7: 0.1154  loss_dice_7: 0.1643  loss_ce_8: 8.768e-05  loss_mask_8: 0.1156  loss_dice_8: 0.1655  time: 0.6457  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:15:24] d2.utils.events INFO:  eta: 5:26:17  iter: 11839  total_loss: 3.076  loss_ce: 5.306e-05  loss_mask: 0.114  loss_dice: 0.1706  loss_ce_0: 0.1222  loss_mask_0: 0.1172  loss_dice_0: 0.1779  loss_ce_1: 8.899e-05  loss_mask_1: 0.1161  loss_dice_1: 0.1751  loss_ce_2: 9.247e-05  loss_mask_2: 0.1194  loss_dice_2: 0.1832  loss_ce_3: 5.102e-05  loss_mask_3: 0.118  loss_dice_3: 0.1794  loss_ce_4: 7.147e-05  loss_mask_4: 0.1179  loss_dice_4: 0.1787  loss_ce_5: 7.281e-05  loss_mask_5: 0.1167  loss_dice_5: 0.1808  loss_ce_6: 6.648e-05  loss_mask_6: 0.121  loss_dice_6: 0.1797  loss_ce_7: 6.71e-05  loss_mask_7: 0.1169  loss_dice_7: 0.1729  loss_ce_8: 8.582e-05  loss_mask_8: 0.1205  loss_dice_8: 0.1752  time: 0.6460  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:15:40] d2.utils.events INFO:  eta: 5:25:38  iter: 11859  total_loss: 3.328  loss_ce: 5.341e-05  loss_mask: 0.126  loss_dice: 0.1877  loss_ce_0: 0.12  loss_mask_0: 0.1324  loss_dice_0: 0.1903  loss_ce_1: 8.818e-05  loss_mask_1: 0.1281  loss_dice_1: 0.1864  loss_ce_2: 8.245e-05  loss_mask_2: 0.1265  loss_dice_2: 0.1819  loss_ce_3: 5.189e-05  loss_mask_3: 0.1265  loss_dice_3: 0.1853  loss_ce_4: 6.195e-05  loss_mask_4: 0.1287  loss_dice_4: 0.1882  loss_ce_5: 6.27e-05  loss_mask_5: 0.129  loss_dice_5: 0.1997  loss_ce_6: 6.615e-05  loss_mask_6: 0.1267  loss_dice_6: 0.1885  loss_ce_7: 6.522e-05  loss_mask_7: 0.1296  loss_dice_7: 0.186  loss_ce_8: 8.561e-05  loss_mask_8: 0.1282  loss_dice_8: 0.1897  time: 0.6463  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:15:57] d2.utils.events INFO:  eta: 5:25:15  iter: 11879  total_loss: 3.091  loss_ce: 5.368e-05  loss_mask: 0.1186  loss_dice: 0.1754  loss_ce_0: 0.1248  loss_mask_0: 0.1164  loss_dice_0: 0.1853  loss_ce_1: 7.741e-05  loss_mask_1: 0.117  loss_dice_1: 0.173  loss_ce_2: 6.939e-05  loss_mask_2: 0.1205  loss_dice_2: 0.1869  loss_ce_3: 3.787e-05  loss_mask_3: 0.1203  loss_dice_3: 0.1795  loss_ce_4: 5.477e-05  loss_mask_4: 0.1181  loss_dice_4: 0.1794  loss_ce_5: 6.383e-05  loss_mask_5: 0.1185  loss_dice_5: 0.1785  loss_ce_6: 4.864e-05  loss_mask_6: 0.1206  loss_dice_6: 0.1808  loss_ce_7: 6.186e-05  loss_mask_7: 0.1191  loss_dice_7: 0.1802  loss_ce_8: 7.289e-05  loss_mask_8: 0.1179  loss_dice_8: 0.1795  time: 0.6466  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:16:14] d2.utils.events INFO:  eta: 5:24:43  iter: 11899  total_loss: 2.998  loss_ce: 5.09e-05  loss_mask: 0.1161  loss_dice: 0.1711  loss_ce_0: 0.1213  loss_mask_0: 0.1193  loss_dice_0: 0.1756  loss_ce_1: 8.322e-05  loss_mask_1: 0.1184  loss_dice_1: 0.1727  loss_ce_2: 8.531e-05  loss_mask_2: 0.1188  loss_dice_2: 0.1731  loss_ce_3: 5.17e-05  loss_mask_3: 0.1141  loss_dice_3: 0.1722  loss_ce_4: 6.515e-05  loss_mask_4: 0.116  loss_dice_4: 0.1718  loss_ce_5: 7.599e-05  loss_mask_5: 0.1147  loss_dice_5: 0.1713  loss_ce_6: 6.092e-05  loss_mask_6: 0.1194  loss_dice_6: 0.1682  loss_ce_7: 6.787e-05  loss_mask_7: 0.1165  loss_dice_7: 0.1712  loss_ce_8: 8.238e-05  loss_mask_8: 0.1177  loss_dice_8: 0.1701  time: 0.6470  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:16:31] d2.utils.events INFO:  eta: 5:24:23  iter: 11919  total_loss: 2.871  loss_ce: 5.341e-05  loss_mask: 0.1157  loss_dice: 0.163  loss_ce_0: 0.1199  loss_mask_0: 0.1127  loss_dice_0: 0.1649  loss_ce_1: 7.683e-05  loss_mask_1: 0.1154  loss_dice_1: 0.1652  loss_ce_2: 7.491e-05  loss_mask_2: 0.1123  loss_dice_2: 0.1664  loss_ce_3: 5.017e-05  loss_mask_3: 0.1171  loss_dice_3: 0.1619  loss_ce_4: 6.375e-05  loss_mask_4: 0.1151  loss_dice_4: 0.1612  loss_ce_5: 6.641e-05  loss_mask_5: 0.1157  loss_dice_5: 0.1628  loss_ce_6: 5.849e-05  loss_mask_6: 0.1123  loss_dice_6: 0.1652  loss_ce_7: 6.058e-05  loss_mask_7: 0.1134  loss_dice_7: 0.1633  loss_ce_8: 7.165e-05  loss_mask_8: 0.1163  loss_dice_8: 0.169  time: 0.6473  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:16:48] d2.utils.events INFO:  eta: 5:24:14  iter: 11939  total_loss: 3.032  loss_ce: 5.512e-05  loss_mask: 0.1171  loss_dice: 0.1754  loss_ce_0: 0.1262  loss_mask_0: 0.1135  loss_dice_0: 0.1812  loss_ce_1: 7.152e-05  loss_mask_1: 0.1141  loss_dice_1: 0.1714  loss_ce_2: 6.868e-05  loss_mask_2: 0.1177  loss_dice_2: 0.1708  loss_ce_3: 4.883e-05  loss_mask_3: 0.1162  loss_dice_3: 0.1725  loss_ce_4: 5.87e-05  loss_mask_4: 0.1205  loss_dice_4: 0.1744  loss_ce_5: 5.399e-05  loss_mask_5: 0.12  loss_dice_5: 0.1783  loss_ce_6: 6.163e-05  loss_mask_6: 0.1163  loss_dice_6: 0.1677  loss_ce_7: 6.219e-05  loss_mask_7: 0.1127  loss_dice_7: 0.1717  loss_ce_8: 7.905e-05  loss_mask_8: 0.1205  loss_dice_8: 0.1713  time: 0.6476  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:17:05] d2.utils.events INFO:  eta: 5:23:57  iter: 11959  total_loss: 3.229  loss_ce: 5.517e-05  loss_mask: 0.1264  loss_dice: 0.1809  loss_ce_0: 0.1247  loss_mask_0: 0.1297  loss_dice_0: 0.1895  loss_ce_1: 8.415e-05  loss_mask_1: 0.1266  loss_dice_1: 0.1731  loss_ce_2: 8.443e-05  loss_mask_2: 0.1276  loss_dice_2: 0.1797  loss_ce_3: 4.668e-05  loss_mask_3: 0.1246  loss_dice_3: 0.1757  loss_ce_4: 5.966e-05  loss_mask_4: 0.1267  loss_dice_4: 0.1745  loss_ce_5: 6.239e-05  loss_mask_5: 0.1278  loss_dice_5: 0.1714  loss_ce_6: 6.267e-05  loss_mask_6: 0.128  loss_dice_6: 0.1758  loss_ce_7: 6.471e-05  loss_mask_7: 0.1265  loss_dice_7: 0.176  loss_ce_8: 8.09e-05  loss_mask_8: 0.1313  loss_dice_8: 0.1765  time: 0.6480  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:17:22] d2.utils.events INFO:  eta: 5:23:40  iter: 11979  total_loss: 2.964  loss_ce: 4.945e-05  loss_mask: 0.1117  loss_dice: 0.1679  loss_ce_0: 0.123  loss_mask_0: 0.1151  loss_dice_0: 0.1667  loss_ce_1: 7.449e-05  loss_mask_1: 0.1142  loss_dice_1: 0.1714  loss_ce_2: 7.1e-05  loss_mask_2: 0.1164  loss_dice_2: 0.1693  loss_ce_3: 3.909e-05  loss_mask_3: 0.1133  loss_dice_3: 0.167  loss_ce_4: 5.614e-05  loss_mask_4: 0.1103  loss_dice_4: 0.1669  loss_ce_5: 6.294e-05  loss_mask_5: 0.1146  loss_dice_5: 0.1699  loss_ce_6: 5.282e-05  loss_mask_6: 0.1176  loss_dice_6: 0.1675  loss_ce_7: 6.004e-05  loss_mask_7: 0.1164  loss_dice_7: 0.1664  loss_ce_8: 6.577e-05  loss_mask_8: 0.1171  loss_dice_8: 0.1712  time: 0.6483  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 19:17:39] d2.utils.events INFO:  eta: 5:23:31  iter: 11999  total_loss: 2.955  loss_ce: 4.45e-05  loss_mask: 0.1129  loss_dice: 0.1622  loss_ce_0: 0.1217  loss_mask_0: 0.1174  loss_dice_0: 0.1718  loss_ce_1: 6.761e-05  loss_mask_1: 0.1173  loss_dice_1: 0.1662  loss_ce_2: 7.553e-05  loss_mask_2: 0.1151  loss_dice_2: 0.1662  loss_ce_3: 4.296e-05  loss_mask_3: 0.1169  loss_dice_3: 0.1615  loss_ce_4: 5.578e-05  loss_mask_4: 0.1137  loss_dice_4: 0.1651  loss_ce_5: 6.266e-05  loss_mask_5: 0.1184  loss_dice_5: 0.1642  loss_ce_6: 4.708e-05  loss_mask_6: 0.1166  loss_dice_6: 0.1695  loss_ce_7: 5.596e-05  loss_mask_7: 0.1102  loss_dice_7: 0.162  loss_ce_8: 6.437e-05  loss_mask_8: 0.1167  loss_dice_8: 0.1685  time: 0.6487  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:17:56] d2.utils.events INFO:  eta: 5:23:16  iter: 12019  total_loss: 3.15  loss_ce: 4.851e-05  loss_mask: 0.1188  loss_dice: 0.1771  loss_ce_0: 0.1232  loss_mask_0: 0.1197  loss_dice_0: 0.1769  loss_ce_1: 6.843e-05  loss_mask_1: 0.1178  loss_dice_1: 0.183  loss_ce_2: 6.648e-05  loss_mask_2: 0.1181  loss_dice_2: 0.1807  loss_ce_3: 3.36e-05  loss_mask_3: 0.1167  loss_dice_3: 0.176  loss_ce_4: 4.962e-05  loss_mask_4: 0.1197  loss_dice_4: 0.179  loss_ce_5: 5.145e-05  loss_mask_5: 0.1153  loss_dice_5: 0.1777  loss_ce_6: 4.714e-05  loss_mask_6: 0.1173  loss_dice_6: 0.1756  loss_ce_7: 5.486e-05  loss_mask_7: 0.1121  loss_dice_7: 0.1734  loss_ce_8: 6.178e-05  loss_mask_8: 0.1164  loss_dice_8: 0.1818  time: 0.6490  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:18:13] d2.utils.events INFO:  eta: 5:23:01  iter: 12039  total_loss: 3.119  loss_ce: 4.096e-05  loss_mask: 0.1185  loss_dice: 0.1881  loss_ce_0: 0.1188  loss_mask_0: 0.1215  loss_dice_0: 0.1835  loss_ce_1: 6.807e-05  loss_mask_1: 0.1242  loss_dice_1: 0.1899  loss_ce_2: 6.378e-05  loss_mask_2: 0.1219  loss_dice_2: 0.1877  loss_ce_3: 3.712e-05  loss_mask_3: 0.1201  loss_dice_3: 0.1802  loss_ce_4: 4.993e-05  loss_mask_4: 0.1274  loss_dice_4: 0.1884  loss_ce_5: 5.498e-05  loss_mask_5: 0.121  loss_dice_5: 0.195  loss_ce_6: 5.324e-05  loss_mask_6: 0.1176  loss_dice_6: 0.1802  loss_ce_7: 5.313e-05  loss_mask_7: 0.1181  loss_dice_7: 0.1812  loss_ce_8: 6.112e-05  loss_mask_8: 0.1225  loss_dice_8: 0.1863  time: 0.6493  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:18:30] d2.utils.events INFO:  eta: 5:22:42  iter: 12059  total_loss: 3.082  loss_ce: 5.365e-05  loss_mask: 0.1152  loss_dice: 0.1726  loss_ce_0: 0.1276  loss_mask_0: 0.1182  loss_dice_0: 0.1805  loss_ce_1: 6.168e-05  loss_mask_1: 0.1145  loss_dice_1: 0.1769  loss_ce_2: 6.143e-05  loss_mask_2: 0.1201  loss_dice_2: 0.1804  loss_ce_3: 4.079e-05  loss_mask_3: 0.1169  loss_dice_3: 0.1858  loss_ce_4: 5.284e-05  loss_mask_4: 0.1188  loss_dice_4: 0.1768  loss_ce_5: 4.975e-05  loss_mask_5: 0.118  loss_dice_5: 0.182  loss_ce_6: 4.623e-05  loss_mask_6: 0.1213  loss_dice_6: 0.1884  loss_ce_7: 5.309e-05  loss_mask_7: 0.1186  loss_dice_7: 0.1806  loss_ce_8: 5.434e-05  loss_mask_8: 0.1165  loss_dice_8: 0.1853  time: 0.6496  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:18:47] d2.utils.events INFO:  eta: 5:22:23  iter: 12079  total_loss: 2.981  loss_ce: 5.048e-05  loss_mask: 0.1127  loss_dice: 0.1767  loss_ce_0: 0.1238  loss_mask_0: 0.1168  loss_dice_0: 0.1818  loss_ce_1: 6.15e-05  loss_mask_1: 0.113  loss_dice_1: 0.1794  loss_ce_2: 6.396e-05  loss_mask_2: 0.1185  loss_dice_2: 0.1803  loss_ce_3: 4.042e-05  loss_mask_3: 0.1127  loss_dice_3: 0.1835  loss_ce_4: 4.981e-05  loss_mask_4: 0.1137  loss_dice_4: 0.177  loss_ce_5: 4.74e-05  loss_mask_5: 0.1138  loss_dice_5: 0.1764  loss_ce_6: 4.823e-05  loss_mask_6: 0.1126  loss_dice_6: 0.1705  loss_ce_7: 5.404e-05  loss_mask_7: 0.1179  loss_dice_7: 0.1765  loss_ce_8: 6.438e-05  loss_mask_8: 0.113  loss_dice_8: 0.1769  time: 0.6499  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:19:04] d2.utils.events INFO:  eta: 5:22:06  iter: 12099  total_loss: 3.136  loss_ce: 5.749e-05  loss_mask: 0.1203  loss_dice: 0.1847  loss_ce_0: 0.1226  loss_mask_0: 0.1202  loss_dice_0: 0.1884  loss_ce_1: 7.092e-05  loss_mask_1: 0.1244  loss_dice_1: 0.1855  loss_ce_2: 6.031e-05  loss_mask_2: 0.1243  loss_dice_2: 0.1813  loss_ce_3: 3.566e-05  loss_mask_3: 0.1225  loss_dice_3: 0.179  loss_ce_4: 4.576e-05  loss_mask_4: 0.1225  loss_dice_4: 0.1776  loss_ce_5: 5.027e-05  loss_mask_5: 0.1181  loss_dice_5: 0.1782  loss_ce_6: 3.815e-05  loss_mask_6: 0.1156  loss_dice_6: 0.1815  loss_ce_7: 5.189e-05  loss_mask_7: 0.1177  loss_dice_7: 0.1845  loss_ce_8: 5.809e-05  loss_mask_8: 0.1228  loss_dice_8: 0.1855  time: 0.6503  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:19:21] d2.utils.events INFO:  eta: 5:21:49  iter: 12119  total_loss: 3.081  loss_ce: 4.249e-05  loss_mask: 0.1198  loss_dice: 0.1719  loss_ce_0: 0.1217  loss_mask_0: 0.1195  loss_dice_0: 0.1732  loss_ce_1: 6.19e-05  loss_mask_1: 0.1229  loss_dice_1: 0.1737  loss_ce_2: 6.921e-05  loss_mask_2: 0.1231  loss_dice_2: 0.1751  loss_ce_3: 3.777e-05  loss_mask_3: 0.1226  loss_dice_3: 0.1724  loss_ce_4: 4.933e-05  loss_mask_4: 0.1243  loss_dice_4: 0.1757  loss_ce_5: 6.008e-05  loss_mask_5: 0.1202  loss_dice_5: 0.1681  loss_ce_6: 4.823e-05  loss_mask_6: 0.1272  loss_dice_6: 0.1757  loss_ce_7: 5.36e-05  loss_mask_7: 0.1234  loss_dice_7: 0.1738  loss_ce_8: 6.319e-05  loss_mask_8: 0.1205  loss_dice_8: 0.1736  time: 0.6506  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:19:37] d2.utils.events INFO:  eta: 5:21:30  iter: 12139  total_loss: 3.34  loss_ce: 4.165e-05  loss_mask: 0.1278  loss_dice: 0.1961  loss_ce_0: 0.1204  loss_mask_0: 0.1252  loss_dice_0: 0.204  loss_ce_1: 6.723e-05  loss_mask_1: 0.1234  loss_dice_1: 0.1993  loss_ce_2: 6.036e-05  loss_mask_2: 0.1225  loss_dice_2: 0.2006  loss_ce_3: 3.419e-05  loss_mask_3: 0.1257  loss_dice_3: 0.197  loss_ce_4: 4.66e-05  loss_mask_4: 0.1215  loss_dice_4: 0.1934  loss_ce_5: 5.573e-05  loss_mask_5: 0.1253  loss_dice_5: 0.2001  loss_ce_6: 4.458e-05  loss_mask_6: 0.1295  loss_dice_6: 0.1882  loss_ce_7: 4.986e-05  loss_mask_7: 0.1217  loss_dice_7: 0.1898  loss_ce_8: 5.972e-05  loss_mask_8: 0.1233  loss_dice_8: 0.1977  time: 0.6509  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:19:54] d2.utils.events INFO:  eta: 5:21:15  iter: 12159  total_loss: 3.029  loss_ce: 3.71e-05  loss_mask: 0.1191  loss_dice: 0.1758  loss_ce_0: 0.1182  loss_mask_0: 0.1202  loss_dice_0: 0.176  loss_ce_1: 6.618e-05  loss_mask_1: 0.1186  loss_dice_1: 0.1687  loss_ce_2: 5.461e-05  loss_mask_2: 0.1207  loss_dice_2: 0.1768  loss_ce_3: 2.96e-05  loss_mask_3: 0.1158  loss_dice_3: 0.1718  loss_ce_4: 4.02e-05  loss_mask_4: 0.1223  loss_dice_4: 0.1805  loss_ce_5: 5.067e-05  loss_mask_5: 0.1149  loss_dice_5: 0.1777  loss_ce_6: 4.251e-05  loss_mask_6: 0.1175  loss_dice_6: 0.1701  loss_ce_7: 4.585e-05  loss_mask_7: 0.1202  loss_dice_7: 0.1773  loss_ce_8: 5.432e-05  loss_mask_8: 0.1175  loss_dice_8: 0.1739  time: 0.6512  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:20:11] d2.utils.events INFO:  eta: 5:20:58  iter: 12179  total_loss: 3.119  loss_ce: 4.063e-05  loss_mask: 0.1225  loss_dice: 0.179  loss_ce_0: 0.116  loss_mask_0: 0.1202  loss_dice_0: 0.1796  loss_ce_1: 5.797e-05  loss_mask_1: 0.1189  loss_dice_1: 0.1802  loss_ce_2: 5.01e-05  loss_mask_2: 0.1209  loss_dice_2: 0.1822  loss_ce_3: 3.216e-05  loss_mask_3: 0.1219  loss_dice_3: 0.1828  loss_ce_4: 4.334e-05  loss_mask_4: 0.1219  loss_dice_4: 0.179  loss_ce_5: 4.357e-05  loss_mask_5: 0.1216  loss_dice_5: 0.1792  loss_ce_6: 3.87e-05  loss_mask_6: 0.1185  loss_dice_6: 0.1762  loss_ce_7: 4.69e-05  loss_mask_7: 0.1247  loss_dice_7: 0.1802  loss_ce_8: 5.389e-05  loss_mask_8: 0.1242  loss_dice_8: 0.187  time: 0.6516  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:20:28] d2.utils.events INFO:  eta: 5:20:32  iter: 12199  total_loss: 2.902  loss_ce: 4.539e-05  loss_mask: 0.1129  loss_dice: 0.1629  loss_ce_0: 0.1315  loss_mask_0: 0.1154  loss_dice_0: 0.1649  loss_ce_1: 4.962e-05  loss_mask_1: 0.1142  loss_dice_1: 0.1664  loss_ce_2: 5.299e-05  loss_mask_2: 0.1139  loss_dice_2: 0.164  loss_ce_3: 3.664e-05  loss_mask_3: 0.1143  loss_dice_3: 0.1588  loss_ce_4: 4.132e-05  loss_mask_4: 0.1147  loss_dice_4: 0.1663  loss_ce_5: 3.713e-05  loss_mask_5: 0.1126  loss_dice_5: 0.1643  loss_ce_6: 3.671e-05  loss_mask_6: 0.1167  loss_dice_6: 0.1639  loss_ce_7: 4.488e-05  loss_mask_7: 0.112  loss_dice_7: 0.1664  loss_ce_8: 4.825e-05  loss_mask_8: 0.113  loss_dice_8: 0.1664  time: 0.6519  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:20:45] d2.utils.events INFO:  eta: 5:20:18  iter: 12219  total_loss: 3.076  loss_ce: 4.438e-05  loss_mask: 0.1184  loss_dice: 0.1734  loss_ce_0: 0.119  loss_mask_0: 0.1198  loss_dice_0: 0.1747  loss_ce_1: 5.313e-05  loss_mask_1: 0.1184  loss_dice_1: 0.1725  loss_ce_2: 4.909e-05  loss_mask_2: 0.1166  loss_dice_2: 0.1728  loss_ce_3: 3.469e-05  loss_mask_3: 0.116  loss_dice_3: 0.1741  loss_ce_4: 4.239e-05  loss_mask_4: 0.1183  loss_dice_4: 0.1711  loss_ce_5: 4.442e-05  loss_mask_5: 0.1196  loss_dice_5: 0.1736  loss_ce_6: 3.691e-05  loss_mask_6: 0.1175  loss_dice_6: 0.1707  loss_ce_7: 4.475e-05  loss_mask_7: 0.1213  loss_dice_7: 0.1749  loss_ce_8: 5.235e-05  loss_mask_8: 0.1193  loss_dice_8: 0.1688  time: 0.6522  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:21:02] d2.utils.events INFO:  eta: 5:19:54  iter: 12239  total_loss: 3.099  loss_ce: 4.263e-05  loss_mask: 0.1163  loss_dice: 0.1722  loss_ce_0: 0.121  loss_mask_0: 0.1182  loss_dice_0: 0.1719  loss_ce_1: 6.331e-05  loss_mask_1: 0.1173  loss_dice_1: 0.175  loss_ce_2: 5.469e-05  loss_mask_2: 0.1178  loss_dice_2: 0.1721  loss_ce_3: 3.515e-05  loss_mask_3: 0.118  loss_dice_3: 0.1722  loss_ce_4: 4.617e-05  loss_mask_4: 0.1197  loss_dice_4: 0.1724  loss_ce_5: 4.904e-05  loss_mask_5: 0.1189  loss_dice_5: 0.174  loss_ce_6: 4.471e-05  loss_mask_6: 0.1182  loss_dice_6: 0.1764  loss_ce_7: 4.48e-05  loss_mask_7: 0.1202  loss_dice_7: 0.1808  loss_ce_8: 5.823e-05  loss_mask_8: 0.1161  loss_dice_8: 0.177  time: 0.6525  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:21:19] d2.utils.events INFO:  eta: 5:19:36  iter: 12259  total_loss: 3.257  loss_ce: 4.08e-05  loss_mask: 0.1294  loss_dice: 0.1824  loss_ce_0: 0.1231  loss_mask_0: 0.1261  loss_dice_0: 0.1914  loss_ce_1: 5.927e-05  loss_mask_1: 0.1299  loss_dice_1: 0.1882  loss_ce_2: 5.307e-05  loss_mask_2: 0.127  loss_dice_2: 0.1847  loss_ce_3: 3.196e-05  loss_mask_3: 0.1281  loss_dice_3: 0.184  loss_ce_4: 4.314e-05  loss_mask_4: 0.1259  loss_dice_4: 0.1839  loss_ce_5: 5.036e-05  loss_mask_5: 0.1282  loss_dice_5: 0.184  loss_ce_6: 3.93e-05  loss_mask_6: 0.1314  loss_dice_6: 0.1833  loss_ce_7: 4.243e-05  loss_mask_7: 0.1289  loss_dice_7: 0.1881  loss_ce_8: 5.337e-05  loss_mask_8: 0.1298  loss_dice_8: 0.1859  time: 0.6528  data_time: 0.0017  lr: 0.0001  max_mem: 8444M
[08/01 19:21:36] d2.utils.events INFO:  eta: 5:19:19  iter: 12279  total_loss: 3.246  loss_ce: 4.288e-05  loss_mask: 0.126  loss_dice: 0.2034  loss_ce_0: 0.1238  loss_mask_0: 0.1217  loss_dice_0: 0.1971  loss_ce_1: 5.925e-05  loss_mask_1: 0.1175  loss_dice_1: 0.1879  loss_ce_2: 5.171e-05  loss_mask_2: 0.1163  loss_dice_2: 0.1886  loss_ce_3: 3.663e-05  loss_mask_3: 0.1218  loss_dice_3: 0.1932  loss_ce_4: 4.84e-05  loss_mask_4: 0.119  loss_dice_4: 0.1865  loss_ce_5: 4.796e-05  loss_mask_5: 0.1146  loss_dice_5: 0.1867  loss_ce_6: 4.531e-05  loss_mask_6: 0.1218  loss_dice_6: 0.1917  loss_ce_7: 4.566e-05  loss_mask_7: 0.1191  loss_dice_7: 0.1919  loss_ce_8: 5.454e-05  loss_mask_8: 0.1205  loss_dice_8: 0.1964  time: 0.6531  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:21:53] d2.utils.events INFO:  eta: 5:19:02  iter: 12299  total_loss: 3.027  loss_ce: 4.824e-05  loss_mask: 0.1156  loss_dice: 0.1795  loss_ce_0: 0.1239  loss_mask_0: 0.1202  loss_dice_0: 0.1749  loss_ce_1: 5.413e-05  loss_mask_1: 0.1203  loss_dice_1: 0.1748  loss_ce_2: 5.422e-05  loss_mask_2: 0.1151  loss_dice_2: 0.1763  loss_ce_3: 4.199e-05  loss_mask_3: 0.1183  loss_dice_3: 0.1699  loss_ce_4: 5.875e-05  loss_mask_4: 0.1142  loss_dice_4: 0.1713  loss_ce_5: 5.027e-05  loss_mask_5: 0.1136  loss_dice_5: 0.1748  loss_ce_6: 4.853e-05  loss_mask_6: 0.1183  loss_dice_6: 0.1753  loss_ce_7: 5.3e-05  loss_mask_7: 0.1197  loss_dice_7: 0.1771  loss_ce_8: 5.921e-05  loss_mask_8: 0.1163  loss_dice_8: 0.1767  time: 0.6534  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:22:10] d2.utils.events INFO:  eta: 5:18:47  iter: 12319  total_loss: 2.998  loss_ce: 4.265e-05  loss_mask: 0.1184  loss_dice: 0.1614  loss_ce_0: 0.1232  loss_mask_0: 0.1196  loss_dice_0: 0.172  loss_ce_1: 6.39e-05  loss_mask_1: 0.1131  loss_dice_1: 0.1621  loss_ce_2: 7.307e-05  loss_mask_2: 0.1187  loss_dice_2: 0.1663  loss_ce_3: 4.524e-05  loss_mask_3: 0.1191  loss_dice_3: 0.1654  loss_ce_4: 5.644e-05  loss_mask_4: 0.1146  loss_dice_4: 0.1697  loss_ce_5: 5.843e-05  loss_mask_5: 0.1184  loss_dice_5: 0.171  loss_ce_6: 5.16e-05  loss_mask_6: 0.1171  loss_dice_6: 0.1693  loss_ce_7: 5.779e-05  loss_mask_7: 0.1154  loss_dice_7: 0.1646  loss_ce_8: 6.235e-05  loss_mask_8: 0.123  loss_dice_8: 0.1689  time: 0.6537  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:22:27] d2.utils.events INFO:  eta: 5:18:28  iter: 12339  total_loss: 3.146  loss_ce: 6.675e-05  loss_mask: 0.1146  loss_dice: 0.1791  loss_ce_0: 0.1263  loss_mask_0: 0.1174  loss_dice_0: 0.1884  loss_ce_1: 7.226e-05  loss_mask_1: 0.1169  loss_dice_1: 0.1814  loss_ce_2: 5.693e-05  loss_mask_2: 0.1171  loss_dice_2: 0.1779  loss_ce_3: 5.841e-05  loss_mask_3: 0.1166  loss_dice_3: 0.182  loss_ce_4: 6.67e-05  loss_mask_4: 0.1133  loss_dice_4: 0.1776  loss_ce_5: 5.88e-05  loss_mask_5: 0.119  loss_dice_5: 0.1805  loss_ce_6: 5.727e-05  loss_mask_6: 0.1179  loss_dice_6: 0.1842  loss_ce_7: 6.648e-05  loss_mask_7: 0.1215  loss_dice_7: 0.1837  loss_ce_8: 6.669e-05  loss_mask_8: 0.1154  loss_dice_8: 0.1802  time: 0.6541  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:22:44] d2.utils.events INFO:  eta: 5:18:12  iter: 12359  total_loss: 2.998  loss_ce: 4.289e-05  loss_mask: 0.1195  loss_dice: 0.1716  loss_ce_0: 0.1213  loss_mask_0: 0.1148  loss_dice_0: 0.1779  loss_ce_1: 6.995e-05  loss_mask_1: 0.1163  loss_dice_1: 0.1795  loss_ce_2: 6.653e-05  loss_mask_2: 0.1165  loss_dice_2: 0.1721  loss_ce_3: 4.227e-05  loss_mask_3: 0.1174  loss_dice_3: 0.1736  loss_ce_4: 5.544e-05  loss_mask_4: 0.1152  loss_dice_4: 0.1747  loss_ce_5: 5.681e-05  loss_mask_5: 0.1141  loss_dice_5: 0.1671  loss_ce_6: 4.87e-05  loss_mask_6: 0.1178  loss_dice_6: 0.1664  loss_ce_7: 5.718e-05  loss_mask_7: 0.1174  loss_dice_7: 0.1699  loss_ce_8: 5.906e-05  loss_mask_8: 0.1172  loss_dice_8: 0.1692  time: 0.6544  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 19:23:01] d2.utils.events INFO:  eta: 5:17:57  iter: 12379  total_loss: 2.897  loss_ce: 5.323e-05  loss_mask: 0.1136  loss_dice: 0.1611  loss_ce_0: 0.125  loss_mask_0: 0.1136  loss_dice_0: 0.1741  loss_ce_1: 7.645e-05  loss_mask_1: 0.1171  loss_dice_1: 0.1647  loss_ce_2: 6.426e-05  loss_mask_2: 0.1182  loss_dice_2: 0.1668  loss_ce_3: 4.562e-05  loss_mask_3: 0.1117  loss_dice_3: 0.164  loss_ce_4: 6.413e-05  loss_mask_4: 0.1123  loss_dice_4: 0.1595  loss_ce_5: 5.931e-05  loss_mask_5: 0.1191  loss_dice_5: 0.1603  loss_ce_6: 5.272e-05  loss_mask_6: 0.1171  loss_dice_6: 0.163  loss_ce_7: 6.126e-05  loss_mask_7: 0.1122  loss_dice_7: 0.1599  loss_ce_8: 6.492e-05  loss_mask_8: 0.1121  loss_dice_8: 0.1631  time: 0.6547  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:23:17] d2.utils.events INFO:  eta: 5:17:40  iter: 12399  total_loss: 3.045  loss_ce: 5.071e-05  loss_mask: 0.1207  loss_dice: 0.1727  loss_ce_0: 0.1224  loss_mask_0: 0.1185  loss_dice_0: 0.1757  loss_ce_1: 6.716e-05  loss_mask_1: 0.1134  loss_dice_1: 0.1694  loss_ce_2: 5.608e-05  loss_mask_2: 0.1139  loss_dice_2: 0.1693  loss_ce_3: 4.22e-05  loss_mask_3: 0.1201  loss_dice_3: 0.1691  loss_ce_4: 5.481e-05  loss_mask_4: 0.1167  loss_dice_4: 0.1727  loss_ce_5: 5.662e-05  loss_mask_5: 0.1143  loss_dice_5: 0.1667  loss_ce_6: 4.992e-05  loss_mask_6: 0.1199  loss_dice_6: 0.1702  loss_ce_7: 5.294e-05  loss_mask_7: 0.1149  loss_dice_7: 0.1669  loss_ce_8: 6.285e-05  loss_mask_8: 0.1168  loss_dice_8: 0.1682  time: 0.6550  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:23:34] d2.utils.events INFO:  eta: 5:17:21  iter: 12419  total_loss: 3.078  loss_ce: 4.384e-05  loss_mask: 0.1196  loss_dice: 0.1713  loss_ce_0: 0.1216  loss_mask_0: 0.1191  loss_dice_0: 0.172  loss_ce_1: 7.515e-05  loss_mask_1: 0.1207  loss_dice_1: 0.1714  loss_ce_2: 6.57e-05  loss_mask_2: 0.1183  loss_dice_2: 0.1683  loss_ce_3: 4.033e-05  loss_mask_3: 0.1185  loss_dice_3: 0.1688  loss_ce_4: 5.01e-05  loss_mask_4: 0.1203  loss_dice_4: 0.1732  loss_ce_5: 5.543e-05  loss_mask_5: 0.118  loss_dice_5: 0.1667  loss_ce_6: 5.003e-05  loss_mask_6: 0.1148  loss_dice_6: 0.1666  loss_ce_7: 5.657e-05  loss_mask_7: 0.1194  loss_dice_7: 0.1712  loss_ce_8: 5.879e-05  loss_mask_8: 0.1223  loss_dice_8: 0.1727  time: 0.6553  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:23:52] d2.utils.events INFO:  eta: 5:17:04  iter: 12439  total_loss: 3.14  loss_ce: 4.768e-05  loss_mask: 0.1108  loss_dice: 0.162  loss_ce_0: 0.126  loss_mask_0: 0.1191  loss_dice_0: 0.1807  loss_ce_1: 5.331e-05  loss_mask_1: 0.1163  loss_dice_1: 0.1758  loss_ce_2: 5.446e-05  loss_mask_2: 0.1148  loss_dice_2: 0.1808  loss_ce_3: 3.654e-05  loss_mask_3: 0.1165  loss_dice_3: 0.168  loss_ce_4: 4.753e-05  loss_mask_4: 0.1171  loss_dice_4: 0.1735  loss_ce_5: 5.369e-05  loss_mask_5: 0.1182  loss_dice_5: 0.1706  loss_ce_6: 4.71e-05  loss_mask_6: 0.1179  loss_dice_6: 0.1656  loss_ce_7: 5.065e-05  loss_mask_7: 0.1173  loss_dice_7: 0.1681  loss_ce_8: 5.718e-05  loss_mask_8: 0.1182  loss_dice_8: 0.1741  time: 0.6556  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:24:09] d2.utils.events INFO:  eta: 5:16:51  iter: 12459  total_loss: 3.246  loss_ce: 4.287e-05  loss_mask: 0.1152  loss_dice: 0.1972  loss_ce_0: 0.1256  loss_mask_0: 0.1205  loss_dice_0: 0.19  loss_ce_1: 5.264e-05  loss_mask_1: 0.1174  loss_dice_1: 0.1926  loss_ce_2: 4.735e-05  loss_mask_2: 0.1166  loss_dice_2: 0.1856  loss_ce_3: 3.16e-05  loss_mask_3: 0.1168  loss_dice_3: 0.1865  loss_ce_4: 4.083e-05  loss_mask_4: 0.1141  loss_dice_4: 0.1835  loss_ce_5: 5.058e-05  loss_mask_5: 0.1204  loss_dice_5: 0.1906  loss_ce_6: 4.599e-05  loss_mask_6: 0.1213  loss_dice_6: 0.191  loss_ce_7: 4.877e-05  loss_mask_7: 0.1177  loss_dice_7: 0.194  loss_ce_8: 5.477e-05  loss_mask_8: 0.1154  loss_dice_8: 0.1878  time: 0.6559  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:24:26] d2.utils.events INFO:  eta: 5:16:34  iter: 12479  total_loss: 3.11  loss_ce: 4.09e-05  loss_mask: 0.1219  loss_dice: 0.1747  loss_ce_0: 0.1227  loss_mask_0: 0.1221  loss_dice_0: 0.1687  loss_ce_1: 6.374e-05  loss_mask_1: 0.1249  loss_dice_1: 0.1753  loss_ce_2: 4.961e-05  loss_mask_2: 0.1172  loss_dice_2: 0.1745  loss_ce_3: 3.522e-05  loss_mask_3: 0.1224  loss_dice_3: 0.181  loss_ce_4: 4.293e-05  loss_mask_4: 0.1259  loss_dice_4: 0.1727  loss_ce_5: 5.299e-05  loss_mask_5: 0.1226  loss_dice_5: 0.1728  loss_ce_6: 4.908e-05  loss_mask_6: 0.1219  loss_dice_6: 0.1723  loss_ce_7: 4.919e-05  loss_mask_7: 0.1171  loss_dice_7: 0.1713  loss_ce_8: 6.181e-05  loss_mask_8: 0.1241  loss_dice_8: 0.1751  time: 0.6563  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:24:43] d2.utils.events INFO:  eta: 5:16:22  iter: 12499  total_loss: 2.884  loss_ce: 7.921e-05  loss_mask: 0.1099  loss_dice: 0.1587  loss_ce_0: 0.1214  loss_mask_0: 0.1106  loss_dice_0: 0.1612  loss_ce_1: 8.25e-05  loss_mask_1: 0.113  loss_dice_1: 0.1641  loss_ce_2: 6.941e-05  loss_mask_2: 0.1128  loss_dice_2: 0.1647  loss_ce_3: 0.0001095  loss_mask_3: 0.1122  loss_dice_3: 0.1578  loss_ce_4: 7.566e-05  loss_mask_4: 0.1085  loss_dice_4: 0.1606  loss_ce_5: 6.641e-05  loss_mask_5: 0.112  loss_dice_5: 0.1655  loss_ce_6: 7.117e-05  loss_mask_6: 0.1148  loss_dice_6: 0.1626  loss_ce_7: 7.025e-05  loss_mask_7: 0.1129  loss_dice_7: 0.1659  loss_ce_8: 7.384e-05  loss_mask_8: 0.1092  loss_dice_8: 0.1601  time: 0.6566  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:25:00] d2.utils.events INFO:  eta: 5:15:58  iter: 12519  total_loss: 3.042  loss_ce: 0.0001686  loss_mask: 0.1245  loss_dice: 0.1666  loss_ce_0: 0.1205  loss_mask_0: 0.1194  loss_dice_0: 0.1788  loss_ce_1: 0.0001046  loss_mask_1: 0.1191  loss_dice_1: 0.1715  loss_ce_2: 0.0001024  loss_mask_2: 0.1197  loss_dice_2: 0.1633  loss_ce_3: 0.0002465  loss_mask_3: 0.1209  loss_dice_3: 0.1725  loss_ce_4: 0.0001652  loss_mask_4: 0.1148  loss_dice_4: 0.1628  loss_ce_5: 0.0001378  loss_mask_5: 0.1209  loss_dice_5: 0.1688  loss_ce_6: 0.0002822  loss_mask_6: 0.1161  loss_dice_6: 0.1733  loss_ce_7: 0.000256  loss_mask_7: 0.1182  loss_dice_7: 0.1682  loss_ce_8: 0.000161  loss_mask_8: 0.1202  loss_dice_8: 0.1677  time: 0.6569  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:25:17] d2.utils.events INFO:  eta: 5:15:42  iter: 12539  total_loss: 3.001  loss_ce: 0.0005  loss_mask: 0.1128  loss_dice: 0.174  loss_ce_0: 0.1159  loss_mask_0: 0.1132  loss_dice_0: 0.1775  loss_ce_1: 0.0001767  loss_mask_1: 0.1156  loss_dice_1: 0.1695  loss_ce_2: 0.0001194  loss_mask_2: 0.1124  loss_dice_2: 0.1741  loss_ce_3: 0.0001048  loss_mask_3: 0.1149  loss_dice_3: 0.175  loss_ce_4: 0.0004081  loss_mask_4: 0.1183  loss_dice_4: 0.1744  loss_ce_5: 0.0003219  loss_mask_5: 0.1161  loss_dice_5: 0.1773  loss_ce_6: 0.000442  loss_mask_6: 0.1169  loss_dice_6: 0.1765  loss_ce_7: 0.0004195  loss_mask_7: 0.1165  loss_dice_7: 0.1764  loss_ce_8: 0.000298  loss_mask_8: 0.1154  loss_dice_8: 0.1717  time: 0.6572  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:25:33] d2.utils.events INFO:  eta: 5:15:23  iter: 12559  total_loss: 3.17  loss_ce: 0.0002384  loss_mask: 0.1271  loss_dice: 0.1815  loss_ce_0: 0.1236  loss_mask_0: 0.1245  loss_dice_0: 0.1814  loss_ce_1: 0.0001811  loss_mask_1: 0.1238  loss_dice_1: 0.1795  loss_ce_2: 0.0001185  loss_mask_2: 0.1215  loss_dice_2: 0.1732  loss_ce_3: 8.868e-05  loss_mask_3: 0.1244  loss_dice_3: 0.1805  loss_ce_4: 0.000278  loss_mask_4: 0.1211  loss_dice_4: 0.1776  loss_ce_5: 0.000241  loss_mask_5: 0.1201  loss_dice_5: 0.1782  loss_ce_6: 0.0002309  loss_mask_6: 0.1239  loss_dice_6: 0.1851  loss_ce_7: 0.0003652  loss_mask_7: 0.1237  loss_dice_7: 0.1777  loss_ce_8: 0.0002337  loss_mask_8: 0.1257  loss_dice_8: 0.1789  time: 0.6575  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:25:50] d2.utils.events INFO:  eta: 5:15:03  iter: 12579  total_loss: 3.041  loss_ce: 0.0001231  loss_mask: 0.1177  loss_dice: 0.1718  loss_ce_0: 0.1259  loss_mask_0: 0.1133  loss_dice_0: 0.1746  loss_ce_1: 0.0001516  loss_mask_1: 0.1197  loss_dice_1: 0.1802  loss_ce_2: 0.0001019  loss_mask_2: 0.1159  loss_dice_2: 0.1742  loss_ce_3: 7.569e-05  loss_mask_3: 0.1167  loss_dice_3: 0.175  loss_ce_4: 0.0001099  loss_mask_4: 0.1185  loss_dice_4: 0.1744  loss_ce_5: 0.0001304  loss_mask_5: 0.1173  loss_dice_5: 0.1761  loss_ce_6: 0.0001429  loss_mask_6: 0.1163  loss_dice_6: 0.1762  loss_ce_7: 0.0002125  loss_mask_7: 0.1183  loss_dice_7: 0.1764  loss_ce_8: 0.0001769  loss_mask_8: 0.116  loss_dice_8: 0.177  time: 0.6578  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:26:07] d2.utils.events INFO:  eta: 5:14:51  iter: 12599  total_loss: 3.2  loss_ce: 0.0001212  loss_mask: 0.1189  loss_dice: 0.1828  loss_ce_0: 0.1244  loss_mask_0: 0.1242  loss_dice_0: 0.1884  loss_ce_1: 0.0001371  loss_mask_1: 0.1217  loss_dice_1: 0.1778  loss_ce_2: 9.861e-05  loss_mask_2: 0.1239  loss_dice_2: 0.1838  loss_ce_3: 7.054e-05  loss_mask_3: 0.1252  loss_dice_3: 0.189  loss_ce_4: 9.787e-05  loss_mask_4: 0.1243  loss_dice_4: 0.1848  loss_ce_5: 0.0001293  loss_mask_5: 0.1256  loss_dice_5: 0.1872  loss_ce_6: 0.0001249  loss_mask_6: 0.1247  loss_dice_6: 0.1827  loss_ce_7: 0.0001907  loss_mask_7: 0.1238  loss_dice_7: 0.1891  loss_ce_8: 0.0001696  loss_mask_8: 0.1238  loss_dice_8: 0.1843  time: 0.6581  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:26:25] d2.utils.events INFO:  eta: 5:14:36  iter: 12619  total_loss: 3.036  loss_ce: 0.0001399  loss_mask: 0.1239  loss_dice: 0.1701  loss_ce_0: 0.1226  loss_mask_0: 0.1207  loss_dice_0: 0.1704  loss_ce_1: 0.0001231  loss_mask_1: 0.121  loss_dice_1: 0.1684  loss_ce_2: 8.175e-05  loss_mask_2: 0.1192  loss_dice_2: 0.1726  loss_ce_3: 6.654e-05  loss_mask_3: 0.1195  loss_dice_3: 0.1736  loss_ce_4: 9.488e-05  loss_mask_4: 0.1239  loss_dice_4: 0.1736  loss_ce_5: 0.0001004  loss_mask_5: 0.1222  loss_dice_5: 0.1686  loss_ce_6: 0.0001325  loss_mask_6: 0.1204  loss_dice_6: 0.1734  loss_ce_7: 0.000137  loss_mask_7: 0.1231  loss_dice_7: 0.1737  loss_ce_8: 0.000136  loss_mask_8: 0.1243  loss_dice_8: 0.1696  time: 0.6584  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:26:41] d2.utils.events INFO:  eta: 5:14:21  iter: 12639  total_loss: 3.113  loss_ce: 0.0001215  loss_mask: 0.1189  loss_dice: 0.1791  loss_ce_0: 0.1221  loss_mask_0: 0.119  loss_dice_0: 0.19  loss_ce_1: 0.0001211  loss_mask_1: 0.1196  loss_dice_1: 0.1741  loss_ce_2: 8.957e-05  loss_mask_2: 0.1206  loss_dice_2: 0.1824  loss_ce_3: 6.202e-05  loss_mask_3: 0.1166  loss_dice_3: 0.1812  loss_ce_4: 0.0001247  loss_mask_4: 0.1191  loss_dice_4: 0.1816  loss_ce_5: 0.0001418  loss_mask_5: 0.1203  loss_dice_5: 0.1806  loss_ce_6: 0.0001287  loss_mask_6: 0.1177  loss_dice_6: 0.1884  loss_ce_7: 0.0001325  loss_mask_7: 0.1118  loss_dice_7: 0.1836  loss_ce_8: 0.0001396  loss_mask_8: 0.1152  loss_dice_8: 0.1788  time: 0.6587  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 19:26:58] d2.utils.events INFO:  eta: 5:14:30  iter: 12659  total_loss: 3.184  loss_ce: 0.000103  loss_mask: 0.1225  loss_dice: 0.1848  loss_ce_0: 0.1259  loss_mask_0: 0.1207  loss_dice_0: 0.1791  loss_ce_1: 0.0001415  loss_mask_1: 0.1223  loss_dice_1: 0.1781  loss_ce_2: 9.214e-05  loss_mask_2: 0.1213  loss_dice_2: 0.1829  loss_ce_3: 6.157e-05  loss_mask_3: 0.1229  loss_dice_3: 0.1824  loss_ce_4: 0.0001003  loss_mask_4: 0.1208  loss_dice_4: 0.1822  loss_ce_5: 0.0001117  loss_mask_5: 0.1227  loss_dice_5: 0.1942  loss_ce_6: 0.0001039  loss_mask_6: 0.1196  loss_dice_6: 0.1891  loss_ce_7: 0.0001373  loss_mask_7: 0.1223  loss_dice_7: 0.1826  loss_ce_8: 0.0001275  loss_mask_8: 0.1222  loss_dice_8: 0.186  time: 0.6590  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:27:15] d2.utils.events INFO:  eta: 5:14:16  iter: 12679  total_loss: 3.206  loss_ce: 8.155e-05  loss_mask: 0.1192  loss_dice: 0.174  loss_ce_0: 0.125  loss_mask_0: 0.122  loss_dice_0: 0.1872  loss_ce_1: 0.0001018  loss_mask_1: 0.1147  loss_dice_1: 0.1721  loss_ce_2: 8.243e-05  loss_mask_2: 0.1196  loss_dice_2: 0.1799  loss_ce_3: 5.183e-05  loss_mask_3: 0.1191  loss_dice_3: 0.1856  loss_ce_4: 6.086e-05  loss_mask_4: 0.1135  loss_dice_4: 0.183  loss_ce_5: 8.276e-05  loss_mask_5: 0.117  loss_dice_5: 0.1824  loss_ce_6: 8.468e-05  loss_mask_6: 0.1162  loss_dice_6: 0.1862  loss_ce_7: 0.0001033  loss_mask_7: 0.1157  loss_dice_7: 0.1815  loss_ce_8: 0.0001087  loss_mask_8: 0.1144  loss_dice_8: 0.1808  time: 0.6593  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:27:32] d2.utils.events INFO:  eta: 5:14:07  iter: 12699  total_loss: 2.892  loss_ce: 6.975e-05  loss_mask: 0.1145  loss_dice: 0.1678  loss_ce_0: 0.1249  loss_mask_0: 0.1106  loss_dice_0: 0.1684  loss_ce_1: 8.728e-05  loss_mask_1: 0.1144  loss_dice_1: 0.1652  loss_ce_2: 5.849e-05  loss_mask_2: 0.1119  loss_dice_2: 0.1624  loss_ce_3: 5.027e-05  loss_mask_3: 0.1121  loss_dice_3: 0.1653  loss_ce_4: 5.66e-05  loss_mask_4: 0.1143  loss_dice_4: 0.1664  loss_ce_5: 7.097e-05  loss_mask_5: 0.1161  loss_dice_5: 0.1662  loss_ce_6: 7.269e-05  loss_mask_6: 0.1116  loss_dice_6: 0.1646  loss_ce_7: 7.948e-05  loss_mask_7: 0.1131  loss_dice_7: 0.1639  loss_ce_8: 8.943e-05  loss_mask_8: 0.1153  loss_dice_8: 0.1654  time: 0.6596  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 19:27:49] d2.utils.events INFO:  eta: 5:13:58  iter: 12719  total_loss: 3.041  loss_ce: 7.754e-05  loss_mask: 0.1167  loss_dice: 0.1696  loss_ce_0: 0.1233  loss_mask_0: 0.117  loss_dice_0: 0.1815  loss_ce_1: 8.676e-05  loss_mask_1: 0.1204  loss_dice_1: 0.1736  loss_ce_2: 6.679e-05  loss_mask_2: 0.1157  loss_dice_2: 0.172  loss_ce_3: 5.276e-05  loss_mask_3: 0.1155  loss_dice_3: 0.174  loss_ce_4: 5.293e-05  loss_mask_4: 0.1163  loss_dice_4: 0.1757  loss_ce_5: 7.151e-05  loss_mask_5: 0.1144  loss_dice_5: 0.1776  loss_ce_6: 7.051e-05  loss_mask_6: 0.1148  loss_dice_6: 0.1758  loss_ce_7: 8.925e-05  loss_mask_7: 0.1155  loss_dice_7: 0.1735  loss_ce_8: 9.028e-05  loss_mask_8: 0.118  loss_dice_8: 0.1767  time: 0.6599  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:28:06] d2.utils.events INFO:  eta: 5:13:33  iter: 12739  total_loss: 3.176  loss_ce: 6.988e-05  loss_mask: 0.1247  loss_dice: 0.1826  loss_ce_0: 0.1205  loss_mask_0: 0.1246  loss_dice_0: 0.1861  loss_ce_1: 9.784e-05  loss_mask_1: 0.1263  loss_dice_1: 0.18  loss_ce_2: 7.853e-05  loss_mask_2: 0.1232  loss_dice_2: 0.1784  loss_ce_3: 4.966e-05  loss_mask_3: 0.1245  loss_dice_3: 0.1848  loss_ce_4: 6.779e-05  loss_mask_4: 0.1226  loss_dice_4: 0.1814  loss_ce_5: 9.192e-05  loss_mask_5: 0.1232  loss_dice_5: 0.1769  loss_ce_6: 8.094e-05  loss_mask_6: 0.1251  loss_dice_6: 0.1858  loss_ce_7: 8.923e-05  loss_mask_7: 0.1229  loss_dice_7: 0.1825  loss_ce_8: 9.689e-05  loss_mask_8: 0.1233  loss_dice_8: 0.1786  time: 0.6601  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:28:23] d2.utils.events INFO:  eta: 5:13:26  iter: 12759  total_loss: 3.065  loss_ce: 6.769e-05  loss_mask: 0.1178  loss_dice: 0.1768  loss_ce_0: 0.1213  loss_mask_0: 0.118  loss_dice_0: 0.1872  loss_ce_1: 6.461e-05  loss_mask_1: 0.1177  loss_dice_1: 0.1802  loss_ce_2: 6.02e-05  loss_mask_2: 0.1225  loss_dice_2: 0.1849  loss_ce_3: 4.855e-05  loss_mask_3: 0.116  loss_dice_3: 0.1804  loss_ce_4: 5.144e-05  loss_mask_4: 0.1177  loss_dice_4: 0.1786  loss_ce_5: 6.244e-05  loss_mask_5: 0.1156  loss_dice_5: 0.1793  loss_ce_6: 6.814e-05  loss_mask_6: 0.1196  loss_dice_6: 0.1819  loss_ce_7: 6.758e-05  loss_mask_7: 0.1216  loss_dice_7: 0.1871  loss_ce_8: 7.862e-05  loss_mask_8: 0.118  loss_dice_8: 0.1784  time: 0.6604  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:28:40] d2.utils.events INFO:  eta: 5:13:12  iter: 12779  total_loss: 2.991  loss_ce: 6.375e-05  loss_mask: 0.116  loss_dice: 0.1693  loss_ce_0: 0.1214  loss_mask_0: 0.1138  loss_dice_0: 0.1778  loss_ce_1: 7.771e-05  loss_mask_1: 0.1103  loss_dice_1: 0.1665  loss_ce_2: 7.38e-05  loss_mask_2: 0.1145  loss_dice_2: 0.1721  loss_ce_3: 4.844e-05  loss_mask_3: 0.1172  loss_dice_3: 0.1718  loss_ce_4: 6.795e-05  loss_mask_4: 0.1095  loss_dice_4: 0.1713  loss_ce_5: 8.861e-05  loss_mask_5: 0.1149  loss_dice_5: 0.1734  loss_ce_6: 7.387e-05  loss_mask_6: 0.1126  loss_dice_6: 0.1733  loss_ce_7: 7.743e-05  loss_mask_7: 0.1096  loss_dice_7: 0.1698  loss_ce_8: 8.734e-05  loss_mask_8: 0.111  loss_dice_8: 0.1712  time: 0.6607  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:28:57] d2.utils.events INFO:  eta: 5:12:53  iter: 12799  total_loss: 2.93  loss_ce: 5.36e-05  loss_mask: 0.1093  loss_dice: 0.1596  loss_ce_0: 0.122  loss_mask_0: 0.1166  loss_dice_0: 0.1679  loss_ce_1: 7.077e-05  loss_mask_1: 0.1128  loss_dice_1: 0.1616  loss_ce_2: 6.999e-05  loss_mask_2: 0.1138  loss_dice_2: 0.1622  loss_ce_3: 4.517e-05  loss_mask_3: 0.1164  loss_dice_3: 0.1679  loss_ce_4: 5.215e-05  loss_mask_4: 0.116  loss_dice_4: 0.1617  loss_ce_5: 7.124e-05  loss_mask_5: 0.1107  loss_dice_5: 0.1632  loss_ce_6: 5.985e-05  loss_mask_6: 0.1173  loss_dice_6: 0.1679  loss_ce_7: 6.883e-05  loss_mask_7: 0.1126  loss_dice_7: 0.1615  loss_ce_8: 7.996e-05  loss_mask_8: 0.1141  loss_dice_8: 0.163  time: 0.6610  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:29:14] d2.utils.events INFO:  eta: 5:12:38  iter: 12819  total_loss: 3.088  loss_ce: 5.545e-05  loss_mask: 0.1155  loss_dice: 0.1682  loss_ce_0: 0.126  loss_mask_0: 0.1161  loss_dice_0: 0.178  loss_ce_1: 7.819e-05  loss_mask_1: 0.115  loss_dice_1: 0.1734  loss_ce_2: 6.704e-05  loss_mask_2: 0.1145  loss_dice_2: 0.1724  loss_ce_3: 4.753e-05  loss_mask_3: 0.1209  loss_dice_3: 0.1735  loss_ce_4: 4.746e-05  loss_mask_4: 0.117  loss_dice_4: 0.1749  loss_ce_5: 6.567e-05  loss_mask_5: 0.1198  loss_dice_5: 0.1733  loss_ce_6: 5.651e-05  loss_mask_6: 0.1196  loss_dice_6: 0.1756  loss_ce_7: 6.735e-05  loss_mask_7: 0.1148  loss_dice_7: 0.1727  loss_ce_8: 7.614e-05  loss_mask_8: 0.1139  loss_dice_8: 0.173  time: 0.6613  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:29:31] d2.utils.events INFO:  eta: 5:12:25  iter: 12839  total_loss: 2.944  loss_ce: 6.35e-05  loss_mask: 0.1155  loss_dice: 0.1678  loss_ce_0: 0.1217  loss_mask_0: 0.1158  loss_dice_0: 0.1695  loss_ce_1: 7.789e-05  loss_mask_1: 0.1131  loss_dice_1: 0.1687  loss_ce_2: 6.891e-05  loss_mask_2: 0.1155  loss_dice_2: 0.1655  loss_ce_3: 4.812e-05  loss_mask_3: 0.1188  loss_dice_3: 0.1664  loss_ce_4: 5.709e-05  loss_mask_4: 0.1174  loss_dice_4: 0.1722  loss_ce_5: 7.381e-05  loss_mask_5: 0.1189  loss_dice_5: 0.1676  loss_ce_6: 6.322e-05  loss_mask_6: 0.1156  loss_dice_6: 0.1671  loss_ce_7: 6.625e-05  loss_mask_7: 0.1131  loss_dice_7: 0.1659  loss_ce_8: 7.741e-05  loss_mask_8: 0.1143  loss_dice_8: 0.1653  time: 0.6616  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:29:48] d2.utils.events INFO:  eta: 5:12:13  iter: 12859  total_loss: 2.999  loss_ce: 6.01e-05  loss_mask: 0.1181  loss_dice: 0.179  loss_ce_0: 0.1213  loss_mask_0: 0.1198  loss_dice_0: 0.1759  loss_ce_1: 7.402e-05  loss_mask_1: 0.1149  loss_dice_1: 0.1725  loss_ce_2: 6.4e-05  loss_mask_2: 0.1188  loss_dice_2: 0.1755  loss_ce_3: 4.498e-05  loss_mask_3: 0.117  loss_dice_3: 0.1632  loss_ce_4: 5.379e-05  loss_mask_4: 0.1159  loss_dice_4: 0.171  loss_ce_5: 6.224e-05  loss_mask_5: 0.1196  loss_dice_5: 0.1735  loss_ce_6: 6.142e-05  loss_mask_6: 0.1186  loss_dice_6: 0.1727  loss_ce_7: 6.212e-05  loss_mask_7: 0.1213  loss_dice_7: 0.172  loss_ce_8: 7.261e-05  loss_mask_8: 0.1158  loss_dice_8: 0.1721  time: 0.6619  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 19:30:05] d2.utils.events INFO:  eta: 5:12:03  iter: 12879  total_loss: 2.984  loss_ce: 5.059e-05  loss_mask: 0.119  loss_dice: 0.1737  loss_ce_0: 0.1283  loss_mask_0: 0.1218  loss_dice_0: 0.1733  loss_ce_1: 7.203e-05  loss_mask_1: 0.115  loss_dice_1: 0.1672  loss_ce_2: 5.989e-05  loss_mask_2: 0.1167  loss_dice_2: 0.1748  loss_ce_3: 4.046e-05  loss_mask_3: 0.121  loss_dice_3: 0.1672  loss_ce_4: 5.213e-05  loss_mask_4: 0.1159  loss_dice_4: 0.1707  loss_ce_5: 6.011e-05  loss_mask_5: 0.1148  loss_dice_5: 0.1678  loss_ce_6: 5.971e-05  loss_mask_6: 0.1191  loss_dice_6: 0.1733  loss_ce_7: 5.962e-05  loss_mask_7: 0.1166  loss_dice_7: 0.1802  loss_ce_8: 6.891e-05  loss_mask_8: 0.1175  loss_dice_8: 0.1682  time: 0.6622  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 19:30:22] d2.utils.events INFO:  eta: 5:11:47  iter: 12899  total_loss: 2.856  loss_ce: 4.948e-05  loss_mask: 0.1145  loss_dice: 0.1662  loss_ce_0: 0.1259  loss_mask_0: 0.1136  loss_dice_0: 0.1639  loss_ce_1: 6.232e-05  loss_mask_1: 0.1175  loss_dice_1: 0.162  loss_ce_2: 4.962e-05  loss_mask_2: 0.1136  loss_dice_2: 0.1668  loss_ce_3: 3.958e-05  loss_mask_3: 0.1111  loss_dice_3: 0.1627  loss_ce_4: 4.015e-05  loss_mask_4: 0.114  loss_dice_4: 0.1608  loss_ce_5: 4.971e-05  loss_mask_5: 0.1111  loss_dice_5: 0.1615  loss_ce_6: 4.928e-05  loss_mask_6: 0.1132  loss_dice_6: 0.1658  loss_ce_7: 5.256e-05  loss_mask_7: 0.1167  loss_dice_7: 0.1625  loss_ce_8: 6.153e-05  loss_mask_8: 0.1167  loss_dice_8: 0.163  time: 0.6625  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:30:38] d2.utils.events INFO:  eta: 5:11:30  iter: 12919  total_loss: 3.101  loss_ce: 4.539e-05  loss_mask: 0.1146  loss_dice: 0.1828  loss_ce_0: 0.1208  loss_mask_0: 0.119  loss_dice_0: 0.1844  loss_ce_1: 4.384e-05  loss_mask_1: 0.1137  loss_dice_1: 0.1768  loss_ce_2: 6.247e-05  loss_mask_2: 0.1184  loss_dice_2: 0.1701  loss_ce_3: 3.74e-05  loss_mask_3: 0.1174  loss_dice_3: 0.179  loss_ce_4: 4.05e-05  loss_mask_4: 0.1186  loss_dice_4: 0.1794  loss_ce_5: 4.553e-05  loss_mask_5: 0.1167  loss_dice_5: 0.1772  loss_ce_6: 3.53e-05  loss_mask_6: 0.114  loss_dice_6: 0.1733  loss_ce_7: 4.199e-05  loss_mask_7: 0.1149  loss_dice_7: 0.1788  loss_ce_8: 5.406e-05  loss_mask_8: 0.1201  loss_dice_8: 0.1801  time: 0.6627  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:30:55] d2.utils.events INFO:  eta: 5:11:15  iter: 12939  total_loss: 3.029  loss_ce: 4.684e-05  loss_mask: 0.1114  loss_dice: 0.1715  loss_ce_0: 0.1238  loss_mask_0: 0.1131  loss_dice_0: 0.1791  loss_ce_1: 6.932e-05  loss_mask_1: 0.1175  loss_dice_1: 0.1781  loss_ce_2: 5.737e-05  loss_mask_2: 0.1119  loss_dice_2: 0.177  loss_ce_3: 6.276e-05  loss_mask_3: 0.1095  loss_dice_3: 0.1731  loss_ce_4: 4.72e-05  loss_mask_4: 0.109  loss_dice_4: 0.1728  loss_ce_5: 5.066e-05  loss_mask_5: 0.1142  loss_dice_5: 0.1777  loss_ce_6: 4.967e-05  loss_mask_6: 0.1119  loss_dice_6: 0.1789  loss_ce_7: 5.638e-05  loss_mask_7: 0.1124  loss_dice_7: 0.1783  loss_ce_8: 6.291e-05  loss_mask_8: 0.1124  loss_dice_8: 0.1748  time: 0.6630  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:31:13] d2.utils.events INFO:  eta: 5:10:58  iter: 12959  total_loss: 3.008  loss_ce: 4.597e-05  loss_mask: 0.1169  loss_dice: 0.1735  loss_ce_0: 0.123  loss_mask_0: 0.1116  loss_dice_0: 0.168  loss_ce_1: 7.746e-05  loss_mask_1: 0.1161  loss_dice_1: 0.1653  loss_ce_2: 5.971e-05  loss_mask_2: 0.116  loss_dice_2: 0.1647  loss_ce_3: 7.473e-05  loss_mask_3: 0.1185  loss_dice_3: 0.1698  loss_ce_4: 5.825e-05  loss_mask_4: 0.1144  loss_dice_4: 0.1703  loss_ce_5: 6.452e-05  loss_mask_5: 0.1189  loss_dice_5: 0.1713  loss_ce_6: 5.455e-05  loss_mask_6: 0.1183  loss_dice_6: 0.1717  loss_ce_7: 6.1e-05  loss_mask_7: 0.1171  loss_dice_7: 0.1683  loss_ce_8: 6.458e-05  loss_mask_8: 0.1185  loss_dice_8: 0.1735  time: 0.6633  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:31:30] d2.utils.events INFO:  eta: 5:10:51  iter: 12979  total_loss: 3.075  loss_ce: 3.479e-05  loss_mask: 0.1183  loss_dice: 0.1706  loss_ce_0: 0.123  loss_mask_0: 0.1219  loss_dice_0: 0.1669  loss_ce_1: 5.629e-05  loss_mask_1: 0.121  loss_dice_1: 0.1696  loss_ce_2: 5.159e-05  loss_mask_2: 0.1216  loss_dice_2: 0.171  loss_ce_3: 4.623e-05  loss_mask_3: 0.1206  loss_dice_3: 0.1685  loss_ce_4: 3.071e-05  loss_mask_4: 0.1191  loss_dice_4: 0.1692  loss_ce_5: 3.885e-05  loss_mask_5: 0.1186  loss_dice_5: 0.169  loss_ce_6: 3.826e-05  loss_mask_6: 0.1162  loss_dice_6: 0.1679  loss_ce_7: 4.372e-05  loss_mask_7: 0.12  loss_dice_7: 0.1678  loss_ce_8: 4.837e-05  loss_mask_8: 0.1201  loss_dice_8: 0.1668  time: 0.6636  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:31:47] d2.utils.events INFO:  eta: 5:10:38  iter: 12999  total_loss: 3.137  loss_ce: 3.849e-05  loss_mask: 0.116  loss_dice: 0.1751  loss_ce_0: 0.1252  loss_mask_0: 0.1141  loss_dice_0: 0.1821  loss_ce_1: 5.957e-05  loss_mask_1: 0.1149  loss_dice_1: 0.1724  loss_ce_2: 4.449e-05  loss_mask_2: 0.1218  loss_dice_2: 0.1798  loss_ce_3: 3.889e-05  loss_mask_3: 0.115  loss_dice_3: 0.1783  loss_ce_4: 3.728e-05  loss_mask_4: 0.1177  loss_dice_4: 0.1785  loss_ce_5: 4.025e-05  loss_mask_5: 0.1166  loss_dice_5: 0.1755  loss_ce_6: 4.13e-05  loss_mask_6: 0.123  loss_dice_6: 0.1798  loss_ce_7: 4.591e-05  loss_mask_7: 0.114  loss_dice_7: 0.1837  loss_ce_8: 4.834e-05  loss_mask_8: 0.1197  loss_dice_8: 0.1798  time: 0.6639  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:32:04] d2.utils.events INFO:  eta: 5:10:25  iter: 13019  total_loss: 2.99  loss_ce: 4.1e-05  loss_mask: 0.123  loss_dice: 0.1692  loss_ce_0: 0.1198  loss_mask_0: 0.12  loss_dice_0: 0.1792  loss_ce_1: 5.747e-05  loss_mask_1: 0.1182  loss_dice_1: 0.1658  loss_ce_2: 5.357e-05  loss_mask_2: 0.1167  loss_dice_2: 0.1668  loss_ce_3: 5.912e-05  loss_mask_3: 0.1155  loss_dice_3: 0.164  loss_ce_4: 4.282e-05  loss_mask_4: 0.1175  loss_dice_4: 0.1635  loss_ce_5: 5.232e-05  loss_mask_5: 0.1162  loss_dice_5: 0.1709  loss_ce_6: 4.987e-05  loss_mask_6: 0.1186  loss_dice_6: 0.1675  loss_ce_7: 4.872e-05  loss_mask_7: 0.1209  loss_dice_7: 0.1692  loss_ce_8: 5.726e-05  loss_mask_8: 0.1214  loss_dice_8: 0.1697  time: 0.6642  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:32:21] d2.utils.events INFO:  eta: 5:10:08  iter: 13039  total_loss: 3.072  loss_ce: 4.5e-05  loss_mask: 0.1177  loss_dice: 0.1817  loss_ce_0: 0.1229  loss_mask_0: 0.1167  loss_dice_0: 0.1702  loss_ce_1: 5.405e-05  loss_mask_1: 0.1189  loss_dice_1: 0.1699  loss_ce_2: 5.108e-05  loss_mask_2: 0.1166  loss_dice_2: 0.1724  loss_ce_3: 4.375e-05  loss_mask_3: 0.116  loss_dice_3: 0.1713  loss_ce_4: 4.118e-05  loss_mask_4: 0.121  loss_dice_4: 0.1769  loss_ce_5: 4.549e-05  loss_mask_5: 0.1143  loss_dice_5: 0.1727  loss_ce_6: 4.403e-05  loss_mask_6: 0.1153  loss_dice_6: 0.174  loss_ce_7: 4.47e-05  loss_mask_7: 0.1157  loss_dice_7: 0.1742  loss_ce_8: 5.544e-05  loss_mask_8: 0.119  loss_dice_8: 0.1785  time: 0.6645  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:32:38] d2.utils.events INFO:  eta: 5:09:56  iter: 13059  total_loss: 3.142  loss_ce: 4.371e-05  loss_mask: 0.1244  loss_dice: 0.1773  loss_ce_0: 0.1222  loss_mask_0: 0.1239  loss_dice_0: 0.179  loss_ce_1: 5.657e-05  loss_mask_1: 0.1205  loss_dice_1: 0.1682  loss_ce_2: 5.394e-05  loss_mask_2: 0.121  loss_dice_2: 0.172  loss_ce_3: 5.475e-05  loss_mask_3: 0.1247  loss_dice_3: 0.1761  loss_ce_4: 4.861e-05  loss_mask_4: 0.1231  loss_dice_4: 0.1749  loss_ce_5: 5.938e-05  loss_mask_5: 0.1231  loss_dice_5: 0.1677  loss_ce_6: 4.816e-05  loss_mask_6: 0.1248  loss_dice_6: 0.1765  loss_ce_7: 4.738e-05  loss_mask_7: 0.1253  loss_dice_7: 0.1743  loss_ce_8: 5.754e-05  loss_mask_8: 0.1198  loss_dice_8: 0.1734  time: 0.6647  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:32:55] d2.utils.events INFO:  eta: 5:09:40  iter: 13079  total_loss: 3.185  loss_ce: 3.554e-05  loss_mask: 0.1205  loss_dice: 0.1847  loss_ce_0: 0.1245  loss_mask_0: 0.1199  loss_dice_0: 0.1872  loss_ce_1: 5.221e-05  loss_mask_1: 0.1174  loss_dice_1: 0.1785  loss_ce_2: 4.326e-05  loss_mask_2: 0.12  loss_dice_2: 0.1812  loss_ce_3: 4.707e-05  loss_mask_3: 0.1193  loss_dice_3: 0.1838  loss_ce_4: 3.494e-05  loss_mask_4: 0.1192  loss_dice_4: 0.1891  loss_ce_5: 3.959e-05  loss_mask_5: 0.1181  loss_dice_5: 0.1794  loss_ce_6: 3.989e-05  loss_mask_6: 0.1156  loss_dice_6: 0.1833  loss_ce_7: 4.197e-05  loss_mask_7: 0.12  loss_dice_7: 0.1823  loss_ce_8: 4.957e-05  loss_mask_8: 0.1204  loss_dice_8: 0.1831  time: 0.6650  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:33:12] d2.utils.events INFO:  eta: 5:09:22  iter: 13099  total_loss: 2.947  loss_ce: 3.438e-05  loss_mask: 0.1151  loss_dice: 0.1745  loss_ce_0: 0.1242  loss_mask_0: 0.1121  loss_dice_0: 0.1717  loss_ce_1: 5.021e-05  loss_mask_1: 0.1157  loss_dice_1: 0.1717  loss_ce_2: 4.64e-05  loss_mask_2: 0.1139  loss_dice_2: 0.1729  loss_ce_3: 2.908e-05  loss_mask_3: 0.1155  loss_dice_3: 0.1781  loss_ce_4: 4.067e-05  loss_mask_4: 0.1112  loss_dice_4: 0.1724  loss_ce_5: 4.248e-05  loss_mask_5: 0.112  loss_dice_5: 0.1719  loss_ce_6: 3.781e-05  loss_mask_6: 0.1145  loss_dice_6: 0.1739  loss_ce_7: 4.196e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1714  loss_ce_8: 5.014e-05  loss_mask_8: 0.1116  loss_dice_8: 0.1728  time: 0.6653  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 19:33:29] d2.utils.events INFO:  eta: 5:09:06  iter: 13119  total_loss: 2.831  loss_ce: 3.03e-05  loss_mask: 0.1102  loss_dice: 0.1649  loss_ce_0: 0.1221  loss_mask_0: 0.1081  loss_dice_0: 0.1559  loss_ce_1: 4.535e-05  loss_mask_1: 0.1097  loss_dice_1: 0.1631  loss_ce_2: 3.819e-05  loss_mask_2: 0.1085  loss_dice_2: 0.1611  loss_ce_3: 3.12e-05  loss_mask_3: 0.1088  loss_dice_3: 0.1629  loss_ce_4: 2.96e-05  loss_mask_4: 0.1074  loss_dice_4: 0.1608  loss_ce_5: 3.911e-05  loss_mask_5: 0.1067  loss_dice_5: 0.1643  loss_ce_6: 3.429e-05  loss_mask_6: 0.1082  loss_dice_6: 0.1577  loss_ce_7: 3.569e-05  loss_mask_7: 0.1072  loss_dice_7: 0.1597  loss_ce_8: 4.629e-05  loss_mask_8: 0.1107  loss_dice_8: 0.1597  time: 0.6656  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 19:33:46] d2.utils.events INFO:  eta: 5:08:51  iter: 13139  total_loss: 2.974  loss_ce: 3.9e-05  loss_mask: 0.115  loss_dice: 0.1709  loss_ce_0: 0.1209  loss_mask_0: 0.109  loss_dice_0: 0.1738  loss_ce_1: 6.49e-05  loss_mask_1: 0.1035  loss_dice_1: 0.1664  loss_ce_2: 4.719e-05  loss_mask_2: 0.1127  loss_dice_2: 0.1691  loss_ce_3: 3.345e-05  loss_mask_3: 0.1065  loss_dice_3: 0.1757  loss_ce_4: 4.258e-05  loss_mask_4: 0.1111  loss_dice_4: 0.1696  loss_ce_5: 5.256e-05  loss_mask_5: 0.1092  loss_dice_5: 0.1723  loss_ce_6: 4.14e-05  loss_mask_6: 0.1158  loss_dice_6: 0.1708  loss_ce_7: 4.071e-05  loss_mask_7: 0.1122  loss_dice_7: 0.1664  loss_ce_8: 5.227e-05  loss_mask_8: 0.111  loss_dice_8: 0.1717  time: 0.6659  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:34:03] d2.utils.events INFO:  eta: 5:08:23  iter: 13159  total_loss: 2.877  loss_ce: 3.305e-05  loss_mask: 0.1141  loss_dice: 0.1617  loss_ce_0: 0.1168  loss_mask_0: 0.1167  loss_dice_0: 0.1644  loss_ce_1: 4.771e-05  loss_mask_1: 0.1172  loss_dice_1: 0.1635  loss_ce_2: 3.872e-05  loss_mask_2: 0.1137  loss_dice_2: 0.1658  loss_ce_3: 4.113e-05  loss_mask_3: 0.1145  loss_dice_3: 0.1638  loss_ce_4: 3.153e-05  loss_mask_4: 0.1168  loss_dice_4: 0.1585  loss_ce_5: 3.663e-05  loss_mask_5: 0.1158  loss_dice_5: 0.1616  loss_ce_6: 3.502e-05  loss_mask_6: 0.1172  loss_dice_6: 0.1633  loss_ce_7: 3.525e-05  loss_mask_7: 0.1134  loss_dice_7: 0.1642  loss_ce_8: 4.187e-05  loss_mask_8: 0.1119  loss_dice_8: 0.158  time: 0.6662  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:34:20] d2.utils.events INFO:  eta: 5:08:06  iter: 13179  total_loss: 3.056  loss_ce: 3.581e-05  loss_mask: 0.1225  loss_dice: 0.1772  loss_ce_0: 0.1313  loss_mask_0: 0.1226  loss_dice_0: 0.1696  loss_ce_1: 4.63e-05  loss_mask_1: 0.119  loss_dice_1: 0.1765  loss_ce_2: 4.626e-05  loss_mask_2: 0.117  loss_dice_2: 0.1677  loss_ce_3: 3.149e-05  loss_mask_3: 0.1215  loss_dice_3: 0.1815  loss_ce_4: 3.527e-05  loss_mask_4: 0.1221  loss_dice_4: 0.1704  loss_ce_5: 3.767e-05  loss_mask_5: 0.1195  loss_dice_5: 0.1685  loss_ce_6: 3.735e-05  loss_mask_6: 0.1196  loss_dice_6: 0.1692  loss_ce_7: 3.924e-05  loss_mask_7: 0.1178  loss_dice_7: 0.1651  loss_ce_8: 4.074e-05  loss_mask_8: 0.1209  loss_dice_8: 0.1702  time: 0.6664  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:34:37] d2.utils.events INFO:  eta: 5:07:55  iter: 13199  total_loss: 3.047  loss_ce: 5.411e-05  loss_mask: 0.1222  loss_dice: 0.1714  loss_ce_0: 0.1292  loss_mask_0: 0.1213  loss_dice_0: 0.1712  loss_ce_1: 6.936e-05  loss_mask_1: 0.1207  loss_dice_1: 0.1731  loss_ce_2: 5.46e-05  loss_mask_2: 0.1223  loss_dice_2: 0.1697  loss_ce_3: 5.8e-05  loss_mask_3: 0.1207  loss_dice_3: 0.1664  loss_ce_4: 4.576e-05  loss_mask_4: 0.1194  loss_dice_4: 0.1662  loss_ce_5: 5.126e-05  loss_mask_5: 0.1205  loss_dice_5: 0.1733  loss_ce_6: 4.66e-05  loss_mask_6: 0.1207  loss_dice_6: 0.1779  loss_ce_7: 6.255e-05  loss_mask_7: 0.1176  loss_dice_7: 0.1784  loss_ce_8: 4.951e-05  loss_mask_8: 0.121  loss_dice_8: 0.1707  time: 0.6667  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:34:54] d2.utils.events INFO:  eta: 5:07:36  iter: 13219  total_loss: 2.946  loss_ce: 0.0005719  loss_mask: 0.1129  loss_dice: 0.1682  loss_ce_0: 0.1243  loss_mask_0: 0.1158  loss_dice_0: 0.1706  loss_ce_1: 0.0001937  loss_mask_1: 0.1146  loss_dice_1: 0.1685  loss_ce_2: 0.0002122  loss_mask_2: 0.1159  loss_dice_2: 0.1697  loss_ce_3: 0.0001809  loss_mask_3: 0.1129  loss_dice_3: 0.1682  loss_ce_4: 0.0001969  loss_mask_4: 0.1135  loss_dice_4: 0.1695  loss_ce_5: 0.00017  loss_mask_5: 0.1113  loss_dice_5: 0.1692  loss_ce_6: 0.0002323  loss_mask_6: 0.1143  loss_dice_6: 0.1703  loss_ce_7: 0.0002927  loss_mask_7: 0.1106  loss_dice_7: 0.1654  loss_ce_8: 0.0001967  loss_mask_8: 0.1138  loss_dice_8: 0.1704  time: 0.6670  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 19:35:10] d2.utils.events INFO:  eta: 5:07:15  iter: 13239  total_loss: 2.773  loss_ce: 0.0001602  loss_mask: 0.1082  loss_dice: 0.1621  loss_ce_0: 0.1218  loss_mask_0: 0.107  loss_dice_0: 0.1575  loss_ce_1: 0.0003638  loss_mask_1: 0.1079  loss_dice_1: 0.1588  loss_ce_2: 0.0006563  loss_mask_2: 0.113  loss_dice_2: 0.1565  loss_ce_3: 0.0004518  loss_mask_3: 0.1052  loss_dice_3: 0.1551  loss_ce_4: 0.0002765  loss_mask_4: 0.11  loss_dice_4: 0.1576  loss_ce_5: 0.0003052  loss_mask_5: 0.1089  loss_dice_5: 0.1572  loss_ce_6: 0.0001602  loss_mask_6: 0.1126  loss_dice_6: 0.1612  loss_ce_7: 0.0002258  loss_mask_7: 0.1108  loss_dice_7: 0.1599  loss_ce_8: 0.0001739  loss_mask_8: 0.1114  loss_dice_8: 0.1625  time: 0.6672  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:35:27] d2.utils.events INFO:  eta: 5:07:02  iter: 13259  total_loss: 3.333  loss_ce: 8.791e-05  loss_mask: 0.1266  loss_dice: 0.1901  loss_ce_0: 0.1244  loss_mask_0: 0.1285  loss_dice_0: 0.1948  loss_ce_1: 0.0001688  loss_mask_1: 0.1253  loss_dice_1: 0.1895  loss_ce_2: 0.0001973  loss_mask_2: 0.1248  loss_dice_2: 0.1899  loss_ce_3: 0.0001823  loss_mask_3: 0.1256  loss_dice_3: 0.1878  loss_ce_4: 8.643e-05  loss_mask_4: 0.1238  loss_dice_4: 0.1906  loss_ce_5: 0.0001115  loss_mask_5: 0.1231  loss_dice_5: 0.1863  loss_ce_6: 8.208e-05  loss_mask_6: 0.1218  loss_dice_6: 0.1861  loss_ce_7: 0.0001382  loss_mask_7: 0.1266  loss_dice_7: 0.1912  loss_ce_8: 9.553e-05  loss_mask_8: 0.1236  loss_dice_8: 0.189  time: 0.6675  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:35:44] d2.utils.events INFO:  eta: 5:06:50  iter: 13279  total_loss: 3.032  loss_ce: 8.039e-05  loss_mask: 0.1181  loss_dice: 0.1799  loss_ce_0: 0.1238  loss_mask_0: 0.1139  loss_dice_0: 0.1781  loss_ce_1: 0.0002127  loss_mask_1: 0.1122  loss_dice_1: 0.1772  loss_ce_2: 0.0001965  loss_mask_2: 0.1157  loss_dice_2: 0.1767  loss_ce_3: 0.0001951  loss_mask_3: 0.1156  loss_dice_3: 0.1754  loss_ce_4: 0.0001113  loss_mask_4: 0.1133  loss_dice_4: 0.1737  loss_ce_5: 0.000102  loss_mask_5: 0.1142  loss_dice_5: 0.1769  loss_ce_6: 7.693e-05  loss_mask_6: 0.1117  loss_dice_6: 0.1743  loss_ce_7: 0.0001038  loss_mask_7: 0.1166  loss_dice_7: 0.1724  loss_ce_8: 8.217e-05  loss_mask_8: 0.1179  loss_dice_8: 0.1816  time: 0.6678  data_time: 0.0018  lr: 0.0001  max_mem: 8444M
[08/01 19:36:01] d2.utils.events INFO:  eta: 5:06:28  iter: 13299  total_loss: 2.955  loss_ce: 0.0001099  loss_mask: 0.1159  loss_dice: 0.1679  loss_ce_0: 0.1256  loss_mask_0: 0.1186  loss_dice_0: 0.167  loss_ce_1: 0.0002186  loss_mask_1: 0.1115  loss_dice_1: 0.1627  loss_ce_2: 0.0001324  loss_mask_2: 0.1125  loss_dice_2: 0.1639  loss_ce_3: 0.0001436  loss_mask_3: 0.1168  loss_dice_3: 0.1689  loss_ce_4: 0.0001318  loss_mask_4: 0.1164  loss_dice_4: 0.1659  loss_ce_5: 8.812e-05  loss_mask_5: 0.1137  loss_dice_5: 0.1639  loss_ce_6: 7.84e-05  loss_mask_6: 0.1176  loss_dice_6: 0.1706  loss_ce_7: 0.0001262  loss_mask_7: 0.1172  loss_dice_7: 0.164  loss_ce_8: 8.742e-05  loss_mask_8: 0.1175  loss_dice_8: 0.168  time: 0.6680  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:36:18] d2.utils.events INFO:  eta: 5:06:07  iter: 13319  total_loss: 2.858  loss_ce: 9.768e-05  loss_mask: 0.1141  loss_dice: 0.1666  loss_ce_0: 0.1251  loss_mask_0: 0.1122  loss_dice_0: 0.1641  loss_ce_1: 0.0001391  loss_mask_1: 0.1094  loss_dice_1: 0.1646  loss_ce_2: 0.0001226  loss_mask_2: 0.1122  loss_dice_2: 0.1643  loss_ce_3: 0.0001376  loss_mask_3: 0.1124  loss_dice_3: 0.1679  loss_ce_4: 0.0001136  loss_mask_4: 0.1123  loss_dice_4: 0.161  loss_ce_5: 0.0001459  loss_mask_5: 0.1145  loss_dice_5: 0.1635  loss_ce_6: 0.0001219  loss_mask_6: 0.1123  loss_dice_6: 0.1577  loss_ce_7: 0.0001161  loss_mask_7: 0.1143  loss_dice_7: 0.1656  loss_ce_8: 9.931e-05  loss_mask_8: 0.1116  loss_dice_8: 0.1646  time: 0.6683  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:36:35] d2.utils.events INFO:  eta: 5:05:50  iter: 13339  total_loss: 3.24  loss_ce: 0.0001196  loss_mask: 0.1268  loss_dice: 0.1681  loss_ce_0: 0.1202  loss_mask_0: 0.1231  loss_dice_0: 0.1653  loss_ce_1: 0.0001117  loss_mask_1: 0.124  loss_dice_1: 0.1739  loss_ce_2: 0.0002387  loss_mask_2: 0.1238  loss_dice_2: 0.169  loss_ce_3: 0.003646  loss_mask_3: 0.1267  loss_dice_3: 0.1706  loss_ce_4: 0.0009345  loss_mask_4: 0.1258  loss_dice_4: 0.1755  loss_ce_5: 0.0003169  loss_mask_5: 0.1227  loss_dice_5: 0.1674  loss_ce_6: 0.0005462  loss_mask_6: 0.1182  loss_dice_6: 0.1637  loss_ce_7: 0.0001226  loss_mask_7: 0.124  loss_dice_7: 0.167  loss_ce_8: 0.0001123  loss_mask_8: 0.1207  loss_dice_8: 0.1653  time: 0.6686  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:36:52] d2.utils.events INFO:  eta: 5:05:27  iter: 13359  total_loss: 3.426  loss_ce: 0.0003442  loss_mask: 0.1205  loss_dice: 0.1812  loss_ce_0: 0.1201  loss_mask_0: 0.1137  loss_dice_0: 0.1807  loss_ce_1: 0.0005751  loss_mask_1: 0.1144  loss_dice_1: 0.1847  loss_ce_2: 0.002609  loss_mask_2: 0.1214  loss_dice_2: 0.1823  loss_ce_3: 0.003644  loss_mask_3: 0.1262  loss_dice_3: 0.1783  loss_ce_4: 0.001517  loss_mask_4: 0.1239  loss_dice_4: 0.1797  loss_ce_5: 0.0007743  loss_mask_5: 0.1219  loss_dice_5: 0.1903  loss_ce_6: 0.0008289  loss_mask_6: 0.1203  loss_dice_6: 0.18  loss_ce_7: 0.0004765  loss_mask_7: 0.1203  loss_dice_7: 0.181  loss_ce_8: 0.0001899  loss_mask_8: 0.1202  loss_dice_8: 0.1758  time: 0.6688  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:37:09] d2.utils.events INFO:  eta: 5:05:11  iter: 13379  total_loss: 4.329  loss_ce: 0.002114  loss_mask: 0.1205  loss_dice: 0.1727  loss_ce_0: 0.1297  loss_mask_0: 0.1177  loss_dice_0: 0.1718  loss_ce_1: 0.241  loss_mask_1: 0.1254  loss_dice_1: 0.1819  loss_ce_2: 0.007332  loss_mask_2: 0.1252  loss_dice_2: 0.1897  loss_ce_3: 0.04164  loss_mask_3: 0.1278  loss_dice_3: 0.1822  loss_ce_4: 0.05094  loss_mask_4: 0.1223  loss_dice_4: 0.1814  loss_ce_5: 0.005302  loss_mask_5: 0.1223  loss_dice_5: 0.1779  loss_ce_6: 0.003846  loss_mask_6: 0.12  loss_dice_6: 0.1734  loss_ce_7: 0.01695  loss_mask_7: 0.1205  loss_dice_7: 0.1767  loss_ce_8: 0.002329  loss_mask_8: 0.1208  loss_dice_8: 0.1747  time: 0.6691  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:37:26] d2.utils.events INFO:  eta: 5:04:54  iter: 13399  total_loss: 3.309  loss_ce: 0.001345  loss_mask: 0.1203  loss_dice: 0.1681  loss_ce_0: 0.1308  loss_mask_0: 0.1244  loss_dice_0: 0.1761  loss_ce_1: 0.01261  loss_mask_1: 0.1203  loss_dice_1: 0.1703  loss_ce_2: 0.008557  loss_mask_2: 0.1178  loss_dice_2: 0.1689  loss_ce_3: 0.01342  loss_mask_3: 0.1204  loss_dice_3: 0.177  loss_ce_4: 0.00811  loss_mask_4: 0.124  loss_dice_4: 0.1707  loss_ce_5: 0.0027  loss_mask_5: 0.1182  loss_dice_5: 0.1667  loss_ce_6: 0.001269  loss_mask_6: 0.1214  loss_dice_6: 0.1712  loss_ce_7: 0.001258  loss_mask_7: 0.1205  loss_dice_7: 0.1714  loss_ce_8: 0.003071  loss_mask_8: 0.1207  loss_dice_8: 0.1696  time: 0.6694  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 19:37:43] d2.utils.events INFO:  eta: 5:04:46  iter: 13419  total_loss: 3.262  loss_ce: 0.0005157  loss_mask: 0.1226  loss_dice: 0.175  loss_ce_0: 0.1276  loss_mask_0: 0.1273  loss_dice_0: 0.1734  loss_ce_1: 0.001272  loss_mask_1: 0.1252  loss_dice_1: 0.1735  loss_ce_2: 0.00172  loss_mask_2: 0.1221  loss_dice_2: 0.1716  loss_ce_3: 0.0009047  loss_mask_3: 0.1236  loss_dice_3: 0.1677  loss_ce_4: 0.001264  loss_mask_4: 0.1297  loss_dice_4: 0.1746  loss_ce_5: 0.0004515  loss_mask_5: 0.126  loss_dice_5: 0.1777  loss_ce_6: 0.0004383  loss_mask_6: 0.1289  loss_dice_6: 0.1876  loss_ce_7: 0.0002668  loss_mask_7: 0.1258  loss_dice_7: 0.172  loss_ce_8: 0.0004966  loss_mask_8: 0.1274  loss_dice_8: 0.173  time: 0.6696  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:38:00] d2.utils.events INFO:  eta: 5:04:25  iter: 13439  total_loss: 3.004  loss_ce: 0.006025  loss_mask: 0.1171  loss_dice: 0.1733  loss_ce_0: 0.1185  loss_mask_0: 0.1131  loss_dice_0: 0.1645  loss_ce_1: 0.005119  loss_mask_1: 0.119  loss_dice_1: 0.1672  loss_ce_2: 0.005678  loss_mask_2: 0.1147  loss_dice_2: 0.1656  loss_ce_3: 0.004344  loss_mask_3: 0.1208  loss_dice_3: 0.1669  loss_ce_4: 0.003257  loss_mask_4: 0.1204  loss_dice_4: 0.1667  loss_ce_5: 0.002199  loss_mask_5: 0.1158  loss_dice_5: 0.1623  loss_ce_6: 0.002178  loss_mask_6: 0.1144  loss_dice_6: 0.1674  loss_ce_7: 0.005231  loss_mask_7: 0.1139  loss_dice_7: 0.1631  loss_ce_8: 0.001922  loss_mask_8: 0.1174  loss_dice_8: 0.1721  time: 0.6699  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:38:17] d2.utils.events INFO:  eta: 5:04:04  iter: 13459  total_loss: 3.038  loss_ce: 0.0008352  loss_mask: 0.1163  loss_dice: 0.1654  loss_ce_0: 0.118  loss_mask_0: 0.1154  loss_dice_0: 0.1655  loss_ce_1: 0.003454  loss_mask_1: 0.1173  loss_dice_1: 0.1765  loss_ce_2: 0.001325  loss_mask_2: 0.1194  loss_dice_2: 0.1795  loss_ce_3: 0.00171  loss_mask_3: 0.1177  loss_dice_3: 0.1732  loss_ce_4: 0.001662  loss_mask_4: 0.1185  loss_dice_4: 0.1714  loss_ce_5: 0.00164  loss_mask_5: 0.1126  loss_dice_5: 0.1719  loss_ce_6: 0.0007383  loss_mask_6: 0.1166  loss_dice_6: 0.1769  loss_ce_7: 0.0003621  loss_mask_7: 0.1158  loss_dice_7: 0.1806  loss_ce_8: 0.0003551  loss_mask_8: 0.1181  loss_dice_8: 0.1683  time: 0.6702  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 19:38:34] d2.utils.events INFO:  eta: 5:03:44  iter: 13479  total_loss: 3.031  loss_ce: 0.0008557  loss_mask: 0.1188  loss_dice: 0.1755  loss_ce_0: 0.1178  loss_mask_0: 0.1154  loss_dice_0: 0.1717  loss_ce_1: 0.001445  loss_mask_1: 0.1179  loss_dice_1: 0.1708  loss_ce_2: 0.0008903  loss_mask_2: 0.1203  loss_dice_2: 0.1697  loss_ce_3: 0.001148  loss_mask_3: 0.1242  loss_dice_3: 0.1732  loss_ce_4: 0.002499  loss_mask_4: 0.1195  loss_dice_4: 0.1698  loss_ce_5: 0.001349  loss_mask_5: 0.1189  loss_dice_5: 0.1707  loss_ce_6: 0.0009801  loss_mask_6: 0.1158  loss_dice_6: 0.1728  loss_ce_7: 0.0005676  loss_mask_7: 0.1145  loss_dice_7: 0.1673  loss_ce_8: 0.0005034  loss_mask_8: 0.1121  loss_dice_8: 0.1659  time: 0.6704  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 19:38:50] d2.utils.events INFO:  eta: 5:03:21  iter: 13499  total_loss: 2.991  loss_ce: 0.0006689  loss_mask: 0.1163  loss_dice: 0.167  loss_ce_0: 0.122  loss_mask_0: 0.1163  loss_dice_0: 0.1704  loss_ce_1: 0.0009343  loss_mask_1: 0.1148  loss_dice_1: 0.1731  loss_ce_2: 0.0008282  loss_mask_2: 0.1101  loss_dice_2: 0.1675  loss_ce_3: 0.001007  loss_mask_3: 0.115  loss_dice_3: 0.1674  loss_ce_4: 0.0009912  loss_mask_4: 0.115  loss_dice_4: 0.1692  loss_ce_5: 0.001262  loss_mask_5: 0.1141  loss_dice_5: 0.1705  loss_ce_6: 0.0008388  loss_mask_6: 0.1163  loss_dice_6: 0.1705  loss_ce_7: 0.0003736  loss_mask_7: 0.1123  loss_dice_7: 0.1649  loss_ce_8: 0.0003483  loss_mask_8: 0.1158  loss_dice_8: 0.1705  time: 0.6707  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:39:07] d2.utils.events INFO:  eta: 5:03:03  iter: 13519  total_loss: 3.256  loss_ce: 0.0004505  loss_mask: 0.1268  loss_dice: 0.1829  loss_ce_0: 0.1192  loss_mask_0: 0.1251  loss_dice_0: 0.1839  loss_ce_1: 0.0008173  loss_mask_1: 0.1283  loss_dice_1: 0.1844  loss_ce_2: 0.0008281  loss_mask_2: 0.125  loss_dice_2: 0.1757  loss_ce_3: 0.0007257  loss_mask_3: 0.1224  loss_dice_3: 0.1759  loss_ce_4: 0.0006204  loss_mask_4: 0.13  loss_dice_4: 0.1867  loss_ce_5: 0.0009967  loss_mask_5: 0.1254  loss_dice_5: 0.1827  loss_ce_6: 0.0002098  loss_mask_6: 0.1248  loss_dice_6: 0.1848  loss_ce_7: 0.0001732  loss_mask_7: 0.1271  loss_dice_7: 0.1903  loss_ce_8: 0.000258  loss_mask_8: 0.1273  loss_dice_8: 0.1799  time: 0.6709  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:39:24] d2.utils.events INFO:  eta: 5:02:47  iter: 13539  total_loss: 3.033  loss_ce: 0.0005006  loss_mask: 0.1137  loss_dice: 0.1694  loss_ce_0: 0.1214  loss_mask_0: 0.1155  loss_dice_0: 0.1691  loss_ce_1: 0.0005824  loss_mask_1: 0.1174  loss_dice_1: 0.1752  loss_ce_2: 0.000529  loss_mask_2: 0.1167  loss_dice_2: 0.1743  loss_ce_3: 0.0006386  loss_mask_3: 0.1156  loss_dice_3: 0.1694  loss_ce_4: 0.0007981  loss_mask_4: 0.119  loss_dice_4: 0.1691  loss_ce_5: 0.00052  loss_mask_5: 0.1118  loss_dice_5: 0.1679  loss_ce_6: 0.0004536  loss_mask_6: 0.1166  loss_dice_6: 0.1729  loss_ce_7: 0.0003259  loss_mask_7: 0.1181  loss_dice_7: 0.1738  loss_ce_8: 0.0003374  loss_mask_8: 0.1165  loss_dice_8: 0.1729  time: 0.6712  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:39:41] d2.utils.events INFO:  eta: 5:02:30  iter: 13559  total_loss: 3.068  loss_ce: 0.0003089  loss_mask: 0.1158  loss_dice: 0.169  loss_ce_0: 0.1237  loss_mask_0: 0.1178  loss_dice_0: 0.1701  loss_ce_1: 0.0004027  loss_mask_1: 0.1158  loss_dice_1: 0.1669  loss_ce_2: 0.0004708  loss_mask_2: 0.1167  loss_dice_2: 0.1654  loss_ce_3: 0.0004578  loss_mask_3: 0.1123  loss_dice_3: 0.1656  loss_ce_4: 0.0004762  loss_mask_4: 0.1175  loss_dice_4: 0.1684  loss_ce_5: 0.0004969  loss_mask_5: 0.1149  loss_dice_5: 0.1668  loss_ce_6: 0.0003697  loss_mask_6: 0.1165  loss_dice_6: 0.1742  loss_ce_7: 0.0002313  loss_mask_7: 0.1171  loss_dice_7: 0.173  loss_ce_8: 0.0002728  loss_mask_8: 0.1165  loss_dice_8: 0.1675  time: 0.6714  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:39:58] d2.utils.events INFO:  eta: 5:02:14  iter: 13579  total_loss: 2.99  loss_ce: 0.000301  loss_mask: 0.118  loss_dice: 0.1645  loss_ce_0: 0.1297  loss_mask_0: 0.1117  loss_dice_0: 0.1677  loss_ce_1: 0.0003675  loss_mask_1: 0.1163  loss_dice_1: 0.1726  loss_ce_2: 0.000403  loss_mask_2: 0.115  loss_dice_2: 0.1677  loss_ce_3: 0.0004476  loss_mask_3: 0.1193  loss_dice_3: 0.1719  loss_ce_4: 0.0004232  loss_mask_4: 0.114  loss_dice_4: 0.1701  loss_ce_5: 0.0003721  loss_mask_5: 0.1172  loss_dice_5: 0.1692  loss_ce_6: 0.0002872  loss_mask_6: 0.1196  loss_dice_6: 0.1721  loss_ce_7: 0.0001553  loss_mask_7: 0.1165  loss_dice_7: 0.1639  loss_ce_8: 0.0002104  loss_mask_8: 0.1175  loss_dice_8: 0.1639  time: 0.6717  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:40:15] d2.utils.events INFO:  eta: 5:01:51  iter: 13599  total_loss: 3.104  loss_ce: 0.0003065  loss_mask: 0.1174  loss_dice: 0.1747  loss_ce_0: 0.123  loss_mask_0: 0.1198  loss_dice_0: 0.1886  loss_ce_1: 0.0003842  loss_mask_1: 0.1228  loss_dice_1: 0.1826  loss_ce_2: 0.000467  loss_mask_2: 0.1185  loss_dice_2: 0.1818  loss_ce_3: 0.0005073  loss_mask_3: 0.1148  loss_dice_3: 0.1858  loss_ce_4: 0.0004233  loss_mask_4: 0.1186  loss_dice_4: 0.1847  loss_ce_5: 0.0003917  loss_mask_5: 0.1194  loss_dice_5: 0.1819  loss_ce_6: 0.00027  loss_mask_6: 0.1163  loss_dice_6: 0.1788  loss_ce_7: 0.0001565  loss_mask_7: 0.1225  loss_dice_7: 0.1802  loss_ce_8: 0.0002919  loss_mask_8: 0.1209  loss_dice_8: 0.1808  time: 0.6720  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:40:32] d2.utils.events INFO:  eta: 5:01:33  iter: 13619  total_loss: 3.104  loss_ce: 0.000332  loss_mask: 0.1176  loss_dice: 0.1712  loss_ce_0: 0.1221  loss_mask_0: 0.1241  loss_dice_0: 0.1773  loss_ce_1: 0.0003773  loss_mask_1: 0.1183  loss_dice_1: 0.1723  loss_ce_2: 0.0004665  loss_mask_2: 0.1175  loss_dice_2: 0.1772  loss_ce_3: 0.0005038  loss_mask_3: 0.1209  loss_dice_3: 0.1791  loss_ce_4: 0.0003741  loss_mask_4: 0.1212  loss_dice_4: 0.178  loss_ce_5: 0.0003877  loss_mask_5: 0.1198  loss_dice_5: 0.1739  loss_ce_6: 0.0003543  loss_mask_6: 0.1196  loss_dice_6: 0.1718  loss_ce_7: 0.0002089  loss_mask_7: 0.1189  loss_dice_7: 0.1756  loss_ce_8: 0.0002648  loss_mask_8: 0.1243  loss_dice_8: 0.1801  time: 0.6722  data_time: 0.0022  lr: 0.0001  max_mem: 8444M
[08/01 19:40:49] d2.utils.events INFO:  eta: 5:01:13  iter: 13639  total_loss: 3.139  loss_ce: 0.0002246  loss_mask: 0.1165  loss_dice: 0.1835  loss_ce_0: 0.1262  loss_mask_0: 0.1164  loss_dice_0: 0.1839  loss_ce_1: 0.0002877  loss_mask_1: 0.1151  loss_dice_1: 0.1802  loss_ce_2: 0.0003253  loss_mask_2: 0.1172  loss_dice_2: 0.1805  loss_ce_3: 0.0003508  loss_mask_3: 0.1213  loss_dice_3: 0.1877  loss_ce_4: 0.0003939  loss_mask_4: 0.1164  loss_dice_4: 0.181  loss_ce_5: 0.0002735  loss_mask_5: 0.1146  loss_dice_5: 0.1915  loss_ce_6: 0.000191  loss_mask_6: 0.115  loss_dice_6: 0.1831  loss_ce_7: 0.0001253  loss_mask_7: 0.1178  loss_dice_7: 0.189  loss_ce_8: 0.0001744  loss_mask_8: 0.1155  loss_dice_8: 0.1856  time: 0.6725  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:41:06] d2.utils.events INFO:  eta: 5:00:55  iter: 13659  total_loss: 3.118  loss_ce: 0.0002387  loss_mask: 0.1242  loss_dice: 0.1721  loss_ce_0: 0.1238  loss_mask_0: 0.1203  loss_dice_0: 0.1741  loss_ce_1: 0.0002714  loss_mask_1: 0.124  loss_dice_1: 0.1779  loss_ce_2: 0.0003672  loss_mask_2: 0.1211  loss_dice_2: 0.1778  loss_ce_3: 0.000402  loss_mask_3: 0.1222  loss_dice_3: 0.1773  loss_ce_4: 0.0002931  loss_mask_4: 0.1223  loss_dice_4: 0.1772  loss_ce_5: 0.0002776  loss_mask_5: 0.1242  loss_dice_5: 0.1727  loss_ce_6: 0.0002064  loss_mask_6: 0.1221  loss_dice_6: 0.1763  loss_ce_7: 0.0001747  loss_mask_7: 0.1241  loss_dice_7: 0.1681  loss_ce_8: 0.000226  loss_mask_8: 0.1243  loss_dice_8: 0.1771  time: 0.6727  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:41:23] d2.utils.events INFO:  eta: 5:00:29  iter: 13679  total_loss: 3.187  loss_ce: 0.000156  loss_mask: 0.1212  loss_dice: 0.1837  loss_ce_0: 0.1224  loss_mask_0: 0.1161  loss_dice_0: 0.1889  loss_ce_1: 0.0002206  loss_mask_1: 0.1196  loss_dice_1: 0.1765  loss_ce_2: 0.0003029  loss_mask_2: 0.1166  loss_dice_2: 0.18  loss_ce_3: 0.0002756  loss_mask_3: 0.1175  loss_dice_3: 0.1793  loss_ce_4: 0.0002613  loss_mask_4: 0.1239  loss_dice_4: 0.1862  loss_ce_5: 0.0002561  loss_mask_5: 0.1199  loss_dice_5: 0.1846  loss_ce_6: 0.000114  loss_mask_6: 0.1219  loss_dice_6: 0.1825  loss_ce_7: 7.909e-05  loss_mask_7: 0.1184  loss_dice_7: 0.1837  loss_ce_8: 0.0001369  loss_mask_8: 0.1158  loss_dice_8: 0.174  time: 0.6730  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:41:40] d2.utils.events INFO:  eta: 5:00:10  iter: 13699  total_loss: 3.046  loss_ce: 0.0001925  loss_mask: 0.1193  loss_dice: 0.1733  loss_ce_0: 0.1212  loss_mask_0: 0.1197  loss_dice_0: 0.1806  loss_ce_1: 0.0002169  loss_mask_1: 0.116  loss_dice_1: 0.177  loss_ce_2: 0.0003168  loss_mask_2: 0.1165  loss_dice_2: 0.1719  loss_ce_3: 0.0003327  loss_mask_3: 0.118  loss_dice_3: 0.1789  loss_ce_4: 0.0003244  loss_mask_4: 0.1163  loss_dice_4: 0.1727  loss_ce_5: 0.0004029  loss_mask_5: 0.115  loss_dice_5: 0.1721  loss_ce_6: 0.0002457  loss_mask_6: 0.1228  loss_dice_6: 0.1781  loss_ce_7: 0.0001148  loss_mask_7: 0.1189  loss_dice_7: 0.1785  loss_ce_8: 0.0001518  loss_mask_8: 0.1192  loss_dice_8: 0.1786  time: 0.6732  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:41:57] d2.utils.events INFO:  eta: 4:59:54  iter: 13719  total_loss: 3.056  loss_ce: 0.0001833  loss_mask: 0.1144  loss_dice: 0.1694  loss_ce_0: 0.1239  loss_mask_0: 0.1153  loss_dice_0: 0.1712  loss_ce_1: 0.0001839  loss_mask_1: 0.1131  loss_dice_1: 0.1751  loss_ce_2: 0.0002789  loss_mask_2: 0.1151  loss_dice_2: 0.1819  loss_ce_3: 0.000185  loss_mask_3: 0.1125  loss_dice_3: 0.1776  loss_ce_4: 0.0002571  loss_mask_4: 0.1162  loss_dice_4: 0.1825  loss_ce_5: 0.0003054  loss_mask_5: 0.115  loss_dice_5: 0.1753  loss_ce_6: 0.0001611  loss_mask_6: 0.1171  loss_dice_6: 0.1782  loss_ce_7: 8.827e-05  loss_mask_7: 0.1178  loss_dice_7: 0.1811  loss_ce_8: 0.0002217  loss_mask_8: 0.1145  loss_dice_8: 0.1733  time: 0.6735  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:42:14] d2.utils.events INFO:  eta: 4:59:38  iter: 13739  total_loss: 3.14  loss_ce: 0.0001926  loss_mask: 0.1219  loss_dice: 0.1784  loss_ce_0: 0.1172  loss_mask_0: 0.1219  loss_dice_0: 0.1739  loss_ce_1: 0.0001753  loss_mask_1: 0.119  loss_dice_1: 0.179  loss_ce_2: 0.0002644  loss_mask_2: 0.123  loss_dice_2: 0.1767  loss_ce_3: 0.0001689  loss_mask_3: 0.1237  loss_dice_3: 0.1795  loss_ce_4: 0.0002511  loss_mask_4: 0.1231  loss_dice_4: 0.1791  loss_ce_5: 0.0003024  loss_mask_5: 0.1263  loss_dice_5: 0.1748  loss_ce_6: 0.0002165  loss_mask_6: 0.1247  loss_dice_6: 0.1823  loss_ce_7: 0.0001175  loss_mask_7: 0.1247  loss_dice_7: 0.1827  loss_ce_8: 0.0001959  loss_mask_8: 0.1232  loss_dice_8: 0.1785  time: 0.6737  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 19:42:31] d2.utils.events INFO:  eta: 4:59:18  iter: 13759  total_loss: 3  loss_ce: 0.0001841  loss_mask: 0.1198  loss_dice: 0.1741  loss_ce_0: 0.12  loss_mask_0: 0.1127  loss_dice_0: 0.1876  loss_ce_1: 0.0001679  loss_mask_1: 0.1151  loss_dice_1: 0.1811  loss_ce_2: 0.000241  loss_mask_2: 0.1183  loss_dice_2: 0.1735  loss_ce_3: 0.0002158  loss_mask_3: 0.1175  loss_dice_3: 0.1777  loss_ce_4: 0.0003765  loss_mask_4: 0.1149  loss_dice_4: 0.178  loss_ce_5: 0.0003018  loss_mask_5: 0.1174  loss_dice_5: 0.1812  loss_ce_6: 0.0002149  loss_mask_6: 0.1136  loss_dice_6: 0.1761  loss_ce_7: 0.0001464  loss_mask_7: 0.1205  loss_dice_7: 0.1799  loss_ce_8: 0.0002112  loss_mask_8: 0.1172  loss_dice_8: 0.1808  time: 0.6740  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:42:47] d2.utils.events INFO:  eta: 4:58:54  iter: 13779  total_loss: 3.004  loss_ce: 0.000158  loss_mask: 0.1205  loss_dice: 0.1647  loss_ce_0: 0.1229  loss_mask_0: 0.1236  loss_dice_0: 0.1726  loss_ce_1: 0.0001764  loss_mask_1: 0.1177  loss_dice_1: 0.1675  loss_ce_2: 0.0002217  loss_mask_2: 0.1173  loss_dice_2: 0.1752  loss_ce_3: 0.000187  loss_mask_3: 0.1192  loss_dice_3: 0.1674  loss_ce_4: 0.0002156  loss_mask_4: 0.1131  loss_dice_4: 0.1649  loss_ce_5: 0.0002025  loss_mask_5: 0.1191  loss_dice_5: 0.167  loss_ce_6: 0.0001455  loss_mask_6: 0.1172  loss_dice_6: 0.1666  loss_ce_7: 7.598e-05  loss_mask_7: 0.1241  loss_dice_7: 0.1715  loss_ce_8: 0.0001516  loss_mask_8: 0.1174  loss_dice_8: 0.1641  time: 0.6742  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 19:43:04] d2.utils.events INFO:  eta: 4:58:35  iter: 13799  total_loss: 3.278  loss_ce: 0.0001877  loss_mask: 0.1243  loss_dice: 0.1888  loss_ce_0: 0.1182  loss_mask_0: 0.1196  loss_dice_0: 0.1795  loss_ce_1: 0.0002772  loss_mask_1: 0.1245  loss_dice_1: 0.1933  loss_ce_2: 0.0005065  loss_mask_2: 0.1233  loss_dice_2: 0.1932  loss_ce_3: 0.0005697  loss_mask_3: 0.126  loss_dice_3: 0.1885  loss_ce_4: 0.0006137  loss_mask_4: 0.1257  loss_dice_4: 0.1919  loss_ce_5: 0.0007175  loss_mask_5: 0.1282  loss_dice_5: 0.1996  loss_ce_6: 0.0004587  loss_mask_6: 0.1264  loss_dice_6: 0.1972  loss_ce_7: 0.0001337  loss_mask_7: 0.125  loss_dice_7: 0.1875  loss_ce_8: 0.0001991  loss_mask_8: 0.1253  loss_dice_8: 0.1868  time: 0.6745  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:43:21] d2.utils.events INFO:  eta: 4:58:09  iter: 13819  total_loss: 3.303  loss_ce: 0.0003225  loss_mask: 0.1213  loss_dice: 0.1845  loss_ce_0: 0.118  loss_mask_0: 0.125  loss_dice_0: 0.1895  loss_ce_1: 0.0003146  loss_mask_1: 0.125  loss_dice_1: 0.1893  loss_ce_2: 0.0006148  loss_mask_2: 0.1254  loss_dice_2: 0.1862  loss_ce_3: 0.0004821  loss_mask_3: 0.1265  loss_dice_3: 0.1887  loss_ce_4: 0.000697  loss_mask_4: 0.1235  loss_dice_4: 0.1837  loss_ce_5: 0.0003172  loss_mask_5: 0.123  loss_dice_5: 0.1872  loss_ce_6: 0.0004938  loss_mask_6: 0.1239  loss_dice_6: 0.1888  loss_ce_7: 0.000147  loss_mask_7: 0.1248  loss_dice_7: 0.1896  loss_ce_8: 0.0002949  loss_mask_8: 0.1234  loss_dice_8: 0.1883  time: 0.6747  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:43:38] d2.utils.events INFO:  eta: 4:57:50  iter: 13839  total_loss: 3.224  loss_ce: 0.0002549  loss_mask: 0.1244  loss_dice: 0.1822  loss_ce_0: 0.1162  loss_mask_0: 0.1226  loss_dice_0: 0.1931  loss_ce_1: 0.0003375  loss_mask_1: 0.1247  loss_dice_1: 0.1846  loss_ce_2: 0.000404  loss_mask_2: 0.1228  loss_dice_2: 0.1854  loss_ce_3: 0.0003966  loss_mask_3: 0.1234  loss_dice_3: 0.1879  loss_ce_4: 0.0006278  loss_mask_4: 0.1212  loss_dice_4: 0.1804  loss_ce_5: 0.0002514  loss_mask_5: 0.1251  loss_dice_5: 0.1852  loss_ce_6: 0.0004893  loss_mask_6: 0.1286  loss_dice_6: 0.1943  loss_ce_7: 0.0001409  loss_mask_7: 0.1286  loss_dice_7: 0.1814  loss_ce_8: 0.0001786  loss_mask_8: 0.1263  loss_dice_8: 0.1773  time: 0.6750  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:43:55] d2.utils.events INFO:  eta: 4:57:33  iter: 13859  total_loss: 3.074  loss_ce: 0.0002237  loss_mask: 0.1184  loss_dice: 0.1743  loss_ce_0: 0.1116  loss_mask_0: 0.1169  loss_dice_0: 0.1736  loss_ce_1: 0.0002433  loss_mask_1: 0.1183  loss_dice_1: 0.1789  loss_ce_2: 0.0002587  loss_mask_2: 0.12  loss_dice_2: 0.1826  loss_ce_3: 0.0003252  loss_mask_3: 0.1197  loss_dice_3: 0.1779  loss_ce_4: 0.0005903  loss_mask_4: 0.1184  loss_dice_4: 0.1727  loss_ce_5: 0.0002632  loss_mask_5: 0.1169  loss_dice_5: 0.1844  loss_ce_6: 0.0003707  loss_mask_6: 0.1192  loss_dice_6: 0.1789  loss_ce_7: 0.0001242  loss_mask_7: 0.1185  loss_dice_7: 0.1818  loss_ce_8: 0.0001943  loss_mask_8: 0.1188  loss_dice_8: 0.1854  time: 0.6752  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 19:44:12] d2.utils.events INFO:  eta: 4:57:16  iter: 13879  total_loss: 3.038  loss_ce: 0.000173  loss_mask: 0.115  loss_dice: 0.1736  loss_ce_0: 0.116  loss_mask_0: 0.1134  loss_dice_0: 0.1766  loss_ce_1: 0.0002009  loss_mask_1: 0.1156  loss_dice_1: 0.179  loss_ce_2: 0.0002172  loss_mask_2: 0.1211  loss_dice_2: 0.1864  loss_ce_3: 0.0002496  loss_mask_3: 0.1201  loss_dice_3: 0.1765  loss_ce_4: 0.0003449  loss_mask_4: 0.1168  loss_dice_4: 0.1814  loss_ce_5: 0.000167  loss_mask_5: 0.1157  loss_dice_5: 0.1755  loss_ce_6: 0.0002502  loss_mask_6: 0.1167  loss_dice_6: 0.1813  loss_ce_7: 0.0001162  loss_mask_7: 0.1184  loss_dice_7: 0.1773  loss_ce_8: 0.0001492  loss_mask_8: 0.1174  loss_dice_8: 0.1785  time: 0.6754  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:44:29] d2.utils.events INFO:  eta: 4:57:07  iter: 13899  total_loss: 2.936  loss_ce: 0.0002065  loss_mask: 0.116  loss_dice: 0.1664  loss_ce_0: 0.1158  loss_mask_0: 0.1124  loss_dice_0: 0.1681  loss_ce_1: 0.0002039  loss_mask_1: 0.1162  loss_dice_1: 0.169  loss_ce_2: 0.000234  loss_mask_2: 0.1107  loss_dice_2: 0.1663  loss_ce_3: 0.0002498  loss_mask_3: 0.115  loss_dice_3: 0.1708  loss_ce_4: 0.0003214  loss_mask_4: 0.1113  loss_dice_4: 0.162  loss_ce_5: 0.000268  loss_mask_5: 0.114  loss_dice_5: 0.1671  loss_ce_6: 0.0003754  loss_mask_6: 0.1184  loss_dice_6: 0.1687  loss_ce_7: 0.0001269  loss_mask_7: 0.1183  loss_dice_7: 0.1724  loss_ce_8: 0.0001529  loss_mask_8: 0.1159  loss_dice_8: 0.1693  time: 0.6757  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:44:46] d2.utils.events INFO:  eta: 4:56:50  iter: 13919  total_loss: 3.037  loss_ce: 0.000138  loss_mask: 0.1174  loss_dice: 0.1733  loss_ce_0: 0.1137  loss_mask_0: 0.1228  loss_dice_0: 0.1776  loss_ce_1: 0.0001331  loss_mask_1: 0.1219  loss_dice_1: 0.1675  loss_ce_2: 0.0001698  loss_mask_2: 0.1196  loss_dice_2: 0.1726  loss_ce_3: 0.0002305  loss_mask_3: 0.1235  loss_dice_3: 0.1699  loss_ce_4: 0.0002539  loss_mask_4: 0.1235  loss_dice_4: 0.1704  loss_ce_5: 0.0001445  loss_mask_5: 0.1187  loss_dice_5: 0.1715  loss_ce_6: 0.000267  loss_mask_6: 0.12  loss_dice_6: 0.1738  loss_ce_7: 8.074e-05  loss_mask_7: 0.1161  loss_dice_7: 0.1751  loss_ce_8: 0.0001303  loss_mask_8: 0.1209  loss_dice_8: 0.1695  time: 0.6760  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:45:03] d2.utils.events INFO:  eta: 4:56:21  iter: 13939  total_loss: 2.989  loss_ce: 0.0001889  loss_mask: 0.1146  loss_dice: 0.1665  loss_ce_0: 0.1107  loss_mask_0: 0.1158  loss_dice_0: 0.167  loss_ce_1: 0.0001962  loss_mask_1: 0.1175  loss_dice_1: 0.1642  loss_ce_2: 0.0002438  loss_mask_2: 0.1158  loss_dice_2: 0.1614  loss_ce_3: 0.0002323  loss_mask_3: 0.1209  loss_dice_3: 0.167  loss_ce_4: 0.0003326  loss_mask_4: 0.1188  loss_dice_4: 0.1711  loss_ce_5: 0.0001787  loss_mask_5: 0.1173  loss_dice_5: 0.1644  loss_ce_6: 0.0002539  loss_mask_6: 0.1169  loss_dice_6: 0.1691  loss_ce_7: 0.0001132  loss_mask_7: 0.1136  loss_dice_7: 0.1601  loss_ce_8: 0.0001431  loss_mask_8: 0.118  loss_dice_8: 0.1675  time: 0.6762  data_time: 0.0018  lr: 0.0001  max_mem: 8444M
[08/01 19:45:19] d2.utils.events INFO:  eta: 4:55:52  iter: 13959  total_loss: 3.005  loss_ce: 0.0002817  loss_mask: 0.1175  loss_dice: 0.1673  loss_ce_0: 0.1168  loss_mask_0: 0.1174  loss_dice_0: 0.1693  loss_ce_1: 0.0002651  loss_mask_1: 0.117  loss_dice_1: 0.1671  loss_ce_2: 0.0004848  loss_mask_2: 0.1203  loss_dice_2: 0.1678  loss_ce_3: 0.001535  loss_mask_3: 0.1226  loss_dice_3: 0.1788  loss_ce_4: 0.001071  loss_mask_4: 0.1178  loss_dice_4: 0.1676  loss_ce_5: 0.0003204  loss_mask_5: 0.1179  loss_dice_5: 0.1665  loss_ce_6: 0.0003669  loss_mask_6: 0.115  loss_dice_6: 0.1661  loss_ce_7: 0.0004715  loss_mask_7: 0.115  loss_dice_7: 0.1682  loss_ce_8: 0.0003581  loss_mask_8: 0.1171  loss_dice_8: 0.1634  time: 0.6763  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 19:45:34] d2.utils.events INFO:  eta: 4:55:19  iter: 13979  total_loss: 3.081  loss_ce: 0.0004691  loss_mask: 0.1162  loss_dice: 0.1727  loss_ce_0: 0.1247  loss_mask_0: 0.1165  loss_dice_0: 0.1714  loss_ce_1: 0.0005373  loss_mask_1: 0.1154  loss_dice_1: 0.1674  loss_ce_2: 0.00103  loss_mask_2: 0.1178  loss_dice_2: 0.1716  loss_ce_3: 0.001249  loss_mask_3: 0.1176  loss_dice_3: 0.1776  loss_ce_4: 0.001114  loss_mask_4: 0.1209  loss_dice_4: 0.1717  loss_ce_5: 0.0005195  loss_mask_5: 0.1138  loss_dice_5: 0.1732  loss_ce_6: 0.0004459  loss_mask_6: 0.1149  loss_dice_6: 0.1713  loss_ce_7: 0.0008536  loss_mask_7: 0.1133  loss_dice_7: 0.1696  loss_ce_8: 0.000535  loss_mask_8: 0.1186  loss_dice_8: 0.1699  time: 0.6765  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:45:50] d2.utils.events INFO:  eta: 4:54:37  iter: 13999  total_loss: 3.538  loss_ce: 0.001134  loss_mask: 0.1239  loss_dice: 0.2085  loss_ce_0: 0.1276  loss_mask_0: 0.1312  loss_dice_0: 0.2152  loss_ce_1: 0.002009  loss_mask_1: 0.1256  loss_dice_1: 0.2115  loss_ce_2: 0.001129  loss_mask_2: 0.125  loss_dice_2: 0.2074  loss_ce_3: 0.001731  loss_mask_3: 0.1245  loss_dice_3: 0.205  loss_ce_4: 0.001281  loss_mask_4: 0.1246  loss_dice_4: 0.2069  loss_ce_5: 0.001155  loss_mask_5: 0.129  loss_dice_5: 0.2047  loss_ce_6: 0.001261  loss_mask_6: 0.1298  loss_dice_6: 0.2134  loss_ce_7: 0.00316  loss_mask_7: 0.1244  loss_dice_7: 0.2058  loss_ce_8: 0.001648  loss_mask_8: 0.1243  loss_dice_8: 0.2054  time: 0.6767  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:46:06] d2.utils.events INFO:  eta: 4:54:01  iter: 14019  total_loss: 2.99  loss_ce: 0.000713  loss_mask: 0.1125  loss_dice: 0.1655  loss_ce_0: 0.116  loss_mask_0: 0.1151  loss_dice_0: 0.1649  loss_ce_1: 0.0009829  loss_mask_1: 0.1171  loss_dice_1: 0.1712  loss_ce_2: 0.0007095  loss_mask_2: 0.1134  loss_dice_2: 0.1682  loss_ce_3: 0.0005247  loss_mask_3: 0.1168  loss_dice_3: 0.1781  loss_ce_4: 0.0005925  loss_mask_4: 0.1151  loss_dice_4: 0.1699  loss_ce_5: 0.0008718  loss_mask_5: 0.1155  loss_dice_5: 0.1671  loss_ce_6: 0.001053  loss_mask_6: 0.1168  loss_dice_6: 0.1701  loss_ce_7: 0.000941  loss_mask_7: 0.1135  loss_dice_7: 0.1686  loss_ce_8: 0.0008908  loss_mask_8: 0.1176  loss_dice_8: 0.1709  time: 0.6768  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:46:22] d2.utils.events INFO:  eta: 4:53:15  iter: 14039  total_loss: 3.113  loss_ce: 0.0007061  loss_mask: 0.1142  loss_dice: 0.1832  loss_ce_0: 0.1099  loss_mask_0: 0.1151  loss_dice_0: 0.1815  loss_ce_1: 0.0007819  loss_mask_1: 0.1131  loss_dice_1: 0.179  loss_ce_2: 0.0005233  loss_mask_2: 0.115  loss_dice_2: 0.1921  loss_ce_3: 0.0005596  loss_mask_3: 0.1139  loss_dice_3: 0.1815  loss_ce_4: 0.0004984  loss_mask_4: 0.113  loss_dice_4: 0.1843  loss_ce_5: 0.0008658  loss_mask_5: 0.1149  loss_dice_5: 0.1751  loss_ce_6: 0.0008841  loss_mask_6: 0.1178  loss_dice_6: 0.1857  loss_ce_7: 0.0008253  loss_mask_7: 0.1161  loss_dice_7: 0.1846  loss_ce_8: 0.0008859  loss_mask_8: 0.1161  loss_dice_8: 0.1848  time: 0.6770  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:46:38] d2.utils.events INFO:  eta: 4:52:30  iter: 14059  total_loss: 3.004  loss_ce: 0.0004021  loss_mask: 0.1125  loss_dice: 0.1654  loss_ce_0: 0.1243  loss_mask_0: 0.1175  loss_dice_0: 0.1622  loss_ce_1: 0.0006618  loss_mask_1: 0.1165  loss_dice_1: 0.1647  loss_ce_2: 0.0004018  loss_mask_2: 0.1141  loss_dice_2: 0.1687  loss_ce_3: 0.0004666  loss_mask_3: 0.1114  loss_dice_3: 0.1734  loss_ce_4: 0.0004021  loss_mask_4: 0.1134  loss_dice_4: 0.166  loss_ce_5: 0.000434  loss_mask_5: 0.114  loss_dice_5: 0.1631  loss_ce_6: 0.0005063  loss_mask_6: 0.1166  loss_dice_6: 0.1644  loss_ce_7: 0.0004872  loss_mask_7: 0.1126  loss_dice_7: 0.1609  loss_ce_8: 0.0003769  loss_mask_8: 0.1114  loss_dice_8: 0.1671  time: 0.6771  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:46:54] d2.utils.events INFO:  eta: 4:52:00  iter: 14079  total_loss: 3.161  loss_ce: 0.0006731  loss_mask: 0.1209  loss_dice: 0.1758  loss_ce_0: 0.1122  loss_mask_0: 0.1187  loss_dice_0: 0.1766  loss_ce_1: 0.0006367  loss_mask_1: 0.1173  loss_dice_1: 0.1755  loss_ce_2: 0.0003977  loss_mask_2: 0.1203  loss_dice_2: 0.1768  loss_ce_3: 0.000512  loss_mask_3: 0.1142  loss_dice_3: 0.1766  loss_ce_4: 0.0005531  loss_mask_4: 0.1216  loss_dice_4: 0.1843  loss_ce_5: 0.0007592  loss_mask_5: 0.1182  loss_dice_5: 0.1833  loss_ce_6: 0.000749  loss_mask_6: 0.1154  loss_dice_6: 0.1787  loss_ce_7: 0.0006294  loss_mask_7: 0.1134  loss_dice_7: 0.18  loss_ce_8: 0.0008234  loss_mask_8: 0.1159  loss_dice_8: 0.1779  time: 0.6773  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:47:09] d2.utils.events INFO:  eta: 4:51:30  iter: 14099  total_loss: 2.964  loss_ce: 0.0004817  loss_mask: 0.1196  loss_dice: 0.1693  loss_ce_0: 0.1176  loss_mask_0: 0.1194  loss_dice_0: 0.1674  loss_ce_1: 0.0004346  loss_mask_1: 0.1227  loss_dice_1: 0.1688  loss_ce_2: 0.0003525  loss_mask_2: 0.1202  loss_dice_2: 0.1679  loss_ce_3: 0.0004549  loss_mask_3: 0.1172  loss_dice_3: 0.1657  loss_ce_4: 0.0004245  loss_mask_4: 0.1192  loss_dice_4: 0.1675  loss_ce_5: 0.0004121  loss_mask_5: 0.1187  loss_dice_5: 0.1684  loss_ce_6: 0.000573  loss_mask_6: 0.1237  loss_dice_6: 0.1644  loss_ce_7: 0.0004138  loss_mask_7: 0.1193  loss_dice_7: 0.1666  loss_ce_8: 0.0004054  loss_mask_8: 0.1212  loss_dice_8: 0.1643  time: 0.6775  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:47:25] d2.utils.events INFO:  eta: 4:51:04  iter: 14119  total_loss: 3.18  loss_ce: 0.0002658  loss_mask: 0.1182  loss_dice: 0.1882  loss_ce_0: 0.1217  loss_mask_0: 0.1171  loss_dice_0: 0.1872  loss_ce_1: 0.0004435  loss_mask_1: 0.1187  loss_dice_1: 0.1974  loss_ce_2: 0.000329  loss_mask_2: 0.1161  loss_dice_2: 0.1927  loss_ce_3: 0.0003427  loss_mask_3: 0.1179  loss_dice_3: 0.1936  loss_ce_4: 0.0002855  loss_mask_4: 0.1213  loss_dice_4: 0.1904  loss_ce_5: 0.0003413  loss_mask_5: 0.1199  loss_dice_5: 0.1849  loss_ce_6: 0.000327  loss_mask_6: 0.1175  loss_dice_6: 0.1874  loss_ce_7: 0.0002506  loss_mask_7: 0.1175  loss_dice_7: 0.1901  loss_ce_8: 0.0002656  loss_mask_8: 0.1189  loss_dice_8: 0.1972  time: 0.6776  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 19:47:41] d2.utils.events INFO:  eta: 4:50:18  iter: 14139  total_loss: 3.248  loss_ce: 0.0002416  loss_mask: 0.1176  loss_dice: 0.1881  loss_ce_0: 0.1245  loss_mask_0: 0.1171  loss_dice_0: 0.1876  loss_ce_1: 0.0003842  loss_mask_1: 0.1191  loss_dice_1: 0.1836  loss_ce_2: 0.000276  loss_mask_2: 0.1196  loss_dice_2: 0.1865  loss_ce_3: 0.0003113  loss_mask_3: 0.1205  loss_dice_3: 0.1879  loss_ce_4: 0.0004165  loss_mask_4: 0.1189  loss_dice_4: 0.1878  loss_ce_5: 0.0003005  loss_mask_5: 0.1184  loss_dice_5: 0.1948  loss_ce_6: 0.0002962  loss_mask_6: 0.1204  loss_dice_6: 0.1874  loss_ce_7: 0.0002696  loss_mask_7: 0.1189  loss_dice_7: 0.1893  loss_ce_8: 0.000267  loss_mask_8: 0.1164  loss_dice_8: 0.1907  time: 0.6778  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:47:57] d2.utils.events INFO:  eta: 4:49:31  iter: 14159  total_loss: 3.22  loss_ce: 0.0003822  loss_mask: 0.1207  loss_dice: 0.1922  loss_ce_0: 0.1179  loss_mask_0: 0.1226  loss_dice_0: 0.187  loss_ce_1: 0.0003789  loss_mask_1: 0.1191  loss_dice_1: 0.1866  loss_ce_2: 0.0002882  loss_mask_2: 0.1233  loss_dice_2: 0.1886  loss_ce_3: 0.0003551  loss_mask_3: 0.1201  loss_dice_3: 0.1884  loss_ce_4: 0.0002386  loss_mask_4: 0.1167  loss_dice_4: 0.1939  loss_ce_5: 0.0004472  loss_mask_5: 0.1229  loss_dice_5: 0.1914  loss_ce_6: 0.0003804  loss_mask_6: 0.1216  loss_dice_6: 0.1877  loss_ce_7: 0.0002801  loss_mask_7: 0.1214  loss_dice_7: 0.1876  loss_ce_8: 0.0004227  loss_mask_8: 0.1236  loss_dice_8: 0.1952  time: 0.6779  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:48:13] d2.utils.events INFO:  eta: 4:48:53  iter: 14179  total_loss: 3.24  loss_ce: 0.0001909  loss_mask: 0.1169  loss_dice: 0.1876  loss_ce_0: 0.1182  loss_mask_0: 0.1204  loss_dice_0: 0.188  loss_ce_1: 0.0003237  loss_mask_1: 0.1167  loss_dice_1: 0.1891  loss_ce_2: 0.0002464  loss_mask_2: 0.122  loss_dice_2: 0.1983  loss_ce_3: 0.0002619  loss_mask_3: 0.1187  loss_dice_3: 0.185  loss_ce_4: 0.0002109  loss_mask_4: 0.119  loss_dice_4: 0.1937  loss_ce_5: 0.0002397  loss_mask_5: 0.1136  loss_dice_5: 0.1821  loss_ce_6: 0.000263  loss_mask_6: 0.1203  loss_dice_6: 0.1875  loss_ce_7: 0.0002074  loss_mask_7: 0.118  loss_dice_7: 0.1865  loss_ce_8: 0.0002222  loss_mask_8: 0.1149  loss_dice_8: 0.1856  time: 0.6781  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:48:28] d2.utils.events INFO:  eta: 4:48:03  iter: 14199  total_loss: 2.982  loss_ce: 0.0001451  loss_mask: 0.1156  loss_dice: 0.1723  loss_ce_0: 0.1328  loss_mask_0: 0.1112  loss_dice_0: 0.1649  loss_ce_1: 0.0001858  loss_mask_1: 0.1127  loss_dice_1: 0.1809  loss_ce_2: 0.0001925  loss_mask_2: 0.1142  loss_dice_2: 0.1729  loss_ce_3: 0.0002082  loss_mask_3: 0.1151  loss_dice_3: 0.1744  loss_ce_4: 0.0001857  loss_mask_4: 0.1148  loss_dice_4: 0.1824  loss_ce_5: 0.0002018  loss_mask_5: 0.1138  loss_dice_5: 0.1644  loss_ce_6: 0.0001664  loss_mask_6: 0.1136  loss_dice_6: 0.1731  loss_ce_7: 0.0001106  loss_mask_7: 0.1137  loss_dice_7: 0.1761  loss_ce_8: 0.0001734  loss_mask_8: 0.1129  loss_dice_8: 0.1744  time: 0.6783  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:48:44] d2.utils.events INFO:  eta: 4:47:28  iter: 14219  total_loss: 2.938  loss_ce: 0.0002287  loss_mask: 0.1135  loss_dice: 0.172  loss_ce_0: 0.1189  loss_mask_0: 0.1116  loss_dice_0: 0.1761  loss_ce_1: 0.0002601  loss_mask_1: 0.1122  loss_dice_1: 0.178  loss_ce_2: 0.0002199  loss_mask_2: 0.1114  loss_dice_2: 0.1796  loss_ce_3: 0.0002352  loss_mask_3: 0.115  loss_dice_3: 0.1762  loss_ce_4: 0.0001971  loss_mask_4: 0.1143  loss_dice_4: 0.1766  loss_ce_5: 0.0002122  loss_mask_5: 0.1113  loss_dice_5: 0.1701  loss_ce_6: 0.0002232  loss_mask_6: 0.1118  loss_dice_6: 0.1752  loss_ce_7: 0.000213  loss_mask_7: 0.1134  loss_dice_7: 0.1769  loss_ce_8: 0.0002044  loss_mask_8: 0.1104  loss_dice_8: 0.1744  time: 0.6784  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:49:00] d2.utils.events INFO:  eta: 4:47:03  iter: 14239  total_loss: 2.988  loss_ce: 0.0001448  loss_mask: 0.1168  loss_dice: 0.1802  loss_ce_0: 0.128  loss_mask_0: 0.1175  loss_dice_0: 0.1752  loss_ce_1: 0.0002438  loss_mask_1: 0.1182  loss_dice_1: 0.1766  loss_ce_2: 0.0002112  loss_mask_2: 0.1161  loss_dice_2: 0.1708  loss_ce_3: 0.0002276  loss_mask_3: 0.1191  loss_dice_3: 0.1724  loss_ce_4: 0.0002398  loss_mask_4: 0.1194  loss_dice_4: 0.1735  loss_ce_5: 0.0001853  loss_mask_5: 0.1225  loss_dice_5: 0.1773  loss_ce_6: 0.0002351  loss_mask_6: 0.1141  loss_dice_6: 0.1782  loss_ce_7: 0.0001724  loss_mask_7: 0.1182  loss_dice_7: 0.1718  loss_ce_8: 0.0001929  loss_mask_8: 0.1168  loss_dice_8: 0.1757  time: 0.6786  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:49:16] d2.utils.events INFO:  eta: 4:46:25  iter: 14259  total_loss: 2.973  loss_ce: 0.0001292  loss_mask: 0.1177  loss_dice: 0.1677  loss_ce_0: 0.1219  loss_mask_0: 0.1145  loss_dice_0: 0.1772  loss_ce_1: 0.0002341  loss_mask_1: 0.1134  loss_dice_1: 0.1724  loss_ce_2: 0.000168  loss_mask_2: 0.1167  loss_dice_2: 0.1725  loss_ce_3: 0.000188  loss_mask_3: 0.1135  loss_dice_3: 0.171  loss_ce_4: 0.0002277  loss_mask_4: 0.1152  loss_dice_4: 0.173  loss_ce_5: 0.0001523  loss_mask_5: 0.1154  loss_dice_5: 0.1718  loss_ce_6: 0.0001774  loss_mask_6: 0.1148  loss_dice_6: 0.1707  loss_ce_7: 0.0001776  loss_mask_7: 0.1145  loss_dice_7: 0.1698  loss_ce_8: 0.0001783  loss_mask_8: 0.1128  loss_dice_8: 0.1699  time: 0.6787  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:49:32] d2.utils.events INFO:  eta: 4:45:49  iter: 14279  total_loss: 3.233  loss_ce: 0.0001221  loss_mask: 0.1231  loss_dice: 0.1843  loss_ce_0: 0.1229  loss_mask_0: 0.1223  loss_dice_0: 0.1954  loss_ce_1: 0.0002492  loss_mask_1: 0.1257  loss_dice_1: 0.1885  loss_ce_2: 0.0001805  loss_mask_2: 0.1258  loss_dice_2: 0.1864  loss_ce_3: 0.0001855  loss_mask_3: 0.1194  loss_dice_3: 0.1827  loss_ce_4: 0.0001789  loss_mask_4: 0.1229  loss_dice_4: 0.1932  loss_ce_5: 0.0001634  loss_mask_5: 0.125  loss_dice_5: 0.1947  loss_ce_6: 0.0001591  loss_mask_6: 0.1242  loss_dice_6: 0.1857  loss_ce_7: 0.0001488  loss_mask_7: 0.1215  loss_dice_7: 0.1865  loss_ce_8: 0.0001609  loss_mask_8: 0.1242  loss_dice_8: 0.1876  time: 0.6789  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:49:48] d2.utils.events INFO:  eta: 4:45:10  iter: 14299  total_loss: 3.134  loss_ce: 9.988e-05  loss_mask: 0.1149  loss_dice: 0.1747  loss_ce_0: 0.1268  loss_mask_0: 0.1131  loss_dice_0: 0.1744  loss_ce_1: 0.0001335  loss_mask_1: 0.1146  loss_dice_1: 0.1795  loss_ce_2: 0.0001538  loss_mask_2: 0.1121  loss_dice_2: 0.1789  loss_ce_3: 0.0001232  loss_mask_3: 0.1108  loss_dice_3: 0.1812  loss_ce_4: 0.0001203  loss_mask_4: 0.1133  loss_dice_4: 0.1791  loss_ce_5: 0.0001387  loss_mask_5: 0.1125  loss_dice_5: 0.1785  loss_ce_6: 0.000102  loss_mask_6: 0.1126  loss_dice_6: 0.1815  loss_ce_7: 6.573e-05  loss_mask_7: 0.111  loss_dice_7: 0.1826  loss_ce_8: 0.0001127  loss_mask_8: 0.1145  loss_dice_8: 0.1782  time: 0.6790  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:50:03] d2.utils.events INFO:  eta: 4:44:35  iter: 14319  total_loss: 3.251  loss_ce: 0.0001292  loss_mask: 0.117  loss_dice: 0.1818  loss_ce_0: 0.1249  loss_mask_0: 0.1214  loss_dice_0: 0.1965  loss_ce_1: 0.0002117  loss_mask_1: 0.1153  loss_dice_1: 0.1864  loss_ce_2: 0.0001806  loss_mask_2: 0.1198  loss_dice_2: 0.1939  loss_ce_3: 0.0001962  loss_mask_3: 0.1174  loss_dice_3: 0.1861  loss_ce_4: 0.0001871  loss_mask_4: 0.1179  loss_dice_4: 0.1919  loss_ce_5: 0.0001496  loss_mask_5: 0.1171  loss_dice_5: 0.1868  loss_ce_6: 0.0001623  loss_mask_6: 0.1148  loss_dice_6: 0.1914  loss_ce_7: 0.0001348  loss_mask_7: 0.1231  loss_dice_7: 0.1874  loss_ce_8: 0.0001718  loss_mask_8: 0.1174  loss_dice_8: 0.1896  time: 0.6792  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:50:19] d2.utils.events INFO:  eta: 4:43:44  iter: 14339  total_loss: 3.082  loss_ce: 0.0001739  loss_mask: 0.1162  loss_dice: 0.1788  loss_ce_0: 0.1215  loss_mask_0: 0.1189  loss_dice_0: 0.1798  loss_ce_1: 0.000229  loss_mask_1: 0.1205  loss_dice_1: 0.1803  loss_ce_2: 0.0002009  loss_mask_2: 0.1201  loss_dice_2: 0.1797  loss_ce_3: 0.0002157  loss_mask_3: 0.1182  loss_dice_3: 0.1766  loss_ce_4: 0.0002141  loss_mask_4: 0.1189  loss_dice_4: 0.178  loss_ce_5: 0.0001837  loss_mask_5: 0.1196  loss_dice_5: 0.1828  loss_ce_6: 0.0001634  loss_mask_6: 0.1186  loss_dice_6: 0.1789  loss_ce_7: 0.0001319  loss_mask_7: 0.1191  loss_dice_7: 0.1776  loss_ce_8: 0.0001925  loss_mask_8: 0.1178  loss_dice_8: 0.1735  time: 0.6793  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:50:35] d2.utils.events INFO:  eta: 4:42:57  iter: 14359  total_loss: 3.036  loss_ce: 0.0001132  loss_mask: 0.1204  loss_dice: 0.1676  loss_ce_0: 0.1279  loss_mask_0: 0.1201  loss_dice_0: 0.172  loss_ce_1: 0.0001919  loss_mask_1: 0.1215  loss_dice_1: 0.1769  loss_ce_2: 0.0001722  loss_mask_2: 0.1182  loss_dice_2: 0.1706  loss_ce_3: 0.0001837  loss_mask_3: 0.1168  loss_dice_3: 0.1712  loss_ce_4: 0.0001464  loss_mask_4: 0.1263  loss_dice_4: 0.1729  loss_ce_5: 0.0001651  loss_mask_5: 0.1215  loss_dice_5: 0.1745  loss_ce_6: 0.000132  loss_mask_6: 0.1208  loss_dice_6: 0.1722  loss_ce_7: 9.937e-05  loss_mask_7: 0.123  loss_dice_7: 0.1688  loss_ce_8: 0.0001405  loss_mask_8: 0.1228  loss_dice_8: 0.1724  time: 0.6795  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:50:51] d2.utils.events INFO:  eta: 4:42:22  iter: 14379  total_loss: 3.105  loss_ce: 0.0001287  loss_mask: 0.1209  loss_dice: 0.1652  loss_ce_0: 0.1225  loss_mask_0: 0.1241  loss_dice_0: 0.1736  loss_ce_1: 0.0001931  loss_mask_1: 0.1203  loss_dice_1: 0.1685  loss_ce_2: 0.0002512  loss_mask_2: 0.1204  loss_dice_2: 0.172  loss_ce_3: 0.0002212  loss_mask_3: 0.1245  loss_dice_3: 0.1693  loss_ce_4: 0.0001363  loss_mask_4: 0.125  loss_dice_4: 0.1719  loss_ce_5: 0.0001649  loss_mask_5: 0.1238  loss_dice_5: 0.1684  loss_ce_6: 0.0001456  loss_mask_6: 0.1179  loss_dice_6: 0.1686  loss_ce_7: 0.0001093  loss_mask_7: 0.1227  loss_dice_7: 0.1722  loss_ce_8: 0.0001398  loss_mask_8: 0.123  loss_dice_8: 0.1679  time: 0.6797  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 19:51:07] d2.utils.events INFO:  eta: 4:41:29  iter: 14399  total_loss: 3.056  loss_ce: 9.527e-05  loss_mask: 0.1194  loss_dice: 0.1778  loss_ce_0: 0.1188  loss_mask_0: 0.1224  loss_dice_0: 0.1889  loss_ce_1: 0.0001427  loss_mask_1: 0.1168  loss_dice_1: 0.1802  loss_ce_2: 0.0001989  loss_mask_2: 0.1202  loss_dice_2: 0.1825  loss_ce_3: 0.0002145  loss_mask_3: 0.1172  loss_dice_3: 0.1758  loss_ce_4: 0.0001312  loss_mask_4: 0.1173  loss_dice_4: 0.1802  loss_ce_5: 0.0001358  loss_mask_5: 0.1231  loss_dice_5: 0.1754  loss_ce_6: 0.0001166  loss_mask_6: 0.1184  loss_dice_6: 0.1745  loss_ce_7: 7.629e-05  loss_mask_7: 0.1173  loss_dice_7: 0.1847  loss_ce_8: 0.000111  loss_mask_8: 0.1214  loss_dice_8: 0.1744  time: 0.6798  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:51:23] d2.utils.events INFO:  eta: 4:40:54  iter: 14419  total_loss: 3.125  loss_ce: 9.226e-05  loss_mask: 0.1192  loss_dice: 0.1747  loss_ce_0: 0.1214  loss_mask_0: 0.1208  loss_dice_0: 0.1847  loss_ce_1: 0.0001834  loss_mask_1: 0.1234  loss_dice_1: 0.1793  loss_ce_2: 0.0001552  loss_mask_2: 0.1192  loss_dice_2: 0.181  loss_ce_3: 0.0001708  loss_mask_3: 0.1239  loss_dice_3: 0.1837  loss_ce_4: 0.0001251  loss_mask_4: 0.1196  loss_dice_4: 0.1781  loss_ce_5: 0.0001414  loss_mask_5: 0.1198  loss_dice_5: 0.1795  loss_ce_6: 0.0001048  loss_mask_6: 0.1195  loss_dice_6: 0.1788  loss_ce_7: 8.993e-05  loss_mask_7: 0.1226  loss_dice_7: 0.1849  loss_ce_8: 0.0001274  loss_mask_8: 0.1197  loss_dice_8: 0.1777  time: 0.6800  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:51:38] d2.utils.events INFO:  eta: 4:40:13  iter: 14439  total_loss: 2.99  loss_ce: 0.0001523  loss_mask: 0.1185  loss_dice: 0.1654  loss_ce_0: 0.1334  loss_mask_0: 0.1202  loss_dice_0: 0.1649  loss_ce_1: 0.0001999  loss_mask_1: 0.1225  loss_dice_1: 0.1691  loss_ce_2: 0.0001873  loss_mask_2: 0.1221  loss_dice_2: 0.1721  loss_ce_3: 0.0001886  loss_mask_3: 0.1145  loss_dice_3: 0.1684  loss_ce_4: 0.000147  loss_mask_4: 0.1202  loss_dice_4: 0.1659  loss_ce_5: 0.0001541  loss_mask_5: 0.1191  loss_dice_5: 0.1668  loss_ce_6: 0.0001675  loss_mask_6: 0.1223  loss_dice_6: 0.1718  loss_ce_7: 0.0001261  loss_mask_7: 0.1205  loss_dice_7: 0.1742  loss_ce_8: 0.0001643  loss_mask_8: 0.119  loss_dice_8: 0.1633  time: 0.6801  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 19:51:54] d2.utils.events INFO:  eta: 4:39:26  iter: 14459  total_loss: 3.059  loss_ce: 0.0002221  loss_mask: 0.1168  loss_dice: 0.1689  loss_ce_0: 0.1218  loss_mask_0: 0.1182  loss_dice_0: 0.1743  loss_ce_1: 0.0001782  loss_mask_1: 0.1186  loss_dice_1: 0.1808  loss_ce_2: 0.0001753  loss_mask_2: 0.1167  loss_dice_2: 0.1702  loss_ce_3: 0.0002277  loss_mask_3: 0.115  loss_dice_3: 0.1663  loss_ce_4: 0.0003114  loss_mask_4: 0.1178  loss_dice_4: 0.1787  loss_ce_5: 0.0001725  loss_mask_5: 0.1166  loss_dice_5: 0.1729  loss_ce_6: 0.0001033  loss_mask_6: 0.1177  loss_dice_6: 0.1748  loss_ce_7: 0.0001295  loss_mask_7: 0.1175  loss_dice_7: 0.1811  loss_ce_8: 0.0002354  loss_mask_8: 0.1188  loss_dice_8: 0.174  time: 0.6803  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:52:10] d2.utils.events INFO:  eta: 4:38:33  iter: 14479  total_loss: 3.015  loss_ce: 0.0001714  loss_mask: 0.1179  loss_dice: 0.1695  loss_ce_0: 0.1287  loss_mask_0: 0.1132  loss_dice_0: 0.1673  loss_ce_1: 0.0001523  loss_mask_1: 0.1154  loss_dice_1: 0.1741  loss_ce_2: 0.0001425  loss_mask_2: 0.1177  loss_dice_2: 0.1665  loss_ce_3: 0.0001807  loss_mask_3: 0.1156  loss_dice_3: 0.1696  loss_ce_4: 0.0002223  loss_mask_4: 0.1134  loss_dice_4: 0.1674  loss_ce_5: 0.0001449  loss_mask_5: 0.1134  loss_dice_5: 0.1659  loss_ce_6: 0.0001058  loss_mask_6: 0.1146  loss_dice_6: 0.1726  loss_ce_7: 0.0001203  loss_mask_7: 0.1135  loss_dice_7: 0.1673  loss_ce_8: 0.0002067  loss_mask_8: 0.1111  loss_dice_8: 0.1647  time: 0.6804  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 19:52:26] d2.utils.events INFO:  eta: 4:37:57  iter: 14499  total_loss: 2.98  loss_ce: 0.0001495  loss_mask: 0.1149  loss_dice: 0.1663  loss_ce_0: 0.1229  loss_mask_0: 0.119  loss_dice_0: 0.1709  loss_ce_1: 0.000136  loss_mask_1: 0.1173  loss_dice_1: 0.1701  loss_ce_2: 0.0001714  loss_mask_2: 0.1193  loss_dice_2: 0.1605  loss_ce_3: 0.0001736  loss_mask_3: 0.1199  loss_dice_3: 0.1723  loss_ce_4: 0.0002091  loss_mask_4: 0.1202  loss_dice_4: 0.1684  loss_ce_5: 0.0001964  loss_mask_5: 0.1128  loss_dice_5: 0.1678  loss_ce_6: 0.0001362  loss_mask_6: 0.1183  loss_dice_6: 0.1703  loss_ce_7: 0.0001141  loss_mask_7: 0.1192  loss_dice_7: 0.1729  loss_ce_8: 0.0002082  loss_mask_8: 0.1182  loss_dice_8: 0.1625  time: 0.6806  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:52:42] d2.utils.events INFO:  eta: 4:37:08  iter: 14519  total_loss: 3.098  loss_ce: 0.0001237  loss_mask: 0.1153  loss_dice: 0.1865  loss_ce_0: 0.124  loss_mask_0: 0.1122  loss_dice_0: 0.1797  loss_ce_1: 0.0001582  loss_mask_1: 0.1119  loss_dice_1: 0.181  loss_ce_2: 0.0001577  loss_mask_2: 0.1141  loss_dice_2: 0.1852  loss_ce_3: 0.0001581  loss_mask_3: 0.115  loss_dice_3: 0.1799  loss_ce_4: 0.0001938  loss_mask_4: 0.1137  loss_dice_4: 0.1804  loss_ce_5: 0.0001344  loss_mask_5: 0.1126  loss_dice_5: 0.1779  loss_ce_6: 8.944e-05  loss_mask_6: 0.1127  loss_dice_6: 0.1807  loss_ce_7: 0.0001064  loss_mask_7: 0.1117  loss_dice_7: 0.1795  loss_ce_8: 0.0001556  loss_mask_8: 0.1124  loss_dice_8: 0.1798  time: 0.6808  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:52:58] d2.utils.events INFO:  eta: 4:36:25  iter: 14539  total_loss: 3.106  loss_ce: 0.0001045  loss_mask: 0.1145  loss_dice: 0.1783  loss_ce_0: 0.1286  loss_mask_0: 0.1163  loss_dice_0: 0.1753  loss_ce_1: 0.0001413  loss_mask_1: 0.1158  loss_dice_1: 0.1769  loss_ce_2: 0.0001228  loss_mask_2: 0.1106  loss_dice_2: 0.1786  loss_ce_3: 0.0001236  loss_mask_3: 0.1124  loss_dice_3: 0.179  loss_ce_4: 0.0001535  loss_mask_4: 0.1091  loss_dice_4: 0.1772  loss_ce_5: 0.0001151  loss_mask_5: 0.1165  loss_dice_5: 0.1898  loss_ce_6: 8.544e-05  loss_mask_6: 0.1143  loss_dice_6: 0.1882  loss_ce_7: 9.795e-05  loss_mask_7: 0.1163  loss_dice_7: 0.1775  loss_ce_8: 0.0001382  loss_mask_8: 0.1132  loss_dice_8: 0.1893  time: 0.6809  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:53:14] d2.utils.events INFO:  eta: 4:35:40  iter: 14559  total_loss: 3.012  loss_ce: 9.598e-05  loss_mask: 0.1144  loss_dice: 0.1707  loss_ce_0: 0.1296  loss_mask_0: 0.1144  loss_dice_0: 0.1716  loss_ce_1: 0.0001366  loss_mask_1: 0.1193  loss_dice_1: 0.1756  loss_ce_2: 0.0001433  loss_mask_2: 0.1149  loss_dice_2: 0.1743  loss_ce_3: 0.000146  loss_mask_3: 0.1156  loss_dice_3: 0.1738  loss_ce_4: 0.0001605  loss_mask_4: 0.1144  loss_dice_4: 0.1734  loss_ce_5: 0.0001324  loss_mask_5: 0.1162  loss_dice_5: 0.1726  loss_ce_6: 9.298e-05  loss_mask_6: 0.114  loss_dice_6: 0.1689  loss_ce_7: 9.444e-05  loss_mask_7: 0.1151  loss_dice_7: 0.1727  loss_ce_8: 0.0001299  loss_mask_8: 0.1145  loss_dice_8: 0.1678  time: 0.6811  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:53:30] d2.utils.events INFO:  eta: 4:35:03  iter: 14579  total_loss: 3.01  loss_ce: 0.0001006  loss_mask: 0.1161  loss_dice: 0.1748  loss_ce_0: 0.1282  loss_mask_0: 0.1158  loss_dice_0: 0.1711  loss_ce_1: 0.0001199  loss_mask_1: 0.1201  loss_dice_1: 0.1722  loss_ce_2: 0.0001233  loss_mask_2: 0.1169  loss_dice_2: 0.1703  loss_ce_3: 0.0001273  loss_mask_3: 0.1185  loss_dice_3: 0.1825  loss_ce_4: 0.0001428  loss_mask_4: 0.1174  loss_dice_4: 0.1764  loss_ce_5: 0.0001105  loss_mask_5: 0.1156  loss_dice_5: 0.1763  loss_ce_6: 0.0001154  loss_mask_6: 0.1171  loss_dice_6: 0.1644  loss_ce_7: 8.872e-05  loss_mask_7: 0.119  loss_dice_7: 0.1736  loss_ce_8: 0.0001177  loss_mask_8: 0.1198  loss_dice_8: 0.175  time: 0.6812  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:53:45] d2.utils.events INFO:  eta: 4:34:07  iter: 14599  total_loss: 3.11  loss_ce: 8.486e-05  loss_mask: 0.116  loss_dice: 0.1782  loss_ce_0: 0.1272  loss_mask_0: 0.1166  loss_dice_0: 0.1761  loss_ce_1: 0.0001397  loss_mask_1: 0.1174  loss_dice_1: 0.1794  loss_ce_2: 0.000137  loss_mask_2: 0.115  loss_dice_2: 0.1777  loss_ce_3: 0.0001346  loss_mask_3: 0.1143  loss_dice_3: 0.173  loss_ce_4: 0.0001269  loss_mask_4: 0.1182  loss_dice_4: 0.1798  loss_ce_5: 0.0001249  loss_mask_5: 0.1208  loss_dice_5: 0.1818  loss_ce_6: 0.0001113  loss_mask_6: 0.1188  loss_dice_6: 0.1793  loss_ce_7: 8.105e-05  loss_mask_7: 0.1157  loss_dice_7: 0.1755  loss_ce_8: 0.0001097  loss_mask_8: 0.1157  loss_dice_8: 0.1767  time: 0.6814  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:54:01] d2.utils.events INFO:  eta: 4:33:18  iter: 14619  total_loss: 2.986  loss_ce: 8.518e-05  loss_mask: 0.1173  loss_dice: 0.1705  loss_ce_0: 0.1257  loss_mask_0: 0.1122  loss_dice_0: 0.1669  loss_ce_1: 0.0001191  loss_mask_1: 0.117  loss_dice_1: 0.1735  loss_ce_2: 0.0001124  loss_mask_2: 0.1166  loss_dice_2: 0.1715  loss_ce_3: 0.0001098  loss_mask_3: 0.1184  loss_dice_3: 0.1644  loss_ce_4: 0.0001216  loss_mask_4: 0.1176  loss_dice_4: 0.172  loss_ce_5: 9.977e-05  loss_mask_5: 0.1177  loss_dice_5: 0.1675  loss_ce_6: 0.0001064  loss_mask_6: 0.119  loss_dice_6: 0.1703  loss_ce_7: 7.95e-05  loss_mask_7: 0.1138  loss_dice_7: 0.168  loss_ce_8: 0.0001108  loss_mask_8: 0.1191  loss_dice_8: 0.17  time: 0.6815  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:54:17] d2.utils.events INFO:  eta: 4:32:51  iter: 14639  total_loss: 2.94  loss_ce: 6.719e-05  loss_mask: 0.1147  loss_dice: 0.168  loss_ce_0: 0.1261  loss_mask_0: 0.1168  loss_dice_0: 0.165  loss_ce_1: 0.0001152  loss_mask_1: 0.1105  loss_dice_1: 0.1601  loss_ce_2: 0.0001162  loss_mask_2: 0.115  loss_dice_2: 0.1656  loss_ce_3: 0.0001099  loss_mask_3: 0.1112  loss_dice_3: 0.1659  loss_ce_4: 0.0001227  loss_mask_4: 0.1137  loss_dice_4: 0.1639  loss_ce_5: 0.0001181  loss_mask_5: 0.1147  loss_dice_5: 0.17  loss_ce_6: 9.151e-05  loss_mask_6: 0.1156  loss_dice_6: 0.1619  loss_ce_7: 8.717e-05  loss_mask_7: 0.1172  loss_dice_7: 0.1656  loss_ce_8: 0.0001051  loss_mask_8: 0.1128  loss_dice_8: 0.162  time: 0.6817  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:54:33] d2.utils.events INFO:  eta: 4:32:24  iter: 14659  total_loss: 2.97  loss_ce: 6.566e-05  loss_mask: 0.1142  loss_dice: 0.1626  loss_ce_0: 0.1261  loss_mask_0: 0.1157  loss_dice_0: 0.1676  loss_ce_1: 0.0001025  loss_mask_1: 0.1147  loss_dice_1: 0.1692  loss_ce_2: 0.0001081  loss_mask_2: 0.117  loss_dice_2: 0.1622  loss_ce_3: 0.0001024  loss_mask_3: 0.1113  loss_dice_3: 0.166  loss_ce_4: 0.0001087  loss_mask_4: 0.1173  loss_dice_4: 0.1682  loss_ce_5: 9.598e-05  loss_mask_5: 0.115  loss_dice_5: 0.1663  loss_ce_6: 7.287e-05  loss_mask_6: 0.1154  loss_dice_6: 0.1619  loss_ce_7: 7.695e-05  loss_mask_7: 0.1148  loss_dice_7: 0.1645  loss_ce_8: 9.29e-05  loss_mask_8: 0.1119  loss_dice_8: 0.1592  time: 0.6818  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:54:49] d2.utils.events INFO:  eta: 4:31:59  iter: 14679  total_loss: 3.036  loss_ce: 9.566e-05  loss_mask: 0.116  loss_dice: 0.169  loss_ce_0: 0.1309  loss_mask_0: 0.1171  loss_dice_0: 0.1762  loss_ce_1: 0.0001372  loss_mask_1: 0.1151  loss_dice_1: 0.1722  loss_ce_2: 0.0001273  loss_mask_2: 0.1143  loss_dice_2: 0.1665  loss_ce_3: 0.0001328  loss_mask_3: 0.1164  loss_dice_3: 0.1712  loss_ce_4: 9.745e-05  loss_mask_4: 0.1154  loss_dice_4: 0.1732  loss_ce_5: 0.0001568  loss_mask_5: 0.1163  loss_dice_5: 0.1679  loss_ce_6: 9.594e-05  loss_mask_6: 0.1129  loss_dice_6: 0.1613  loss_ce_7: 0.0001057  loss_mask_7: 0.117  loss_dice_7: 0.167  loss_ce_8: 0.0001236  loss_mask_8: 0.1129  loss_dice_8: 0.1724  time: 0.6820  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:55:04] d2.utils.events INFO:  eta: 4:31:24  iter: 14699  total_loss: 3.093  loss_ce: 6.544e-05  loss_mask: 0.1148  loss_dice: 0.181  loss_ce_0: 0.1299  loss_mask_0: 0.1124  loss_dice_0: 0.1815  loss_ce_1: 0.0001661  loss_mask_1: 0.1142  loss_dice_1: 0.1774  loss_ce_2: 0.0001297  loss_mask_2: 0.1119  loss_dice_2: 0.1823  loss_ce_3: 0.0001326  loss_mask_3: 0.1137  loss_dice_3: 0.1819  loss_ce_4: 9.511e-05  loss_mask_4: 0.1163  loss_dice_4: 0.1834  loss_ce_5: 0.0001383  loss_mask_5: 0.1138  loss_dice_5: 0.1735  loss_ce_6: 0.0001081  loss_mask_6: 0.1147  loss_dice_6: 0.18  loss_ce_7: 9.526e-05  loss_mask_7: 0.1163  loss_dice_7: 0.182  loss_ce_8: 9.753e-05  loss_mask_8: 0.1093  loss_dice_8: 0.1731  time: 0.6821  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:55:20] d2.utils.events INFO:  eta: 4:30:41  iter: 14719  total_loss: 2.985  loss_ce: 8.72e-05  loss_mask: 0.1145  loss_dice: 0.1644  loss_ce_0: 0.1313  loss_mask_0: 0.1188  loss_dice_0: 0.1707  loss_ce_1: 0.0001217  loss_mask_1: 0.1158  loss_dice_1: 0.1706  loss_ce_2: 0.0001273  loss_mask_2: 0.1153  loss_dice_2: 0.1707  loss_ce_3: 0.0001419  loss_mask_3: 0.1143  loss_dice_3: 0.1709  loss_ce_4: 0.0001494  loss_mask_4: 0.1155  loss_dice_4: 0.1722  loss_ce_5: 0.0001449  loss_mask_5: 0.114  loss_dice_5: 0.1677  loss_ce_6: 0.0001027  loss_mask_6: 0.1144  loss_dice_6: 0.169  loss_ce_7: 7.865e-05  loss_mask_7: 0.1148  loss_dice_7: 0.1741  loss_ce_8: 9.982e-05  loss_mask_8: 0.1173  loss_dice_8: 0.1732  time: 0.6822  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:55:36] d2.utils.events INFO:  eta: 4:29:54  iter: 14739  total_loss: 3.047  loss_ce: 9.083e-05  loss_mask: 0.1121  loss_dice: 0.1651  loss_ce_0: 0.13  loss_mask_0: 0.1195  loss_dice_0: 0.1743  loss_ce_1: 0.0001725  loss_mask_1: 0.116  loss_dice_1: 0.17  loss_ce_2: 0.0001391  loss_mask_2: 0.1187  loss_dice_2: 0.1748  loss_ce_3: 0.0001705  loss_mask_3: 0.1216  loss_dice_3: 0.1702  loss_ce_4: 0.0001641  loss_mask_4: 0.1202  loss_dice_4: 0.1715  loss_ce_5: 0.0001575  loss_mask_5: 0.1188  loss_dice_5: 0.1643  loss_ce_6: 0.00012  loss_mask_6: 0.1178  loss_dice_6: 0.1715  loss_ce_7: 9.548e-05  loss_mask_7: 0.1166  loss_dice_7: 0.1689  loss_ce_8: 0.0001089  loss_mask_8: 0.1191  loss_dice_8: 0.1674  time: 0.6824  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:55:52] d2.utils.events INFO:  eta: 4:29:14  iter: 14759  total_loss: 2.98  loss_ce: 0.0001014  loss_mask: 0.1228  loss_dice: 0.1652  loss_ce_0: 0.1263  loss_mask_0: 0.12  loss_dice_0: 0.1683  loss_ce_1: 0.0002116  loss_mask_1: 0.1203  loss_dice_1: 0.1666  loss_ce_2: 0.0001515  loss_mask_2: 0.1194  loss_dice_2: 0.1619  loss_ce_3: 0.0001869  loss_mask_3: 0.1244  loss_dice_3: 0.1688  loss_ce_4: 0.0001902  loss_mask_4: 0.121  loss_dice_4: 0.1687  loss_ce_5: 0.000159  loss_mask_5: 0.1228  loss_dice_5: 0.1649  loss_ce_6: 0.0001279  loss_mask_6: 0.1194  loss_dice_6: 0.1628  loss_ce_7: 0.000126  loss_mask_7: 0.121  loss_dice_7: 0.1649  loss_ce_8: 0.0001525  loss_mask_8: 0.1254  loss_dice_8: 0.164  time: 0.6825  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:56:08] d2.utils.events INFO:  eta: 4:28:42  iter: 14779  total_loss: 2.816  loss_ce: 8.408e-05  loss_mask: 0.1092  loss_dice: 0.1572  loss_ce_0: 0.1294  loss_mask_0: 0.1063  loss_dice_0: 0.1555  loss_ce_1: 0.0001951  loss_mask_1: 0.108  loss_dice_1: 0.163  loss_ce_2: 0.0001271  loss_mask_2: 0.1101  loss_dice_2: 0.1556  loss_ce_3: 0.0001307  loss_mask_3: 0.1141  loss_dice_3: 0.1615  loss_ce_4: 0.0001507  loss_mask_4: 0.1144  loss_dice_4: 0.1616  loss_ce_5: 0.0001231  loss_mask_5: 0.1058  loss_dice_5: 0.1551  loss_ce_6: 9.508e-05  loss_mask_6: 0.1085  loss_dice_6: 0.158  loss_ce_7: 0.0001023  loss_mask_7: 0.1095  loss_dice_7: 0.161  loss_ce_8: 0.0001098  loss_mask_8: 0.1117  loss_dice_8: 0.158  time: 0.6827  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:56:23] d2.utils.events INFO:  eta: 4:28:07  iter: 14799  total_loss: 2.895  loss_ce: 0.0001666  loss_mask: 0.1102  loss_dice: 0.1651  loss_ce_0: 0.1241  loss_mask_0: 0.1169  loss_dice_0: 0.1658  loss_ce_1: 0.0002893  loss_mask_1: 0.1126  loss_dice_1: 0.168  loss_ce_2: 0.0001634  loss_mask_2: 0.1119  loss_dice_2: 0.1615  loss_ce_3: 0.0001628  loss_mask_3: 0.1137  loss_dice_3: 0.1661  loss_ce_4: 0.000136  loss_mask_4: 0.1119  loss_dice_4: 0.1664  loss_ce_5: 0.0002162  loss_mask_5: 0.1113  loss_dice_5: 0.164  loss_ce_6: 0.0001561  loss_mask_6: 0.1139  loss_dice_6: 0.1642  loss_ce_7: 0.0001717  loss_mask_7: 0.1156  loss_dice_7: 0.1641  loss_ce_8: 0.0001724  loss_mask_8: 0.1132  loss_dice_8: 0.1663  time: 0.6828  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:56:39] d2.utils.events INFO:  eta: 4:27:38  iter: 14819  total_loss: 2.895  loss_ce: 7.707e-05  loss_mask: 0.1137  loss_dice: 0.1698  loss_ce_0: 0.1248  loss_mask_0: 0.1116  loss_dice_0: 0.1723  loss_ce_1: 0.0001378  loss_mask_1: 0.1164  loss_dice_1: 0.1675  loss_ce_2: 0.0001196  loss_mask_2: 0.1123  loss_dice_2: 0.1724  loss_ce_3: 0.0001087  loss_mask_3: 0.1124  loss_dice_3: 0.1673  loss_ce_4: 0.0001207  loss_mask_4: 0.1138  loss_dice_4: 0.1683  loss_ce_5: 0.0001057  loss_mask_5: 0.1137  loss_dice_5: 0.1699  loss_ce_6: 7.586e-05  loss_mask_6: 0.1134  loss_dice_6: 0.1646  loss_ce_7: 9.738e-05  loss_mask_7: 0.1156  loss_dice_7: 0.1667  loss_ce_8: 0.0001477  loss_mask_8: 0.1124  loss_dice_8: 0.1685  time: 0.6830  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:56:55] d2.utils.events INFO:  eta: 4:27:04  iter: 14839  total_loss: 3.086  loss_ce: 7.493e-05  loss_mask: 0.1181  loss_dice: 0.1775  loss_ce_0: 0.1294  loss_mask_0: 0.1179  loss_dice_0: 0.1802  loss_ce_1: 0.0001183  loss_mask_1: 0.1167  loss_dice_1: 0.1813  loss_ce_2: 0.0001136  loss_mask_2: 0.1168  loss_dice_2: 0.182  loss_ce_3: 0.0001098  loss_mask_3: 0.1192  loss_dice_3: 0.1882  loss_ce_4: 0.0001095  loss_mask_4: 0.1185  loss_dice_4: 0.1832  loss_ce_5: 9.691e-05  loss_mask_5: 0.1171  loss_dice_5: 0.1715  loss_ce_6: 7.509e-05  loss_mask_6: 0.1188  loss_dice_6: 0.1802  loss_ce_7: 6.957e-05  loss_mask_7: 0.119  loss_dice_7: 0.1868  loss_ce_8: 8.708e-05  loss_mask_8: 0.1201  loss_dice_8: 0.1767  time: 0.6831  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:57:11] d2.utils.events INFO:  eta: 4:26:22  iter: 14859  total_loss: 3.053  loss_ce: 7.829e-05  loss_mask: 0.1176  loss_dice: 0.1767  loss_ce_0: 0.1239  loss_mask_0: 0.1124  loss_dice_0: 0.1807  loss_ce_1: 0.0001342  loss_mask_1: 0.1173  loss_dice_1: 0.1781  loss_ce_2: 0.0001173  loss_mask_2: 0.1156  loss_dice_2: 0.1792  loss_ce_3: 0.0001169  loss_mask_3: 0.1149  loss_dice_3: 0.1842  loss_ce_4: 0.0001101  loss_mask_4: 0.1126  loss_dice_4: 0.1762  loss_ce_5: 0.0001047  loss_mask_5: 0.1122  loss_dice_5: 0.1778  loss_ce_6: 8.211e-05  loss_mask_6: 0.1128  loss_dice_6: 0.1725  loss_ce_7: 9.988e-05  loss_mask_7: 0.1203  loss_dice_7: 0.1776  loss_ce_8: 0.0001357  loss_mask_8: 0.1123  loss_dice_8: 0.1766  time: 0.6832  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:57:27] d2.utils.events INFO:  eta: 4:25:36  iter: 14879  total_loss: 2.988  loss_ce: 0.0002092  loss_mask: 0.1134  loss_dice: 0.1766  loss_ce_0: 0.1334  loss_mask_0: 0.1158  loss_dice_0: 0.1755  loss_ce_1: 0.0004326  loss_mask_1: 0.1127  loss_dice_1: 0.1681  loss_ce_2: 0.0005652  loss_mask_2: 0.1095  loss_dice_2: 0.1696  loss_ce_3: 0.001812  loss_mask_3: 0.1119  loss_dice_3: 0.1644  loss_ce_4: 0.0004082  loss_mask_4: 0.1132  loss_dice_4: 0.1731  loss_ce_5: 0.001066  loss_mask_5: 0.1139  loss_dice_5: 0.1681  loss_ce_6: 0.0005978  loss_mask_6: 0.1169  loss_dice_6: 0.1748  loss_ce_7: 0.0006873  loss_mask_7: 0.1129  loss_dice_7: 0.1709  loss_ce_8: 0.0001814  loss_mask_8: 0.1147  loss_dice_8: 0.1737  time: 0.6834  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:57:42] d2.utils.events INFO:  eta: 4:24:46  iter: 14899  total_loss: 3.126  loss_ce: 0.0003368  loss_mask: 0.1211  loss_dice: 0.1699  loss_ce_0: 0.1197  loss_mask_0: 0.1217  loss_dice_0: 0.1846  loss_ce_1: 0.0004413  loss_mask_1: 0.127  loss_dice_1: 0.181  loss_ce_2: 0.0007314  loss_mask_2: 0.1249  loss_dice_2: 0.1766  loss_ce_3: 0.0005477  loss_mask_3: 0.1219  loss_dice_3: 0.1779  loss_ce_4: 0.0007046  loss_mask_4: 0.1218  loss_dice_4: 0.1773  loss_ce_5: 0.001355  loss_mask_5: 0.1212  loss_dice_5: 0.1752  loss_ce_6: 0.001123  loss_mask_6: 0.1207  loss_dice_6: 0.1754  loss_ce_7: 0.0006356  loss_mask_7: 0.1188  loss_dice_7: 0.1761  loss_ce_8: 0.000383  loss_mask_8: 0.1216  loss_dice_8: 0.1784  time: 0.6835  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:57:58] d2.utils.events INFO:  eta: 4:24:19  iter: 14919  total_loss: 2.876  loss_ce: 0.0003558  loss_mask: 0.1116  loss_dice: 0.1671  loss_ce_0: 0.1299  loss_mask_0: 0.1117  loss_dice_0: 0.1647  loss_ce_1: 0.0003232  loss_mask_1: 0.1147  loss_dice_1: 0.1653  loss_ce_2: 0.0004408  loss_mask_2: 0.1141  loss_dice_2: 0.1609  loss_ce_3: 0.000306  loss_mask_3: 0.118  loss_dice_3: 0.1699  loss_ce_4: 0.0004709  loss_mask_4: 0.1151  loss_dice_4: 0.1719  loss_ce_5: 0.0004832  loss_mask_5: 0.1146  loss_dice_5: 0.1697  loss_ce_6: 0.0004554  loss_mask_6: 0.1144  loss_dice_6: 0.1662  loss_ce_7: 0.0003065  loss_mask_7: 0.113  loss_dice_7: 0.1623  loss_ce_8: 0.0003653  loss_mask_8: 0.1127  loss_dice_8: 0.1696  time: 0.6836  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:58:13] d2.utils.events INFO:  eta: 4:23:52  iter: 14939  total_loss: 3.037  loss_ce: 0.0002557  loss_mask: 0.1183  loss_dice: 0.1766  loss_ce_0: 0.126  loss_mask_0: 0.1201  loss_dice_0: 0.1725  loss_ce_1: 0.00029  loss_mask_1: 0.1199  loss_dice_1: 0.1773  loss_ce_2: 0.0003197  loss_mask_2: 0.1176  loss_dice_2: 0.1794  loss_ce_3: 0.0002351  loss_mask_3: 0.1177  loss_dice_3: 0.1787  loss_ce_4: 0.0003354  loss_mask_4: 0.1193  loss_dice_4: 0.1783  loss_ce_5: 0.0002736  loss_mask_5: 0.1165  loss_dice_5: 0.1756  loss_ce_6: 0.0002744  loss_mask_6: 0.1185  loss_dice_6: 0.1746  loss_ce_7: 0.0002106  loss_mask_7: 0.1158  loss_dice_7: 0.1766  loss_ce_8: 0.0003072  loss_mask_8: 0.1206  loss_dice_8: 0.1767  time: 0.6838  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 19:58:29] d2.utils.events INFO:  eta: 4:23:35  iter: 14959  total_loss: 2.943  loss_ce: 0.0003258  loss_mask: 0.1122  loss_dice: 0.1725  loss_ce_0: 0.1264  loss_mask_0: 0.1132  loss_dice_0: 0.172  loss_ce_1: 0.0002137  loss_mask_1: 0.1133  loss_dice_1: 0.1661  loss_ce_2: 0.0003045  loss_mask_2: 0.1148  loss_dice_2: 0.1731  loss_ce_3: 0.0002277  loss_mask_3: 0.1127  loss_dice_3: 0.175  loss_ce_4: 0.0003409  loss_mask_4: 0.1223  loss_dice_4: 0.171  loss_ce_5: 0.0002235  loss_mask_5: 0.1136  loss_dice_5: 0.1679  loss_ce_6: 0.0002205  loss_mask_6: 0.1161  loss_dice_6: 0.1683  loss_ce_7: 0.0001939  loss_mask_7: 0.1165  loss_dice_7: 0.176  loss_ce_8: 0.0004004  loss_mask_8: 0.1136  loss_dice_8: 0.1685  time: 0.6839  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 19:58:45] d2.utils.events INFO:  eta: 4:23:19  iter: 14979  total_loss: 3.024  loss_ce: 0.0001814  loss_mask: 0.1135  loss_dice: 0.1688  loss_ce_0: 0.1243  loss_mask_0: 0.1179  loss_dice_0: 0.1741  loss_ce_1: 0.0002053  loss_mask_1: 0.1211  loss_dice_1: 0.1739  loss_ce_2: 0.0002499  loss_mask_2: 0.1181  loss_dice_2: 0.1696  loss_ce_3: 0.0001892  loss_mask_3: 0.1191  loss_dice_3: 0.171  loss_ce_4: 0.0002242  loss_mask_4: 0.1181  loss_dice_4: 0.1724  loss_ce_5: 0.0001966  loss_mask_5: 0.1169  loss_dice_5: 0.166  loss_ce_6: 0.0001723  loss_mask_6: 0.1201  loss_dice_6: 0.1708  loss_ce_7: 0.000165  loss_mask_7: 0.1184  loss_dice_7: 0.1698  loss_ce_8: 0.0002224  loss_mask_8: 0.1179  loss_dice_8: 0.17  time: 0.6841  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 19:59:01] fvcore.common.checkpoint INFO: Saving checkpoint to ./R101_overlap/model_0014999.pth
[08/01 19:59:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(256, 256), max_size=256, sample_style='choice')]
[08/01 19:59:01] d2.data.common INFO: Serializing 535 elements to byte tensors and concatenating them all ...
[08/01 19:59:01] d2.data.common INFO: Serialized dataset takes 0.22 MiB
[08/01 19:59:02] d2.evaluation.evaluator INFO: Start inference on 535 batches
[08/01 19:59:26] d2.evaluation.evaluator INFO: Inference done 11/535. Dataloading: 0.0006 s/iter. Inference: 1.1775 s/iter. Eval: 1.0105 s/iter. Total: 2.1886 s/iter. ETA=0:19:06
[08/01 19:59:33] d2.evaluation.evaluator INFO: Inference done 14/535. Dataloading: 0.0007 s/iter. Inference: 1.1842 s/iter. Eval: 1.0017 s/iter. Total: 2.1866 s/iter. ETA=0:18:59
[08/01 19:59:39] d2.evaluation.evaluator INFO: Inference done 17/535. Dataloading: 0.0007 s/iter. Inference: 1.1847 s/iter. Eval: 1.0031 s/iter. Total: 2.1885 s/iter. ETA=0:18:53
[08/01 19:59:46] d2.evaluation.evaluator INFO: Inference done 20/535. Dataloading: 0.0007 s/iter. Inference: 1.1816 s/iter. Eval: 1.0084 s/iter. Total: 2.1908 s/iter. ETA=0:18:48
[08/01 19:59:52] d2.evaluation.evaluator INFO: Inference done 23/535. Dataloading: 0.0007 s/iter. Inference: 1.1829 s/iter. Eval: 1.0067 s/iter. Total: 2.1904 s/iter. ETA=0:18:41
[08/01 19:59:59] d2.evaluation.evaluator INFO: Inference done 26/535. Dataloading: 0.0007 s/iter. Inference: 1.1789 s/iter. Eval: 1.0021 s/iter. Total: 2.1818 s/iter. ETA=0:18:30
[08/01 20:00:05] d2.evaluation.evaluator INFO: Inference done 29/535. Dataloading: 0.0007 s/iter. Inference: 1.1797 s/iter. Eval: 0.9998 s/iter. Total: 2.1802 s/iter. ETA=0:18:23
[08/01 20:00:12] d2.evaluation.evaluator INFO: Inference done 32/535. Dataloading: 0.0007 s/iter. Inference: 1.1810 s/iter. Eval: 0.9995 s/iter. Total: 2.1813 s/iter. ETA=0:18:17
[08/01 20:00:18] d2.evaluation.evaluator INFO: Inference done 35/535. Dataloading: 0.0007 s/iter. Inference: 1.1804 s/iter. Eval: 1.0011 s/iter. Total: 2.1823 s/iter. ETA=0:18:11
[08/01 20:00:25] d2.evaluation.evaluator INFO: Inference done 38/535. Dataloading: 0.0009 s/iter. Inference: 1.1770 s/iter. Eval: 1.0025 s/iter. Total: 2.1806 s/iter. ETA=0:18:03
[08/01 20:00:32] d2.evaluation.evaluator INFO: Inference done 41/535. Dataloading: 0.0009 s/iter. Inference: 1.1800 s/iter. Eval: 1.0032 s/iter. Total: 2.1842 s/iter. ETA=0:17:59
[08/01 20:00:38] d2.evaluation.evaluator INFO: Inference done 44/535. Dataloading: 0.0009 s/iter. Inference: 1.1812 s/iter. Eval: 1.0027 s/iter. Total: 2.1849 s/iter. ETA=0:17:52
[08/01 20:00:45] d2.evaluation.evaluator INFO: Inference done 47/535. Dataloading: 0.0009 s/iter. Inference: 1.1767 s/iter. Eval: 1.0025 s/iter. Total: 2.1802 s/iter. ETA=0:17:43
[08/01 20:00:51] d2.evaluation.evaluator INFO: Inference done 50/535. Dataloading: 0.0009 s/iter. Inference: 1.1784 s/iter. Eval: 1.0015 s/iter. Total: 2.1809 s/iter. ETA=0:17:37
[08/01 20:00:58] d2.evaluation.evaluator INFO: Inference done 53/535. Dataloading: 0.0009 s/iter. Inference: 1.1852 s/iter. Eval: 1.0000 s/iter. Total: 2.1862 s/iter. ETA=0:17:33
[08/01 20:01:05] d2.evaluation.evaluator INFO: Inference done 56/535. Dataloading: 0.0009 s/iter. Inference: 1.1913 s/iter. Eval: 0.9983 s/iter. Total: 2.1906 s/iter. ETA=0:17:29
[08/01 20:01:11] d2.evaluation.evaluator INFO: Inference done 59/535. Dataloading: 0.0009 s/iter. Inference: 1.1962 s/iter. Eval: 0.9969 s/iter. Total: 2.1941 s/iter. ETA=0:17:24
[08/01 20:01:18] d2.evaluation.evaluator INFO: Inference done 62/535. Dataloading: 0.0008 s/iter. Inference: 1.2023 s/iter. Eval: 0.9958 s/iter. Total: 2.1991 s/iter. ETA=0:17:20
[08/01 20:01:25] d2.evaluation.evaluator INFO: Inference done 65/535. Dataloading: 0.0008 s/iter. Inference: 1.2038 s/iter. Eval: 0.9948 s/iter. Total: 2.1995 s/iter. ETA=0:17:13
[08/01 20:01:32] d2.evaluation.evaluator INFO: Inference done 68/535. Dataloading: 0.0008 s/iter. Inference: 1.2090 s/iter. Eval: 0.9930 s/iter. Total: 2.2030 s/iter. ETA=0:17:08
[08/01 20:01:39] d2.evaluation.evaluator INFO: Inference done 71/535. Dataloading: 0.0009 s/iter. Inference: 1.2110 s/iter. Eval: 0.9934 s/iter. Total: 2.2053 s/iter. ETA=0:17:03
[08/01 20:01:45] d2.evaluation.evaluator INFO: Inference done 74/535. Dataloading: 0.0008 s/iter. Inference: 1.2142 s/iter. Eval: 0.9930 s/iter. Total: 2.2082 s/iter. ETA=0:16:57
[08/01 20:01:52] d2.evaluation.evaluator INFO: Inference done 77/535. Dataloading: 0.0008 s/iter. Inference: 1.2195 s/iter. Eval: 0.9928 s/iter. Total: 2.2132 s/iter. ETA=0:16:53
[08/01 20:01:59] d2.evaluation.evaluator INFO: Inference done 80/535. Dataloading: 0.0008 s/iter. Inference: 1.2208 s/iter. Eval: 0.9930 s/iter. Total: 2.2148 s/iter. ETA=0:16:47
[08/01 20:02:06] d2.evaluation.evaluator INFO: Inference done 83/535. Dataloading: 0.0008 s/iter. Inference: 1.2237 s/iter. Eval: 0.9922 s/iter. Total: 2.2168 s/iter. ETA=0:16:41
[08/01 20:02:13] d2.evaluation.evaluator INFO: Inference done 86/535. Dataloading: 0.0008 s/iter. Inference: 1.2255 s/iter. Eval: 0.9913 s/iter. Total: 2.2177 s/iter. ETA=0:16:35
[08/01 20:02:19] d2.evaluation.evaluator INFO: Inference done 89/535. Dataloading: 0.0008 s/iter. Inference: 1.2280 s/iter. Eval: 0.9914 s/iter. Total: 2.2203 s/iter. ETA=0:16:30
[08/01 20:02:26] d2.evaluation.evaluator INFO: Inference done 92/535. Dataloading: 0.0008 s/iter. Inference: 1.2307 s/iter. Eval: 0.9929 s/iter. Total: 2.2246 s/iter. ETA=0:16:25
[08/01 20:02:33] d2.evaluation.evaluator INFO: Inference done 95/535. Dataloading: 0.0008 s/iter. Inference: 1.2317 s/iter. Eval: 0.9936 s/iter. Total: 2.2263 s/iter. ETA=0:16:19
[08/01 20:02:40] d2.evaluation.evaluator INFO: Inference done 98/535. Dataloading: 0.0008 s/iter. Inference: 1.2337 s/iter. Eval: 0.9919 s/iter. Total: 2.2266 s/iter. ETA=0:16:13
[08/01 20:02:47] d2.evaluation.evaluator INFO: Inference done 101/535. Dataloading: 0.0008 s/iter. Inference: 1.2354 s/iter. Eval: 0.9911 s/iter. Total: 2.2274 s/iter. ETA=0:16:06
[08/01 20:02:53] d2.evaluation.evaluator INFO: Inference done 104/535. Dataloading: 0.0008 s/iter. Inference: 1.2370 s/iter. Eval: 0.9895 s/iter. Total: 2.2274 s/iter. ETA=0:16:00
[08/01 20:03:00] d2.evaluation.evaluator INFO: Inference done 107/535. Dataloading: 0.0008 s/iter. Inference: 1.2391 s/iter. Eval: 0.9884 s/iter. Total: 2.2285 s/iter. ETA=0:15:53
[08/01 20:03:07] d2.evaluation.evaluator INFO: Inference done 110/535. Dataloading: 0.0008 s/iter. Inference: 1.2399 s/iter. Eval: 0.9876 s/iter. Total: 2.2284 s/iter. ETA=0:15:47
[08/01 20:03:14] d2.evaluation.evaluator INFO: Inference done 113/535. Dataloading: 0.0008 s/iter. Inference: 1.2414 s/iter. Eval: 0.9865 s/iter. Total: 2.2288 s/iter. ETA=0:15:40
[08/01 20:03:20] d2.evaluation.evaluator INFO: Inference done 116/535. Dataloading: 0.0008 s/iter. Inference: 1.2430 s/iter. Eval: 0.9854 s/iter. Total: 2.2293 s/iter. ETA=0:15:34
[08/01 20:03:27] d2.evaluation.evaluator INFO: Inference done 119/535. Dataloading: 0.0008 s/iter. Inference: 1.2437 s/iter. Eval: 0.9839 s/iter. Total: 2.2285 s/iter. ETA=0:15:27
[08/01 20:03:34] d2.evaluation.evaluator INFO: Inference done 122/535. Dataloading: 0.0008 s/iter. Inference: 1.2448 s/iter. Eval: 0.9836 s/iter. Total: 2.2292 s/iter. ETA=0:15:20
[08/01 20:03:40] d2.evaluation.evaluator INFO: Inference done 125/535. Dataloading: 0.0008 s/iter. Inference: 1.2453 s/iter. Eval: 0.9829 s/iter. Total: 2.2291 s/iter. ETA=0:15:13
[08/01 20:03:47] d2.evaluation.evaluator INFO: Inference done 128/535. Dataloading: 0.0008 s/iter. Inference: 1.2465 s/iter. Eval: 0.9827 s/iter. Total: 2.2301 s/iter. ETA=0:15:07
[08/01 20:03:54] d2.evaluation.evaluator INFO: Inference done 131/535. Dataloading: 0.0008 s/iter. Inference: 1.2472 s/iter. Eval: 0.9818 s/iter. Total: 2.2299 s/iter. ETA=0:15:00
[08/01 20:04:01] d2.evaluation.evaluator INFO: Inference done 134/535. Dataloading: 0.0008 s/iter. Inference: 1.2486 s/iter. Eval: 0.9814 s/iter. Total: 2.2309 s/iter. ETA=0:14:54
[08/01 20:04:08] d2.evaluation.evaluator INFO: Inference done 137/535. Dataloading: 0.0008 s/iter. Inference: 1.2497 s/iter. Eval: 0.9811 s/iter. Total: 2.2316 s/iter. ETA=0:14:48
[08/01 20:04:14] d2.evaluation.evaluator INFO: Inference done 140/535. Dataloading: 0.0008 s/iter. Inference: 1.2507 s/iter. Eval: 0.9805 s/iter. Total: 2.2321 s/iter. ETA=0:14:41
[08/01 20:04:21] d2.evaluation.evaluator INFO: Inference done 143/535. Dataloading: 0.0008 s/iter. Inference: 1.2506 s/iter. Eval: 0.9804 s/iter. Total: 2.2319 s/iter. ETA=0:14:34
[08/01 20:04:28] d2.evaluation.evaluator INFO: Inference done 146/535. Dataloading: 0.0008 s/iter. Inference: 1.2514 s/iter. Eval: 0.9801 s/iter. Total: 2.2324 s/iter. ETA=0:14:28
[08/01 20:04:34] d2.evaluation.evaluator INFO: Inference done 149/535. Dataloading: 0.0008 s/iter. Inference: 1.2519 s/iter. Eval: 0.9800 s/iter. Total: 2.2328 s/iter. ETA=0:14:21
[08/01 20:04:41] d2.evaluation.evaluator INFO: Inference done 152/535. Dataloading: 0.0008 s/iter. Inference: 1.2524 s/iter. Eval: 0.9796 s/iter. Total: 2.2329 s/iter. ETA=0:14:15
[08/01 20:04:48] d2.evaluation.evaluator INFO: Inference done 155/535. Dataloading: 0.0008 s/iter. Inference: 1.2530 s/iter. Eval: 0.9795 s/iter. Total: 2.2333 s/iter. ETA=0:14:08
[08/01 20:04:55] d2.evaluation.evaluator INFO: Inference done 158/535. Dataloading: 0.0008 s/iter. Inference: 1.2543 s/iter. Eval: 0.9791 s/iter. Total: 2.2343 s/iter. ETA=0:14:02
[08/01 20:05:01] d2.evaluation.evaluator INFO: Inference done 161/535. Dataloading: 0.0008 s/iter. Inference: 1.2544 s/iter. Eval: 0.9786 s/iter. Total: 2.2339 s/iter. ETA=0:13:55
[08/01 20:05:08] d2.evaluation.evaluator INFO: Inference done 164/535. Dataloading: 0.0008 s/iter. Inference: 1.2552 s/iter. Eval: 0.9790 s/iter. Total: 2.2351 s/iter. ETA=0:13:49
[08/01 20:05:15] d2.evaluation.evaluator INFO: Inference done 167/535. Dataloading: 0.0008 s/iter. Inference: 1.2556 s/iter. Eval: 0.9783 s/iter. Total: 2.2348 s/iter. ETA=0:13:42
[08/01 20:05:22] d2.evaluation.evaluator INFO: Inference done 170/535. Dataloading: 0.0008 s/iter. Inference: 1.2571 s/iter. Eval: 0.9779 s/iter. Total: 2.2359 s/iter. ETA=0:13:36
[08/01 20:05:29] d2.evaluation.evaluator INFO: Inference done 173/535. Dataloading: 0.0008 s/iter. Inference: 1.2579 s/iter. Eval: 0.9776 s/iter. Total: 2.2363 s/iter. ETA=0:13:29
[08/01 20:05:35] d2.evaluation.evaluator INFO: Inference done 176/535. Dataloading: 0.0008 s/iter. Inference: 1.2581 s/iter. Eval: 0.9771 s/iter. Total: 2.2361 s/iter. ETA=0:13:22
[08/01 20:05:42] d2.evaluation.evaluator INFO: Inference done 179/535. Dataloading: 0.0008 s/iter. Inference: 1.2582 s/iter. Eval: 0.9768 s/iter. Total: 2.2359 s/iter. ETA=0:13:15
[08/01 20:05:49] d2.evaluation.evaluator INFO: Inference done 182/535. Dataloading: 0.0008 s/iter. Inference: 1.2596 s/iter. Eval: 0.9765 s/iter. Total: 2.2370 s/iter. ETA=0:13:09
[08/01 20:05:56] d2.evaluation.evaluator INFO: Inference done 185/535. Dataloading: 0.0008 s/iter. Inference: 1.2599 s/iter. Eval: 0.9762 s/iter. Total: 2.2369 s/iter. ETA=0:13:02
[08/01 20:06:02] d2.evaluation.evaluator INFO: Inference done 188/535. Dataloading: 0.0008 s/iter. Inference: 1.2606 s/iter. Eval: 0.9763 s/iter. Total: 2.2378 s/iter. ETA=0:12:56
[08/01 20:06:09] d2.evaluation.evaluator INFO: Inference done 191/535. Dataloading: 0.0008 s/iter. Inference: 1.2614 s/iter. Eval: 0.9761 s/iter. Total: 2.2384 s/iter. ETA=0:12:50
[08/01 20:06:16] d2.evaluation.evaluator INFO: Inference done 194/535. Dataloading: 0.0008 s/iter. Inference: 1.2620 s/iter. Eval: 0.9766 s/iter. Total: 2.2395 s/iter. ETA=0:12:43
[08/01 20:06:23] d2.evaluation.evaluator INFO: Inference done 197/535. Dataloading: 0.0008 s/iter. Inference: 1.2630 s/iter. Eval: 0.9769 s/iter. Total: 2.2407 s/iter. ETA=0:12:37
[08/01 20:06:30] d2.evaluation.evaluator INFO: Inference done 200/535. Dataloading: 0.0008 s/iter. Inference: 1.2630 s/iter. Eval: 0.9765 s/iter. Total: 2.2404 s/iter. ETA=0:12:30
[08/01 20:06:37] d2.evaluation.evaluator INFO: Inference done 203/535. Dataloading: 0.0008 s/iter. Inference: 1.2632 s/iter. Eval: 0.9768 s/iter. Total: 2.2409 s/iter. ETA=0:12:23
[08/01 20:06:44] d2.evaluation.evaluator INFO: Inference done 206/535. Dataloading: 0.0008 s/iter. Inference: 1.2640 s/iter. Eval: 0.9771 s/iter. Total: 2.2420 s/iter. ETA=0:12:17
[08/01 20:06:50] d2.evaluation.evaluator INFO: Inference done 209/535. Dataloading: 0.0008 s/iter. Inference: 1.2639 s/iter. Eval: 0.9772 s/iter. Total: 2.2419 s/iter. ETA=0:12:10
[08/01 20:06:57] d2.evaluation.evaluator INFO: Inference done 212/535. Dataloading: 0.0008 s/iter. Inference: 1.2644 s/iter. Eval: 0.9775 s/iter. Total: 2.2428 s/iter. ETA=0:12:04
[08/01 20:07:04] d2.evaluation.evaluator INFO: Inference done 215/535. Dataloading: 0.0008 s/iter. Inference: 1.2648 s/iter. Eval: 0.9776 s/iter. Total: 2.2433 s/iter. ETA=0:11:57
[08/01 20:07:11] d2.evaluation.evaluator INFO: Inference done 218/535. Dataloading: 0.0008 s/iter. Inference: 1.2644 s/iter. Eval: 0.9775 s/iter. Total: 2.2428 s/iter. ETA=0:11:50
[08/01 20:07:18] d2.evaluation.evaluator INFO: Inference done 221/535. Dataloading: 0.0008 s/iter. Inference: 1.2653 s/iter. Eval: 0.9779 s/iter. Total: 2.2440 s/iter. ETA=0:11:44
[08/01 20:07:24] d2.evaluation.evaluator INFO: Inference done 224/535. Dataloading: 0.0008 s/iter. Inference: 1.2652 s/iter. Eval: 0.9781 s/iter. Total: 2.2442 s/iter. ETA=0:11:37
[08/01 20:07:31] d2.evaluation.evaluator INFO: Inference done 227/535. Dataloading: 0.0008 s/iter. Inference: 1.2653 s/iter. Eval: 0.9778 s/iter. Total: 2.2440 s/iter. ETA=0:11:31
[08/01 20:07:38] d2.evaluation.evaluator INFO: Inference done 230/535. Dataloading: 0.0008 s/iter. Inference: 1.2652 s/iter. Eval: 0.9776 s/iter. Total: 2.2437 s/iter. ETA=0:11:24
[08/01 20:07:45] d2.evaluation.evaluator INFO: Inference done 233/535. Dataloading: 0.0008 s/iter. Inference: 1.2663 s/iter. Eval: 0.9775 s/iter. Total: 2.2447 s/iter. ETA=0:11:17
[08/01 20:07:51] d2.evaluation.evaluator INFO: Inference done 236/535. Dataloading: 0.0008 s/iter. Inference: 1.2662 s/iter. Eval: 0.9775 s/iter. Total: 2.2446 s/iter. ETA=0:11:11
[08/01 20:07:58] d2.evaluation.evaluator INFO: Inference done 239/535. Dataloading: 0.0008 s/iter. Inference: 1.2665 s/iter. Eval: 0.9774 s/iter. Total: 2.2448 s/iter. ETA=0:11:04
[08/01 20:08:05] d2.evaluation.evaluator INFO: Inference done 242/535. Dataloading: 0.0008 s/iter. Inference: 1.2671 s/iter. Eval: 0.9775 s/iter. Total: 2.2455 s/iter. ETA=0:10:57
[08/01 20:08:12] d2.evaluation.evaluator INFO: Inference done 245/535. Dataloading: 0.0008 s/iter. Inference: 1.2673 s/iter. Eval: 0.9773 s/iter. Total: 2.2456 s/iter. ETA=0:10:51
[08/01 20:08:19] d2.evaluation.evaluator INFO: Inference done 248/535. Dataloading: 0.0008 s/iter. Inference: 1.2678 s/iter. Eval: 0.9773 s/iter. Total: 2.2460 s/iter. ETA=0:10:44
[08/01 20:08:26] d2.evaluation.evaluator INFO: Inference done 251/535. Dataloading: 0.0008 s/iter. Inference: 1.2677 s/iter. Eval: 0.9778 s/iter. Total: 2.2464 s/iter. ETA=0:10:37
[08/01 20:08:33] d2.evaluation.evaluator INFO: Inference done 254/535. Dataloading: 0.0008 s/iter. Inference: 1.2680 s/iter. Eval: 0.9783 s/iter. Total: 2.2472 s/iter. ETA=0:10:31
[08/01 20:08:39] d2.evaluation.evaluator INFO: Inference done 257/535. Dataloading: 0.0008 s/iter. Inference: 1.2684 s/iter. Eval: 0.9788 s/iter. Total: 2.2481 s/iter. ETA=0:10:24
[08/01 20:08:46] d2.evaluation.evaluator INFO: Inference done 260/535. Dataloading: 0.0008 s/iter. Inference: 1.2689 s/iter. Eval: 0.9790 s/iter. Total: 2.2487 s/iter. ETA=0:10:18
[08/01 20:08:53] d2.evaluation.evaluator INFO: Inference done 263/535. Dataloading: 0.0008 s/iter. Inference: 1.2686 s/iter. Eval: 0.9792 s/iter. Total: 2.2488 s/iter. ETA=0:10:11
[08/01 20:09:00] d2.evaluation.evaluator INFO: Inference done 266/535. Dataloading: 0.0008 s/iter. Inference: 1.2695 s/iter. Eval: 0.9795 s/iter. Total: 2.2499 s/iter. ETA=0:10:05
[08/01 20:09:07] d2.evaluation.evaluator INFO: Inference done 269/535. Dataloading: 0.0008 s/iter. Inference: 1.2699 s/iter. Eval: 0.9800 s/iter. Total: 2.2508 s/iter. ETA=0:09:58
[08/01 20:09:14] d2.evaluation.evaluator INFO: Inference done 272/535. Dataloading: 0.0008 s/iter. Inference: 1.2703 s/iter. Eval: 0.9802 s/iter. Total: 2.2514 s/iter. ETA=0:09:52
[08/01 20:09:21] d2.evaluation.evaluator INFO: Inference done 275/535. Dataloading: 0.0008 s/iter. Inference: 1.2706 s/iter. Eval: 0.9807 s/iter. Total: 2.2522 s/iter. ETA=0:09:45
[08/01 20:09:28] d2.evaluation.evaluator INFO: Inference done 278/535. Dataloading: 0.0008 s/iter. Inference: 1.2712 s/iter. Eval: 0.9812 s/iter. Total: 2.2533 s/iter. ETA=0:09:39
[08/01 20:09:35] d2.evaluation.evaluator INFO: Inference done 281/535. Dataloading: 0.0008 s/iter. Inference: 1.2720 s/iter. Eval: 0.9816 s/iter. Total: 2.2545 s/iter. ETA=0:09:32
[08/01 20:09:42] d2.evaluation.evaluator INFO: Inference done 284/535. Dataloading: 0.0008 s/iter. Inference: 1.2724 s/iter. Eval: 0.9820 s/iter. Total: 2.2553 s/iter. ETA=0:09:26
[08/01 20:09:49] d2.evaluation.evaluator INFO: Inference done 287/535. Dataloading: 0.0008 s/iter. Inference: 1.2730 s/iter. Eval: 0.9823 s/iter. Total: 2.2563 s/iter. ETA=0:09:19
[08/01 20:09:56] d2.evaluation.evaluator INFO: Inference done 290/535. Dataloading: 0.0008 s/iter. Inference: 1.2733 s/iter. Eval: 0.9825 s/iter. Total: 2.2568 s/iter. ETA=0:09:12
[08/01 20:10:03] d2.evaluation.evaluator INFO: Inference done 293/535. Dataloading: 0.0008 s/iter. Inference: 1.2730 s/iter. Eval: 0.9824 s/iter. Total: 2.2563 s/iter. ETA=0:09:06
[08/01 20:10:10] d2.evaluation.evaluator INFO: Inference done 296/535. Dataloading: 0.0008 s/iter. Inference: 1.2732 s/iter. Eval: 0.9823 s/iter. Total: 2.2564 s/iter. ETA=0:08:59
[08/01 20:10:16] d2.evaluation.evaluator INFO: Inference done 299/535. Dataloading: 0.0008 s/iter. Inference: 1.2731 s/iter. Eval: 0.9821 s/iter. Total: 2.2561 s/iter. ETA=0:08:52
[08/01 20:10:23] d2.evaluation.evaluator INFO: Inference done 302/535. Dataloading: 0.0008 s/iter. Inference: 1.2728 s/iter. Eval: 0.9821 s/iter. Total: 2.2558 s/iter. ETA=0:08:45
[08/01 20:10:30] d2.evaluation.evaluator INFO: Inference done 305/535. Dataloading: 0.0008 s/iter. Inference: 1.2730 s/iter. Eval: 0.9819 s/iter. Total: 2.2558 s/iter. ETA=0:08:38
[08/01 20:10:36] d2.evaluation.evaluator INFO: Inference done 308/535. Dataloading: 0.0008 s/iter. Inference: 1.2732 s/iter. Eval: 0.9817 s/iter. Total: 2.2558 s/iter. ETA=0:08:32
[08/01 20:10:43] d2.evaluation.evaluator INFO: Inference done 311/535. Dataloading: 0.0008 s/iter. Inference: 1.2738 s/iter. Eval: 0.9816 s/iter. Total: 2.2562 s/iter. ETA=0:08:25
[08/01 20:10:50] d2.evaluation.evaluator INFO: Inference done 314/535. Dataloading: 0.0008 s/iter. Inference: 1.2738 s/iter. Eval: 0.9814 s/iter. Total: 2.2560 s/iter. ETA=0:08:18
[08/01 20:10:57] d2.evaluation.evaluator INFO: Inference done 317/535. Dataloading: 0.0008 s/iter. Inference: 1.2740 s/iter. Eval: 0.9810 s/iter. Total: 2.2558 s/iter. ETA=0:08:11
[08/01 20:11:03] d2.evaluation.evaluator INFO: Inference done 320/535. Dataloading: 0.0008 s/iter. Inference: 1.2738 s/iter. Eval: 0.9810 s/iter. Total: 2.2556 s/iter. ETA=0:08:04
[08/01 20:11:10] d2.evaluation.evaluator INFO: Inference done 323/535. Dataloading: 0.0008 s/iter. Inference: 1.2743 s/iter. Eval: 0.9806 s/iter. Total: 2.2558 s/iter. ETA=0:07:58
[08/01 20:11:17] d2.evaluation.evaluator INFO: Inference done 326/535. Dataloading: 0.0008 s/iter. Inference: 1.2742 s/iter. Eval: 0.9805 s/iter. Total: 2.2556 s/iter. ETA=0:07:51
[08/01 20:11:24] d2.evaluation.evaluator INFO: Inference done 329/535. Dataloading: 0.0008 s/iter. Inference: 1.2742 s/iter. Eval: 0.9804 s/iter. Total: 2.2555 s/iter. ETA=0:07:44
[08/01 20:11:30] d2.evaluation.evaluator INFO: Inference done 332/535. Dataloading: 0.0008 s/iter. Inference: 1.2742 s/iter. Eval: 0.9802 s/iter. Total: 2.2553 s/iter. ETA=0:07:37
[08/01 20:11:37] d2.evaluation.evaluator INFO: Inference done 335/535. Dataloading: 0.0008 s/iter. Inference: 1.2742 s/iter. Eval: 0.9800 s/iter. Total: 2.2551 s/iter. ETA=0:07:31
[08/01 20:11:44] d2.evaluation.evaluator INFO: Inference done 338/535. Dataloading: 0.0008 s/iter. Inference: 1.2739 s/iter. Eval: 0.9800 s/iter. Total: 2.2549 s/iter. ETA=0:07:24
[08/01 20:11:51] d2.evaluation.evaluator INFO: Inference done 341/535. Dataloading: 0.0008 s/iter. Inference: 1.2740 s/iter. Eval: 0.9798 s/iter. Total: 2.2547 s/iter. ETA=0:07:17
[08/01 20:11:57] d2.evaluation.evaluator INFO: Inference done 344/535. Dataloading: 0.0008 s/iter. Inference: 1.2739 s/iter. Eval: 0.9797 s/iter. Total: 2.2545 s/iter. ETA=0:07:10
[08/01 20:12:04] d2.evaluation.evaluator INFO: Inference done 347/535. Dataloading: 0.0008 s/iter. Inference: 1.2740 s/iter. Eval: 0.9796 s/iter. Total: 2.2545 s/iter. ETA=0:07:03
[08/01 20:12:11] d2.evaluation.evaluator INFO: Inference done 350/535. Dataloading: 0.0008 s/iter. Inference: 1.2737 s/iter. Eval: 0.9793 s/iter. Total: 2.2539 s/iter. ETA=0:06:56
[08/01 20:12:17] d2.evaluation.evaluator INFO: Inference done 353/535. Dataloading: 0.0008 s/iter. Inference: 1.2741 s/iter. Eval: 0.9791 s/iter. Total: 2.2541 s/iter. ETA=0:06:50
[08/01 20:12:24] d2.evaluation.evaluator INFO: Inference done 356/535. Dataloading: 0.0008 s/iter. Inference: 1.2742 s/iter. Eval: 0.9790 s/iter. Total: 2.2541 s/iter. ETA=0:06:43
[08/01 20:12:31] d2.evaluation.evaluator INFO: Inference done 359/535. Dataloading: 0.0008 s/iter. Inference: 1.2743 s/iter. Eval: 0.9788 s/iter. Total: 2.2540 s/iter. ETA=0:06:36
[08/01 20:12:38] d2.evaluation.evaluator INFO: Inference done 362/535. Dataloading: 0.0008 s/iter. Inference: 1.2746 s/iter. Eval: 0.9788 s/iter. Total: 2.2542 s/iter. ETA=0:06:29
[08/01 20:12:44] d2.evaluation.evaluator INFO: Inference done 365/535. Dataloading: 0.0008 s/iter. Inference: 1.2750 s/iter. Eval: 0.9783 s/iter. Total: 2.2542 s/iter. ETA=0:06:23
[08/01 20:12:51] d2.evaluation.evaluator INFO: Inference done 368/535. Dataloading: 0.0008 s/iter. Inference: 1.2751 s/iter. Eval: 0.9781 s/iter. Total: 2.2541 s/iter. ETA=0:06:16
[08/01 20:12:58] d2.evaluation.evaluator INFO: Inference done 371/535. Dataloading: 0.0008 s/iter. Inference: 1.2751 s/iter. Eval: 0.9779 s/iter. Total: 2.2539 s/iter. ETA=0:06:09
[08/01 20:13:04] d2.evaluation.evaluator INFO: Inference done 374/535. Dataloading: 0.0008 s/iter. Inference: 1.2748 s/iter. Eval: 0.9778 s/iter. Total: 2.2535 s/iter. ETA=0:06:02
[08/01 20:13:11] d2.evaluation.evaluator INFO: Inference done 377/535. Dataloading: 0.0008 s/iter. Inference: 1.2750 s/iter. Eval: 0.9775 s/iter. Total: 2.2534 s/iter. ETA=0:05:56
[08/01 20:13:18] d2.evaluation.evaluator INFO: Inference done 380/535. Dataloading: 0.0008 s/iter. Inference: 1.2750 s/iter. Eval: 0.9774 s/iter. Total: 2.2533 s/iter. ETA=0:05:49
[08/01 20:13:25] d2.evaluation.evaluator INFO: Inference done 383/535. Dataloading: 0.0008 s/iter. Inference: 1.2751 s/iter. Eval: 0.9771 s/iter. Total: 2.2532 s/iter. ETA=0:05:42
[08/01 20:13:31] d2.evaluation.evaluator INFO: Inference done 386/535. Dataloading: 0.0008 s/iter. Inference: 1.2748 s/iter. Eval: 0.9770 s/iter. Total: 2.2527 s/iter. ETA=0:05:35
[08/01 20:13:38] d2.evaluation.evaluator INFO: Inference done 389/535. Dataloading: 0.0008 s/iter. Inference: 1.2749 s/iter. Eval: 0.9766 s/iter. Total: 2.2524 s/iter. ETA=0:05:28
[08/01 20:13:45] d2.evaluation.evaluator INFO: Inference done 392/535. Dataloading: 0.0008 s/iter. Inference: 1.2752 s/iter. Eval: 0.9772 s/iter. Total: 2.2533 s/iter. ETA=0:05:22
[08/01 20:13:52] d2.evaluation.evaluator INFO: Inference done 395/535. Dataloading: 0.0008 s/iter. Inference: 1.2753 s/iter. Eval: 0.9771 s/iter. Total: 2.2532 s/iter. ETA=0:05:15
[08/01 20:13:58] d2.evaluation.evaluator INFO: Inference done 398/535. Dataloading: 0.0008 s/iter. Inference: 1.2754 s/iter. Eval: 0.9768 s/iter. Total: 2.2531 s/iter. ETA=0:05:08
[08/01 20:14:05] d2.evaluation.evaluator INFO: Inference done 401/535. Dataloading: 0.0008 s/iter. Inference: 1.2754 s/iter. Eval: 0.9765 s/iter. Total: 2.2529 s/iter. ETA=0:05:01
[08/01 20:14:12] d2.evaluation.evaluator INFO: Inference done 404/535. Dataloading: 0.0008 s/iter. Inference: 1.2755 s/iter. Eval: 0.9762 s/iter. Total: 2.2526 s/iter. ETA=0:04:55
[08/01 20:14:19] d2.evaluation.evaluator INFO: Inference done 407/535. Dataloading: 0.0008 s/iter. Inference: 1.2759 s/iter. Eval: 0.9760 s/iter. Total: 2.2528 s/iter. ETA=0:04:48
[08/01 20:14:25] d2.evaluation.evaluator INFO: Inference done 410/535. Dataloading: 0.0008 s/iter. Inference: 1.2761 s/iter. Eval: 0.9758 s/iter. Total: 2.2528 s/iter. ETA=0:04:41
[08/01 20:14:32] d2.evaluation.evaluator INFO: Inference done 413/535. Dataloading: 0.0008 s/iter. Inference: 1.2764 s/iter. Eval: 0.9756 s/iter. Total: 2.2529 s/iter. ETA=0:04:34
[08/01 20:14:39] d2.evaluation.evaluator INFO: Inference done 416/535. Dataloading: 0.0008 s/iter. Inference: 1.2764 s/iter. Eval: 0.9754 s/iter. Total: 2.2527 s/iter. ETA=0:04:28
[08/01 20:14:46] d2.evaluation.evaluator INFO: Inference done 419/535. Dataloading: 0.0008 s/iter. Inference: 1.2766 s/iter. Eval: 0.9753 s/iter. Total: 2.2528 s/iter. ETA=0:04:21
[08/01 20:14:52] d2.evaluation.evaluator INFO: Inference done 422/535. Dataloading: 0.0008 s/iter. Inference: 1.2765 s/iter. Eval: 0.9751 s/iter. Total: 2.2525 s/iter. ETA=0:04:14
[08/01 20:14:59] d2.evaluation.evaluator INFO: Inference done 425/535. Dataloading: 0.0008 s/iter. Inference: 1.2767 s/iter. Eval: 0.9751 s/iter. Total: 2.2526 s/iter. ETA=0:04:07
[08/01 20:15:06] d2.evaluation.evaluator INFO: Inference done 428/535. Dataloading: 0.0008 s/iter. Inference: 1.2766 s/iter. Eval: 0.9756 s/iter. Total: 2.2530 s/iter. ETA=0:04:01
[08/01 20:15:13] d2.evaluation.evaluator INFO: Inference done 431/535. Dataloading: 0.0008 s/iter. Inference: 1.2768 s/iter. Eval: 0.9755 s/iter. Total: 2.2531 s/iter. ETA=0:03:54
[08/01 20:15:20] d2.evaluation.evaluator INFO: Inference done 434/535. Dataloading: 0.0008 s/iter. Inference: 1.2769 s/iter. Eval: 0.9753 s/iter. Total: 2.2531 s/iter. ETA=0:03:47
[08/01 20:15:26] d2.evaluation.evaluator INFO: Inference done 437/535. Dataloading: 0.0008 s/iter. Inference: 1.2769 s/iter. Eval: 0.9752 s/iter. Total: 2.2530 s/iter. ETA=0:03:40
[08/01 20:15:33] d2.evaluation.evaluator INFO: Inference done 440/535. Dataloading: 0.0008 s/iter. Inference: 1.2769 s/iter. Eval: 0.9751 s/iter. Total: 2.2528 s/iter. ETA=0:03:34
[08/01 20:15:40] d2.evaluation.evaluator INFO: Inference done 443/535. Dataloading: 0.0008 s/iter. Inference: 1.2768 s/iter. Eval: 0.9750 s/iter. Total: 2.2527 s/iter. ETA=0:03:27
[08/01 20:15:46] d2.evaluation.evaluator INFO: Inference done 446/535. Dataloading: 0.0008 s/iter. Inference: 1.2768 s/iter. Eval: 0.9749 s/iter. Total: 2.2526 s/iter. ETA=0:03:20
[08/01 20:15:53] d2.evaluation.evaluator INFO: Inference done 449/535. Dataloading: 0.0008 s/iter. Inference: 1.2772 s/iter. Eval: 0.9748 s/iter. Total: 2.2529 s/iter. ETA=0:03:13
[08/01 20:16:00] d2.evaluation.evaluator INFO: Inference done 452/535. Dataloading: 0.0008 s/iter. Inference: 1.2772 s/iter. Eval: 0.9748 s/iter. Total: 2.2528 s/iter. ETA=0:03:06
[08/01 20:16:07] d2.evaluation.evaluator INFO: Inference done 455/535. Dataloading: 0.0008 s/iter. Inference: 1.2771 s/iter. Eval: 0.9747 s/iter. Total: 2.2527 s/iter. ETA=0:03:00
[08/01 20:16:13] d2.evaluation.evaluator INFO: Inference done 458/535. Dataloading: 0.0008 s/iter. Inference: 1.2771 s/iter. Eval: 0.9746 s/iter. Total: 2.2526 s/iter. ETA=0:02:53
[08/01 20:16:20] d2.evaluation.evaluator INFO: Inference done 461/535. Dataloading: 0.0008 s/iter. Inference: 1.2772 s/iter. Eval: 0.9745 s/iter. Total: 2.2526 s/iter. ETA=0:02:46
[08/01 20:16:27] d2.evaluation.evaluator INFO: Inference done 464/535. Dataloading: 0.0008 s/iter. Inference: 1.2773 s/iter. Eval: 0.9744 s/iter. Total: 2.2525 s/iter. ETA=0:02:39
[08/01 20:16:34] d2.evaluation.evaluator INFO: Inference done 467/535. Dataloading: 0.0008 s/iter. Inference: 1.2770 s/iter. Eval: 0.9744 s/iter. Total: 2.2523 s/iter. ETA=0:02:33
[08/01 20:16:40] d2.evaluation.evaluator INFO: Inference done 470/535. Dataloading: 0.0008 s/iter. Inference: 1.2770 s/iter. Eval: 0.9742 s/iter. Total: 2.2521 s/iter. ETA=0:02:26
[08/01 20:16:47] d2.evaluation.evaluator INFO: Inference done 473/535. Dataloading: 0.0008 s/iter. Inference: 1.2771 s/iter. Eval: 0.9741 s/iter. Total: 2.2521 s/iter. ETA=0:02:19
[08/01 20:16:54] d2.evaluation.evaluator INFO: Inference done 476/535. Dataloading: 0.0008 s/iter. Inference: 1.2772 s/iter. Eval: 0.9745 s/iter. Total: 2.2526 s/iter. ETA=0:02:12
[08/01 20:17:01] d2.evaluation.evaluator INFO: Inference done 479/535. Dataloading: 0.0008 s/iter. Inference: 1.2771 s/iter. Eval: 0.9750 s/iter. Total: 2.2530 s/iter. ETA=0:02:06
[08/01 20:17:08] d2.evaluation.evaluator INFO: Inference done 482/535. Dataloading: 0.0008 s/iter. Inference: 1.2772 s/iter. Eval: 0.9754 s/iter. Total: 2.2535 s/iter. ETA=0:01:59
[08/01 20:17:15] d2.evaluation.evaluator INFO: Inference done 485/535. Dataloading: 0.0008 s/iter. Inference: 1.2777 s/iter. Eval: 0.9757 s/iter. Total: 2.2542 s/iter. ETA=0:01:52
[08/01 20:17:22] d2.evaluation.evaluator INFO: Inference done 488/535. Dataloading: 0.0008 s/iter. Inference: 1.2776 s/iter. Eval: 0.9758 s/iter. Total: 2.2544 s/iter. ETA=0:01:45
[08/01 20:17:29] d2.evaluation.evaluator INFO: Inference done 491/535. Dataloading: 0.0008 s/iter. Inference: 1.2776 s/iter. Eval: 0.9760 s/iter. Total: 2.2545 s/iter. ETA=0:01:39
[08/01 20:17:36] d2.evaluation.evaluator INFO: Inference done 494/535. Dataloading: 0.0008 s/iter. Inference: 1.2778 s/iter. Eval: 0.9762 s/iter. Total: 2.2549 s/iter. ETA=0:01:32
[08/01 20:17:42] d2.evaluation.evaluator INFO: Inference done 497/535. Dataloading: 0.0008 s/iter. Inference: 1.2779 s/iter. Eval: 0.9763 s/iter. Total: 2.2550 s/iter. ETA=0:01:25
[08/01 20:17:49] d2.evaluation.evaluator INFO: Inference done 500/535. Dataloading: 0.0008 s/iter. Inference: 1.2779 s/iter. Eval: 0.9764 s/iter. Total: 2.2552 s/iter. ETA=0:01:18
[08/01 20:17:56] d2.evaluation.evaluator INFO: Inference done 503/535. Dataloading: 0.0008 s/iter. Inference: 1.2783 s/iter. Eval: 0.9765 s/iter. Total: 2.2557 s/iter. ETA=0:01:12
[08/01 20:18:03] d2.evaluation.evaluator INFO: Inference done 506/535. Dataloading: 0.0008 s/iter. Inference: 1.2782 s/iter. Eval: 0.9766 s/iter. Total: 2.2557 s/iter. ETA=0:01:05
[08/01 20:18:10] d2.evaluation.evaluator INFO: Inference done 509/535. Dataloading: 0.0008 s/iter. Inference: 1.2784 s/iter. Eval: 0.9768 s/iter. Total: 2.2560 s/iter. ETA=0:00:58
[08/01 20:18:17] d2.evaluation.evaluator INFO: Inference done 512/535. Dataloading: 0.0008 s/iter. Inference: 1.2785 s/iter. Eval: 0.9769 s/iter. Total: 2.2562 s/iter. ETA=0:00:51
[08/01 20:18:24] d2.evaluation.evaluator INFO: Inference done 515/535. Dataloading: 0.0008 s/iter. Inference: 1.2786 s/iter. Eval: 0.9770 s/iter. Total: 2.2565 s/iter. ETA=0:00:45
[08/01 20:18:31] d2.evaluation.evaluator INFO: Inference done 518/535. Dataloading: 0.0008 s/iter. Inference: 1.2787 s/iter. Eval: 0.9771 s/iter. Total: 2.2567 s/iter. ETA=0:00:38
[08/01 20:18:38] d2.evaluation.evaluator INFO: Inference done 521/535. Dataloading: 0.0008 s/iter. Inference: 1.2787 s/iter. Eval: 0.9773 s/iter. Total: 2.2569 s/iter. ETA=0:00:31
[08/01 20:18:44] d2.evaluation.evaluator INFO: Inference done 524/535. Dataloading: 0.0008 s/iter. Inference: 1.2787 s/iter. Eval: 0.9775 s/iter. Total: 2.2570 s/iter. ETA=0:00:24
[08/01 20:18:51] d2.evaluation.evaluator INFO: Inference done 527/535. Dataloading: 0.0008 s/iter. Inference: 1.2786 s/iter. Eval: 0.9775 s/iter. Total: 2.2570 s/iter. ETA=0:00:18
[08/01 20:18:58] d2.evaluation.evaluator INFO: Inference done 530/535. Dataloading: 0.0008 s/iter. Inference: 1.2788 s/iter. Eval: 0.9775 s/iter. Total: 2.2572 s/iter. ETA=0:00:11
[08/01 20:19:05] d2.evaluation.evaluator INFO: Inference done 533/535. Dataloading: 0.0008 s/iter. Inference: 1.2786 s/iter. Eval: 0.9777 s/iter. Total: 2.2571 s/iter. ETA=0:00:04
[08/01 20:19:09] d2.evaluation.evaluator INFO: Total inference time: 0:19:56.368784 (2.257300 s / iter per device, on 1 devices)
[08/01 20:19:09] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:11:17 (1.278511 s / iter per device, on 1 devices)
[08/01 20:19:10] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[08/01 20:19:10] d2.evaluation.coco_evaluation INFO: Saving results to ./R101_overlap/inference/coco_instances_results.json
[08/01 20:19:11] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[08/01 20:19:13] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 |  nan  | 0.000 |
[08/01 20:19:13] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 20:19:13] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| normal     | 0.000 | defect     | 0.000 |
[08/01 20:19:19] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl   |
|:------:|:------:|:------:|:------:|:-----:|:------:|
| 98.683 | 99.684 | 99.194 | 93.305 |  nan  | 98.683 |
[08/01 20:19:19] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 20:19:19] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| normal     | 98.906 | defect     | 98.460 |
[08/01 20:19:19] d2.engine.defaults INFO: Evaluation results for front2class_2017_val_overlap_panoptic in csv format:
[08/01 20:19:19] d2.evaluation.testing INFO: copypaste: Task: bbox
[08/01 20:19:19] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 20:19:19] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,nan,0.0000
[08/01 20:19:19] d2.evaluation.testing INFO: copypaste: Task: segm
[08/01 20:19:19] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 20:19:19] d2.evaluation.testing INFO: copypaste: 98.6830,99.6838,99.1940,93.3052,nan,98.6830
[08/01 20:19:19] d2.utils.events INFO:  eta: 4:23:03  iter: 14999  total_loss: 3.109  loss_ce: 0.0001423  loss_mask: 0.1177  loss_dice: 0.1772  loss_ce_0: 0.1298  loss_mask_0: 0.1179  loss_dice_0: 0.1852  loss_ce_1: 0.0001912  loss_mask_1: 0.1193  loss_dice_1: 0.1799  loss_ce_2: 0.0002265  loss_mask_2: 0.1201  loss_dice_2: 0.1799  loss_ce_3: 0.000165  loss_mask_3: 0.1181  loss_dice_3: 0.1838  loss_ce_4: 0.0001668  loss_mask_4: 0.1155  loss_dice_4: 0.174  loss_ce_5: 0.0001596  loss_mask_5: 0.119  loss_dice_5: 0.1781  loss_ce_6: 0.0001511  loss_mask_6: 0.1197  loss_dice_6: 0.1856  loss_ce_7: 0.0001324  loss_mask_7: 0.1245  loss_dice_7: 0.1808  loss_ce_8: 0.0001265  loss_mask_8: 0.1192  loss_dice_8: 0.1769  time: 0.6842  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:19:19] d2.engine.hooks INFO: Not saving as latest eval score for total_loss is 3.43352, not better than best score 3.09764 @ iteration 9999.
[08/01 20:19:36] d2.utils.events INFO:  eta: 4:23:00  iter: 15019  total_loss: 2.971  loss_ce: 0.0002022  loss_mask: 0.1153  loss_dice: 0.1716  loss_ce_0: 0.1304  loss_mask_0: 0.1128  loss_dice_0: 0.1706  loss_ce_1: 0.0001613  loss_mask_1: 0.1143  loss_dice_1: 0.1689  loss_ce_2: 0.0002257  loss_mask_2: 0.1102  loss_dice_2: 0.1706  loss_ce_3: 0.0001531  loss_mask_3: 0.1151  loss_dice_3: 0.1712  loss_ce_4: 0.0002207  loss_mask_4: 0.1129  loss_dice_4: 0.1706  loss_ce_5: 0.0001445  loss_mask_5: 0.1158  loss_dice_5: 0.1748  loss_ce_6: 0.0001342  loss_mask_6: 0.1132  loss_dice_6: 0.1675  loss_ce_7: 0.0001163  loss_mask_7: 0.1139  loss_dice_7: 0.1713  loss_ce_8: 0.0002156  loss_mask_8: 0.1171  loss_dice_8: 0.1666  time: 0.6844  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:19:53] d2.utils.events INFO:  eta: 4:22:54  iter: 15039  total_loss: 3.288  loss_ce: 0.0001524  loss_mask: 0.1207  loss_dice: 0.1858  loss_ce_0: 0.1293  loss_mask_0: 0.1192  loss_dice_0: 0.1886  loss_ce_1: 0.0001653  loss_mask_1: 0.1235  loss_dice_1: 0.1844  loss_ce_2: 0.0002163  loss_mask_2: 0.1271  loss_dice_2: 0.1902  loss_ce_3: 0.0001753  loss_mask_3: 0.1248  loss_dice_3: 0.1866  loss_ce_4: 0.0001409  loss_mask_4: 0.126  loss_dice_4: 0.1888  loss_ce_5: 0.0001351  loss_mask_5: 0.1193  loss_dice_5: 0.186  loss_ce_6: 0.0001274  loss_mask_6: 0.1259  loss_dice_6: 0.1896  loss_ce_7: 0.0001167  loss_mask_7: 0.1264  loss_dice_7: 0.1905  loss_ce_8: 0.0001362  loss_mask_8: 0.1271  loss_dice_8: 0.186  time: 0.6846  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:20:10] d2.utils.events INFO:  eta: 4:23:02  iter: 15059  total_loss: 2.913  loss_ce: 0.0001729  loss_mask: 0.1113  loss_dice: 0.1679  loss_ce_0: 0.1285  loss_mask_0: 0.1163  loss_dice_0: 0.1667  loss_ce_1: 0.0001452  loss_mask_1: 0.1098  loss_dice_1: 0.1612  loss_ce_2: 0.0001934  loss_mask_2: 0.1137  loss_dice_2: 0.1615  loss_ce_3: 0.0001574  loss_mask_3: 0.1125  loss_dice_3: 0.163  loss_ce_4: 0.0001767  loss_mask_4: 0.1121  loss_dice_4: 0.1663  loss_ce_5: 0.0001282  loss_mask_5: 0.1156  loss_dice_5: 0.1647  loss_ce_6: 0.0001173  loss_mask_6: 0.1117  loss_dice_6: 0.1648  loss_ce_7: 0.0001102  loss_mask_7: 0.1093  loss_dice_7: 0.1651  loss_ce_8: 0.0001782  loss_mask_8: 0.1133  loss_dice_8: 0.1637  time: 0.6848  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 20:20:26] d2.utils.events INFO:  eta: 4:23:05  iter: 15079  total_loss: 3.082  loss_ce: 0.0001457  loss_mask: 0.1138  loss_dice: 0.1733  loss_ce_0: 0.1227  loss_mask_0: 0.1188  loss_dice_0: 0.1799  loss_ce_1: 0.0001338  loss_mask_1: 0.1192  loss_dice_1: 0.1792  loss_ce_2: 0.0001746  loss_mask_2: 0.1161  loss_dice_2: 0.1727  loss_ce_3: 0.0001278  loss_mask_3: 0.1196  loss_dice_3: 0.1793  loss_ce_4: 0.0001236  loss_mask_4: 0.1162  loss_dice_4: 0.1795  loss_ce_5: 0.0001095  loss_mask_5: 0.1177  loss_dice_5: 0.1724  loss_ce_6: 0.0001033  loss_mask_6: 0.1157  loss_dice_6: 0.174  loss_ce_7: 8.905e-05  loss_mask_7: 0.1191  loss_dice_7: 0.1817  loss_ce_8: 0.0001239  loss_mask_8: 0.1199  loss_dice_8: 0.1743  time: 0.6850  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:20:43] d2.utils.events INFO:  eta: 4:23:11  iter: 15099  total_loss: 3.043  loss_ce: 0.0001466  loss_mask: 0.1177  loss_dice: 0.1771  loss_ce_0: 0.1244  loss_mask_0: 0.1169  loss_dice_0: 0.176  loss_ce_1: 0.0001461  loss_mask_1: 0.1164  loss_dice_1: 0.18  loss_ce_2: 0.0001824  loss_mask_2: 0.1167  loss_dice_2: 0.174  loss_ce_3: 0.0001434  loss_mask_3: 0.1142  loss_dice_3: 0.1824  loss_ce_4: 0.0001454  loss_mask_4: 0.1146  loss_dice_4: 0.1803  loss_ce_5: 0.0001281  loss_mask_5: 0.1151  loss_dice_5: 0.1685  loss_ce_6: 0.0001097  loss_mask_6: 0.1128  loss_dice_6: 0.1718  loss_ce_7: 0.0001169  loss_mask_7: 0.1193  loss_dice_7: 0.176  loss_ce_8: 0.0001443  loss_mask_8: 0.1146  loss_dice_8: 0.1734  time: 0.6853  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:21:00] d2.utils.events INFO:  eta: 4:23:21  iter: 15119  total_loss: 3.011  loss_ce: 0.000116  loss_mask: 0.1186  loss_dice: 0.1691  loss_ce_0: 0.1216  loss_mask_0: 0.1179  loss_dice_0: 0.1744  loss_ce_1: 0.0001063  loss_mask_1: 0.122  loss_dice_1: 0.1779  loss_ce_2: 0.0001592  loss_mask_2: 0.119  loss_dice_2: 0.1706  loss_ce_3: 0.0001193  loss_mask_3: 0.12  loss_dice_3: 0.1655  loss_ce_4: 0.000104  loss_mask_4: 0.1185  loss_dice_4: 0.1713  loss_ce_5: 0.0001021  loss_mask_5: 0.117  loss_dice_5: 0.1669  loss_ce_6: 9.537e-05  loss_mask_6: 0.1207  loss_dice_6: 0.1688  loss_ce_7: 8.867e-05  loss_mask_7: 0.1169  loss_dice_7: 0.1728  loss_ce_8: 0.0001107  loss_mask_8: 0.1185  loss_dice_8: 0.1686  time: 0.6855  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:21:17] d2.utils.events INFO:  eta: 4:23:18  iter: 15139  total_loss: 2.827  loss_ce: 0.0001066  loss_mask: 0.1117  loss_dice: 0.1525  loss_ce_0: 0.1293  loss_mask_0: 0.1145  loss_dice_0: 0.1597  loss_ce_1: 9.905e-05  loss_mask_1: 0.1127  loss_dice_1: 0.1549  loss_ce_2: 0.0001414  loss_mask_2: 0.113  loss_dice_2: 0.1541  loss_ce_3: 0.0001088  loss_mask_3: 0.1112  loss_dice_3: 0.1548  loss_ce_4: 0.0001036  loss_mask_4: 0.1146  loss_dice_4: 0.1588  loss_ce_5: 8.817e-05  loss_mask_5: 0.1135  loss_dice_5: 0.1567  loss_ce_6: 7.846e-05  loss_mask_6: 0.1154  loss_dice_6: 0.1556  loss_ce_7: 7.199e-05  loss_mask_7: 0.1125  loss_dice_7: 0.155  loss_ce_8: 0.0001207  loss_mask_8: 0.1139  loss_dice_8: 0.1542  time: 0.6857  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:21:34] d2.utils.events INFO:  eta: 4:23:12  iter: 15159  total_loss: 3.098  loss_ce: 0.0001182  loss_mask: 0.1225  loss_dice: 0.1794  loss_ce_0: 0.1189  loss_mask_0: 0.1195  loss_dice_0: 0.1804  loss_ce_1: 0.0001202  loss_mask_1: 0.1206  loss_dice_1: 0.1721  loss_ce_2: 0.0001504  loss_mask_2: 0.124  loss_dice_2: 0.182  loss_ce_3: 0.0001182  loss_mask_3: 0.1197  loss_dice_3: 0.1778  loss_ce_4: 9.806e-05  loss_mask_4: 0.1249  loss_dice_4: 0.1803  loss_ce_5: 9.608e-05  loss_mask_5: 0.1208  loss_dice_5: 0.1756  loss_ce_6: 9.719e-05  loss_mask_6: 0.1196  loss_dice_6: 0.1754  loss_ce_7: 9.076e-05  loss_mask_7: 0.1201  loss_dice_7: 0.1775  loss_ce_8: 0.0001137  loss_mask_8: 0.1188  loss_dice_8: 0.1791  time: 0.6859  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:21:51] d2.utils.events INFO:  eta: 4:23:22  iter: 15179  total_loss: 3.118  loss_ce: 0.0001243  loss_mask: 0.117  loss_dice: 0.1769  loss_ce_0: 0.1212  loss_mask_0: 0.1174  loss_dice_0: 0.1768  loss_ce_1: 0.0001137  loss_mask_1: 0.1142  loss_dice_1: 0.1856  loss_ce_2: 0.0001453  loss_mask_2: 0.1136  loss_dice_2: 0.176  loss_ce_3: 0.0001199  loss_mask_3: 0.1208  loss_dice_3: 0.1811  loss_ce_4: 0.0001067  loss_mask_4: 0.1141  loss_dice_4: 0.1782  loss_ce_5: 9.821e-05  loss_mask_5: 0.1168  loss_dice_5: 0.1751  loss_ce_6: 9.349e-05  loss_mask_6: 0.1166  loss_dice_6: 0.1841  loss_ce_7: 8.627e-05  loss_mask_7: 0.1162  loss_dice_7: 0.176  loss_ce_8: 0.0001137  loss_mask_8: 0.1197  loss_dice_8: 0.1821  time: 0.6861  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:22:08] d2.utils.events INFO:  eta: 4:23:41  iter: 15199  total_loss: 2.979  loss_ce: 0.0001087  loss_mask: 0.1118  loss_dice: 0.1622  loss_ce_0: 0.1176  loss_mask_0: 0.1181  loss_dice_0: 0.1652  loss_ce_1: 0.000109  loss_mask_1: 0.1207  loss_dice_1: 0.1734  loss_ce_2: 0.0001428  loss_mask_2: 0.1213  loss_dice_2: 0.1678  loss_ce_3: 0.0001164  loss_mask_3: 0.1166  loss_dice_3: 0.1729  loss_ce_4: 9.744e-05  loss_mask_4: 0.1173  loss_dice_4: 0.1723  loss_ce_5: 0.0001069  loss_mask_5: 0.1203  loss_dice_5: 0.1726  loss_ce_6: 8.092e-05  loss_mask_6: 0.1193  loss_dice_6: 0.1711  loss_ce_7: 9.206e-05  loss_mask_7: 0.1211  loss_dice_7: 0.1717  loss_ce_8: 0.0001039  loss_mask_8: 0.1193  loss_dice_8: 0.1667  time: 0.6863  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:22:25] d2.utils.events INFO:  eta: 4:24:01  iter: 15219  total_loss: 3.065  loss_ce: 0.0001037  loss_mask: 0.1215  loss_dice: 0.1677  loss_ce_0: 0.1226  loss_mask_0: 0.1191  loss_dice_0: 0.1707  loss_ce_1: 9.887e-05  loss_mask_1: 0.1178  loss_dice_1: 0.1638  loss_ce_2: 0.0001344  loss_mask_2: 0.1244  loss_dice_2: 0.1715  loss_ce_3: 9.907e-05  loss_mask_3: 0.1201  loss_dice_3: 0.167  loss_ce_4: 9.595e-05  loss_mask_4: 0.1199  loss_dice_4: 0.1693  loss_ce_5: 9.659e-05  loss_mask_5: 0.124  loss_dice_5: 0.1698  loss_ce_6: 8.811e-05  loss_mask_6: 0.1213  loss_dice_6: 0.1655  loss_ce_7: 9.653e-05  loss_mask_7: 0.1219  loss_dice_7: 0.1715  loss_ce_8: 0.0001047  loss_mask_8: 0.1201  loss_dice_8: 0.1665  time: 0.6865  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:22:42] d2.utils.events INFO:  eta: 4:23:57  iter: 15239  total_loss: 2.872  loss_ce: 0.0001038  loss_mask: 0.113  loss_dice: 0.1664  loss_ce_0: 0.1261  loss_mask_0: 0.1088  loss_dice_0: 0.1643  loss_ce_1: 0.0001099  loss_mask_1: 0.1079  loss_dice_1: 0.1586  loss_ce_2: 0.0001336  loss_mask_2: 0.112  loss_dice_2: 0.165  loss_ce_3: 9.365e-05  loss_mask_3: 0.1124  loss_dice_3: 0.1625  loss_ce_4: 0.0001007  loss_mask_4: 0.1133  loss_dice_4: 0.1683  loss_ce_5: 8.832e-05  loss_mask_5: 0.1131  loss_dice_5: 0.1629  loss_ce_6: 8.127e-05  loss_mask_6: 0.1087  loss_dice_6: 0.1603  loss_ce_7: 9.358e-05  loss_mask_7: 0.1098  loss_dice_7: 0.1631  loss_ce_8: 0.0001007  loss_mask_8: 0.1066  loss_dice_8: 0.1582  time: 0.6867  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:22:58] d2.utils.events INFO:  eta: 4:24:06  iter: 15259  total_loss: 2.857  loss_ce: 0.0001007  loss_mask: 0.1131  loss_dice: 0.1687  loss_ce_0: 0.1267  loss_mask_0: 0.1141  loss_dice_0: 0.1677  loss_ce_1: 0.0001244  loss_mask_1: 0.1088  loss_dice_1: 0.1618  loss_ce_2: 0.0001338  loss_mask_2: 0.115  loss_dice_2: 0.163  loss_ce_3: 9.224e-05  loss_mask_3: 0.1137  loss_dice_3: 0.1695  loss_ce_4: 0.0001193  loss_mask_4: 0.1141  loss_dice_4: 0.1709  loss_ce_5: 8.911e-05  loss_mask_5: 0.116  loss_dice_5: 0.1694  loss_ce_6: 9.111e-05  loss_mask_6: 0.1113  loss_dice_6: 0.1659  loss_ce_7: 9.865e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1663  loss_ce_8: 0.000123  loss_mask_8: 0.1115  loss_dice_8: 0.163  time: 0.6869  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:23:15] d2.utils.events INFO:  eta: 4:23:59  iter: 15279  total_loss: 3.077  loss_ce: 0.0001896  loss_mask: 0.115  loss_dice: 0.1794  loss_ce_0: 0.1303  loss_mask_0: 0.1145  loss_dice_0: 0.1854  loss_ce_1: 0.0002357  loss_mask_1: 0.1141  loss_dice_1: 0.1894  loss_ce_2: 0.0001679  loss_mask_2: 0.1147  loss_dice_2: 0.1754  loss_ce_3: 0.0001441  loss_mask_3: 0.1158  loss_dice_3: 0.1796  loss_ce_4: 0.0001246  loss_mask_4: 0.1118  loss_dice_4: 0.1753  loss_ce_5: 0.0001595  loss_mask_5: 0.1147  loss_dice_5: 0.1792  loss_ce_6: 0.0001788  loss_mask_6: 0.1132  loss_dice_6: 0.1807  loss_ce_7: 0.0001566  loss_mask_7: 0.112  loss_dice_7: 0.1783  loss_ce_8: 0.0002106  loss_mask_8: 0.1104  loss_dice_8: 0.1814  time: 0.6871  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:23:32] d2.utils.events INFO:  eta: 4:23:57  iter: 15299  total_loss: 2.843  loss_ce: 0.0001822  loss_mask: 0.1167  loss_dice: 0.1606  loss_ce_0: 0.1249  loss_mask_0: 0.117  loss_dice_0: 0.1619  loss_ce_1: 0.0001542  loss_mask_1: 0.1134  loss_dice_1: 0.1572  loss_ce_2: 0.0001776  loss_mask_2: 0.1144  loss_dice_2: 0.1568  loss_ce_3: 0.0001415  loss_mask_3: 0.1125  loss_dice_3: 0.158  loss_ce_4: 0.0001396  loss_mask_4: 0.1144  loss_dice_4: 0.1599  loss_ce_5: 0.0001843  loss_mask_5: 0.116  loss_dice_5: 0.163  loss_ce_6: 0.0002153  loss_mask_6: 0.1125  loss_dice_6: 0.1573  loss_ce_7: 0.0001938  loss_mask_7: 0.1137  loss_dice_7: 0.1637  loss_ce_8: 0.0002746  loss_mask_8: 0.1129  loss_dice_8: 0.1512  time: 0.6873  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:23:49] d2.utils.events INFO:  eta: 4:24:05  iter: 15319  total_loss: 2.944  loss_ce: 0.0001739  loss_mask: 0.1164  loss_dice: 0.1747  loss_ce_0: 0.1221  loss_mask_0: 0.1146  loss_dice_0: 0.1664  loss_ce_1: 0.0001079  loss_mask_1: 0.1139  loss_dice_1: 0.1631  loss_ce_2: 0.0001648  loss_mask_2: 0.1186  loss_dice_2: 0.1703  loss_ce_3: 0.000131  loss_mask_3: 0.1143  loss_dice_3: 0.1647  loss_ce_4: 0.0001131  loss_mask_4: 0.1146  loss_dice_4: 0.1689  loss_ce_5: 0.0001721  loss_mask_5: 0.1154  loss_dice_5: 0.1647  loss_ce_6: 0.0001541  loss_mask_6: 0.1188  loss_dice_6: 0.1689  loss_ce_7: 0.0001462  loss_mask_7: 0.1156  loss_dice_7: 0.1697  loss_ce_8: 0.0002192  loss_mask_8: 0.1169  loss_dice_8: 0.1686  time: 0.6875  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 20:24:06] d2.utils.events INFO:  eta: 4:24:09  iter: 15339  total_loss: 3.214  loss_ce: 0.0002015  loss_mask: 0.1175  loss_dice: 0.186  loss_ce_0: 0.1177  loss_mask_0: 0.1253  loss_dice_0: 0.187  loss_ce_1: 0.0001143  loss_mask_1: 0.123  loss_dice_1: 0.183  loss_ce_2: 0.0001638  loss_mask_2: 0.1184  loss_dice_2: 0.1794  loss_ce_3: 0.0001547  loss_mask_3: 0.1257  loss_dice_3: 0.1852  loss_ce_4: 0.0001704  loss_mask_4: 0.1213  loss_dice_4: 0.18  loss_ce_5: 0.0002014  loss_mask_5: 0.1221  loss_dice_5: 0.1854  loss_ce_6: 0.0002132  loss_mask_6: 0.1204  loss_dice_6: 0.1836  loss_ce_7: 0.0001684  loss_mask_7: 0.1225  loss_dice_7: 0.1821  loss_ce_8: 0.0002976  loss_mask_8: 0.1231  loss_dice_8: 0.1846  time: 0.6877  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 20:24:23] d2.utils.events INFO:  eta: 4:24:27  iter: 15359  total_loss: 3.017  loss_ce: 0.0003011  loss_mask: 0.1162  loss_dice: 0.1717  loss_ce_0: 0.1239  loss_mask_0: 0.1159  loss_dice_0: 0.1719  loss_ce_1: 0.0001242  loss_mask_1: 0.1228  loss_dice_1: 0.1799  loss_ce_2: 0.0002059  loss_mask_2: 0.1168  loss_dice_2: 0.1734  loss_ce_3: 0.0001608  loss_mask_3: 0.1206  loss_dice_3: 0.1751  loss_ce_4: 0.000163  loss_mask_4: 0.118  loss_dice_4: 0.1755  loss_ce_5: 0.0002004  loss_mask_5: 0.1185  loss_dice_5: 0.1781  loss_ce_6: 0.0001437  loss_mask_6: 0.1197  loss_dice_6: 0.1731  loss_ce_7: 0.0001963  loss_mask_7: 0.1193  loss_dice_7: 0.1743  loss_ce_8: 0.0003293  loss_mask_8: 0.12  loss_dice_8: 0.1751  time: 0.6879  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:24:40] d2.utils.events INFO:  eta: 4:24:24  iter: 15379  total_loss: 2.902  loss_ce: 0.0001614  loss_mask: 0.115  loss_dice: 0.1651  loss_ce_0: 0.1216  loss_mask_0: 0.1132  loss_dice_0: 0.1735  loss_ce_1: 7.741e-05  loss_mask_1: 0.1097  loss_dice_1: 0.1594  loss_ce_2: 0.0001489  loss_mask_2: 0.1132  loss_dice_2: 0.1728  loss_ce_3: 0.0001416  loss_mask_3: 0.1133  loss_dice_3: 0.1649  loss_ce_4: 0.0001298  loss_mask_4: 0.1152  loss_dice_4: 0.1611  loss_ce_5: 0.0001695  loss_mask_5: 0.1126  loss_dice_5: 0.1648  loss_ce_6: 0.0001246  loss_mask_6: 0.1164  loss_dice_6: 0.1653  loss_ce_7: 0.0001476  loss_mask_7: 0.1165  loss_dice_7: 0.1625  loss_ce_8: 0.0002236  loss_mask_8: 0.1149  loss_dice_8: 0.164  time: 0.6881  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:24:56] d2.utils.events INFO:  eta: 4:24:35  iter: 15399  total_loss: 2.9  loss_ce: 0.0003009  loss_mask: 0.1128  loss_dice: 0.1681  loss_ce_0: 0.1219  loss_mask_0: 0.1129  loss_dice_0: 0.169  loss_ce_1: 0.0001486  loss_mask_1: 0.1179  loss_dice_1: 0.1724  loss_ce_2: 0.0001874  loss_mask_2: 0.1143  loss_dice_2: 0.1696  loss_ce_3: 0.0001547  loss_mask_3: 0.1144  loss_dice_3: 0.1689  loss_ce_4: 0.0001923  loss_mask_4: 0.1118  loss_dice_4: 0.1642  loss_ce_5: 0.0001683  loss_mask_5: 0.1141  loss_dice_5: 0.1625  loss_ce_6: 0.0001581  loss_mask_6: 0.1131  loss_dice_6: 0.1672  loss_ce_7: 0.0001742  loss_mask_7: 0.1124  loss_dice_7: 0.1658  loss_ce_8: 0.0002763  loss_mask_8: 0.1105  loss_dice_8: 0.1605  time: 0.6883  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:25:13] d2.utils.events INFO:  eta: 4:24:32  iter: 15419  total_loss: 2.946  loss_ce: 0.0001654  loss_mask: 0.1147  loss_dice: 0.168  loss_ce_0: 0.1229  loss_mask_0: 0.1116  loss_dice_0: 0.1657  loss_ce_1: 0.0001237  loss_mask_1: 0.1141  loss_dice_1: 0.1646  loss_ce_2: 0.0001751  loss_mask_2: 0.1164  loss_dice_2: 0.1679  loss_ce_3: 0.0001409  loss_mask_3: 0.1169  loss_dice_3: 0.1736  loss_ce_4: 0.000143  loss_mask_4: 0.1122  loss_dice_4: 0.1695  loss_ce_5: 0.0001614  loss_mask_5: 0.1134  loss_dice_5: 0.1684  loss_ce_6: 0.0001592  loss_mask_6: 0.1159  loss_dice_6: 0.1681  loss_ce_7: 0.0001301  loss_mask_7: 0.1151  loss_dice_7: 0.1691  loss_ce_8: 0.0002133  loss_mask_8: 0.1155  loss_dice_8: 0.1713  time: 0.6885  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:25:30] d2.utils.events INFO:  eta: 4:24:41  iter: 15439  total_loss: 3.061  loss_ce: 0.0002972  loss_mask: 0.1138  loss_dice: 0.1762  loss_ce_0: 0.1286  loss_mask_0: 0.1185  loss_dice_0: 0.1791  loss_ce_1: 0.0001176  loss_mask_1: 0.1195  loss_dice_1: 0.1723  loss_ce_2: 0.000189  loss_mask_2: 0.1169  loss_dice_2: 0.1723  loss_ce_3: 0.0001899  loss_mask_3: 0.1164  loss_dice_3: 0.1781  loss_ce_4: 0.000174  loss_mask_4: 0.1171  loss_dice_4: 0.1725  loss_ce_5: 0.0001675  loss_mask_5: 0.1194  loss_dice_5: 0.1785  loss_ce_6: 0.00019  loss_mask_6: 0.1184  loss_dice_6: 0.1787  loss_ce_7: 0.0002131  loss_mask_7: 0.1184  loss_dice_7: 0.1757  loss_ce_8: 0.000233  loss_mask_8: 0.117  loss_dice_8: 0.1704  time: 0.6887  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 20:25:47] d2.utils.events INFO:  eta: 4:24:35  iter: 15459  total_loss: 3.215  loss_ce: 0.0006355  loss_mask: 0.1177  loss_dice: 0.181  loss_ce_0: 0.1213  loss_mask_0: 0.1218  loss_dice_0: 0.1826  loss_ce_1: 0.0004586  loss_mask_1: 0.1179  loss_dice_1: 0.1828  loss_ce_2: 0.0003584  loss_mask_2: 0.1192  loss_dice_2: 0.1774  loss_ce_3: 0.0008626  loss_mask_3: 0.1208  loss_dice_3: 0.1852  loss_ce_4: 0.0007929  loss_mask_4: 0.1223  loss_dice_4: 0.187  loss_ce_5: 0.0004076  loss_mask_5: 0.1172  loss_dice_5: 0.1904  loss_ce_6: 0.0003433  loss_mask_6: 0.1189  loss_dice_6: 0.1855  loss_ce_7: 0.0007013  loss_mask_7: 0.1212  loss_dice_7: 0.1858  loss_ce_8: 0.0005091  loss_mask_8: 0.1238  loss_dice_8: 0.1789  time: 0.6889  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:26:04] d2.utils.events INFO:  eta: 4:24:49  iter: 15479  total_loss: 2.967  loss_ce: 0.0003268  loss_mask: 0.1211  loss_dice: 0.1664  loss_ce_0: 0.1279  loss_mask_0: 0.1174  loss_dice_0: 0.1643  loss_ce_1: 0.0001976  loss_mask_1: 0.1217  loss_dice_1: 0.1667  loss_ce_2: 0.0003024  loss_mask_2: 0.117  loss_dice_2: 0.1691  loss_ce_3: 0.0003455  loss_mask_3: 0.1176  loss_dice_3: 0.1651  loss_ce_4: 0.0003251  loss_mask_4: 0.1193  loss_dice_4: 0.1623  loss_ce_5: 0.0002602  loss_mask_5: 0.1151  loss_dice_5: 0.1619  loss_ce_6: 0.0005108  loss_mask_6: 0.1213  loss_dice_6: 0.1618  loss_ce_7: 0.0004121  loss_mask_7: 0.1215  loss_dice_7: 0.1627  loss_ce_8: 0.0003317  loss_mask_8: 0.1232  loss_dice_8: 0.1707  time: 0.6891  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:26:21] d2.utils.events INFO:  eta: 4:24:54  iter: 15499  total_loss: 2.92  loss_ce: 0.0002652  loss_mask: 0.115  loss_dice: 0.1659  loss_ce_0: 0.1259  loss_mask_0: 0.1177  loss_dice_0: 0.1795  loss_ce_1: 0.0001625  loss_mask_1: 0.1163  loss_dice_1: 0.1655  loss_ce_2: 0.0002542  loss_mask_2: 0.1157  loss_dice_2: 0.1677  loss_ce_3: 0.0002859  loss_mask_3: 0.1166  loss_dice_3: 0.1676  loss_ce_4: 0.0002225  loss_mask_4: 0.1159  loss_dice_4: 0.1664  loss_ce_5: 0.0001964  loss_mask_5: 0.1131  loss_dice_5: 0.1687  loss_ce_6: 0.0001815  loss_mask_6: 0.1184  loss_dice_6: 0.1673  loss_ce_7: 0.0002561  loss_mask_7: 0.1152  loss_dice_7: 0.1715  loss_ce_8: 0.0002644  loss_mask_8: 0.1145  loss_dice_8: 0.1609  time: 0.6893  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:26:38] d2.utils.events INFO:  eta: 4:24:51  iter: 15519  total_loss: 3.103  loss_ce: 0.0002628  loss_mask: 0.1199  loss_dice: 0.1677  loss_ce_0: 0.1199  loss_mask_0: 0.1165  loss_dice_0: 0.1675  loss_ce_1: 0.0001829  loss_mask_1: 0.1194  loss_dice_1: 0.1725  loss_ce_2: 0.0002578  loss_mask_2: 0.1197  loss_dice_2: 0.1793  loss_ce_3: 0.000281  loss_mask_3: 0.1171  loss_dice_3: 0.1764  loss_ce_4: 0.0002691  loss_mask_4: 0.1155  loss_dice_4: 0.1745  loss_ce_5: 0.0002341  loss_mask_5: 0.1161  loss_dice_5: 0.1766  loss_ce_6: 0.0002109  loss_mask_6: 0.1169  loss_dice_6: 0.1697  loss_ce_7: 0.0002896  loss_mask_7: 0.115  loss_dice_7: 0.166  loss_ce_8: 0.0002947  loss_mask_8: 0.1151  loss_dice_8: 0.17  time: 0.6895  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:26:55] d2.utils.events INFO:  eta: 4:24:50  iter: 15539  total_loss: 3.069  loss_ce: 0.0002286  loss_mask: 0.1189  loss_dice: 0.1773  loss_ce_0: 0.1211  loss_mask_0: 0.1156  loss_dice_0: 0.1776  loss_ce_1: 0.0001394  loss_mask_1: 0.1153  loss_dice_1: 0.1766  loss_ce_2: 0.0002395  loss_mask_2: 0.1158  loss_dice_2: 0.1754  loss_ce_3: 0.0002362  loss_mask_3: 0.1148  loss_dice_3: 0.1773  loss_ce_4: 0.0002746  loss_mask_4: 0.1156  loss_dice_4: 0.1763  loss_ce_5: 0.0002226  loss_mask_5: 0.1192  loss_dice_5: 0.1748  loss_ce_6: 0.0002248  loss_mask_6: 0.1203  loss_dice_6: 0.1729  loss_ce_7: 0.0002634  loss_mask_7: 0.1139  loss_dice_7: 0.1712  loss_ce_8: 0.0002684  loss_mask_8: 0.1162  loss_dice_8: 0.1703  time: 0.6897  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 20:27:12] d2.utils.events INFO:  eta: 4:25:09  iter: 15559  total_loss: 2.949  loss_ce: 0.0001875  loss_mask: 0.1088  loss_dice: 0.1734  loss_ce_0: 0.1276  loss_mask_0: 0.1141  loss_dice_0: 0.1673  loss_ce_1: 0.0001169  loss_mask_1: 0.1069  loss_dice_1: 0.1664  loss_ce_2: 0.0001778  loss_mask_2: 0.1113  loss_dice_2: 0.1768  loss_ce_3: 0.0001729  loss_mask_3: 0.1112  loss_dice_3: 0.1726  loss_ce_4: 0.0001145  loss_mask_4: 0.1135  loss_dice_4: 0.1788  loss_ce_5: 0.0001391  loss_mask_5: 0.1108  loss_dice_5: 0.1648  loss_ce_6: 0.000116  loss_mask_6: 0.1146  loss_dice_6: 0.1679  loss_ce_7: 0.0001409  loss_mask_7: 0.1134  loss_dice_7: 0.178  loss_ce_8: 0.0001726  loss_mask_8: 0.1117  loss_dice_8: 0.1718  time: 0.6899  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 20:27:29] d2.utils.events INFO:  eta: 4:25:09  iter: 15579  total_loss: 3.149  loss_ce: 0.0001784  loss_mask: 0.123  loss_dice: 0.1867  loss_ce_0: 0.1282  loss_mask_0: 0.1149  loss_dice_0: 0.1773  loss_ce_1: 0.0001137  loss_mask_1: 0.1226  loss_dice_1: 0.1767  loss_ce_2: 0.0001726  loss_mask_2: 0.1197  loss_dice_2: 0.1808  loss_ce_3: 0.0001626  loss_mask_3: 0.1211  loss_dice_3: 0.1842  loss_ce_4: 9.974e-05  loss_mask_4: 0.1204  loss_dice_4: 0.1801  loss_ce_5: 0.0001352  loss_mask_5: 0.1183  loss_dice_5: 0.1798  loss_ce_6: 0.0001107  loss_mask_6: 0.1174  loss_dice_6: 0.1768  loss_ce_7: 0.00013  loss_mask_7: 0.1223  loss_dice_7: 0.1806  loss_ce_8: 0.0001622  loss_mask_8: 0.1182  loss_dice_8: 0.1792  time: 0.6901  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:27:46] d2.utils.events INFO:  eta: 4:25:20  iter: 15599  total_loss: 3.07  loss_ce: 0.0001866  loss_mask: 0.1163  loss_dice: 0.1738  loss_ce_0: 0.1253  loss_mask_0: 0.1173  loss_dice_0: 0.1762  loss_ce_1: 0.0001696  loss_mask_1: 0.115  loss_dice_1: 0.1808  loss_ce_2: 0.0002297  loss_mask_2: 0.1177  loss_dice_2: 0.1792  loss_ce_3: 0.0002114  loss_mask_3: 0.1161  loss_dice_3: 0.1742  loss_ce_4: 0.0001698  loss_mask_4: 0.1158  loss_dice_4: 0.1793  loss_ce_5: 0.0001852  loss_mask_5: 0.119  loss_dice_5: 0.1771  loss_ce_6: 0.0001353  loss_mask_6: 0.1147  loss_dice_6: 0.1721  loss_ce_7: 0.0001872  loss_mask_7: 0.1153  loss_dice_7: 0.1724  loss_ce_8: 0.0002087  loss_mask_8: 0.1164  loss_dice_8: 0.1773  time: 0.6903  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:28:03] d2.utils.events INFO:  eta: 4:25:30  iter: 15619  total_loss: 3.155  loss_ce: 0.000175  loss_mask: 0.1192  loss_dice: 0.1764  loss_ce_0: 0.1251  loss_mask_0: 0.1163  loss_dice_0: 0.1842  loss_ce_1: 0.0001564  loss_mask_1: 0.1171  loss_dice_1: 0.1756  loss_ce_2: 0.000207  loss_mask_2: 0.1184  loss_dice_2: 0.1838  loss_ce_3: 0.0002077  loss_mask_3: 0.1177  loss_dice_3: 0.1843  loss_ce_4: 0.0001669  loss_mask_4: 0.1213  loss_dice_4: 0.1846  loss_ce_5: 0.0001879  loss_mask_5: 0.1168  loss_dice_5: 0.1822  loss_ce_6: 0.0001482  loss_mask_6: 0.1151  loss_dice_6: 0.1804  loss_ce_7: 0.0002129  loss_mask_7: 0.118  loss_dice_7: 0.1819  loss_ce_8: 0.0002059  loss_mask_8: 0.1157  loss_dice_8: 0.1763  time: 0.6905  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:28:19] d2.utils.events INFO:  eta: 4:25:40  iter: 15639  total_loss: 3.166  loss_ce: 0.000157  loss_mask: 0.1217  loss_dice: 0.181  loss_ce_0: 0.1261  loss_mask_0: 0.1209  loss_dice_0: 0.1805  loss_ce_1: 0.0001332  loss_mask_1: 0.1178  loss_dice_1: 0.1816  loss_ce_2: 0.0001906  loss_mask_2: 0.1213  loss_dice_2: 0.183  loss_ce_3: 0.0001793  loss_mask_3: 0.1201  loss_dice_3: 0.1793  loss_ce_4: 0.0001425  loss_mask_4: 0.1219  loss_dice_4: 0.1876  loss_ce_5: 0.0001551  loss_mask_5: 0.1226  loss_dice_5: 0.1824  loss_ce_6: 0.0001252  loss_mask_6: 0.1188  loss_dice_6: 0.1739  loss_ce_7: 0.0001564  loss_mask_7: 0.1193  loss_dice_7: 0.1856  loss_ce_8: 0.0001769  loss_mask_8: 0.1218  loss_dice_8: 0.178  time: 0.6907  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:28:36] d2.utils.events INFO:  eta: 4:25:58  iter: 15659  total_loss: 3.309  loss_ce: 0.000167  loss_mask: 0.1199  loss_dice: 0.1915  loss_ce_0: 0.1076  loss_mask_0: 0.1271  loss_dice_0: 0.2016  loss_ce_1: 0.0001664  loss_mask_1: 0.1244  loss_dice_1: 0.1936  loss_ce_2: 0.0002015  loss_mask_2: 0.1256  loss_dice_2: 0.1881  loss_ce_3: 0.0001958  loss_mask_3: 0.1216  loss_dice_3: 0.1891  loss_ce_4: 0.0001382  loss_mask_4: 0.1233  loss_dice_4: 0.1982  loss_ce_5: 0.0001992  loss_mask_5: 0.1254  loss_dice_5: 0.1997  loss_ce_6: 0.0001259  loss_mask_6: 0.1204  loss_dice_6: 0.1958  loss_ce_7: 0.0001916  loss_mask_7: 0.1233  loss_dice_7: 0.1966  loss_ce_8: 0.0002037  loss_mask_8: 0.1246  loss_dice_8: 0.1934  time: 0.6909  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:28:53] d2.utils.events INFO:  eta: 4:26:16  iter: 15679  total_loss: 3.227  loss_ce: 0.0001376  loss_mask: 0.1194  loss_dice: 0.1997  loss_ce_0: 0.1396  loss_mask_0: 0.1172  loss_dice_0: 0.1967  loss_ce_1: 0.0001234  loss_mask_1: 0.1154  loss_dice_1: 0.1964  loss_ce_2: 0.00017  loss_mask_2: 0.1169  loss_dice_2: 0.1934  loss_ce_3: 0.0001487  loss_mask_3: 0.1163  loss_dice_3: 0.1967  loss_ce_4: 0.0001023  loss_mask_4: 0.1177  loss_dice_4: 0.1905  loss_ce_5: 0.0001229  loss_mask_5: 0.1163  loss_dice_5: 0.1958  loss_ce_6: 0.0001048  loss_mask_6: 0.119  loss_dice_6: 0.1934  loss_ce_7: 0.0001218  loss_mask_7: 0.1193  loss_dice_7: 0.1987  loss_ce_8: 0.0001476  loss_mask_8: 0.1181  loss_dice_8: 0.19  time: 0.6911  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:29:10] d2.utils.events INFO:  eta: 4:26:10  iter: 15699  total_loss: 3.11  loss_ce: 0.0001308  loss_mask: 0.1212  loss_dice: 0.1828  loss_ce_0: 0.1214  loss_mask_0: 0.1252  loss_dice_0: 0.1811  loss_ce_1: 0.0001187  loss_mask_1: 0.122  loss_dice_1: 0.1759  loss_ce_2: 0.0001616  loss_mask_2: 0.1202  loss_dice_2: 0.1774  loss_ce_3: 0.0001414  loss_mask_3: 0.1269  loss_dice_3: 0.1807  loss_ce_4: 0.0001018  loss_mask_4: 0.1241  loss_dice_4: 0.1787  loss_ce_5: 0.0001161  loss_mask_5: 0.1194  loss_dice_5: 0.1808  loss_ce_6: 9.989e-05  loss_mask_6: 0.1249  loss_dice_6: 0.1797  loss_ce_7: 0.0001134  loss_mask_7: 0.1203  loss_dice_7: 0.1798  loss_ce_8: 0.0001439  loss_mask_8: 0.1216  loss_dice_8: 0.1802  time: 0.6913  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:29:27] d2.utils.events INFO:  eta: 4:26:09  iter: 15719  total_loss: 3.051  loss_ce: 0.0001296  loss_mask: 0.1216  loss_dice: 0.1796  loss_ce_0: 0.1303  loss_mask_0: 0.1202  loss_dice_0: 0.1815  loss_ce_1: 0.0001091  loss_mask_1: 0.1205  loss_dice_1: 0.1729  loss_ce_2: 0.0001618  loss_mask_2: 0.1161  loss_dice_2: 0.1721  loss_ce_3: 0.0001375  loss_mask_3: 0.1222  loss_dice_3: 0.1718  loss_ce_4: 0.0001112  loss_mask_4: 0.1186  loss_dice_4: 0.1737  loss_ce_5: 0.0001159  loss_mask_5: 0.1182  loss_dice_5: 0.1744  loss_ce_6: 9.785e-05  loss_mask_6: 0.1146  loss_dice_6: 0.1696  loss_ce_7: 0.0001168  loss_mask_7: 0.1194  loss_dice_7: 0.1782  loss_ce_8: 0.0001427  loss_mask_8: 0.1206  loss_dice_8: 0.1717  time: 0.6915  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:29:44] d2.utils.events INFO:  eta: 4:26:16  iter: 15739  total_loss: 2.958  loss_ce: 0.0001251  loss_mask: 0.1131  loss_dice: 0.1685  loss_ce_0: 0.123  loss_mask_0: 0.116  loss_dice_0: 0.1764  loss_ce_1: 0.0001039  loss_mask_1: 0.1147  loss_dice_1: 0.1647  loss_ce_2: 0.0001593  loss_mask_2: 0.1141  loss_dice_2: 0.1756  loss_ce_3: 0.0001399  loss_mask_3: 0.1152  loss_dice_3: 0.167  loss_ce_4: 0.000111  loss_mask_4: 0.114  loss_dice_4: 0.1669  loss_ce_5: 0.0001526  loss_mask_5: 0.1171  loss_dice_5: 0.1717  loss_ce_6: 9.034e-05  loss_mask_6: 0.1161  loss_dice_6: 0.1706  loss_ce_7: 0.0001396  loss_mask_7: 0.1162  loss_dice_7: 0.1711  loss_ce_8: 0.000156  loss_mask_8: 0.1168  loss_dice_8: 0.1689  time: 0.6917  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:30:01] d2.utils.events INFO:  eta: 4:26:32  iter: 15759  total_loss: 2.867  loss_ce: 0.0001204  loss_mask: 0.114  loss_dice: 0.159  loss_ce_0: 0.1331  loss_mask_0: 0.1104  loss_dice_0: 0.1667  loss_ce_1: 0.0001024  loss_mask_1: 0.1103  loss_dice_1: 0.1616  loss_ce_2: 0.0001522  loss_mask_2: 0.1113  loss_dice_2: 0.1671  loss_ce_3: 0.000131  loss_mask_3: 0.118  loss_dice_3: 0.1626  loss_ce_4: 0.0001046  loss_mask_4: 0.1115  loss_dice_4: 0.1641  loss_ce_5: 0.0001114  loss_mask_5: 0.1141  loss_dice_5: 0.1629  loss_ce_6: 9.113e-05  loss_mask_6: 0.1092  loss_dice_6: 0.1591  loss_ce_7: 0.000115  loss_mask_7: 0.1089  loss_dice_7: 0.1605  loss_ce_8: 0.0001289  loss_mask_8: 0.1117  loss_dice_8: 0.1598  time: 0.6919  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:30:17] d2.utils.events INFO:  eta: 4:26:42  iter: 15779  total_loss: 3.226  loss_ce: 9.555e-05  loss_mask: 0.1184  loss_dice: 0.1993  loss_ce_0: 0.1268  loss_mask_0: 0.1174  loss_dice_0: 0.186  loss_ce_1: 7.1e-05  loss_mask_1: 0.1183  loss_dice_1: 0.1949  loss_ce_2: 9.454e-05  loss_mask_2: 0.1166  loss_dice_2: 0.1896  loss_ce_3: 8.338e-05  loss_mask_3: 0.1204  loss_dice_3: 0.1862  loss_ce_4: 5.458e-05  loss_mask_4: 0.1145  loss_dice_4: 0.1912  loss_ce_5: 6.821e-05  loss_mask_5: 0.1163  loss_dice_5: 0.191  loss_ce_6: 5.286e-05  loss_mask_6: 0.1151  loss_dice_6: 0.1937  loss_ce_7: 5.986e-05  loss_mask_7: 0.1173  loss_dice_7: 0.1905  loss_ce_8: 9.052e-05  loss_mask_8: 0.1191  loss_dice_8: 0.1867  time: 0.6921  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:30:34] d2.utils.events INFO:  eta: 4:26:37  iter: 15799  total_loss: 3.011  loss_ce: 8.505e-05  loss_mask: 0.1133  loss_dice: 0.1734  loss_ce_0: 0.1234  loss_mask_0: 0.1176  loss_dice_0: 0.1693  loss_ce_1: 6.99e-05  loss_mask_1: 0.1171  loss_dice_1: 0.1712  loss_ce_2: 9.288e-05  loss_mask_2: 0.1198  loss_dice_2: 0.1693  loss_ce_3: 6.564e-05  loss_mask_3: 0.1122  loss_dice_3: 0.1713  loss_ce_4: 5.08e-05  loss_mask_4: 0.1144  loss_dice_4: 0.1745  loss_ce_5: 6.615e-05  loss_mask_5: 0.1165  loss_dice_5: 0.164  loss_ce_6: 4.289e-05  loss_mask_6: 0.1208  loss_dice_6: 0.1687  loss_ce_7: 5.101e-05  loss_mask_7: 0.1134  loss_dice_7: 0.1639  loss_ce_8: 7.96e-05  loss_mask_8: 0.1188  loss_dice_8: 0.1672  time: 0.6923  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:30:51] d2.utils.events INFO:  eta: 4:26:51  iter: 15819  total_loss: 3.039  loss_ce: 8.425e-05  loss_mask: 0.1113  loss_dice: 0.1733  loss_ce_0: 0.1208  loss_mask_0: 0.1118  loss_dice_0: 0.1784  loss_ce_1: 8.765e-05  loss_mask_1: 0.1137  loss_dice_1: 0.1826  loss_ce_2: 0.0001435  loss_mask_2: 0.114  loss_dice_2: 0.185  loss_ce_3: 0.0001099  loss_mask_3: 0.1146  loss_dice_3: 0.1798  loss_ce_4: 5.829e-05  loss_mask_4: 0.1128  loss_dice_4: 0.1779  loss_ce_5: 7.507e-05  loss_mask_5: 0.1113  loss_dice_5: 0.1776  loss_ce_6: 4.569e-05  loss_mask_6: 0.1133  loss_dice_6: 0.1815  loss_ce_7: 6.139e-05  loss_mask_7: 0.1144  loss_dice_7: 0.1763  loss_ce_8: 9.645e-05  loss_mask_8: 0.1117  loss_dice_8: 0.1822  time: 0.6924  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 20:31:08] d2.utils.events INFO:  eta: 4:26:55  iter: 15839  total_loss: 2.929  loss_ce: 0.0002718  loss_mask: 0.1177  loss_dice: 0.1682  loss_ce_0: 0.1191  loss_mask_0: 0.1157  loss_dice_0: 0.1675  loss_ce_1: 0.0003634  loss_mask_1: 0.113  loss_dice_1: 0.1643  loss_ce_2: 0.0004177  loss_mask_2: 0.115  loss_dice_2: 0.1632  loss_ce_3: 0.0007982  loss_mask_3: 0.1144  loss_dice_3: 0.1537  loss_ce_4: 0.0001631  loss_mask_4: 0.1159  loss_dice_4: 0.1674  loss_ce_5: 0.0002543  loss_mask_5: 0.1156  loss_dice_5: 0.1681  loss_ce_6: 0.0001971  loss_mask_6: 0.114  loss_dice_6: 0.1623  loss_ce_7: 0.0003044  loss_mask_7: 0.1163  loss_dice_7: 0.1613  loss_ce_8: 0.000292  loss_mask_8: 0.1145  loss_dice_8: 0.1587  time: 0.6926  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:31:25] d2.utils.events INFO:  eta: 4:26:56  iter: 15859  total_loss: 2.851  loss_ce: 0.0001578  loss_mask: 0.1067  loss_dice: 0.1636  loss_ce_0: 0.1176  loss_mask_0: 0.1114  loss_dice_0: 0.1711  loss_ce_1: 0.0002148  loss_mask_1: 0.1093  loss_dice_1: 0.1748  loss_ce_2: 0.0006373  loss_mask_2: 0.1097  loss_dice_2: 0.1762  loss_ce_3: 0.0006843  loss_mask_3: 0.1104  loss_dice_3: 0.168  loss_ce_4: 6.698e-05  loss_mask_4: 0.106  loss_dice_4: 0.173  loss_ce_5: 0.0001563  loss_mask_5: 0.1061  loss_dice_5: 0.165  loss_ce_6: 0.0001492  loss_mask_6: 0.1133  loss_dice_6: 0.1694  loss_ce_7: 0.0001694  loss_mask_7: 0.1068  loss_dice_7: 0.1664  loss_ce_8: 0.00015  loss_mask_8: 0.1051  loss_dice_8: 0.166  time: 0.6928  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:31:42] d2.utils.events INFO:  eta: 4:27:00  iter: 15879  total_loss: 2.928  loss_ce: 0.0001979  loss_mask: 0.1142  loss_dice: 0.1638  loss_ce_0: 0.1233  loss_mask_0: 0.1186  loss_dice_0: 0.1631  loss_ce_1: 0.000232  loss_mask_1: 0.1158  loss_dice_1: 0.1647  loss_ce_2: 0.0003994  loss_mask_2: 0.1122  loss_dice_2: 0.1602  loss_ce_3: 0.0003604  loss_mask_3: 0.1151  loss_dice_3: 0.16  loss_ce_4: 0.0001811  loss_mask_4: 0.115  loss_dice_4: 0.1629  loss_ce_5: 0.0002628  loss_mask_5: 0.1147  loss_dice_5: 0.1662  loss_ce_6: 0.0001807  loss_mask_6: 0.1132  loss_dice_6: 0.1625  loss_ce_7: 0.0001987  loss_mask_7: 0.1156  loss_dice_7: 0.1637  loss_ce_8: 0.0002624  loss_mask_8: 0.1175  loss_dice_8: 0.1692  time: 0.6930  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:31:59] d2.utils.events INFO:  eta: 4:27:05  iter: 15899  total_loss: 3.101  loss_ce: 0.0001902  loss_mask: 0.1208  loss_dice: 0.1767  loss_ce_0: 0.1212  loss_mask_0: 0.1197  loss_dice_0: 0.1834  loss_ce_1: 0.0001579  loss_mask_1: 0.1224  loss_dice_1: 0.1789  loss_ce_2: 0.0002825  loss_mask_2: 0.1202  loss_dice_2: 0.1778  loss_ce_3: 0.000238  loss_mask_3: 0.1256  loss_dice_3: 0.1896  loss_ce_4: 0.0001563  loss_mask_4: 0.1181  loss_dice_4: 0.1771  loss_ce_5: 0.0002168  loss_mask_5: 0.1247  loss_dice_5: 0.1798  loss_ce_6: 0.0001869  loss_mask_6: 0.1228  loss_dice_6: 0.1745  loss_ce_7: 0.000151  loss_mask_7: 0.118  loss_dice_7: 0.1778  loss_ce_8: 0.0002135  loss_mask_8: 0.1198  loss_dice_8: 0.1752  time: 0.6932  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:32:16] d2.utils.events INFO:  eta: 4:27:03  iter: 15919  total_loss: 2.895  loss_ce: 0.0001212  loss_mask: 0.1132  loss_dice: 0.1678  loss_ce_0: 0.1233  loss_mask_0: 0.1127  loss_dice_0: 0.1665  loss_ce_1: 0.0001634  loss_mask_1: 0.1136  loss_dice_1: 0.169  loss_ce_2: 0.0002429  loss_mask_2: 0.1104  loss_dice_2: 0.168  loss_ce_3: 0.0001898  loss_mask_3: 0.1111  loss_dice_3: 0.1697  loss_ce_4: 0.0001214  loss_mask_4: 0.1104  loss_dice_4: 0.1652  loss_ce_5: 0.0001717  loss_mask_5: 0.1088  loss_dice_5: 0.1669  loss_ce_6: 0.0001396  loss_mask_6: 0.113  loss_dice_6: 0.1729  loss_ce_7: 0.0001302  loss_mask_7: 0.1122  loss_dice_7: 0.1711  loss_ce_8: 0.0001609  loss_mask_8: 0.1139  loss_dice_8: 0.168  time: 0.6934  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:32:33] d2.utils.events INFO:  eta: 4:27:19  iter: 15939  total_loss: 3.112  loss_ce: 9.872e-05  loss_mask: 0.1165  loss_dice: 0.1766  loss_ce_0: 0.1249  loss_mask_0: 0.117  loss_dice_0: 0.1847  loss_ce_1: 0.0001325  loss_mask_1: 0.1149  loss_dice_1: 0.1794  loss_ce_2: 0.0001999  loss_mask_2: 0.1157  loss_dice_2: 0.1784  loss_ce_3: 0.0001452  loss_mask_3: 0.1156  loss_dice_3: 0.1819  loss_ce_4: 5.404e-05  loss_mask_4: 0.1127  loss_dice_4: 0.1835  loss_ce_5: 0.0001331  loss_mask_5: 0.1192  loss_dice_5: 0.1769  loss_ce_6: 9.65e-05  loss_mask_6: 0.1185  loss_dice_6: 0.1756  loss_ce_7: 0.0001058  loss_mask_7: 0.1109  loss_dice_7: 0.1792  loss_ce_8: 0.0001279  loss_mask_8: 0.1168  loss_dice_8: 0.1796  time: 0.6936  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:32:50] d2.utils.events INFO:  eta: 4:27:06  iter: 15959  total_loss: 2.97  loss_ce: 0.0001195  loss_mask: 0.1131  loss_dice: 0.1602  loss_ce_0: 0.1253  loss_mask_0: 0.1154  loss_dice_0: 0.1654  loss_ce_1: 0.0001712  loss_mask_1: 0.11  loss_dice_1: 0.1517  loss_ce_2: 0.0002227  loss_mask_2: 0.1148  loss_dice_2: 0.1625  loss_ce_3: 0.0001744  loss_mask_3: 0.118  loss_dice_3: 0.164  loss_ce_4: 0.0001093  loss_mask_4: 0.118  loss_dice_4: 0.1643  loss_ce_5: 0.0001727  loss_mask_5: 0.1163  loss_dice_5: 0.1679  loss_ce_6: 0.0001324  loss_mask_6: 0.1141  loss_dice_6: 0.1659  loss_ce_7: 0.0001355  loss_mask_7: 0.1186  loss_dice_7: 0.1668  loss_ce_8: 0.0001661  loss_mask_8: 0.1135  loss_dice_8: 0.1599  time: 0.6938  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:33:06] d2.utils.events INFO:  eta: 4:26:57  iter: 15979  total_loss: 3.034  loss_ce: 0.001506  loss_mask: 0.1185  loss_dice: 0.1696  loss_ce_0: 0.125  loss_mask_0: 0.1181  loss_dice_0: 0.1683  loss_ce_1: 0.0006061  loss_mask_1: 0.1195  loss_dice_1: 0.1736  loss_ce_2: 0.001091  loss_mask_2: 0.1194  loss_dice_2: 0.172  loss_ce_3: 0.0009659  loss_mask_3: 0.119  loss_dice_3: 0.1745  loss_ce_4: 0.0005719  loss_mask_4: 0.1164  loss_dice_4: 0.1762  loss_ce_5: 0.001373  loss_mask_5: 0.1143  loss_dice_5: 0.1666  loss_ce_6: 0.001337  loss_mask_6: 0.1154  loss_dice_6: 0.166  loss_ce_7: 0.001315  loss_mask_7: 0.1171  loss_dice_7: 0.1683  loss_ce_8: 0.001427  loss_mask_8: 0.1154  loss_dice_8: 0.1679  time: 0.6940  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:33:23] d2.utils.events INFO:  eta: 4:27:01  iter: 15999  total_loss: 2.848  loss_ce: 0.0002376  loss_mask: 0.1142  loss_dice: 0.1581  loss_ce_0: 0.1261  loss_mask_0: 0.1132  loss_dice_0: 0.1572  loss_ce_1: 0.0001793  loss_mask_1: 0.1135  loss_dice_1: 0.164  loss_ce_2: 0.0002616  loss_mask_2: 0.1132  loss_dice_2: 0.1624  loss_ce_3: 0.000242  loss_mask_3: 0.1116  loss_dice_3: 0.1599  loss_ce_4: 0.000248  loss_mask_4: 0.1166  loss_dice_4: 0.1598  loss_ce_5: 0.0003761  loss_mask_5: 0.1118  loss_dice_5: 0.1605  loss_ce_6: 0.0002294  loss_mask_6: 0.1131  loss_dice_6: 0.1571  loss_ce_7: 0.0002943  loss_mask_7: 0.1145  loss_dice_7: 0.1626  loss_ce_8: 0.0003223  loss_mask_8: 0.1124  loss_dice_8: 0.1601  time: 0.6942  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:33:40] d2.utils.events INFO:  eta: 4:26:48  iter: 16019  total_loss: 2.93  loss_ce: 0.0003593  loss_mask: 0.1133  loss_dice: 0.1677  loss_ce_0: 0.1185  loss_mask_0: 0.1138  loss_dice_0: 0.1648  loss_ce_1: 0.0002244  loss_mask_1: 0.1146  loss_dice_1: 0.1659  loss_ce_2: 0.0003749  loss_mask_2: 0.1162  loss_dice_2: 0.1607  loss_ce_3: 0.0002831  loss_mask_3: 0.1143  loss_dice_3: 0.1612  loss_ce_4: 0.0001918  loss_mask_4: 0.1108  loss_dice_4: 0.1609  loss_ce_5: 0.0004046  loss_mask_5: 0.1165  loss_dice_5: 0.1656  loss_ce_6: 0.0003653  loss_mask_6: 0.1163  loss_dice_6: 0.1683  loss_ce_7: 0.0003664  loss_mask_7: 0.1157  loss_dice_7: 0.1634  loss_ce_8: 0.0004575  loss_mask_8: 0.1146  loss_dice_8: 0.1628  time: 0.6943  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:33:57] d2.utils.events INFO:  eta: 4:26:32  iter: 16039  total_loss: 2.943  loss_ce: 0.0002171  loss_mask: 0.1145  loss_dice: 0.1717  loss_ce_0: 0.1318  loss_mask_0: 0.122  loss_dice_0: 0.1779  loss_ce_1: 0.0001621  loss_mask_1: 0.1155  loss_dice_1: 0.1733  loss_ce_2: 0.0002107  loss_mask_2: 0.1172  loss_dice_2: 0.1763  loss_ce_3: 0.0002038  loss_mask_3: 0.1165  loss_dice_3: 0.1802  loss_ce_4: 0.000188  loss_mask_4: 0.1176  loss_dice_4: 0.1779  loss_ce_5: 0.0002483  loss_mask_5: 0.1124  loss_dice_5: 0.1654  loss_ce_6: 0.0001855  loss_mask_6: 0.1217  loss_dice_6: 0.1749  loss_ce_7: 0.0002389  loss_mask_7: 0.1164  loss_dice_7: 0.1703  loss_ce_8: 0.0002397  loss_mask_8: 0.1152  loss_dice_8: 0.1742  time: 0.6945  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:34:14] d2.utils.events INFO:  eta: 4:26:19  iter: 16059  total_loss: 2.852  loss_ce: 0.0001682  loss_mask: 0.1121  loss_dice: 0.1636  loss_ce_0: 0.1266  loss_mask_0: 0.1077  loss_dice_0: 0.1695  loss_ce_1: 0.0001448  loss_mask_1: 0.1152  loss_dice_1: 0.1721  loss_ce_2: 0.0001896  loss_mask_2: 0.1124  loss_dice_2: 0.1647  loss_ce_3: 0.0001761  loss_mask_3: 0.1122  loss_dice_3: 0.1644  loss_ce_4: 0.0001626  loss_mask_4: 0.1116  loss_dice_4: 0.1671  loss_ce_5: 0.0002207  loss_mask_5: 0.1124  loss_dice_5: 0.1651  loss_ce_6: 0.000151  loss_mask_6: 0.1118  loss_dice_6: 0.1635  loss_ce_7: 0.000193  loss_mask_7: 0.1159  loss_dice_7: 0.1708  loss_ce_8: 0.0002072  loss_mask_8: 0.1116  loss_dice_8: 0.1622  time: 0.6947  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:34:31] d2.utils.events INFO:  eta: 4:26:09  iter: 16079  total_loss: 3.011  loss_ce: 0.0001297  loss_mask: 0.1158  loss_dice: 0.1782  loss_ce_0: 0.129  loss_mask_0: 0.1119  loss_dice_0: 0.1818  loss_ce_1: 8.134e-05  loss_mask_1: 0.1086  loss_dice_1: 0.1775  loss_ce_2: 0.0001273  loss_mask_2: 0.1117  loss_dice_2: 0.173  loss_ce_3: 0.0001257  loss_mask_3: 0.1092  loss_dice_3: 0.1762  loss_ce_4: 5.469e-05  loss_mask_4: 0.1129  loss_dice_4: 0.1836  loss_ce_5: 0.0001337  loss_mask_5: 0.1137  loss_dice_5: 0.179  loss_ce_6: 0.0001224  loss_mask_6: 0.1116  loss_dice_6: 0.1724  loss_ce_7: 9.778e-05  loss_mask_7: 0.1114  loss_dice_7: 0.177  loss_ce_8: 0.000114  loss_mask_8: 0.1114  loss_dice_8: 0.1725  time: 0.6949  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:34:48] d2.utils.events INFO:  eta: 4:25:52  iter: 16099  total_loss: 3.121  loss_ce: 0.0001186  loss_mask: 0.1169  loss_dice: 0.1839  loss_ce_0: 0.1221  loss_mask_0: 0.1174  loss_dice_0: 0.1851  loss_ce_1: 0.0001249  loss_mask_1: 0.1129  loss_dice_1: 0.1778  loss_ce_2: 0.0001666  loss_mask_2: 0.114  loss_dice_2: 0.1757  loss_ce_3: 0.0001546  loss_mask_3: 0.1127  loss_dice_3: 0.1787  loss_ce_4: 0.0001356  loss_mask_4: 0.1145  loss_dice_4: 0.1828  loss_ce_5: 0.0001647  loss_mask_5: 0.1155  loss_dice_5: 0.1761  loss_ce_6: 0.0001299  loss_mask_6: 0.1155  loss_dice_6: 0.1789  loss_ce_7: 0.0001541  loss_mask_7: 0.1179  loss_dice_7: 0.1736  loss_ce_8: 0.0001399  loss_mask_8: 0.1162  loss_dice_8: 0.1788  time: 0.6951  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 20:35:05] d2.utils.events INFO:  eta: 4:25:33  iter: 16119  total_loss: 3.021  loss_ce: 0.0001482  loss_mask: 0.1141  loss_dice: 0.1727  loss_ce_0: 0.1274  loss_mask_0: 0.1136  loss_dice_0: 0.1769  loss_ce_1: 0.0001292  loss_mask_1: 0.1106  loss_dice_1: 0.1751  loss_ce_2: 0.0001672  loss_mask_2: 0.1104  loss_dice_2: 0.1658  loss_ce_3: 0.0001546  loss_mask_3: 0.1098  loss_dice_3: 0.1707  loss_ce_4: 0.0001281  loss_mask_4: 0.1113  loss_dice_4: 0.1734  loss_ce_5: 0.0001791  loss_mask_5: 0.1122  loss_dice_5: 0.1687  loss_ce_6: 0.000181  loss_mask_6: 0.1095  loss_dice_6: 0.1674  loss_ce_7: 0.0001642  loss_mask_7: 0.1132  loss_dice_7: 0.1763  loss_ce_8: 0.0001676  loss_mask_8: 0.1144  loss_dice_8: 0.1729  time: 0.6953  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:35:21] d2.utils.events INFO:  eta: 4:25:07  iter: 16139  total_loss: 3.036  loss_ce: 0.0001081  loss_mask: 0.1184  loss_dice: 0.1793  loss_ce_0: 0.1258  loss_mask_0: 0.1151  loss_dice_0: 0.1786  loss_ce_1: 0.0001312  loss_mask_1: 0.1165  loss_dice_1: 0.1716  loss_ce_2: 0.0001569  loss_mask_2: 0.1157  loss_dice_2: 0.1754  loss_ce_3: 0.0001331  loss_mask_3: 0.1187  loss_dice_3: 0.1735  loss_ce_4: 0.0001348  loss_mask_4: 0.1168  loss_dice_4: 0.1685  loss_ce_5: 0.0001198  loss_mask_5: 0.117  loss_dice_5: 0.1707  loss_ce_6: 0.0001429  loss_mask_6: 0.1179  loss_dice_6: 0.1724  loss_ce_7: 0.0001389  loss_mask_7: 0.1145  loss_dice_7: 0.1735  loss_ce_8: 0.000117  loss_mask_8: 0.1166  loss_dice_8: 0.1776  time: 0.6954  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:35:38] d2.utils.events INFO:  eta: 4:24:46  iter: 16159  total_loss: 3.032  loss_ce: 0.0001137  loss_mask: 0.1115  loss_dice: 0.1735  loss_ce_0: 0.1232  loss_mask_0: 0.1129  loss_dice_0: 0.182  loss_ce_1: 0.0001259  loss_mask_1: 0.1112  loss_dice_1: 0.1799  loss_ce_2: 0.000163  loss_mask_2: 0.1145  loss_dice_2: 0.1738  loss_ce_3: 0.0001323  loss_mask_3: 0.1135  loss_dice_3: 0.1821  loss_ce_4: 0.0001133  loss_mask_4: 0.112  loss_dice_4: 0.1715  loss_ce_5: 0.0001378  loss_mask_5: 0.1144  loss_dice_5: 0.1795  loss_ce_6: 0.0001494  loss_mask_6: 0.1137  loss_dice_6: 0.1682  loss_ce_7: 0.000144  loss_mask_7: 0.1145  loss_dice_7: 0.1738  loss_ce_8: 0.0001351  loss_mask_8: 0.1137  loss_dice_8: 0.1729  time: 0.6956  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 20:35:54] d2.utils.events INFO:  eta: 4:24:19  iter: 16179  total_loss: 3.023  loss_ce: 0.0001296  loss_mask: 0.1176  loss_dice: 0.1765  loss_ce_0: 0.1253  loss_mask_0: 0.121  loss_dice_0: 0.1732  loss_ce_1: 0.0001231  loss_mask_1: 0.1169  loss_dice_1: 0.1738  loss_ce_2: 0.0001719  loss_mask_2: 0.1142  loss_dice_2: 0.1685  loss_ce_3: 0.0001372  loss_mask_3: 0.1169  loss_dice_3: 0.1754  loss_ce_4: 0.0001271  loss_mask_4: 0.1209  loss_dice_4: 0.1787  loss_ce_5: 0.0001533  loss_mask_5: 0.1186  loss_dice_5: 0.1766  loss_ce_6: 0.0001303  loss_mask_6: 0.1168  loss_dice_6: 0.1701  loss_ce_7: 0.0001417  loss_mask_7: 0.1209  loss_dice_7: 0.1779  loss_ce_8: 0.0001506  loss_mask_8: 0.1137  loss_dice_8: 0.1774  time: 0.6958  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:36:10] d2.utils.events INFO:  eta: 4:23:51  iter: 16199  total_loss: 2.963  loss_ce: 8.044e-05  loss_mask: 0.1139  loss_dice: 0.1708  loss_ce_0: 0.1283  loss_mask_0: 0.1139  loss_dice_0: 0.1672  loss_ce_1: 9.835e-05  loss_mask_1: 0.1123  loss_dice_1: 0.1664  loss_ce_2: 0.0001323  loss_mask_2: 0.116  loss_dice_2: 0.1721  loss_ce_3: 0.000109  loss_mask_3: 0.1139  loss_dice_3: 0.1683  loss_ce_4: 0.0001167  loss_mask_4: 0.1109  loss_dice_4: 0.1665  loss_ce_5: 9.745e-05  loss_mask_5: 0.114  loss_dice_5: 0.1672  loss_ce_6: 0.0001029  loss_mask_6: 0.1172  loss_dice_6: 0.1699  loss_ce_7: 0.0001019  loss_mask_7: 0.1139  loss_dice_7: 0.1691  loss_ce_8: 9.686e-05  loss_mask_8: 0.1126  loss_dice_8: 0.169  time: 0.6959  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:36:27] d2.utils.events INFO:  eta: 4:23:27  iter: 16219  total_loss: 3.204  loss_ce: 8.563e-05  loss_mask: 0.1242  loss_dice: 0.1805  loss_ce_0: 0.1307  loss_mask_0: 0.1211  loss_dice_0: 0.1775  loss_ce_1: 9.236e-05  loss_mask_1: 0.1264  loss_dice_1: 0.1899  loss_ce_2: 0.0001283  loss_mask_2: 0.1255  loss_dice_2: 0.1867  loss_ce_3: 0.0001081  loss_mask_3: 0.1234  loss_dice_3: 0.1816  loss_ce_4: 0.0001032  loss_mask_4: 0.1221  loss_dice_4: 0.1796  loss_ce_5: 9.333e-05  loss_mask_5: 0.1223  loss_dice_5: 0.1796  loss_ce_6: 9.336e-05  loss_mask_6: 0.1231  loss_dice_6: 0.1773  loss_ce_7: 0.0001035  loss_mask_7: 0.1218  loss_dice_7: 0.1804  loss_ce_8: 9.41e-05  loss_mask_8: 0.1272  loss_dice_8: 0.1853  time: 0.6960  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 20:36:43] d2.utils.events INFO:  eta: 4:22:52  iter: 16239  total_loss: 3.058  loss_ce: 9.718e-05  loss_mask: 0.1178  loss_dice: 0.1763  loss_ce_0: 0.1312  loss_mask_0: 0.1211  loss_dice_0: 0.1812  loss_ce_1: 7.706e-05  loss_mask_1: 0.1195  loss_dice_1: 0.1716  loss_ce_2: 0.0001128  loss_mask_2: 0.1167  loss_dice_2: 0.1751  loss_ce_3: 0.0001112  loss_mask_3: 0.122  loss_dice_3: 0.1806  loss_ce_4: 6.47e-05  loss_mask_4: 0.1241  loss_dice_4: 0.1858  loss_ce_5: 0.0001034  loss_mask_5: 0.1173  loss_dice_5: 0.177  loss_ce_6: 8.544e-05  loss_mask_6: 0.1171  loss_dice_6: 0.1758  loss_ce_7: 8.512e-05  loss_mask_7: 0.1215  loss_dice_7: 0.1716  loss_ce_8: 9.495e-05  loss_mask_8: 0.1178  loss_dice_8: 0.1829  time: 0.6962  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:36:59] d2.utils.events INFO:  eta: 4:22:23  iter: 16259  total_loss: 2.895  loss_ce: 6.807e-05  loss_mask: 0.1136  loss_dice: 0.161  loss_ce_0: 0.1246  loss_mask_0: 0.114  loss_dice_0: 0.1654  loss_ce_1: 4.943e-05  loss_mask_1: 0.113  loss_dice_1: 0.1594  loss_ce_2: 9.913e-05  loss_mask_2: 0.1157  loss_dice_2: 0.1635  loss_ce_3: 9.881e-05  loss_mask_3: 0.1139  loss_dice_3: 0.1636  loss_ce_4: 3.439e-05  loss_mask_4: 0.1156  loss_dice_4: 0.164  loss_ce_5: 7.58e-05  loss_mask_5: 0.1143  loss_dice_5: 0.1615  loss_ce_6: 5.462e-05  loss_mask_6: 0.1128  loss_dice_6: 0.1629  loss_ce_7: 5.857e-05  loss_mask_7: 0.1116  loss_dice_7: 0.1605  loss_ce_8: 6.92e-05  loss_mask_8: 0.1143  loss_dice_8: 0.1633  time: 0.6963  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:37:16] d2.utils.events INFO:  eta: 4:21:57  iter: 16279  total_loss: 2.884  loss_ce: 6.567e-05  loss_mask: 0.1093  loss_dice: 0.1612  loss_ce_0: 0.1251  loss_mask_0: 0.1181  loss_dice_0: 0.1628  loss_ce_1: 6.8e-05  loss_mask_1: 0.1148  loss_dice_1: 0.1651  loss_ce_2: 9.691e-05  loss_mask_2: 0.1147  loss_dice_2: 0.1692  loss_ce_3: 8.145e-05  loss_mask_3: 0.1145  loss_dice_3: 0.1671  loss_ce_4: 6.278e-05  loss_mask_4: 0.1097  loss_dice_4: 0.1649  loss_ce_5: 7.927e-05  loss_mask_5: 0.1113  loss_dice_5: 0.1614  loss_ce_6: 6.294e-05  loss_mask_6: 0.1135  loss_dice_6: 0.1663  loss_ce_7: 7.072e-05  loss_mask_7: 0.1156  loss_dice_7: 0.1621  loss_ce_8: 7.486e-05  loss_mask_8: 0.1136  loss_dice_8: 0.1618  time: 0.6965  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 20:37:32] d2.utils.events INFO:  eta: 4:21:22  iter: 16299  total_loss: 3.062  loss_ce: 6.117e-05  loss_mask: 0.118  loss_dice: 0.1798  loss_ce_0: 0.1257  loss_mask_0: 0.121  loss_dice_0: 0.1702  loss_ce_1: 4.714e-05  loss_mask_1: 0.1141  loss_dice_1: 0.1751  loss_ce_2: 7.688e-05  loss_mask_2: 0.1155  loss_dice_2: 0.1751  loss_ce_3: 7.523e-05  loss_mask_3: 0.1145  loss_dice_3: 0.1737  loss_ce_4: 3.258e-05  loss_mask_4: 0.1169  loss_dice_4: 0.1707  loss_ce_5: 7.068e-05  loss_mask_5: 0.1141  loss_dice_5: 0.1743  loss_ce_6: 4.365e-05  loss_mask_6: 0.1185  loss_dice_6: 0.1753  loss_ce_7: 5.412e-05  loss_mask_7: 0.1176  loss_dice_7: 0.1738  loss_ce_8: 6.193e-05  loss_mask_8: 0.1172  loss_dice_8: 0.1748  time: 0.6966  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:37:48] d2.utils.events INFO:  eta: 4:20:49  iter: 16319  total_loss: 3.053  loss_ce: 7.021e-05  loss_mask: 0.1195  loss_dice: 0.1681  loss_ce_0: 0.1194  loss_mask_0: 0.1236  loss_dice_0: 0.177  loss_ce_1: 8.71e-05  loss_mask_1: 0.1184  loss_dice_1: 0.169  loss_ce_2: 0.0001116  loss_mask_2: 0.119  loss_dice_2: 0.1723  loss_ce_3: 8.992e-05  loss_mask_3: 0.1226  loss_dice_3: 0.1711  loss_ce_4: 8.506e-05  loss_mask_4: 0.1209  loss_dice_4: 0.1773  loss_ce_5: 8.408e-05  loss_mask_5: 0.1177  loss_dice_5: 0.1647  loss_ce_6: 7.858e-05  loss_mask_6: 0.1154  loss_dice_6: 0.1653  loss_ce_7: 8.574e-05  loss_mask_7: 0.1179  loss_dice_7: 0.1702  loss_ce_8: 8.245e-05  loss_mask_8: 0.1186  loss_dice_8: 0.1745  time: 0.6967  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:38:02] d2.utils.events INFO:  eta: 4:20:20  iter: 16339  total_loss: 2.933  loss_ce: 9.838e-05  loss_mask: 0.1129  loss_dice: 0.1641  loss_ce_0: 0.1262  loss_mask_0: 0.1132  loss_dice_0: 0.1665  loss_ce_1: 8.607e-05  loss_mask_1: 0.1121  loss_dice_1: 0.1732  loss_ce_2: 0.0001267  loss_mask_2: 0.1127  loss_dice_2: 0.1721  loss_ce_3: 0.0001035  loss_mask_3: 0.1119  loss_dice_3: 0.165  loss_ce_4: 9.174e-05  loss_mask_4: 0.1114  loss_dice_4: 0.168  loss_ce_5: 0.0001167  loss_mask_5: 0.1147  loss_dice_5: 0.1676  loss_ce_6: 8.356e-05  loss_mask_6: 0.1161  loss_dice_6: 0.1689  loss_ce_7: 0.0001003  loss_mask_7: 0.1152  loss_dice_7: 0.1687  loss_ce_8: 0.0001122  loss_mask_8: 0.115  loss_dice_8: 0.1738  time: 0.6968  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:38:17] d2.utils.events INFO:  eta: 4:19:51  iter: 16359  total_loss: 3.022  loss_ce: 7.719e-05  loss_mask: 0.1148  loss_dice: 0.1769  loss_ce_0: 0.1214  loss_mask_0: 0.1126  loss_dice_0: 0.1765  loss_ce_1: 8.709e-05  loss_mask_1: 0.1153  loss_dice_1: 0.1768  loss_ce_2: 0.0001114  loss_mask_2: 0.1101  loss_dice_2: 0.1757  loss_ce_3: 8.992e-05  loss_mask_3: 0.1154  loss_dice_3: 0.1762  loss_ce_4: 9.077e-05  loss_mask_4: 0.117  loss_dice_4: 0.1747  loss_ce_5: 9.272e-05  loss_mask_5: 0.1137  loss_dice_5: 0.1795  loss_ce_6: 9.508e-05  loss_mask_6: 0.1093  loss_dice_6: 0.1799  loss_ce_7: 9.284e-05  loss_mask_7: 0.1125  loss_dice_7: 0.1781  loss_ce_8: 9.086e-05  loss_mask_8: 0.1161  loss_dice_8: 0.1807  time: 0.6968  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:38:32] d2.utils.events INFO:  eta: 4:19:09  iter: 16379  total_loss: 2.916  loss_ce: 6.011e-05  loss_mask: 0.1124  loss_dice: 0.1716  loss_ce_0: 0.1286  loss_mask_0: 0.1135  loss_dice_0: 0.168  loss_ce_1: 7.06e-05  loss_mask_1: 0.1139  loss_dice_1: 0.1684  loss_ce_2: 9.941e-05  loss_mask_2: 0.1059  loss_dice_2: 0.1636  loss_ce_3: 8.089e-05  loss_mask_3: 0.1127  loss_dice_3: 0.1674  loss_ce_4: 8.292e-05  loss_mask_4: 0.1122  loss_dice_4: 0.1625  loss_ce_5: 7.518e-05  loss_mask_5: 0.1129  loss_dice_5: 0.1678  loss_ce_6: 7.3e-05  loss_mask_6: 0.1114  loss_dice_6: 0.1665  loss_ce_7: 7.772e-05  loss_mask_7: 0.1165  loss_dice_7: 0.1678  loss_ce_8: 7.439e-05  loss_mask_8: 0.1098  loss_dice_8: 0.1598  time: 0.6969  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:38:47] d2.utils.events INFO:  eta: 4:18:27  iter: 16399  total_loss: 3.125  loss_ce: 7.042e-05  loss_mask: 0.119  loss_dice: 0.1837  loss_ce_0: 0.1268  loss_mask_0: 0.1117  loss_dice_0: 0.1812  loss_ce_1: 7.522e-05  loss_mask_1: 0.123  loss_dice_1: 0.1825  loss_ce_2: 0.0001051  loss_mask_2: 0.1142  loss_dice_2: 0.1804  loss_ce_3: 8.456e-05  loss_mask_3: 0.1147  loss_dice_3: 0.1782  loss_ce_4: 8.091e-05  loss_mask_4: 0.1143  loss_dice_4: 0.1817  loss_ce_5: 8.69e-05  loss_mask_5: 0.1135  loss_dice_5: 0.1763  loss_ce_6: 7.058e-05  loss_mask_6: 0.1179  loss_dice_6: 0.1796  loss_ce_7: 7.988e-05  loss_mask_7: 0.1192  loss_dice_7: 0.1824  loss_ce_8: 8.482e-05  loss_mask_8: 0.1173  loss_dice_8: 0.1797  time: 0.6970  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:39:02] d2.utils.events INFO:  eta: 4:17:54  iter: 16419  total_loss: 3.129  loss_ce: 7.375e-05  loss_mask: 0.1133  loss_dice: 0.1825  loss_ce_0: 0.1265  loss_mask_0: 0.1149  loss_dice_0: 0.1858  loss_ce_1: 7.394e-05  loss_mask_1: 0.1163  loss_dice_1: 0.1909  loss_ce_2: 0.000103  loss_mask_2: 0.1199  loss_dice_2: 0.1834  loss_ce_3: 8.387e-05  loss_mask_3: 0.1193  loss_dice_3: 0.1891  loss_ce_4: 7.497e-05  loss_mask_4: 0.1155  loss_dice_4: 0.1849  loss_ce_5: 9.379e-05  loss_mask_5: 0.118  loss_dice_5: 0.1804  loss_ce_6: 6.155e-05  loss_mask_6: 0.1195  loss_dice_6: 0.1826  loss_ce_7: 7.835e-05  loss_mask_7: 0.1166  loss_dice_7: 0.1808  loss_ce_8: 8.954e-05  loss_mask_8: 0.1191  loss_dice_8: 0.1857  time: 0.6970  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 20:39:17] d2.utils.events INFO:  eta: 4:17:18  iter: 16439  total_loss: 3.321  loss_ce: 5.387e-05  loss_mask: 0.1217  loss_dice: 0.1912  loss_ce_0: 0.1261  loss_mask_0: 0.1283  loss_dice_0: 0.1978  loss_ce_1: 5.398e-05  loss_mask_1: 0.1274  loss_dice_1: 0.1893  loss_ce_2: 7.674e-05  loss_mask_2: 0.1271  loss_dice_2: 0.1898  loss_ce_3: 6.721e-05  loss_mask_3: 0.1242  loss_dice_3: 0.1919  loss_ce_4: 5.118e-05  loss_mask_4: 0.1258  loss_dice_4: 0.1918  loss_ce_5: 6.257e-05  loss_mask_5: 0.1241  loss_dice_5: 0.1946  loss_ce_6: 4.734e-05  loss_mask_6: 0.1207  loss_dice_6: 0.1845  loss_ce_7: 5.636e-05  loss_mask_7: 0.1255  loss_dice_7: 0.1885  loss_ce_8: 5.866e-05  loss_mask_8: 0.1269  loss_dice_8: 0.195  time: 0.6970  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:39:31] d2.utils.events INFO:  eta: 4:16:33  iter: 16459  total_loss: 3.362  loss_ce: 0.002318  loss_mask: 0.1124  loss_dice: 0.1753  loss_ce_0: 0.1227  loss_mask_0: 0.1128  loss_dice_0: 0.1811  loss_ce_1: 0.0008906  loss_mask_1: 0.1175  loss_dice_1: 0.1868  loss_ce_2: 0.001369  loss_mask_2: 0.1174  loss_dice_2: 0.1807  loss_ce_3: 0.002368  loss_mask_3: 0.1138  loss_dice_3: 0.1803  loss_ce_4: 0.0008838  loss_mask_4: 0.11  loss_dice_4: 0.1805  loss_ce_5: 0.001245  loss_mask_5: 0.1177  loss_dice_5: 0.1806  loss_ce_6: 0.003109  loss_mask_6: 0.1175  loss_dice_6: 0.1799  loss_ce_7: 0.00163  loss_mask_7: 0.1169  loss_dice_7: 0.1766  loss_ce_8: 0.001609  loss_mask_8: 0.1173  loss_dice_8: 0.1856  time: 0.6971  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:39:46] d2.utils.events INFO:  eta: 4:15:45  iter: 16479  total_loss: 3.146  loss_ce: 0.002025  loss_mask: 0.1169  loss_dice: 0.1891  loss_ce_0: 0.1191  loss_mask_0: 0.1147  loss_dice_0: 0.1833  loss_ce_1: 0.001984  loss_mask_1: 0.1148  loss_dice_1: 0.1854  loss_ce_2: 0.002083  loss_mask_2: 0.1148  loss_dice_2: 0.19  loss_ce_3: 0.001581  loss_mask_3: 0.1173  loss_dice_3: 0.1956  loss_ce_4: 0.002115  loss_mask_4: 0.1177  loss_dice_4: 0.1878  loss_ce_5: 0.002778  loss_mask_5: 0.1144  loss_dice_5: 0.185  loss_ce_6: 0.001974  loss_mask_6: 0.1187  loss_dice_6: 0.1824  loss_ce_7: 0.001961  loss_mask_7: 0.1153  loss_dice_7: 0.1946  loss_ce_8: 0.002202  loss_mask_8: 0.1194  loss_dice_8: 0.1907  time: 0.6971  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:40:01] d2.utils.events INFO:  eta: 4:14:58  iter: 16499  total_loss: 3.115  loss_ce: 0.000745  loss_mask: 0.1208  loss_dice: 0.173  loss_ce_0: 0.1178  loss_mask_0: 0.1201  loss_dice_0: 0.169  loss_ce_1: 0.0002802  loss_mask_1: 0.1203  loss_dice_1: 0.1763  loss_ce_2: 0.0003892  loss_mask_2: 0.1204  loss_dice_2: 0.1745  loss_ce_3: 0.00074  loss_mask_3: 0.1231  loss_dice_3: 0.1766  loss_ce_4: 0.000726  loss_mask_4: 0.1192  loss_dice_4: 0.1762  loss_ce_5: 0.0004312  loss_mask_5: 0.1202  loss_dice_5: 0.1782  loss_ce_6: 0.000428  loss_mask_6: 0.1246  loss_dice_6: 0.1777  loss_ce_7: 0.0003377  loss_mask_7: 0.1192  loss_dice_7: 0.1755  loss_ce_8: 0.00034  loss_mask_8: 0.1211  loss_dice_8: 0.1745  time: 0.6972  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:40:16] d2.utils.events INFO:  eta: 4:14:25  iter: 16519  total_loss: 3.065  loss_ce: 0.000265  loss_mask: 0.1172  loss_dice: 0.174  loss_ce_0: 0.1163  loss_mask_0: 0.1169  loss_dice_0: 0.1719  loss_ce_1: 0.0001516  loss_mask_1: 0.1184  loss_dice_1: 0.1715  loss_ce_2: 0.0002078  loss_mask_2: 0.1161  loss_dice_2: 0.1722  loss_ce_3: 0.0003911  loss_mask_3: 0.122  loss_dice_3: 0.171  loss_ce_4: 0.0005095  loss_mask_4: 0.1172  loss_dice_4: 0.1702  loss_ce_5: 0.0003232  loss_mask_5: 0.1175  loss_dice_5: 0.1724  loss_ce_6: 0.0001389  loss_mask_6: 0.1204  loss_dice_6: 0.1794  loss_ce_7: 0.0002096  loss_mask_7: 0.1153  loss_dice_7: 0.1715  loss_ce_8: 0.0001919  loss_mask_8: 0.1138  loss_dice_8: 0.1676  time: 0.6972  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 20:40:30] d2.utils.events INFO:  eta: 4:13:30  iter: 16539  total_loss: 3.144  loss_ce: 0.0002408  loss_mask: 0.1192  loss_dice: 0.18  loss_ce_0: 0.116  loss_mask_0: 0.1231  loss_dice_0: 0.1924  loss_ce_1: 0.0001256  loss_mask_1: 0.1195  loss_dice_1: 0.1807  loss_ce_2: 0.0001719  loss_mask_2: 0.1231  loss_dice_2: 0.1808  loss_ce_3: 0.0001737  loss_mask_3: 0.1201  loss_dice_3: 0.1834  loss_ce_4: 0.0001559  loss_mask_4: 0.1236  loss_dice_4: 0.1856  loss_ce_5: 0.0002341  loss_mask_5: 0.1204  loss_dice_5: 0.175  loss_ce_6: 0.0001634  loss_mask_6: 0.1203  loss_dice_6: 0.1841  loss_ce_7: 0.0001459  loss_mask_7: 0.1245  loss_dice_7: 0.1859  loss_ce_8: 0.0001596  loss_mask_8: 0.1204  loss_dice_8: 0.1795  time: 0.6973  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:40:44] d2.utils.events INFO:  eta: 4:12:31  iter: 16559  total_loss: 2.817  loss_ce: 0.000137  loss_mask: 0.11  loss_dice: 0.1601  loss_ce_0: 0.138  loss_mask_0: 0.112  loss_dice_0: 0.1588  loss_ce_1: 9.959e-05  loss_mask_1: 0.1142  loss_dice_1: 0.1583  loss_ce_2: 0.0001227  loss_mask_2: 0.1101  loss_dice_2: 0.1561  loss_ce_3: 0.0001248  loss_mask_3: 0.1083  loss_dice_3: 0.1594  loss_ce_4: 0.0001582  loss_mask_4: 0.1142  loss_dice_4: 0.1625  loss_ce_5: 0.0001346  loss_mask_5: 0.1087  loss_dice_5: 0.1539  loss_ce_6: 9.231e-05  loss_mask_6: 0.1142  loss_dice_6: 0.162  loss_ce_7: 0.0001289  loss_mask_7: 0.1115  loss_dice_7: 0.1587  loss_ce_8: 9.528e-05  loss_mask_8: 0.1124  loss_dice_8: 0.1602  time: 0.6973  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:40:58] d2.utils.events INFO:  eta: 4:10:58  iter: 16579  total_loss: 3.119  loss_ce: 0.0001334  loss_mask: 0.1141  loss_dice: 0.1747  loss_ce_0: 0.1356  loss_mask_0: 0.1179  loss_dice_0: 0.1851  loss_ce_1: 0.0001164  loss_mask_1: 0.1184  loss_dice_1: 0.1805  loss_ce_2: 0.0001432  loss_mask_2: 0.1185  loss_dice_2: 0.1746  loss_ce_3: 0.000175  loss_mask_3: 0.1196  loss_dice_3: 0.1846  loss_ce_4: 0.0001899  loss_mask_4: 0.1181  loss_dice_4: 0.1812  loss_ce_5: 0.0001607  loss_mask_5: 0.1176  loss_dice_5: 0.1761  loss_ce_6: 9.453e-05  loss_mask_6: 0.1221  loss_dice_6: 0.1788  loss_ce_7: 0.0001427  loss_mask_7: 0.1202  loss_dice_7: 0.1898  loss_ce_8: 0.0001193  loss_mask_8: 0.1176  loss_dice_8: 0.173  time: 0.6973  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:41:13] d2.utils.events INFO:  eta: 4:09:49  iter: 16599  total_loss: 3.001  loss_ce: 0.0001139  loss_mask: 0.1165  loss_dice: 0.1717  loss_ce_0: 0.1212  loss_mask_0: 0.1173  loss_dice_0: 0.1777  loss_ce_1: 8.771e-05  loss_mask_1: 0.1157  loss_dice_1: 0.1729  loss_ce_2: 0.0001333  loss_mask_2: 0.1154  loss_dice_2: 0.1798  loss_ce_3: 0.0001429  loss_mask_3: 0.1139  loss_dice_3: 0.1694  loss_ce_4: 0.0001403  loss_mask_4: 0.1145  loss_dice_4: 0.1788  loss_ce_5: 0.0001548  loss_mask_5: 0.1203  loss_dice_5: 0.1756  loss_ce_6: 8.543e-05  loss_mask_6: 0.1137  loss_dice_6: 0.1706  loss_ce_7: 0.0001171  loss_mask_7: 0.1153  loss_dice_7: 0.1715  loss_ce_8: 0.0001126  loss_mask_8: 0.117  loss_dice_8: 0.176  time: 0.6973  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 20:41:27] d2.utils.events INFO:  eta: 4:08:35  iter: 16619  total_loss: 3.099  loss_ce: 0.0003126  loss_mask: 0.1177  loss_dice: 0.1753  loss_ce_0: 0.1155  loss_mask_0: 0.1173  loss_dice_0: 0.1754  loss_ce_1: 0.0003181  loss_mask_1: 0.1162  loss_dice_1: 0.1745  loss_ce_2: 0.0002986  loss_mask_2: 0.1173  loss_dice_2: 0.1744  loss_ce_3: 0.0003611  loss_mask_3: 0.1198  loss_dice_3: 0.1743  loss_ce_4: 0.0003681  loss_mask_4: 0.1187  loss_dice_4: 0.1783  loss_ce_5: 0.0003224  loss_mask_5: 0.1223  loss_dice_5: 0.1771  loss_ce_6: 0.0002351  loss_mask_6: 0.1214  loss_dice_6: 0.173  loss_ce_7: 0.0003333  loss_mask_7: 0.1182  loss_dice_7: 0.1737  loss_ce_8: 0.0002669  loss_mask_8: 0.1173  loss_dice_8: 0.1718  time: 0.6974  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:41:42] d2.utils.events INFO:  eta: 4:07:50  iter: 16639  total_loss: 3.189  loss_ce: 0.0002271  loss_mask: 0.1158  loss_dice: 0.1811  loss_ce_0: 0.127  loss_mask_0: 0.1126  loss_dice_0: 0.1883  loss_ce_1: 0.0004737  loss_mask_1: 0.1153  loss_dice_1: 0.1847  loss_ce_2: 0.0001993  loss_mask_2: 0.113  loss_dice_2: 0.1891  loss_ce_3: 0.0001621  loss_mask_3: 0.1143  loss_dice_3: 0.1861  loss_ce_4: 0.0002477  loss_mask_4: 0.1154  loss_dice_4: 0.1864  loss_ce_5: 0.0002001  loss_mask_5: 0.1155  loss_dice_5: 0.192  loss_ce_6: 0.0002281  loss_mask_6: 0.1198  loss_dice_6: 0.1958  loss_ce_7: 0.0002365  loss_mask_7: 0.1138  loss_dice_7: 0.192  loss_ce_8: 0.0002177  loss_mask_8: 0.1143  loss_dice_8: 0.1866  time: 0.6974  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:41:57] d2.utils.events INFO:  eta: 4:06:11  iter: 16659  total_loss: 3.01  loss_ce: 0.0003342  loss_mask: 0.1139  loss_dice: 0.1717  loss_ce_0: 0.1202  loss_mask_0: 0.1208  loss_dice_0: 0.1758  loss_ce_1: 0.0003234  loss_mask_1: 0.1152  loss_dice_1: 0.1718  loss_ce_2: 0.0003908  loss_mask_2: 0.1158  loss_dice_2: 0.1719  loss_ce_3: 0.0002566  loss_mask_3: 0.1174  loss_dice_3: 0.1707  loss_ce_4: 0.0002299  loss_mask_4: 0.1144  loss_dice_4: 0.1766  loss_ce_5: 0.0004313  loss_mask_5: 0.1188  loss_dice_5: 0.1753  loss_ce_6: 0.0003253  loss_mask_6: 0.1177  loss_dice_6: 0.1763  loss_ce_7: 0.0003395  loss_mask_7: 0.1167  loss_dice_7: 0.1695  loss_ce_8: 0.0004215  loss_mask_8: 0.1214  loss_dice_8: 0.173  time: 0.6974  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:42:12] d2.utils.events INFO:  eta: 4:05:10  iter: 16679  total_loss: 3.103  loss_ce: 0.0002219  loss_mask: 0.1194  loss_dice: 0.1837  loss_ce_0: 0.1219  loss_mask_0: 0.1113  loss_dice_0: 0.1823  loss_ce_1: 0.0002345  loss_mask_1: 0.1157  loss_dice_1: 0.1767  loss_ce_2: 0.0003212  loss_mask_2: 0.1151  loss_dice_2: 0.1847  loss_ce_3: 0.0001923  loss_mask_3: 0.1149  loss_dice_3: 0.1827  loss_ce_4: 0.0001328  loss_mask_4: 0.1136  loss_dice_4: 0.1803  loss_ce_5: 0.0003295  loss_mask_5: 0.117  loss_dice_5: 0.1847  loss_ce_6: 0.0003554  loss_mask_6: 0.1161  loss_dice_6: 0.1861  loss_ce_7: 0.0002633  loss_mask_7: 0.1154  loss_dice_7: 0.1818  loss_ce_8: 0.000327  loss_mask_8: 0.1195  loss_dice_8: 0.1798  time: 0.6975  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:42:26] d2.utils.events INFO:  eta: 4:04:09  iter: 16699  total_loss: 3.039  loss_ce: 0.0002828  loss_mask: 0.1176  loss_dice: 0.1674  loss_ce_0: 0.1256  loss_mask_0: 0.1179  loss_dice_0: 0.171  loss_ce_1: 0.0003311  loss_mask_1: 0.1188  loss_dice_1: 0.1688  loss_ce_2: 0.0003194  loss_mask_2: 0.121  loss_dice_2: 0.1676  loss_ce_3: 0.000231  loss_mask_3: 0.1222  loss_dice_3: 0.1697  loss_ce_4: 0.0002414  loss_mask_4: 0.1204  loss_dice_4: 0.1698  loss_ce_5: 0.0003698  loss_mask_5: 0.1203  loss_dice_5: 0.174  loss_ce_6: 0.0002913  loss_mask_6: 0.1211  loss_dice_6: 0.1728  loss_ce_7: 0.0003433  loss_mask_7: 0.1195  loss_dice_7: 0.1724  loss_ce_8: 0.0003428  loss_mask_8: 0.1173  loss_dice_8: 0.1676  time: 0.6976  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:42:41] d2.utils.events INFO:  eta: 4:03:02  iter: 16719  total_loss: 3.199  loss_ce: 0.0002435  loss_mask: 0.1155  loss_dice: 0.1848  loss_ce_0: 0.1249  loss_mask_0: 0.1172  loss_dice_0: 0.1921  loss_ce_1: 0.0003463  loss_mask_1: 0.1175  loss_dice_1: 0.1834  loss_ce_2: 0.0003082  loss_mask_2: 0.1181  loss_dice_2: 0.1937  loss_ce_3: 0.0002134  loss_mask_3: 0.1202  loss_dice_3: 0.1877  loss_ce_4: 0.0001716  loss_mask_4: 0.1203  loss_dice_4: 0.1867  loss_ce_5: 0.0002854  loss_mask_5: 0.1138  loss_dice_5: 0.1808  loss_ce_6: 0.0002746  loss_mask_6: 0.1136  loss_dice_6: 0.1856  loss_ce_7: 0.000315  loss_mask_7: 0.1167  loss_dice_7: 0.1897  loss_ce_8: 0.0003068  loss_mask_8: 0.1134  loss_dice_8: 0.1847  time: 0.6976  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:42:56] d2.utils.events INFO:  eta: 4:02:05  iter: 16739  total_loss: 2.983  loss_ce: 0.0001973  loss_mask: 0.1196  loss_dice: 0.1708  loss_ce_0: 0.1275  loss_mask_0: 0.1209  loss_dice_0: 0.1702  loss_ce_1: 0.000225  loss_mask_1: 0.1186  loss_dice_1: 0.1688  loss_ce_2: 0.0002651  loss_mask_2: 0.1192  loss_dice_2: 0.1716  loss_ce_3: 0.0001744  loss_mask_3: 0.1192  loss_dice_3: 0.165  loss_ce_4: 0.0001541  loss_mask_4: 0.1175  loss_dice_4: 0.1708  loss_ce_5: 0.0002423  loss_mask_5: 0.1223  loss_dice_5: 0.1745  loss_ce_6: 0.0002541  loss_mask_6: 0.1177  loss_dice_6: 0.1623  loss_ce_7: 0.0002412  loss_mask_7: 0.1167  loss_dice_7: 0.1647  loss_ce_8: 0.0002606  loss_mask_8: 0.1235  loss_dice_8: 0.1699  time: 0.6977  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:43:11] d2.utils.events INFO:  eta: 4:00:52  iter: 16759  total_loss: 3.005  loss_ce: 0.000179  loss_mask: 0.1193  loss_dice: 0.1695  loss_ce_0: 0.127  loss_mask_0: 0.1192  loss_dice_0: 0.1739  loss_ce_1: 0.0001747  loss_mask_1: 0.1157  loss_dice_1: 0.1729  loss_ce_2: 0.0002146  loss_mask_2: 0.1194  loss_dice_2: 0.1705  loss_ce_3: 0.0001333  loss_mask_3: 0.117  loss_dice_3: 0.1723  loss_ce_4: 8.925e-05  loss_mask_4: 0.1203  loss_dice_4: 0.1704  loss_ce_5: 0.0001845  loss_mask_5: 0.1159  loss_dice_5: 0.1686  loss_ce_6: 0.0001677  loss_mask_6: 0.1216  loss_dice_6: 0.1796  loss_ce_7: 0.0001578  loss_mask_7: 0.1191  loss_dice_7: 0.1696  loss_ce_8: 0.0002202  loss_mask_8: 0.117  loss_dice_8: 0.169  time: 0.6977  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:43:26] d2.utils.events INFO:  eta: 3:59:00  iter: 16779  total_loss: 2.908  loss_ce: 0.0005356  loss_mask: 0.1138  loss_dice: 0.1644  loss_ce_0: 0.125  loss_mask_0: 0.1156  loss_dice_0: 0.1599  loss_ce_1: 0.000428  loss_mask_1: 0.1172  loss_dice_1: 0.169  loss_ce_2: 0.0005369  loss_mask_2: 0.1144  loss_dice_2: 0.1675  loss_ce_3: 0.0005623  loss_mask_3: 0.115  loss_dice_3: 0.1659  loss_ce_4: 0.0007479  loss_mask_4: 0.1128  loss_dice_4: 0.1635  loss_ce_5: 0.0005313  loss_mask_5: 0.1197  loss_dice_5: 0.1699  loss_ce_6: 0.0005075  loss_mask_6: 0.1173  loss_dice_6: 0.1634  loss_ce_7: 0.0005242  loss_mask_7: 0.1173  loss_dice_7: 0.1675  loss_ce_8: 0.0005374  loss_mask_8: 0.1157  loss_dice_8: 0.1652  time: 0.6977  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:43:40] d2.utils.events INFO:  eta: 3:57:48  iter: 16799  total_loss: 2.936  loss_ce: 0.000611  loss_mask: 0.1116  loss_dice: 0.1701  loss_ce_0: 0.123  loss_mask_0: 0.1158  loss_dice_0: 0.17  loss_ce_1: 0.000367  loss_mask_1: 0.1137  loss_dice_1: 0.1717  loss_ce_2: 0.0005897  loss_mask_2: 0.1127  loss_dice_2: 0.1695  loss_ce_3: 0.0005389  loss_mask_3: 0.1147  loss_dice_3: 0.175  loss_ce_4: 0.0005554  loss_mask_4: 0.114  loss_dice_4: 0.1748  loss_ce_5: 0.0004919  loss_mask_5: 0.113  loss_dice_5: 0.1687  loss_ce_6: 0.0004822  loss_mask_6: 0.112  loss_dice_6: 0.1721  loss_ce_7: 0.0005496  loss_mask_7: 0.1165  loss_dice_7: 0.1744  loss_ce_8: 0.0005791  loss_mask_8: 0.1124  loss_dice_8: 0.1719  time: 0.6978  data_time: 0.0016  lr: 0.0001  max_mem: 8444M
[08/01 20:43:55] d2.utils.events INFO:  eta: 3:56:33  iter: 16819  total_loss: 3.19  loss_ce: 0.0003829  loss_mask: 0.1247  loss_dice: 0.1732  loss_ce_0: 0.1221  loss_mask_0: 0.1178  loss_dice_0: 0.1697  loss_ce_1: 0.0003124  loss_mask_1: 0.1228  loss_dice_1: 0.1694  loss_ce_2: 0.00043  loss_mask_2: 0.1236  loss_dice_2: 0.1645  loss_ce_3: 0.0004138  loss_mask_3: 0.1225  loss_dice_3: 0.1695  loss_ce_4: 0.0004756  loss_mask_4: 0.1201  loss_dice_4: 0.1715  loss_ce_5: 0.0004187  loss_mask_5: 0.127  loss_dice_5: 0.1782  loss_ce_6: 0.0003125  loss_mask_6: 0.1239  loss_dice_6: 0.1745  loss_ce_7: 0.0004021  loss_mask_7: 0.1244  loss_dice_7: 0.1751  loss_ce_8: 0.000406  loss_mask_8: 0.1223  loss_dice_8: 0.1675  time: 0.6978  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:44:10] d2.utils.events INFO:  eta: 3:55:19  iter: 16839  total_loss: 2.959  loss_ce: 0.0003434  loss_mask: 0.1142  loss_dice: 0.1627  loss_ce_0: 0.1331  loss_mask_0: 0.1203  loss_dice_0: 0.1728  loss_ce_1: 0.0003494  loss_mask_1: 0.1157  loss_dice_1: 0.1658  loss_ce_2: 0.0003886  loss_mask_2: 0.1163  loss_dice_2: 0.1633  loss_ce_3: 0.0003557  loss_mask_3: 0.1171  loss_dice_3: 0.1643  loss_ce_4: 0.0004081  loss_mask_4: 0.1148  loss_dice_4: 0.1671  loss_ce_5: 0.0003787  loss_mask_5: 0.1178  loss_dice_5: 0.1719  loss_ce_6: 0.0002677  loss_mask_6: 0.1135  loss_dice_6: 0.1603  loss_ce_7: 0.0003806  loss_mask_7: 0.12  loss_dice_7: 0.1677  loss_ce_8: 0.000367  loss_mask_8: 0.1165  loss_dice_8: 0.1668  time: 0.6979  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:44:25] d2.utils.events INFO:  eta: 3:54:09  iter: 16859  total_loss: 3.128  loss_ce: 0.0003027  loss_mask: 0.1202  loss_dice: 0.173  loss_ce_0: 0.1186  loss_mask_0: 0.1214  loss_dice_0: 0.1802  loss_ce_1: 0.0002987  loss_mask_1: 0.1195  loss_dice_1: 0.1738  loss_ce_2: 0.0003539  loss_mask_2: 0.1242  loss_dice_2: 0.1831  loss_ce_3: 0.0003188  loss_mask_3: 0.1226  loss_dice_3: 0.1729  loss_ce_4: 0.0003639  loss_mask_4: 0.1183  loss_dice_4: 0.1771  loss_ce_5: 0.0003441  loss_mask_5: 0.122  loss_dice_5: 0.1781  loss_ce_6: 0.0002399  loss_mask_6: 0.119  loss_dice_6: 0.1786  loss_ce_7: 0.0003293  loss_mask_7: 0.118  loss_dice_7: 0.1747  loss_ce_8: 0.0003412  loss_mask_8: 0.1192  loss_dice_8: 0.1721  time: 0.6980  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:44:40] d2.utils.events INFO:  eta: 3:52:41  iter: 16879  total_loss: 3.022  loss_ce: 0.0002351  loss_mask: 0.1169  loss_dice: 0.1747  loss_ce_0: 0.1245  loss_mask_0: 0.1161  loss_dice_0: 0.1719  loss_ce_1: 0.0001506  loss_mask_1: 0.1179  loss_dice_1: 0.1778  loss_ce_2: 0.000313  loss_mask_2: 0.1154  loss_dice_2: 0.1768  loss_ce_3: 0.0002448  loss_mask_3: 0.1163  loss_dice_3: 0.1771  loss_ce_4: 0.0002542  loss_mask_4: 0.1135  loss_dice_4: 0.1784  loss_ce_5: 0.0002187  loss_mask_5: 0.1157  loss_dice_5: 0.1761  loss_ce_6: 0.000191  loss_mask_6: 0.1161  loss_dice_6: 0.171  loss_ce_7: 0.0002426  loss_mask_7: 0.1168  loss_dice_7: 0.1765  loss_ce_8: 0.0002672  loss_mask_8: 0.1148  loss_dice_8: 0.175  time: 0.6980  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:44:55] d2.utils.events INFO:  eta: 3:51:33  iter: 16899  total_loss: 3.029  loss_ce: 0.0002321  loss_mask: 0.1136  loss_dice: 0.1745  loss_ce_0: 0.1318  loss_mask_0: 0.1113  loss_dice_0: 0.1669  loss_ce_1: 0.0002403  loss_mask_1: 0.1115  loss_dice_1: 0.1803  loss_ce_2: 0.000303  loss_mask_2: 0.1132  loss_dice_2: 0.1751  loss_ce_3: 0.0002365  loss_mask_3: 0.1101  loss_dice_3: 0.1715  loss_ce_4: 0.0002563  loss_mask_4: 0.1105  loss_dice_4: 0.1733  loss_ce_5: 0.000287  loss_mask_5: 0.1118  loss_dice_5: 0.1771  loss_ce_6: 0.000186  loss_mask_6: 0.1102  loss_dice_6: 0.1771  loss_ce_7: 0.0002434  loss_mask_7: 0.1118  loss_dice_7: 0.1704  loss_ce_8: 0.0002862  loss_mask_8: 0.1112  loss_dice_8: 0.1752  time: 0.6981  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:45:10] d2.utils.events INFO:  eta: 3:50:33  iter: 16919  total_loss: 3.158  loss_ce: 0.0002034  loss_mask: 0.1202  loss_dice: 0.183  loss_ce_0: 0.1307  loss_mask_0: 0.1208  loss_dice_0: 0.1907  loss_ce_1: 0.0001723  loss_mask_1: 0.1207  loss_dice_1: 0.1977  loss_ce_2: 0.0002742  loss_mask_2: 0.1229  loss_dice_2: 0.1843  loss_ce_3: 0.0002169  loss_mask_3: 0.1187  loss_dice_3: 0.1908  loss_ce_4: 0.0002385  loss_mask_4: 0.1254  loss_dice_4: 0.1864  loss_ce_5: 0.0002344  loss_mask_5: 0.1209  loss_dice_5: 0.1891  loss_ce_6: 0.0001643  loss_mask_6: 0.1201  loss_dice_6: 0.1875  loss_ce_7: 0.0002154  loss_mask_7: 0.1241  loss_dice_7: 0.1881  loss_ce_8: 0.0002417  loss_mask_8: 0.1207  loss_dice_8: 0.1874  time: 0.6981  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:45:24] d2.utils.events INFO:  eta: 3:49:37  iter: 16939  total_loss: 2.956  loss_ce: 9.36e-05  loss_mask: 0.1128  loss_dice: 0.1709  loss_ce_0: 0.1291  loss_mask_0: 0.1133  loss_dice_0: 0.1702  loss_ce_1: 4.436e-05  loss_mask_1: 0.1137  loss_dice_1: 0.1716  loss_ce_2: 0.0001105  loss_mask_2: 0.1173  loss_dice_2: 0.1695  loss_ce_3: 5.575e-05  loss_mask_3: 0.1155  loss_dice_3: 0.1712  loss_ce_4: 4.099e-05  loss_mask_4: 0.1168  loss_dice_4: 0.1739  loss_ce_5: 8.497e-05  loss_mask_5: 0.1106  loss_dice_5: 0.168  loss_ce_6: 5.106e-05  loss_mask_6: 0.1148  loss_dice_6: 0.1673  loss_ce_7: 5.549e-05  loss_mask_7: 0.1081  loss_dice_7: 0.1722  loss_ce_8: 9.75e-05  loss_mask_8: 0.1134  loss_dice_8: 0.1713  time: 0.6982  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:45:39] d2.utils.events INFO:  eta: 3:48:39  iter: 16959  total_loss: 2.921  loss_ce: 0.0001176  loss_mask: 0.1199  loss_dice: 0.1612  loss_ce_0: 0.1267  loss_mask_0: 0.1215  loss_dice_0: 0.165  loss_ce_1: 8.321e-05  loss_mask_1: 0.1186  loss_dice_1: 0.171  loss_ce_2: 0.0001657  loss_mask_2: 0.1174  loss_dice_2: 0.1605  loss_ce_3: 0.0001172  loss_mask_3: 0.1206  loss_dice_3: 0.1633  loss_ce_4: 0.0001161  loss_mask_4: 0.1197  loss_dice_4: 0.1623  loss_ce_5: 0.0001246  loss_mask_5: 0.12  loss_dice_5: 0.1659  loss_ce_6: 9.935e-05  loss_mask_6: 0.1211  loss_dice_6: 0.1607  loss_ce_7: 0.0001092  loss_mask_7: 0.118  loss_dice_7: 0.1623  loss_ce_8: 0.0001327  loss_mask_8: 0.1232  loss_dice_8: 0.1636  time: 0.6982  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:45:54] d2.utils.events INFO:  eta: 3:47:37  iter: 16979  total_loss: 3.025  loss_ce: 0.0001591  loss_mask: 0.1109  loss_dice: 0.1714  loss_ce_0: 0.1224  loss_mask_0: 0.1182  loss_dice_0: 0.1691  loss_ce_1: 0.0001278  loss_mask_1: 0.1159  loss_dice_1: 0.1764  loss_ce_2: 0.0002276  loss_mask_2: 0.117  loss_dice_2: 0.1703  loss_ce_3: 0.0001769  loss_mask_3: 0.1149  loss_dice_3: 0.1725  loss_ce_4: 0.0001824  loss_mask_4: 0.1146  loss_dice_4: 0.168  loss_ce_5: 0.0002014  loss_mask_5: 0.1152  loss_dice_5: 0.1784  loss_ce_6: 0.0001381  loss_mask_6: 0.1145  loss_dice_6: 0.1759  loss_ce_7: 0.0001614  loss_mask_7: 0.1153  loss_dice_7: 0.1675  loss_ce_8: 0.000208  loss_mask_8: 0.119  loss_dice_8: 0.1779  time: 0.6982  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:46:09] d2.utils.events INFO:  eta: 3:46:35  iter: 16999  total_loss: 2.957  loss_ce: 0.0001493  loss_mask: 0.111  loss_dice: 0.1771  loss_ce_0: 0.1235  loss_mask_0: 0.1119  loss_dice_0: 0.1758  loss_ce_1: 0.0001511  loss_mask_1: 0.1091  loss_dice_1: 0.176  loss_ce_2: 0.0002157  loss_mask_2: 0.1106  loss_dice_2: 0.1746  loss_ce_3: 0.0001583  loss_mask_3: 0.1138  loss_dice_3: 0.1836  loss_ce_4: 0.0001815  loss_mask_4: 0.1108  loss_dice_4: 0.1699  loss_ce_5: 0.0001897  loss_mask_5: 0.1134  loss_dice_5: 0.1759  loss_ce_6: 0.0001137  loss_mask_6: 0.1103  loss_dice_6: 0.171  loss_ce_7: 0.0001595  loss_mask_7: 0.1138  loss_dice_7: 0.1768  loss_ce_8: 0.0001855  loss_mask_8: 0.1104  loss_dice_8: 0.1646  time: 0.6983  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:46:23] d2.utils.events INFO:  eta: 3:45:52  iter: 17019  total_loss: 3.089  loss_ce: 0.0001469  loss_mask: 0.1177  loss_dice: 0.1768  loss_ce_0: 0.1253  loss_mask_0: 0.122  loss_dice_0: 0.1773  loss_ce_1: 0.0001487  loss_mask_1: 0.1239  loss_dice_1: 0.1854  loss_ce_2: 0.0002091  loss_mask_2: 0.1236  loss_dice_2: 0.1827  loss_ce_3: 0.0001651  loss_mask_3: 0.1216  loss_dice_3: 0.1825  loss_ce_4: 0.0001548  loss_mask_4: 0.1184  loss_dice_4: 0.1798  loss_ce_5: 0.0002096  loss_mask_5: 0.1205  loss_dice_5: 0.1834  loss_ce_6: 0.0001228  loss_mask_6: 0.1203  loss_dice_6: 0.1782  loss_ce_7: 0.0001504  loss_mask_7: 0.121  loss_dice_7: 0.1786  loss_ce_8: 0.0002078  loss_mask_8: 0.1232  loss_dice_8: 0.1814  time: 0.6983  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:46:38] d2.utils.events INFO:  eta: 3:44:43  iter: 17039  total_loss: 3.287  loss_ce: 0.0001324  loss_mask: 0.1202  loss_dice: 0.1926  loss_ce_0: 0.1261  loss_mask_0: 0.1287  loss_dice_0: 0.1935  loss_ce_1: 0.0001244  loss_mask_1: 0.1195  loss_dice_1: 0.1964  loss_ce_2: 0.0001832  loss_mask_2: 0.1186  loss_dice_2: 0.1959  loss_ce_3: 0.0001434  loss_mask_3: 0.1248  loss_dice_3: 0.1914  loss_ce_4: 0.0001343  loss_mask_4: 0.1198  loss_dice_4: 0.1956  loss_ce_5: 0.0001627  loss_mask_5: 0.1215  loss_dice_5: 0.1907  loss_ce_6: 0.0001176  loss_mask_6: 0.118  loss_dice_6: 0.1912  loss_ce_7: 0.0001276  loss_mask_7: 0.1181  loss_dice_7: 0.1985  loss_ce_8: 0.000163  loss_mask_8: 0.1223  loss_dice_8: 0.1929  time: 0.6984  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:46:53] d2.utils.events INFO:  eta: 3:44:06  iter: 17059  total_loss: 3  loss_ce: 0.000114  loss_mask: 0.116  loss_dice: 0.1713  loss_ce_0: 0.132  loss_mask_0: 0.1154  loss_dice_0: 0.1758  loss_ce_1: 9.006e-05  loss_mask_1: 0.1119  loss_dice_1: 0.172  loss_ce_2: 0.0001704  loss_mask_2: 0.112  loss_dice_2: 0.1741  loss_ce_3: 0.0001307  loss_mask_3: 0.1119  loss_dice_3: 0.1751  loss_ce_4: 0.0001388  loss_mask_4: 0.1099  loss_dice_4: 0.167  loss_ce_5: 0.0001305  loss_mask_5: 0.1183  loss_dice_5: 0.1695  loss_ce_6: 0.0001127  loss_mask_6: 0.1164  loss_dice_6: 0.1749  loss_ce_7: 0.0001243  loss_mask_7: 0.114  loss_dice_7: 0.1706  loss_ce_8: 0.0001311  loss_mask_8: 0.114  loss_dice_8: 0.1675  time: 0.6984  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:47:07] d2.utils.events INFO:  eta: 3:43:13  iter: 17079  total_loss: 2.919  loss_ce: 0.000129  loss_mask: 0.1143  loss_dice: 0.1721  loss_ce_0: 0.1219  loss_mask_0: 0.1167  loss_dice_0: 0.1725  loss_ce_1: 0.0001347  loss_mask_1: 0.1157  loss_dice_1: 0.1742  loss_ce_2: 0.0001785  loss_mask_2: 0.1174  loss_dice_2: 0.1746  loss_ce_3: 0.00014  loss_mask_3: 0.1193  loss_dice_3: 0.1755  loss_ce_4: 0.0001424  loss_mask_4: 0.1154  loss_dice_4: 0.1689  loss_ce_5: 0.000152  loss_mask_5: 0.117  loss_dice_5: 0.1784  loss_ce_6: 0.0001095  loss_mask_6: 0.1113  loss_dice_6: 0.1717  loss_ce_7: 0.0001375  loss_mask_7: 0.1119  loss_dice_7: 0.1756  loss_ce_8: 0.0001554  loss_mask_8: 0.116  loss_dice_8: 0.176  time: 0.6985  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 20:47:22] d2.utils.events INFO:  eta: 3:42:17  iter: 17099  total_loss: 3.304  loss_ce: 0.0001235  loss_mask: 0.1207  loss_dice: 0.1976  loss_ce_0: 0.1246  loss_mask_0: 0.1236  loss_dice_0: 0.1979  loss_ce_1: 0.0001494  loss_mask_1: 0.1206  loss_dice_1: 0.1991  loss_ce_2: 0.0001795  loss_mask_2: 0.1228  loss_dice_2: 0.1955  loss_ce_3: 0.0001332  loss_mask_3: 0.1219  loss_dice_3: 0.2018  loss_ce_4: 0.0001206  loss_mask_4: 0.1235  loss_dice_4: 0.19  loss_ce_5: 0.0001707  loss_mask_5: 0.1237  loss_dice_5: 0.2002  loss_ce_6: 0.0001027  loss_mask_6: 0.1235  loss_dice_6: 0.2002  loss_ce_7: 0.000121  loss_mask_7: 0.1226  loss_dice_7: 0.1931  loss_ce_8: 0.0001707  loss_mask_8: 0.1222  loss_dice_8: 0.1939  time: 0.6985  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:47:37] d2.utils.events INFO:  eta: 3:41:43  iter: 17119  total_loss: 2.916  loss_ce: 0.0001081  loss_mask: 0.1165  loss_dice: 0.1725  loss_ce_0: 0.126  loss_mask_0: 0.1099  loss_dice_0: 0.1624  loss_ce_1: 0.0001035  loss_mask_1: 0.1142  loss_dice_1: 0.1728  loss_ce_2: 0.0001611  loss_mask_2: 0.1192  loss_dice_2: 0.1716  loss_ce_3: 0.0001241  loss_mask_3: 0.1115  loss_dice_3: 0.1705  loss_ce_4: 0.000108  loss_mask_4: 0.1152  loss_dice_4: 0.172  loss_ce_5: 0.0001183  loss_mask_5: 0.1126  loss_dice_5: 0.1722  loss_ce_6: 0.0001019  loss_mask_6: 0.118  loss_dice_6: 0.1645  loss_ce_7: 0.0001095  loss_mask_7: 0.1122  loss_dice_7: 0.1685  loss_ce_8: 0.0001181  loss_mask_8: 0.1154  loss_dice_8: 0.1745  time: 0.6986  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:47:52] d2.utils.events INFO:  eta: 3:41:01  iter: 17139  total_loss: 2.963  loss_ce: 7.176e-05  loss_mask: 0.1132  loss_dice: 0.1675  loss_ce_0: 0.1267  loss_mask_0: 0.1182  loss_dice_0: 0.1749  loss_ce_1: 5.52e-05  loss_mask_1: 0.1143  loss_dice_1: 0.165  loss_ce_2: 0.00011  loss_mask_2: 0.1172  loss_dice_2: 0.1737  loss_ce_3: 0.0001172  loss_mask_3: 0.1161  loss_dice_3: 0.1714  loss_ce_4: 6.113e-05  loss_mask_4: 0.1191  loss_dice_4: 0.1699  loss_ce_5: 8.024e-05  loss_mask_5: 0.1182  loss_dice_5: 0.1792  loss_ce_6: 7.29e-05  loss_mask_6: 0.1164  loss_dice_6: 0.1656  loss_ce_7: 6.309e-05  loss_mask_7: 0.1131  loss_dice_7: 0.1686  loss_ce_8: 8.165e-05  loss_mask_8: 0.1178  loss_dice_8: 0.1701  time: 0.6986  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:48:06] d2.utils.events INFO:  eta: 3:40:30  iter: 17159  total_loss: 3.035  loss_ce: 6.88e-05  loss_mask: 0.1189  loss_dice: 0.1787  loss_ce_0: 0.1234  loss_mask_0: 0.1189  loss_dice_0: 0.1906  loss_ce_1: 4.963e-05  loss_mask_1: 0.1131  loss_dice_1: 0.1732  loss_ce_2: 0.0001065  loss_mask_2: 0.1169  loss_dice_2: 0.18  loss_ce_3: 7.28e-05  loss_mask_3: 0.117  loss_dice_3: 0.1861  loss_ce_4: 6.056e-05  loss_mask_4: 0.113  loss_dice_4: 0.1789  loss_ce_5: 7.612e-05  loss_mask_5: 0.118  loss_dice_5: 0.1835  loss_ce_6: 5.508e-05  loss_mask_6: 0.1172  loss_dice_6: 0.1804  loss_ce_7: 6.425e-05  loss_mask_7: 0.1183  loss_dice_7: 0.1808  loss_ce_8: 7.85e-05  loss_mask_8: 0.1145  loss_dice_8: 0.1832  time: 0.6986  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:48:21] d2.utils.events INFO:  eta: 3:40:06  iter: 17179  total_loss: 2.885  loss_ce: 9.266e-05  loss_mask: 0.1096  loss_dice: 0.1641  loss_ce_0: 0.1226  loss_mask_0: 0.1084  loss_dice_0: 0.1683  loss_ce_1: 7.433e-05  loss_mask_1: 0.1111  loss_dice_1: 0.1667  loss_ce_2: 0.000141  loss_mask_2: 0.1125  loss_dice_2: 0.1701  loss_ce_3: 9.884e-05  loss_mask_3: 0.1111  loss_dice_3: 0.1652  loss_ce_4: 8.726e-05  loss_mask_4: 0.1132  loss_dice_4: 0.1683  loss_ce_5: 9.821e-05  loss_mask_5: 0.1101  loss_dice_5: 0.1679  loss_ce_6: 8.431e-05  loss_mask_6: 0.1108  loss_dice_6: 0.1636  loss_ce_7: 9.399e-05  loss_mask_7: 0.1114  loss_dice_7: 0.1607  loss_ce_8: 0.0001037  loss_mask_8: 0.1121  loss_dice_8: 0.1685  time: 0.6987  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 20:48:36] d2.utils.events INFO:  eta: 3:39:40  iter: 17199  total_loss: 3.036  loss_ce: 9.834e-05  loss_mask: 0.1144  loss_dice: 0.1782  loss_ce_0: 0.122  loss_mask_0: 0.1197  loss_dice_0: 0.1891  loss_ce_1: 9.515e-05  loss_mask_1: 0.1126  loss_dice_1: 0.1753  loss_ce_2: 0.000144  loss_mask_2: 0.1153  loss_dice_2: 0.1756  loss_ce_3: 0.0001027  loss_mask_3: 0.1168  loss_dice_3: 0.1763  loss_ce_4: 0.0001031  loss_mask_4: 0.1178  loss_dice_4: 0.1744  loss_ce_5: 9.933e-05  loss_mask_5: 0.1171  loss_dice_5: 0.1812  loss_ce_6: 8.096e-05  loss_mask_6: 0.1137  loss_dice_6: 0.1748  loss_ce_7: 0.0001095  loss_mask_7: 0.1171  loss_dice_7: 0.1756  loss_ce_8: 0.0001041  loss_mask_8: 0.1145  loss_dice_8: 0.1749  time: 0.6988  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:48:51] d2.utils.events INFO:  eta: 3:39:14  iter: 17219  total_loss: 3.094  loss_ce: 9.142e-05  loss_mask: 0.1192  loss_dice: 0.1809  loss_ce_0: 0.1189  loss_mask_0: 0.1201  loss_dice_0: 0.1834  loss_ce_1: 0.0001147  loss_mask_1: 0.1139  loss_dice_1: 0.1839  loss_ce_2: 0.0001407  loss_mask_2: 0.1236  loss_dice_2: 0.1851  loss_ce_3: 0.0001014  loss_mask_3: 0.1236  loss_dice_3: 0.1833  loss_ce_4: 0.0001135  loss_mask_4: 0.118  loss_dice_4: 0.1822  loss_ce_5: 9.63e-05  loss_mask_5: 0.1169  loss_dice_5: 0.1843  loss_ce_6: 8.148e-05  loss_mask_6: 0.1169  loss_dice_6: 0.1785  loss_ce_7: 0.0001053  loss_mask_7: 0.114  loss_dice_7: 0.1804  loss_ce_8: 0.0001028  loss_mask_8: 0.1177  loss_dice_8: 0.1827  time: 0.6988  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:49:06] d2.utils.events INFO:  eta: 3:38:43  iter: 17239  total_loss: 3.305  loss_ce: 7.614e-05  loss_mask: 0.1266  loss_dice: 0.1847  loss_ce_0: 0.119  loss_mask_0: 0.1254  loss_dice_0: 0.2008  loss_ce_1: 5.586e-05  loss_mask_1: 0.1223  loss_dice_1: 0.1891  loss_ce_2: 0.0001236  loss_mask_2: 0.1221  loss_dice_2: 0.1884  loss_ce_3: 7.93e-05  loss_mask_3: 0.1221  loss_dice_3: 0.1943  loss_ce_4: 6.382e-05  loss_mask_4: 0.1285  loss_dice_4: 0.1963  loss_ce_5: 8.332e-05  loss_mask_5: 0.1285  loss_dice_5: 0.1931  loss_ce_6: 5.834e-05  loss_mask_6: 0.1214  loss_dice_6: 0.1907  loss_ce_7: 6.295e-05  loss_mask_7: 0.1234  loss_dice_7: 0.1935  loss_ce_8: 7.881e-05  loss_mask_8: 0.1233  loss_dice_8: 0.1917  time: 0.6988  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:49:21] d2.utils.events INFO:  eta: 3:38:17  iter: 17259  total_loss: 3.118  loss_ce: 7.396e-05  loss_mask: 0.1156  loss_dice: 0.1861  loss_ce_0: 0.1207  loss_mask_0: 0.1165  loss_dice_0: 0.175  loss_ce_1: 6.203e-05  loss_mask_1: 0.1177  loss_dice_1: 0.1863  loss_ce_2: 0.0001071  loss_mask_2: 0.1177  loss_dice_2: 0.1837  loss_ce_3: 7.1e-05  loss_mask_3: 0.1187  loss_dice_3: 0.1821  loss_ce_4: 6.264e-05  loss_mask_4: 0.118  loss_dice_4: 0.1847  loss_ce_5: 7.812e-05  loss_mask_5: 0.1128  loss_dice_5: 0.1809  loss_ce_6: 5.006e-05  loss_mask_6: 0.1149  loss_dice_6: 0.1841  loss_ce_7: 6.368e-05  loss_mask_7: 0.115  loss_dice_7: 0.1825  loss_ce_8: 7.61e-05  loss_mask_8: 0.1136  loss_dice_8: 0.1803  time: 0.6989  data_time: 0.0014  lr: 0.0001  max_mem: 8444M
[08/01 20:49:35] d2.utils.events INFO:  eta: 3:37:39  iter: 17279  total_loss: 2.946  loss_ce: 9.082e-05  loss_mask: 0.1132  loss_dice: 0.1677  loss_ce_0: 0.1233  loss_mask_0: 0.1195  loss_dice_0: 0.1773  loss_ce_1: 7.312e-05  loss_mask_1: 0.1165  loss_dice_1: 0.1686  loss_ce_2: 0.0001268  loss_mask_2: 0.113  loss_dice_2: 0.167  loss_ce_3: 0.0001008  loss_mask_3: 0.1123  loss_dice_3: 0.1698  loss_ce_4: 9.114e-05  loss_mask_4: 0.1106  loss_dice_4: 0.1663  loss_ce_5: 9.102e-05  loss_mask_5: 0.1118  loss_dice_5: 0.1658  loss_ce_6: 8.068e-05  loss_mask_6: 0.1156  loss_dice_6: 0.172  loss_ce_7: 8.516e-05  loss_mask_7: 0.1125  loss_dice_7: 0.1616  loss_ce_8: 9.652e-05  loss_mask_8: 0.115  loss_dice_8: 0.1662  time: 0.6989  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:49:49] d2.utils.events INFO:  eta: 3:37:04  iter: 17299  total_loss: 2.97  loss_ce: 9.601e-05  loss_mask: 0.117  loss_dice: 0.1711  loss_ce_0: 0.1242  loss_mask_0: 0.1187  loss_dice_0: 0.1683  loss_ce_1: 0.0001156  loss_mask_1: 0.116  loss_dice_1: 0.1702  loss_ce_2: 0.0001294  loss_mask_2: 0.1164  loss_dice_2: 0.1661  loss_ce_3: 9.844e-05  loss_mask_3: 0.1147  loss_dice_3: 0.1694  loss_ce_4: 0.0001057  loss_mask_4: 0.1153  loss_dice_4: 0.1667  loss_ce_5: 0.0001212  loss_mask_5: 0.1194  loss_dice_5: 0.18  loss_ce_6: 7.886e-05  loss_mask_6: 0.1183  loss_dice_6: 0.1686  loss_ce_7: 0.0001069  loss_mask_7: 0.1153  loss_dice_7: 0.1682  loss_ce_8: 0.0001309  loss_mask_8: 0.1168  loss_dice_8: 0.1696  time: 0.6989  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:50:03] d2.utils.events INFO:  eta: 3:36:25  iter: 17319  total_loss: 3.047  loss_ce: 6.201e-05  loss_mask: 0.112  loss_dice: 0.1726  loss_ce_0: 0.123  loss_mask_0: 0.1181  loss_dice_0: 0.1806  loss_ce_1: 4.371e-05  loss_mask_1: 0.1168  loss_dice_1: 0.1739  loss_ce_2: 8.149e-05  loss_mask_2: 0.116  loss_dice_2: 0.1745  loss_ce_3: 6.062e-05  loss_mask_3: 0.1168  loss_dice_3: 0.1767  loss_ce_4: 5.484e-05  loss_mask_4: 0.1169  loss_dice_4: 0.1781  loss_ce_5: 6.2e-05  loss_mask_5: 0.1194  loss_dice_5: 0.178  loss_ce_6: 5.142e-05  loss_mask_6: 0.1154  loss_dice_6: 0.1773  loss_ce_7: 5.193e-05  loss_mask_7: 0.1177  loss_dice_7: 0.1766  loss_ce_8: 6.003e-05  loss_mask_8: 0.1202  loss_dice_8: 0.1772  time: 0.6989  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:50:17] d2.utils.events INFO:  eta: 3:35:49  iter: 17339  total_loss: 3.024  loss_ce: 8.944e-05  loss_mask: 0.1189  loss_dice: 0.1726  loss_ce_0: 0.121  loss_mask_0: 0.1166  loss_dice_0: 0.1761  loss_ce_1: 9.587e-05  loss_mask_1: 0.1171  loss_dice_1: 0.1737  loss_ce_2: 0.000125  loss_mask_2: 0.1181  loss_dice_2: 0.1728  loss_ce_3: 9.088e-05  loss_mask_3: 0.1196  loss_dice_3: 0.1733  loss_ce_4: 0.0001042  loss_mask_4: 0.118  loss_dice_4: 0.1762  loss_ce_5: 0.0001107  loss_mask_5: 0.1164  loss_dice_5: 0.1714  loss_ce_6: 7.765e-05  loss_mask_6: 0.1181  loss_dice_6: 0.1758  loss_ce_7: 0.0001046  loss_mask_7: 0.117  loss_dice_7: 0.1769  loss_ce_8: 0.000125  loss_mask_8: 0.1167  loss_dice_8: 0.1764  time: 0.6989  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:50:32] d2.utils.events INFO:  eta: 3:35:29  iter: 17359  total_loss: 3.049  loss_ce: 5.496e-05  loss_mask: 0.1058  loss_dice: 0.1739  loss_ce_0: 0.1281  loss_mask_0: 0.1106  loss_dice_0: 0.1812  loss_ce_1: 4.791e-05  loss_mask_1: 0.1124  loss_dice_1: 0.1746  loss_ce_2: 8.121e-05  loss_mask_2: 0.1097  loss_dice_2: 0.173  loss_ce_3: 6.212e-05  loss_mask_3: 0.1082  loss_dice_3: 0.1748  loss_ce_4: 4.791e-05  loss_mask_4: 0.1097  loss_dice_4: 0.1741  loss_ce_5: 5.71e-05  loss_mask_5: 0.107  loss_dice_5: 0.1761  loss_ce_6: 5.54e-05  loss_mask_6: 0.1087  loss_dice_6: 0.1728  loss_ce_7: 4.684e-05  loss_mask_7: 0.1083  loss_dice_7: 0.1721  loss_ce_8: 5.856e-05  loss_mask_8: 0.1071  loss_dice_8: 0.1758  time: 0.6989  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:50:46] d2.utils.events INFO:  eta: 3:35:05  iter: 17379  total_loss: 3.006  loss_ce: 7.077e-05  loss_mask: 0.1122  loss_dice: 0.1673  loss_ce_0: 0.1197  loss_mask_0: 0.1157  loss_dice_0: 0.1732  loss_ce_1: 7.237e-05  loss_mask_1: 0.1175  loss_dice_1: 0.1756  loss_ce_2: 0.0001075  loss_mask_2: 0.1151  loss_dice_2: 0.1709  loss_ce_3: 7.712e-05  loss_mask_3: 0.1166  loss_dice_3: 0.1741  loss_ce_4: 8.474e-05  loss_mask_4: 0.115  loss_dice_4: 0.1743  loss_ce_5: 7.289e-05  loss_mask_5: 0.114  loss_dice_5: 0.172  loss_ce_6: 6.424e-05  loss_mask_6: 0.1133  loss_dice_6: 0.1735  loss_ce_7: 7.357e-05  loss_mask_7: 0.118  loss_dice_7: 0.1705  loss_ce_8: 7.281e-05  loss_mask_8: 0.1208  loss_dice_8: 0.1718  time: 0.6990  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:51:00] d2.utils.events INFO:  eta: 3:34:32  iter: 17399  total_loss: 2.891  loss_ce: 7.342e-05  loss_mask: 0.1172  loss_dice: 0.1598  loss_ce_0: 0.1243  loss_mask_0: 0.119  loss_dice_0: 0.1664  loss_ce_1: 7.562e-05  loss_mask_1: 0.1143  loss_dice_1: 0.1598  loss_ce_2: 0.0001096  loss_mask_2: 0.1183  loss_dice_2: 0.1629  loss_ce_3: 7.777e-05  loss_mask_3: 0.115  loss_dice_3: 0.1628  loss_ce_4: 7.882e-05  loss_mask_4: 0.1181  loss_dice_4: 0.166  loss_ce_5: 8.52e-05  loss_mask_5: 0.1128  loss_dice_5: 0.1614  loss_ce_6: 6.542e-05  loss_mask_6: 0.1128  loss_dice_6: 0.1609  loss_ce_7: 8.195e-05  loss_mask_7: 0.1142  loss_dice_7: 0.1618  loss_ce_8: 9.052e-05  loss_mask_8: 0.1169  loss_dice_8: 0.1633  time: 0.6990  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:51:14] d2.utils.events INFO:  eta: 3:34:02  iter: 17419  total_loss: 2.97  loss_ce: 7.387e-05  loss_mask: 0.1155  loss_dice: 0.1774  loss_ce_0: 0.1216  loss_mask_0: 0.1194  loss_dice_0: 0.174  loss_ce_1: 6.55e-05  loss_mask_1: 0.1148  loss_dice_1: 0.1747  loss_ce_2: 0.0001042  loss_mask_2: 0.1146  loss_dice_2: 0.1712  loss_ce_3: 8.119e-05  loss_mask_3: 0.1186  loss_dice_3: 0.1826  loss_ce_4: 9.038e-05  loss_mask_4: 0.1156  loss_dice_4: 0.1681  loss_ce_5: 7.373e-05  loss_mask_5: 0.1174  loss_dice_5: 0.1731  loss_ce_6: 6.692e-05  loss_mask_6: 0.1205  loss_dice_6: 0.1727  loss_ce_7: 8.82e-05  loss_mask_7: 0.1174  loss_dice_7: 0.1777  loss_ce_8: 7.602e-05  loss_mask_8: 0.1155  loss_dice_8: 0.1731  time: 0.6990  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:51:27] d2.utils.events INFO:  eta: 3:33:26  iter: 17439  total_loss: 3.091  loss_ce: 4.658e-05  loss_mask: 0.1192  loss_dice: 0.1786  loss_ce_0: 0.1216  loss_mask_0: 0.1218  loss_dice_0: 0.1722  loss_ce_1: 3.735e-05  loss_mask_1: 0.117  loss_dice_1: 0.1693  loss_ce_2: 6.659e-05  loss_mask_2: 0.1158  loss_dice_2: 0.1673  loss_ce_3: 4.483e-05  loss_mask_3: 0.1165  loss_dice_3: 0.1702  loss_ce_4: 4.225e-05  loss_mask_4: 0.1169  loss_dice_4: 0.1679  loss_ce_5: 4.926e-05  loss_mask_5: 0.1204  loss_dice_5: 0.1766  loss_ce_6: 4.025e-05  loss_mask_6: 0.118  loss_dice_6: 0.1686  loss_ce_7: 3.943e-05  loss_mask_7: 0.119  loss_dice_7: 0.1718  loss_ce_8: 4.939e-05  loss_mask_8: 0.1174  loss_dice_8: 0.17  time: 0.6989  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:51:39] d2.utils.events INFO:  eta: 3:32:59  iter: 17459  total_loss: 3.173  loss_ce: 5.473e-05  loss_mask: 0.1215  loss_dice: 0.1824  loss_ce_0: 0.1194  loss_mask_0: 0.1224  loss_dice_0: 0.1894  loss_ce_1: 4.297e-05  loss_mask_1: 0.1243  loss_dice_1: 0.1741  loss_ce_2: 7.337e-05  loss_mask_2: 0.1207  loss_dice_2: 0.1732  loss_ce_3: 5.913e-05  loss_mask_3: 0.1214  loss_dice_3: 0.1792  loss_ce_4: 4.659e-05  loss_mask_4: 0.1279  loss_dice_4: 0.1783  loss_ce_5: 6.7e-05  loss_mask_5: 0.1208  loss_dice_5: 0.1751  loss_ce_6: 4.415e-05  loss_mask_6: 0.122  loss_dice_6: 0.1723  loss_ce_7: 5.065e-05  loss_mask_7: 0.1247  loss_dice_7: 0.176  loss_ce_8: 6.984e-05  loss_mask_8: 0.1227  loss_dice_8: 0.1696  time: 0.6988  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:51:52] d2.utils.events INFO:  eta: 3:32:16  iter: 17479  total_loss: 3.017  loss_ce: 7.091e-05  loss_mask: 0.1222  loss_dice: 0.1704  loss_ce_0: 0.1239  loss_mask_0: 0.122  loss_dice_0: 0.1743  loss_ce_1: 6.869e-05  loss_mask_1: 0.12  loss_dice_1: 0.1699  loss_ce_2: 0.0001027  loss_mask_2: 0.1227  loss_dice_2: 0.1713  loss_ce_3: 7.28e-05  loss_mask_3: 0.119  loss_dice_3: 0.1657  loss_ce_4: 6.919e-05  loss_mask_4: 0.1236  loss_dice_4: 0.1706  loss_ce_5: 9.064e-05  loss_mask_5: 0.1224  loss_dice_5: 0.1723  loss_ce_6: 6.27e-05  loss_mask_6: 0.1189  loss_dice_6: 0.1656  loss_ce_7: 7.462e-05  loss_mask_7: 0.1226  loss_dice_7: 0.1721  loss_ce_8: 9.742e-05  loss_mask_8: 0.1206  loss_dice_8: 0.1655  time: 0.6987  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:52:04] d2.utils.events INFO:  eta: 3:31:30  iter: 17499  total_loss: 2.876  loss_ce: 6.843e-05  loss_mask: 0.1128  loss_dice: 0.163  loss_ce_0: 0.1232  loss_mask_0: 0.1119  loss_dice_0: 0.1603  loss_ce_1: 8.646e-05  loss_mask_1: 0.1144  loss_dice_1: 0.1667  loss_ce_2: 9.624e-05  loss_mask_2: 0.1156  loss_dice_2: 0.163  loss_ce_3: 7.473e-05  loss_mask_3: 0.1108  loss_dice_3: 0.1633  loss_ce_4: 6.901e-05  loss_mask_4: 0.1126  loss_dice_4: 0.1629  loss_ce_5: 8.606e-05  loss_mask_5: 0.1135  loss_dice_5: 0.1621  loss_ce_6: 6.31e-05  loss_mask_6: 0.1103  loss_dice_6: 0.1616  loss_ce_7: 7.054e-05  loss_mask_7: 0.111  loss_dice_7: 0.1571  loss_ce_8: 9.266e-05  loss_mask_8: 0.1118  loss_dice_8: 0.1599  time: 0.6986  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:52:17] d2.utils.events INFO:  eta: 3:30:45  iter: 17519  total_loss: 3.054  loss_ce: 6.056e-05  loss_mask: 0.1166  loss_dice: 0.1745  loss_ce_0: 0.1236  loss_mask_0: 0.1198  loss_dice_0: 0.1869  loss_ce_1: 6.325e-05  loss_mask_1: 0.1147  loss_dice_1: 0.1738  loss_ce_2: 8.804e-05  loss_mask_2: 0.1193  loss_dice_2: 0.167  loss_ce_3: 6.431e-05  loss_mask_3: 0.1171  loss_dice_3: 0.1735  loss_ce_4: 6.591e-05  loss_mask_4: 0.1158  loss_dice_4: 0.1718  loss_ce_5: 6.111e-05  loss_mask_5: 0.1184  loss_dice_5: 0.176  loss_ce_6: 5.745e-05  loss_mask_6: 0.1191  loss_dice_6: 0.1709  loss_ce_7: 6.499e-05  loss_mask_7: 0.1177  loss_dice_7: 0.1719  loss_ce_8: 6.432e-05  loss_mask_8: 0.1168  loss_dice_8: 0.1772  time: 0.6986  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:52:30] d2.utils.events INFO:  eta: 3:30:09  iter: 17539  total_loss: 2.967  loss_ce: 5.871e-05  loss_mask: 0.1091  loss_dice: 0.1634  loss_ce_0: 0.1236  loss_mask_0: 0.1137  loss_dice_0: 0.174  loss_ce_1: 6.603e-05  loss_mask_1: 0.1113  loss_dice_1: 0.1698  loss_ce_2: 8.394e-05  loss_mask_2: 0.1142  loss_dice_2: 0.1732  loss_ce_3: 6.17e-05  loss_mask_3: 0.1141  loss_dice_3: 0.1725  loss_ce_4: 6.729e-05  loss_mask_4: 0.1144  loss_dice_4: 0.1674  loss_ce_5: 5.663e-05  loss_mask_5: 0.1161  loss_dice_5: 0.1743  loss_ce_6: 5.682e-05  loss_mask_6: 0.1111  loss_dice_6: 0.1673  loss_ce_7: 6.63e-05  loss_mask_7: 0.117  loss_dice_7: 0.1683  loss_ce_8: 6.538e-05  loss_mask_8: 0.1151  loss_dice_8: 0.1711  time: 0.6985  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:52:42] d2.utils.events INFO:  eta: 3:29:43  iter: 17559  total_loss: 2.92  loss_ce: 6.736e-05  loss_mask: 0.1136  loss_dice: 0.1668  loss_ce_0: 0.1224  loss_mask_0: 0.1095  loss_dice_0: 0.1634  loss_ce_1: 7.625e-05  loss_mask_1: 0.113  loss_dice_1: 0.1662  loss_ce_2: 8.899e-05  loss_mask_2: 0.1118  loss_dice_2: 0.1709  loss_ce_3: 7.029e-05  loss_mask_3: 0.1163  loss_dice_3: 0.1705  loss_ce_4: 7.146e-05  loss_mask_4: 0.1147  loss_dice_4: 0.1625  loss_ce_5: 7.65e-05  loss_mask_5: 0.1124  loss_dice_5: 0.1626  loss_ce_6: 5.709e-05  loss_mask_6: 0.1134  loss_dice_6: 0.1667  loss_ce_7: 6.827e-05  loss_mask_7: 0.1099  loss_dice_7: 0.1613  loss_ce_8: 9.027e-05  loss_mask_8: 0.113  loss_dice_8: 0.1656  time: 0.6984  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:52:55] d2.utils.events INFO:  eta: 3:29:12  iter: 17579  total_loss: 3.032  loss_ce: 5.954e-05  loss_mask: 0.1171  loss_dice: 0.1678  loss_ce_0: 0.1308  loss_mask_0: 0.118  loss_dice_0: 0.1696  loss_ce_1: 5.405e-05  loss_mask_1: 0.1157  loss_dice_1: 0.1735  loss_ce_2: 8.061e-05  loss_mask_2: 0.118  loss_dice_2: 0.1654  loss_ce_3: 6.265e-05  loss_mask_3: 0.115  loss_dice_3: 0.1684  loss_ce_4: 5.051e-05  loss_mask_4: 0.1157  loss_dice_4: 0.1709  loss_ce_5: 6.217e-05  loss_mask_5: 0.119  loss_dice_5: 0.1762  loss_ce_6: 4.997e-05  loss_mask_6: 0.116  loss_dice_6: 0.1713  loss_ce_7: 5.734e-05  loss_mask_7: 0.1167  loss_dice_7: 0.1695  loss_ce_8: 7.255e-05  loss_mask_8: 0.1203  loss_dice_8: 0.1722  time: 0.6983  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:53:07] d2.utils.events INFO:  eta: 3:28:50  iter: 17599  total_loss: 3.138  loss_ce: 3.244e-05  loss_mask: 0.1114  loss_dice: 0.1821  loss_ce_0: 0.1296  loss_mask_0: 0.1097  loss_dice_0: 0.1863  loss_ce_1: 1.876e-05  loss_mask_1: 0.1126  loss_dice_1: 0.1896  loss_ce_2: 3.945e-05  loss_mask_2: 0.1145  loss_dice_2: 0.1833  loss_ce_3: 2.01e-05  loss_mask_3: 0.11  loss_dice_3: 0.184  loss_ce_4: 1.838e-05  loss_mask_4: 0.1101  loss_dice_4: 0.1831  loss_ce_5: 2.896e-05  loss_mask_5: 0.1126  loss_dice_5: 0.1881  loss_ce_6: 1.991e-05  loss_mask_6: 0.1121  loss_dice_6: 0.1792  loss_ce_7: 2.023e-05  loss_mask_7: 0.1115  loss_dice_7: 0.1899  loss_ce_8: 2.964e-05  loss_mask_8: 0.1122  loss_dice_8: 0.1802  time: 0.6982  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:53:20] d2.utils.events INFO:  eta: 3:28:18  iter: 17619  total_loss: 3.018  loss_ce: 2.817e-05  loss_mask: 0.1188  loss_dice: 0.1644  loss_ce_0: 0.1254  loss_mask_0: 0.1228  loss_dice_0: 0.1728  loss_ce_1: 2.007e-05  loss_mask_1: 0.1188  loss_dice_1: 0.163  loss_ce_2: 3.853e-05  loss_mask_2: 0.1198  loss_dice_2: 0.1687  loss_ce_3: 1.946e-05  loss_mask_3: 0.1248  loss_dice_3: 0.1688  loss_ce_4: 1.871e-05  loss_mask_4: 0.1239  loss_dice_4: 0.1684  loss_ce_5: 2.884e-05  loss_mask_5: 0.1223  loss_dice_5: 0.1798  loss_ce_6: 1.879e-05  loss_mask_6: 0.1233  loss_dice_6: 0.1666  loss_ce_7: 1.944e-05  loss_mask_7: 0.122  loss_dice_7: 0.168  loss_ce_8: 2.776e-05  loss_mask_8: 0.1233  loss_dice_8: 0.1691  time: 0.6981  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:53:32] d2.utils.events INFO:  eta: 3:27:35  iter: 17639  total_loss: 2.88  loss_ce: 5.944e-05  loss_mask: 0.1113  loss_dice: 0.1619  loss_ce_0: 0.1206  loss_mask_0: 0.111  loss_dice_0: 0.1668  loss_ce_1: 6.884e-05  loss_mask_1: 0.1101  loss_dice_1: 0.1617  loss_ce_2: 8.436e-05  loss_mask_2: 0.1149  loss_dice_2: 0.1595  loss_ce_3: 6.256e-05  loss_mask_3: 0.1131  loss_dice_3: 0.1655  loss_ce_4: 6.262e-05  loss_mask_4: 0.1148  loss_dice_4: 0.1594  loss_ce_5: 7.279e-05  loss_mask_5: 0.1142  loss_dice_5: 0.1661  loss_ce_6: 5.359e-05  loss_mask_6: 0.1125  loss_dice_6: 0.1631  loss_ce_7: 6.406e-05  loss_mask_7: 0.113  loss_dice_7: 0.1696  loss_ce_8: 8.214e-05  loss_mask_8: 0.113  loss_dice_8: 0.1647  time: 0.6981  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:53:45] d2.utils.events INFO:  eta: 3:26:43  iter: 17659  total_loss: 2.963  loss_ce: 6e-05  loss_mask: 0.1142  loss_dice: 0.1634  loss_ce_0: 0.1185  loss_mask_0: 0.1103  loss_dice_0: 0.1621  loss_ce_1: 6.94e-05  loss_mask_1: 0.1103  loss_dice_1: 0.1624  loss_ce_2: 8.328e-05  loss_mask_2: 0.1138  loss_dice_2: 0.1664  loss_ce_3: 6.184e-05  loss_mask_3: 0.1154  loss_dice_3: 0.1681  loss_ce_4: 7.065e-05  loss_mask_4: 0.1131  loss_dice_4: 0.1667  loss_ce_5: 7.128e-05  loss_mask_5: 0.1127  loss_dice_5: 0.1648  loss_ce_6: 5.134e-05  loss_mask_6: 0.1132  loss_dice_6: 0.1621  loss_ce_7: 6.562e-05  loss_mask_7: 0.1169  loss_dice_7: 0.1706  loss_ce_8: 8.326e-05  loss_mask_8: 0.1172  loss_dice_8: 0.1672  time: 0.6980  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:53:57] d2.utils.events INFO:  eta: 3:25:46  iter: 17679  total_loss: 3.095  loss_ce: 5.289e-05  loss_mask: 0.1207  loss_dice: 0.1804  loss_ce_0: 0.1211  loss_mask_0: 0.116  loss_dice_0: 0.1785  loss_ce_1: 5.811e-05  loss_mask_1: 0.1164  loss_dice_1: 0.1765  loss_ce_2: 7.543e-05  loss_mask_2: 0.1188  loss_dice_2: 0.1811  loss_ce_3: 5.398e-05  loss_mask_3: 0.1179  loss_dice_3: 0.1813  loss_ce_4: 4.812e-05  loss_mask_4: 0.1174  loss_dice_4: 0.1811  loss_ce_5: 6.027e-05  loss_mask_5: 0.116  loss_dice_5: 0.1788  loss_ce_6: 4.75e-05  loss_mask_6: 0.1185  loss_dice_6: 0.1802  loss_ce_7: 5.542e-05  loss_mask_7: 0.1166  loss_dice_7: 0.1832  loss_ce_8: 6.842e-05  loss_mask_8: 0.1164  loss_dice_8: 0.1747  time: 0.6979  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:54:09] d2.utils.events INFO:  eta: 3:25:03  iter: 17699  total_loss: 2.856  loss_ce: 5.362e-05  loss_mask: 0.1113  loss_dice: 0.1654  loss_ce_0: 0.1321  loss_mask_0: 0.1108  loss_dice_0: 0.1613  loss_ce_1: 5.918e-05  loss_mask_1: 0.111  loss_dice_1: 0.1643  loss_ce_2: 7.522e-05  loss_mask_2: 0.1095  loss_dice_2: 0.1614  loss_ce_3: 5.598e-05  loss_mask_3: 0.112  loss_dice_3: 0.1602  loss_ce_4: 6.424e-05  loss_mask_4: 0.1096  loss_dice_4: 0.1625  loss_ce_5: 5.807e-05  loss_mask_5: 0.1142  loss_dice_5: 0.1599  loss_ce_6: 4.975e-05  loss_mask_6: 0.1143  loss_dice_6: 0.1598  loss_ce_7: 6.534e-05  loss_mask_7: 0.1093  loss_dice_7: 0.1641  loss_ce_8: 6.717e-05  loss_mask_8: 0.1145  loss_dice_8: 0.1622  time: 0.6978  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:54:22] d2.utils.events INFO:  eta: 3:24:20  iter: 17719  total_loss: 3.143  loss_ce: 5.91e-05  loss_mask: 0.1182  loss_dice: 0.1743  loss_ce_0: 0.1084  loss_mask_0: 0.1201  loss_dice_0: 0.1784  loss_ce_1: 6.817e-05  loss_mask_1: 0.1247  loss_dice_1: 0.1796  loss_ce_2: 8.176e-05  loss_mask_2: 0.1175  loss_dice_2: 0.1814  loss_ce_3: 5.382e-05  loss_mask_3: 0.119  loss_dice_3: 0.1771  loss_ce_4: 6.667e-05  loss_mask_4: 0.1225  loss_dice_4: 0.1742  loss_ce_5: 7.616e-05  loss_mask_5: 0.117  loss_dice_5: 0.1723  loss_ce_6: 4.591e-05  loss_mask_6: 0.1212  loss_dice_6: 0.1797  loss_ce_7: 6.428e-05  loss_mask_7: 0.118  loss_dice_7: 0.1728  loss_ce_8: 8.014e-05  loss_mask_8: 0.1198  loss_dice_8: 0.1777  time: 0.6977  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:54:35] d2.utils.events INFO:  eta: 3:23:26  iter: 17739  total_loss: 2.966  loss_ce: 3.715e-05  loss_mask: 0.1211  loss_dice: 0.1686  loss_ce_0: 0.1294  loss_mask_0: 0.1158  loss_dice_0: 0.1696  loss_ce_1: 3.657e-05  loss_mask_1: 0.1201  loss_dice_1: 0.1711  loss_ce_2: 5.052e-05  loss_mask_2: 0.1196  loss_dice_2: 0.1677  loss_ce_3: 3.386e-05  loss_mask_3: 0.1203  loss_dice_3: 0.165  loss_ce_4: 3.242e-05  loss_mask_4: 0.12  loss_dice_4: 0.1634  loss_ce_5: 3.568e-05  loss_mask_5: 0.1169  loss_dice_5: 0.1675  loss_ce_6: 2.549e-05  loss_mask_6: 0.1208  loss_dice_6: 0.1672  loss_ce_7: 3.136e-05  loss_mask_7: 0.1194  loss_dice_7: 0.1702  loss_ce_8: 3.692e-05  loss_mask_8: 0.1212  loss_dice_8: 0.1725  time: 0.6977  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 20:54:47] d2.utils.events INFO:  eta: 3:22:40  iter: 17759  total_loss: 3.017  loss_ce: 4.629e-05  loss_mask: 0.116  loss_dice: 0.1725  loss_ce_0: 0.1266  loss_mask_0: 0.1153  loss_dice_0: 0.1789  loss_ce_1: 4.051e-05  loss_mask_1: 0.1208  loss_dice_1: 0.1778  loss_ce_2: 6.853e-05  loss_mask_2: 0.1145  loss_dice_2: 0.1721  loss_ce_3: 5.256e-05  loss_mask_3: 0.1185  loss_dice_3: 0.1721  loss_ce_4: 5.023e-05  loss_mask_4: 0.1158  loss_dice_4: 0.17  loss_ce_5: 4.6e-05  loss_mask_5: 0.1214  loss_dice_5: 0.1741  loss_ce_6: 4.461e-05  loss_mask_6: 0.118  loss_dice_6: 0.1683  loss_ce_7: 4.667e-05  loss_mask_7: 0.1159  loss_dice_7: 0.1723  loss_ce_8: 4.927e-05  loss_mask_8: 0.1187  loss_dice_8: 0.1706  time: 0.6976  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:55:00] d2.utils.events INFO:  eta: 3:21:44  iter: 17779  total_loss: 2.949  loss_ce: 4.627e-05  loss_mask: 0.1144  loss_dice: 0.168  loss_ce_0: 0.1285  loss_mask_0: 0.116  loss_dice_0: 0.1696  loss_ce_1: 4.473e-05  loss_mask_1: 0.1149  loss_dice_1: 0.1672  loss_ce_2: 6.685e-05  loss_mask_2: 0.118  loss_dice_2: 0.1673  loss_ce_3: 5.111e-05  loss_mask_3: 0.1146  loss_dice_3: 0.1668  loss_ce_4: 5.135e-05  loss_mask_4: 0.1118  loss_dice_4: 0.1658  loss_ce_5: 4.769e-05  loss_mask_5: 0.1151  loss_dice_5: 0.1628  loss_ce_6: 4.152e-05  loss_mask_6: 0.1166  loss_dice_6: 0.1683  loss_ce_7: 4.932e-05  loss_mask_7: 0.1196  loss_dice_7: 0.1646  loss_ce_8: 5.463e-05  loss_mask_8: 0.1137  loss_dice_8: 0.1664  time: 0.6975  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:55:12] d2.utils.events INFO:  eta: 3:20:06  iter: 17799  total_loss: 2.985  loss_ce: 5.375e-05  loss_mask: 0.1142  loss_dice: 0.1628  loss_ce_0: 0.1262  loss_mask_0: 0.1177  loss_dice_0: 0.1735  loss_ce_1: 5.83e-05  loss_mask_1: 0.1146  loss_dice_1: 0.1638  loss_ce_2: 7.005e-05  loss_mask_2: 0.1152  loss_dice_2: 0.1682  loss_ce_3: 5.481e-05  loss_mask_3: 0.1161  loss_dice_3: 0.1699  loss_ce_4: 5.713e-05  loss_mask_4: 0.1139  loss_dice_4: 0.162  loss_ce_5: 6.281e-05  loss_mask_5: 0.1174  loss_dice_5: 0.1669  loss_ce_6: 4.36e-05  loss_mask_6: 0.1167  loss_dice_6: 0.1642  loss_ce_7: 5.47e-05  loss_mask_7: 0.1088  loss_dice_7: 0.1609  loss_ce_8: 7.394e-05  loss_mask_8: 0.1145  loss_dice_8: 0.1697  time: 0.6974  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:55:25] d2.utils.events INFO:  eta: 3:18:59  iter: 17819  total_loss: 3.094  loss_ce: 4.465e-05  loss_mask: 0.1128  loss_dice: 0.1748  loss_ce_0: 0.1298  loss_mask_0: 0.1144  loss_dice_0: 0.182  loss_ce_1: 4.617e-05  loss_mask_1: 0.1121  loss_dice_1: 0.1765  loss_ce_2: 6.35e-05  loss_mask_2: 0.1161  loss_dice_2: 0.1821  loss_ce_3: 4.903e-05  loss_mask_3: 0.1106  loss_dice_3: 0.1757  loss_ce_4: 4.639e-05  loss_mask_4: 0.1169  loss_dice_4: 0.1843  loss_ce_5: 5.094e-05  loss_mask_5: 0.1105  loss_dice_5: 0.1729  loss_ce_6: 4.28e-05  loss_mask_6: 0.115  loss_dice_6: 0.173  loss_ce_7: 4.599e-05  loss_mask_7: 0.1162  loss_dice_7: 0.1811  loss_ce_8: 5.564e-05  loss_mask_8: 0.1154  loss_dice_8: 0.1812  time: 0.6973  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:55:37] d2.utils.events INFO:  eta: 3:17:48  iter: 17839  total_loss: 2.964  loss_ce: 4.415e-05  loss_mask: 0.1139  loss_dice: 0.1694  loss_ce_0: 0.1241  loss_mask_0: 0.1145  loss_dice_0: 0.1764  loss_ce_1: 4.877e-05  loss_mask_1: 0.1164  loss_dice_1: 0.1808  loss_ce_2: 6.807e-05  loss_mask_2: 0.1114  loss_dice_2: 0.171  loss_ce_3: 4.897e-05  loss_mask_3: 0.114  loss_dice_3: 0.1701  loss_ce_4: 5.195e-05  loss_mask_4: 0.1141  loss_dice_4: 0.1714  loss_ce_5: 4.39e-05  loss_mask_5: 0.1117  loss_dice_5: 0.1696  loss_ce_6: 4.052e-05  loss_mask_6: 0.1146  loss_dice_6: 0.1716  loss_ce_7: 4.711e-05  loss_mask_7: 0.1152  loss_dice_7: 0.1737  loss_ce_8: 4.899e-05  loss_mask_8: 0.1136  loss_dice_8: 0.1681  time: 0.6972  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:55:50] d2.utils.events INFO:  eta: 3:16:16  iter: 17859  total_loss: 3.058  loss_ce: 2.367e-05  loss_mask: 0.1196  loss_dice: 0.1702  loss_ce_0: 0.1257  loss_mask_0: 0.1242  loss_dice_0: 0.1918  loss_ce_1: 1.721e-05  loss_mask_1: 0.1208  loss_dice_1: 0.1757  loss_ce_2: 3.237e-05  loss_mask_2: 0.1162  loss_dice_2: 0.1677  loss_ce_3: 1.638e-05  loss_mask_3: 0.1206  loss_dice_3: 0.1699  loss_ce_4: 1.625e-05  loss_mask_4: 0.1227  loss_dice_4: 0.1702  loss_ce_5: 2.36e-05  loss_mask_5: 0.1205  loss_dice_5: 0.1685  loss_ce_6: 1.686e-05  loss_mask_6: 0.1207  loss_dice_6: 0.174  loss_ce_7: 1.696e-05  loss_mask_7: 0.1216  loss_dice_7: 0.1716  loss_ce_8: 2.362e-05  loss_mask_8: 0.1204  loss_dice_8: 0.169  time: 0.6972  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:56:02] d2.utils.events INFO:  eta: 3:15:21  iter: 17879  total_loss: 2.977  loss_ce: 4.834e-05  loss_mask: 0.1128  loss_dice: 0.1724  loss_ce_0: 0.1243  loss_mask_0: 0.1129  loss_dice_0: 0.1757  loss_ce_1: 5.786e-05  loss_mask_1: 0.1156  loss_dice_1: 0.1726  loss_ce_2: 6.674e-05  loss_mask_2: 0.1154  loss_dice_2: 0.1728  loss_ce_3: 4.88e-05  loss_mask_3: 0.1135  loss_dice_3: 0.1727  loss_ce_4: 5.823e-05  loss_mask_4: 0.1121  loss_dice_4: 0.173  loss_ce_5: 5.593e-05  loss_mask_5: 0.1167  loss_dice_5: 0.1715  loss_ce_6: 4.646e-05  loss_mask_6: 0.1165  loss_dice_6: 0.1738  loss_ce_7: 4.865e-05  loss_mask_7: 0.1153  loss_dice_7: 0.1714  loss_ce_8: 6.206e-05  loss_mask_8: 0.1149  loss_dice_8: 0.1683  time: 0.6971  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:56:15] d2.utils.events INFO:  eta: 3:12:44  iter: 17899  total_loss: 2.898  loss_ce: 4.588e-05  loss_mask: 0.1141  loss_dice: 0.163  loss_ce_0: 0.1236  loss_mask_0: 0.1111  loss_dice_0: 0.1719  loss_ce_1: 5.129e-05  loss_mask_1: 0.1148  loss_dice_1: 0.1673  loss_ce_2: 6.179e-05  loss_mask_2: 0.1157  loss_dice_2: 0.1646  loss_ce_3: 4.584e-05  loss_mask_3: 0.1134  loss_dice_3: 0.1628  loss_ce_4: 5.806e-05  loss_mask_4: 0.117  loss_dice_4: 0.1654  loss_ce_5: 4.991e-05  loss_mask_5: 0.1136  loss_dice_5: 0.1626  loss_ce_6: 4.416e-05  loss_mask_6: 0.1128  loss_dice_6: 0.1648  loss_ce_7: 4.75e-05  loss_mask_7: 0.1141  loss_dice_7: 0.1661  loss_ce_8: 5.265e-05  loss_mask_8: 0.1139  loss_dice_8: 0.1642  time: 0.6970  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:56:28] d2.utils.events INFO:  eta: 3:11:08  iter: 17919  total_loss: 3.081  loss_ce: 3.998e-05  loss_mask: 0.1139  loss_dice: 0.1744  loss_ce_0: 0.1297  loss_mask_0: 0.1172  loss_dice_0: 0.1829  loss_ce_1: 3.834e-05  loss_mask_1: 0.1189  loss_dice_1: 0.1772  loss_ce_2: 5.712e-05  loss_mask_2: 0.1105  loss_dice_2: 0.1773  loss_ce_3: 4.306e-05  loss_mask_3: 0.1174  loss_dice_3: 0.1767  loss_ce_4: 4.157e-05  loss_mask_4: 0.1139  loss_dice_4: 0.1769  loss_ce_5: 4.177e-05  loss_mask_5: 0.1173  loss_dice_5: 0.1841  loss_ce_6: 3.938e-05  loss_mask_6: 0.1157  loss_dice_6: 0.1772  loss_ce_7: 4.064e-05  loss_mask_7: 0.1136  loss_dice_7: 0.1819  loss_ce_8: 4.301e-05  loss_mask_8: 0.1118  loss_dice_8: 0.1776  time: 0.6969  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:56:40] d2.utils.events INFO:  eta: 3:09:47  iter: 17939  total_loss: 2.963  loss_ce: 4.603e-05  loss_mask: 0.1154  loss_dice: 0.1648  loss_ce_0: 0.1274  loss_mask_0: 0.1157  loss_dice_0: 0.1703  loss_ce_1: 4.997e-05  loss_mask_1: 0.1143  loss_dice_1: 0.1662  loss_ce_2: 6.043e-05  loss_mask_2: 0.1164  loss_dice_2: 0.1685  loss_ce_3: 4.642e-05  loss_mask_3: 0.1132  loss_dice_3: 0.1668  loss_ce_4: 5.591e-05  loss_mask_4: 0.1166  loss_dice_4: 0.1613  loss_ce_5: 4.735e-05  loss_mask_5: 0.1141  loss_dice_5: 0.1648  loss_ce_6: 4.312e-05  loss_mask_6: 0.1155  loss_dice_6: 0.1678  loss_ce_7: 4.867e-05  loss_mask_7: 0.1145  loss_dice_7: 0.1641  loss_ce_8: 5.456e-05  loss_mask_8: 0.1176  loss_dice_8: 0.1677  time: 0.6969  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:56:53] d2.utils.events INFO:  eta: 3:07:59  iter: 17959  total_loss: 2.848  loss_ce: 2.445e-05  loss_mask: 0.118  loss_dice: 0.163  loss_ce_0: 0.1296  loss_mask_0: 0.1117  loss_dice_0: 0.1599  loss_ce_1: 1.552e-05  loss_mask_1: 0.1153  loss_dice_1: 0.1612  loss_ce_2: 2.932e-05  loss_mask_2: 0.1105  loss_dice_2: 0.163  loss_ce_3: 1.838e-05  loss_mask_3: 0.1171  loss_dice_3: 0.1596  loss_ce_4: 1.574e-05  loss_mask_4: 0.1147  loss_dice_4: 0.1603  loss_ce_5: 2.66e-05  loss_mask_5: 0.115  loss_dice_5: 0.1596  loss_ce_6: 1.49e-05  loss_mask_6: 0.1151  loss_dice_6: 0.1556  loss_ce_7: 1.72e-05  loss_mask_7: 0.1142  loss_dice_7: 0.1611  loss_ce_8: 2.482e-05  loss_mask_8: 0.1107  loss_dice_8: 0.1558  time: 0.6968  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:57:05] d2.utils.events INFO:  eta: 3:07:07  iter: 17979  total_loss: 3.05  loss_ce: 4.038e-05  loss_mask: 0.1159  loss_dice: 0.1689  loss_ce_0: 0.1246  loss_mask_0: 0.117  loss_dice_0: 0.1745  loss_ce_1: 4.707e-05  loss_mask_1: 0.1188  loss_dice_1: 0.1692  loss_ce_2: 6.05e-05  loss_mask_2: 0.1178  loss_dice_2: 0.1659  loss_ce_3: 4.233e-05  loss_mask_3: 0.1237  loss_dice_3: 0.176  loss_ce_4: 4.974e-05  loss_mask_4: 0.1169  loss_dice_4: 0.1668  loss_ce_5: 4.544e-05  loss_mask_5: 0.1154  loss_dice_5: 0.1712  loss_ce_6: 3.669e-05  loss_mask_6: 0.1186  loss_dice_6: 0.1748  loss_ce_7: 4.683e-05  loss_mask_7: 0.1197  loss_dice_7: 0.1693  loss_ce_8: 5.114e-05  loss_mask_8: 0.1181  loss_dice_8: 0.1722  time: 0.6967  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:57:18] d2.utils.events INFO:  eta: 3:05:55  iter: 17999  total_loss: 2.843  loss_ce: 4.687e-05  loss_mask: 0.1151  loss_dice: 0.1621  loss_ce_0: 0.1198  loss_mask_0: 0.1154  loss_dice_0: 0.1647  loss_ce_1: 6.029e-05  loss_mask_1: 0.1123  loss_dice_1: 0.1594  loss_ce_2: 6.715e-05  loss_mask_2: 0.1161  loss_dice_2: 0.1642  loss_ce_3: 4.415e-05  loss_mask_3: 0.1119  loss_dice_3: 0.1622  loss_ce_4: 5.421e-05  loss_mask_4: 0.1151  loss_dice_4: 0.1624  loss_ce_5: 6.287e-05  loss_mask_5: 0.1129  loss_dice_5: 0.1594  loss_ce_6: 4.009e-05  loss_mask_6: 0.1131  loss_dice_6: 0.1592  loss_ce_7: 5.068e-05  loss_mask_7: 0.1123  loss_dice_7: 0.163  loss_ce_8: 6.716e-05  loss_mask_8: 0.1126  loss_dice_8: 0.1591  time: 0.6966  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:57:30] d2.utils.events INFO:  eta: 3:04:58  iter: 18019  total_loss: 2.889  loss_ce: 4.458e-05  loss_mask: 0.112  loss_dice: 0.1662  loss_ce_0: 0.1245  loss_mask_0: 0.1121  loss_dice_0: 0.1661  loss_ce_1: 4.492e-05  loss_mask_1: 0.1121  loss_dice_1: 0.1616  loss_ce_2: 6.017e-05  loss_mask_2: 0.1136  loss_dice_2: 0.1651  loss_ce_3: 4.393e-05  loss_mask_3: 0.1134  loss_dice_3: 0.164  loss_ce_4: 5.007e-05  loss_mask_4: 0.1145  loss_dice_4: 0.1681  loss_ce_5: 5.001e-05  loss_mask_5: 0.1164  loss_dice_5: 0.163  loss_ce_6: 4.194e-05  loss_mask_6: 0.1155  loss_dice_6: 0.1642  loss_ce_7: 4.698e-05  loss_mask_7: 0.1149  loss_dice_7: 0.1652  loss_ce_8: 5.895e-05  loss_mask_8: 0.1137  loss_dice_8: 0.1643  time: 0.6966  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:57:43] d2.utils.events INFO:  eta: 3:04:10  iter: 18039  total_loss: 2.921  loss_ce: 4.359e-05  loss_mask: 0.1146  loss_dice: 0.1664  loss_ce_0: 0.1195  loss_mask_0: 0.1127  loss_dice_0: 0.1645  loss_ce_1: 5.437e-05  loss_mask_1: 0.1177  loss_dice_1: 0.1677  loss_ce_2: 6.063e-05  loss_mask_2: 0.1136  loss_dice_2: 0.1675  loss_ce_3: 4.079e-05  loss_mask_3: 0.1126  loss_dice_3: 0.1625  loss_ce_4: 5.06e-05  loss_mask_4: 0.1154  loss_dice_4: 0.1704  loss_ce_5: 5.104e-05  loss_mask_5: 0.1146  loss_dice_5: 0.1676  loss_ce_6: 3.91e-05  loss_mask_6: 0.1124  loss_dice_6: 0.1664  loss_ce_7: 4.875e-05  loss_mask_7: 0.1157  loss_dice_7: 0.167  loss_ce_8: 6.006e-05  loss_mask_8: 0.1126  loss_dice_8: 0.1649  time: 0.6965  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:57:56] d2.utils.events INFO:  eta: 3:03:06  iter: 18059  total_loss: 2.853  loss_ce: 3.861e-05  loss_mask: 0.1112  loss_dice: 0.1595  loss_ce_0: 0.1261  loss_mask_0: 0.1134  loss_dice_0: 0.1632  loss_ce_1: 4.801e-05  loss_mask_1: 0.1123  loss_dice_1: 0.1593  loss_ce_2: 5.689e-05  loss_mask_2: 0.1089  loss_dice_2: 0.1594  loss_ce_3: 4.058e-05  loss_mask_3: 0.1098  loss_dice_3: 0.1588  loss_ce_4: 5.087e-05  loss_mask_4: 0.1139  loss_dice_4: 0.162  loss_ce_5: 3.96e-05  loss_mask_5: 0.1112  loss_dice_5: 0.161  loss_ce_6: 3.853e-05  loss_mask_6: 0.1131  loss_dice_6: 0.1638  loss_ce_7: 4.657e-05  loss_mask_7: 0.1113  loss_dice_7: 0.1608  loss_ce_8: 4.284e-05  loss_mask_8: 0.1118  loss_dice_8: 0.1584  time: 0.6964  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:58:08] d2.utils.events INFO:  eta: 3:02:20  iter: 18079  total_loss: 2.951  loss_ce: 4.364e-05  loss_mask: 0.1128  loss_dice: 0.1682  loss_ce_0: 0.1241  loss_mask_0: 0.1127  loss_dice_0: 0.1698  loss_ce_1: 5.135e-05  loss_mask_1: 0.115  loss_dice_1: 0.1692  loss_ce_2: 6.388e-05  loss_mask_2: 0.1131  loss_dice_2: 0.1726  loss_ce_3: 4.37e-05  loss_mask_3: 0.1163  loss_dice_3: 0.1712  loss_ce_4: 5.013e-05  loss_mask_4: 0.1135  loss_dice_4: 0.1663  loss_ce_5: 5.983e-05  loss_mask_5: 0.1154  loss_dice_5: 0.177  loss_ce_6: 3.882e-05  loss_mask_6: 0.1154  loss_dice_6: 0.1684  loss_ce_7: 4.705e-05  loss_mask_7: 0.118  loss_dice_7: 0.1687  loss_ce_8: 6.289e-05  loss_mask_8: 0.1131  loss_dice_8: 0.1679  time: 0.6963  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:58:21] d2.utils.events INFO:  eta: 3:01:39  iter: 18099  total_loss: 3.015  loss_ce: 7.667e-05  loss_mask: 0.1154  loss_dice: 0.167  loss_ce_0: 0.123  loss_mask_0: 0.1193  loss_dice_0: 0.1738  loss_ce_1: 0.0001061  loss_mask_1: 0.1152  loss_dice_1: 0.1684  loss_ce_2: 9.154e-05  loss_mask_2: 0.1182  loss_dice_2: 0.1735  loss_ce_3: 9.892e-05  loss_mask_3: 0.1146  loss_dice_3: 0.1656  loss_ce_4: 9.704e-05  loss_mask_4: 0.1159  loss_dice_4: 0.1732  loss_ce_5: 8.324e-05  loss_mask_5: 0.1144  loss_dice_5: 0.1701  loss_ce_6: 8.093e-05  loss_mask_6: 0.1189  loss_dice_6: 0.1731  loss_ce_7: 0.0001033  loss_mask_7: 0.1157  loss_dice_7: 0.1654  loss_ce_8: 8.888e-05  loss_mask_8: 0.1138  loss_dice_8: 0.1709  time: 0.6963  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:58:33] d2.utils.events INFO:  eta: 3:00:45  iter: 18119  total_loss: 3.02  loss_ce: 0.0003598  loss_mask: 0.1165  loss_dice: 0.169  loss_ce_0: 0.1236  loss_mask_0: 0.1149  loss_dice_0: 0.177  loss_ce_1: 0.0001175  loss_mask_1: 0.1137  loss_dice_1: 0.168  loss_ce_2: 0.000194  loss_mask_2: 0.114  loss_dice_2: 0.1687  loss_ce_3: 0.0001548  loss_mask_3: 0.1134  loss_dice_3: 0.1618  loss_ce_4: 0.0001337  loss_mask_4: 0.1172  loss_dice_4: 0.169  loss_ce_5: 0.0002426  loss_mask_5: 0.1153  loss_dice_5: 0.1652  loss_ce_6: 0.000179  loss_mask_6: 0.117  loss_dice_6: 0.1721  loss_ce_7: 0.0002013  loss_mask_7: 0.1157  loss_dice_7: 0.1711  loss_ce_8: 0.0002912  loss_mask_8: 0.113  loss_dice_8: 0.1671  time: 0.6962  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:58:46] d2.utils.events INFO:  eta: 2:59:56  iter: 18139  total_loss: 3.194  loss_ce: 0.0001028  loss_mask: 0.1252  loss_dice: 0.189  loss_ce_0: 0.1226  loss_mask_0: 0.1211  loss_dice_0: 0.1883  loss_ce_1: 0.0001233  loss_mask_1: 0.1196  loss_dice_1: 0.1798  loss_ce_2: 0.0001509  loss_mask_2: 0.121  loss_dice_2: 0.1853  loss_ce_3: 0.0001804  loss_mask_3: 0.1225  loss_dice_3: 0.1809  loss_ce_4: 0.0001271  loss_mask_4: 0.121  loss_dice_4: 0.1896  loss_ce_5: 0.0001203  loss_mask_5: 0.1222  loss_dice_5: 0.1809  loss_ce_6: 0.0001441  loss_mask_6: 0.1231  loss_dice_6: 0.1853  loss_ce_7: 0.0001088  loss_mask_7: 0.1195  loss_dice_7: 0.1801  loss_ce_8: 0.000136  loss_mask_8: 0.1153  loss_dice_8: 0.1787  time: 0.6961  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:58:59] d2.utils.events INFO:  eta: 2:59:16  iter: 18159  total_loss: 2.938  loss_ce: 0.0004774  loss_mask: 0.1161  loss_dice: 0.1649  loss_ce_0: 0.1245  loss_mask_0: 0.1156  loss_dice_0: 0.1653  loss_ce_1: 0.001018  loss_mask_1: 0.1138  loss_dice_1: 0.1685  loss_ce_2: 0.001204  loss_mask_2: 0.1179  loss_dice_2: 0.1683  loss_ce_3: 0.0004553  loss_mask_3: 0.113  loss_dice_3: 0.1687  loss_ce_4: 0.0003767  loss_mask_4: 0.1135  loss_dice_4: 0.171  loss_ce_5: 0.0009456  loss_mask_5: 0.1157  loss_dice_5: 0.1728  loss_ce_6: 0.0004281  loss_mask_6: 0.1141  loss_dice_6: 0.1659  loss_ce_7: 0.0007714  loss_mask_7: 0.1148  loss_dice_7: 0.1626  loss_ce_8: 0.0009034  loss_mask_8: 0.1116  loss_dice_8: 0.1599  time: 0.6960  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 20:59:11] d2.utils.events INFO:  eta: 2:58:36  iter: 18179  total_loss: 2.869  loss_ce: 0.0002239  loss_mask: 0.1108  loss_dice: 0.1625  loss_ce_0: 0.1223  loss_mask_0: 0.1095  loss_dice_0: 0.1632  loss_ce_1: 0.0002518  loss_mask_1: 0.1105  loss_dice_1: 0.1621  loss_ce_2: 0.0004214  loss_mask_2: 0.1121  loss_dice_2: 0.16  loss_ce_3: 0.0009517  loss_mask_3: 0.1148  loss_dice_3: 0.1641  loss_ce_4: 0.0003204  loss_mask_4: 0.1124  loss_dice_4: 0.166  loss_ce_5: 0.0002746  loss_mask_5: 0.1115  loss_dice_5: 0.163  loss_ce_6: 0.0003869  loss_mask_6: 0.1127  loss_dice_6: 0.1695  loss_ce_7: 0.0002331  loss_mask_7: 0.1101  loss_dice_7: 0.1603  loss_ce_8: 0.0004856  loss_mask_8: 0.1097  loss_dice_8: 0.1644  time: 0.6960  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:59:24] d2.utils.events INFO:  eta: 2:57:56  iter: 18199  total_loss: 2.998  loss_ce: 0.0002003  loss_mask: 0.119  loss_dice: 0.1635  loss_ce_0: 0.1244  loss_mask_0: 0.1159  loss_dice_0: 0.1601  loss_ce_1: 0.0001638  loss_mask_1: 0.1198  loss_dice_1: 0.1666  loss_ce_2: 0.0002459  loss_mask_2: 0.1177  loss_dice_2: 0.1625  loss_ce_3: 0.0006724  loss_mask_3: 0.1209  loss_dice_3: 0.1617  loss_ce_4: 0.0004534  loss_mask_4: 0.1205  loss_dice_4: 0.1656  loss_ce_5: 0.0002385  loss_mask_5: 0.1181  loss_dice_5: 0.1644  loss_ce_6: 0.0003233  loss_mask_6: 0.1246  loss_dice_6: 0.1685  loss_ce_7: 0.0001953  loss_mask_7: 0.1225  loss_dice_7: 0.1648  loss_ce_8: 0.0003952  loss_mask_8: 0.1208  loss_dice_8: 0.1664  time: 0.6959  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:59:36] d2.utils.events INFO:  eta: 2:57:25  iter: 18219  total_loss: 2.818  loss_ce: 0.0003838  loss_mask: 0.108  loss_dice: 0.1565  loss_ce_0: 0.1226  loss_mask_0: 0.1102  loss_dice_0: 0.1574  loss_ce_1: 0.0003538  loss_mask_1: 0.1088  loss_dice_1: 0.156  loss_ce_2: 0.0003763  loss_mask_2: 0.1098  loss_dice_2: 0.1552  loss_ce_3: 0.0002941  loss_mask_3: 0.1123  loss_dice_3: 0.1575  loss_ce_4: 0.0002302  loss_mask_4: 0.1135  loss_dice_4: 0.157  loss_ce_5: 0.0001825  loss_mask_5: 0.113  loss_dice_5: 0.1561  loss_ce_6: 0.0002328  loss_mask_6: 0.1107  loss_dice_6: 0.1535  loss_ce_7: 0.0002588  loss_mask_7: 0.1119  loss_dice_7: 0.1584  loss_ce_8: 0.0004134  loss_mask_8: 0.1134  loss_dice_8: 0.1602  time: 0.6958  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 20:59:49] d2.utils.events INFO:  eta: 2:56:59  iter: 18239  total_loss: 3.042  loss_ce: 0.0004205  loss_mask: 0.1143  loss_dice: 0.1651  loss_ce_0: 0.1188  loss_mask_0: 0.1166  loss_dice_0: 0.1745  loss_ce_1: 0.0005069  loss_mask_1: 0.1204  loss_dice_1: 0.1704  loss_ce_2: 0.0005859  loss_mask_2: 0.1121  loss_dice_2: 0.1661  loss_ce_3: 0.0003539  loss_mask_3: 0.1165  loss_dice_3: 0.1711  loss_ce_4: 0.0002627  loss_mask_4: 0.1161  loss_dice_4: 0.1674  loss_ce_5: 0.0002402  loss_mask_5: 0.1163  loss_dice_5: 0.1722  loss_ce_6: 0.0002347  loss_mask_6: 0.1149  loss_dice_6: 0.1695  loss_ce_7: 0.0002765  loss_mask_7: 0.1189  loss_dice_7: 0.1688  loss_ce_8: 0.0005809  loss_mask_8: 0.1196  loss_dice_8: 0.1774  time: 0.6957  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:00:01] d2.utils.events INFO:  eta: 2:56:16  iter: 18259  total_loss: 2.943  loss_ce: 0.0003518  loss_mask: 0.112  loss_dice: 0.1722  loss_ce_0: 0.1314  loss_mask_0: 0.1125  loss_dice_0: 0.1649  loss_ce_1: 0.000452  loss_mask_1: 0.1095  loss_dice_1: 0.1724  loss_ce_2: 0.0005724  loss_mask_2: 0.1122  loss_dice_2: 0.1718  loss_ce_3: 0.0003149  loss_mask_3: 0.1074  loss_dice_3: 0.1629  loss_ce_4: 0.0003021  loss_mask_4: 0.1126  loss_dice_4: 0.1651  loss_ce_5: 0.0004867  loss_mask_5: 0.1135  loss_dice_5: 0.1751  loss_ce_6: 0.0002093  loss_mask_6: 0.1123  loss_dice_6: 0.1644  loss_ce_7: 0.0004719  loss_mask_7: 0.1104  loss_dice_7: 0.1731  loss_ce_8: 0.0005539  loss_mask_8: 0.1125  loss_dice_8: 0.1674  time: 0.6957  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:00:14] d2.utils.events INFO:  eta: 2:55:53  iter: 18279  total_loss: 2.856  loss_ce: 0.000192  loss_mask: 0.1103  loss_dice: 0.1601  loss_ce_0: 0.1254  loss_mask_0: 0.1091  loss_dice_0: 0.1601  loss_ce_1: 0.0002494  loss_mask_1: 0.1113  loss_dice_1: 0.1618  loss_ce_2: 0.0002381  loss_mask_2: 0.1116  loss_dice_2: 0.1614  loss_ce_3: 0.0002041  loss_mask_3: 0.1126  loss_dice_3: 0.1602  loss_ce_4: 0.0001987  loss_mask_4: 0.1135  loss_dice_4: 0.1595  loss_ce_5: 0.0001976  loss_mask_5: 0.111  loss_dice_5: 0.1637  loss_ce_6: 0.0001659  loss_mask_6: 0.1104  loss_dice_6: 0.1586  loss_ce_7: 0.0002142  loss_mask_7: 0.1096  loss_dice_7: 0.1585  loss_ce_8: 0.000262  loss_mask_8: 0.1136  loss_dice_8: 0.1678  time: 0.6956  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:00:26] d2.utils.events INFO:  eta: 2:55:29  iter: 18299  total_loss: 3.051  loss_ce: 9.722e-05  loss_mask: 0.1218  loss_dice: 0.1725  loss_ce_0: 0.1213  loss_mask_0: 0.1161  loss_dice_0: 0.1663  loss_ce_1: 0.000177  loss_mask_1: 0.1199  loss_dice_1: 0.1718  loss_ce_2: 9.972e-05  loss_mask_2: 0.1191  loss_dice_2: 0.1715  loss_ce_3: 0.0001697  loss_mask_3: 0.1224  loss_dice_3: 0.1714  loss_ce_4: 0.0001861  loss_mask_4: 0.1192  loss_dice_4: 0.1667  loss_ce_5: 0.0001042  loss_mask_5: 0.1199  loss_dice_5: 0.1698  loss_ce_6: 9.648e-05  loss_mask_6: 0.1176  loss_dice_6: 0.1618  loss_ce_7: 0.0001015  loss_mask_7: 0.1207  loss_dice_7: 0.1702  loss_ce_8: 9.544e-05  loss_mask_8: 0.1214  loss_dice_8: 0.1716  time: 0.6955  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:00:39] d2.utils.events INFO:  eta: 2:54:54  iter: 18319  total_loss: 3.04  loss_ce: 0.0002219  loss_mask: 0.1199  loss_dice: 0.1705  loss_ce_0: 0.1269  loss_mask_0: 0.1154  loss_dice_0: 0.1671  loss_ce_1: 0.0002214  loss_mask_1: 0.1169  loss_dice_1: 0.1714  loss_ce_2: 0.0002595  loss_mask_2: 0.121  loss_dice_2: 0.1725  loss_ce_3: 0.0001643  loss_mask_3: 0.1206  loss_dice_3: 0.1728  loss_ce_4: 0.0001733  loss_mask_4: 0.1205  loss_dice_4: 0.1775  loss_ce_5: 0.0002686  loss_mask_5: 0.1175  loss_dice_5: 0.1792  loss_ce_6: 0.0001594  loss_mask_6: 0.1193  loss_dice_6: 0.1691  loss_ce_7: 0.0001838  loss_mask_7: 0.1203  loss_dice_7: 0.1698  loss_ce_8: 0.000237  loss_mask_8: 0.1245  loss_dice_8: 0.1746  time: 0.6954  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:00:51] d2.utils.events INFO:  eta: 2:54:23  iter: 18339  total_loss: 3.105  loss_ce: 9.849e-05  loss_mask: 0.1158  loss_dice: 0.1743  loss_ce_0: 0.1181  loss_mask_0: 0.1239  loss_dice_0: 0.1809  loss_ce_1: 0.0001467  loss_mask_1: 0.1219  loss_dice_1: 0.1827  loss_ce_2: 9.256e-05  loss_mask_2: 0.1166  loss_dice_2: 0.1733  loss_ce_3: 0.0001355  loss_mask_3: 0.1192  loss_dice_3: 0.1782  loss_ce_4: 0.0001419  loss_mask_4: 0.1169  loss_dice_4: 0.1765  loss_ce_5: 9.192e-05  loss_mask_5: 0.1199  loss_dice_5: 0.1723  loss_ce_6: 8.346e-05  loss_mask_6: 0.1174  loss_dice_6: 0.1734  loss_ce_7: 9.279e-05  loss_mask_7: 0.1198  loss_dice_7: 0.1779  loss_ce_8: 8.988e-05  loss_mask_8: 0.1177  loss_dice_8: 0.178  time: 0.6953  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:01:04] d2.utils.events INFO:  eta: 2:53:54  iter: 18359  total_loss: 2.834  loss_ce: 0.0001277  loss_mask: 0.1128  loss_dice: 0.1564  loss_ce_0: 0.1233  loss_mask_0: 0.1112  loss_dice_0: 0.1587  loss_ce_1: 0.0002011  loss_mask_1: 0.1128  loss_dice_1: 0.1605  loss_ce_2: 0.0001735  loss_mask_2: 0.1133  loss_dice_2: 0.158  loss_ce_3: 0.0002031  loss_mask_3: 0.1148  loss_dice_3: 0.156  loss_ce_4: 0.0001867  loss_mask_4: 0.1122  loss_dice_4: 0.1506  loss_ce_5: 0.0001547  loss_mask_5: 0.1167  loss_dice_5: 0.156  loss_ce_6: 0.0001114  loss_mask_6: 0.1156  loss_dice_6: 0.1592  loss_ce_7: 0.0001661  loss_mask_7: 0.1167  loss_dice_7: 0.1615  loss_ce_8: 0.0001903  loss_mask_8: 0.1145  loss_dice_8: 0.1553  time: 0.6953  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:01:16] d2.utils.events INFO:  eta: 2:53:36  iter: 18379  total_loss: 2.918  loss_ce: 0.0001116  loss_mask: 0.1165  loss_dice: 0.1645  loss_ce_0: 0.1217  loss_mask_0: 0.117  loss_dice_0: 0.1627  loss_ce_1: 0.0001526  loss_mask_1: 0.1128  loss_dice_1: 0.1547  loss_ce_2: 0.0001395  loss_mask_2: 0.1177  loss_dice_2: 0.1586  loss_ce_3: 0.0001347  loss_mask_3: 0.1151  loss_dice_3: 0.164  loss_ce_4: 0.0001386  loss_mask_4: 0.1184  loss_dice_4: 0.1617  loss_ce_5: 0.0001375  loss_mask_5: 0.1143  loss_dice_5: 0.1639  loss_ce_6: 0.000117  loss_mask_6: 0.1122  loss_dice_6: 0.1584  loss_ce_7: 0.0001455  loss_mask_7: 0.1169  loss_dice_7: 0.1603  loss_ce_8: 0.0001686  loss_mask_8: 0.1164  loss_dice_8: 0.1611  time: 0.6952  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:01:29] d2.utils.events INFO:  eta: 2:53:10  iter: 18399  total_loss: 2.965  loss_ce: 9.378e-05  loss_mask: 0.1137  loss_dice: 0.1679  loss_ce_0: 0.1168  loss_mask_0: 0.1165  loss_dice_0: 0.1813  loss_ce_1: 0.0001331  loss_mask_1: 0.1153  loss_dice_1: 0.1702  loss_ce_2: 0.0001344  loss_mask_2: 0.1128  loss_dice_2: 0.166  loss_ce_3: 0.0001356  loss_mask_3: 0.1163  loss_dice_3: 0.1649  loss_ce_4: 0.0001209  loss_mask_4: 0.1133  loss_dice_4: 0.1728  loss_ce_5: 0.0001299  loss_mask_5: 0.113  loss_dice_5: 0.1646  loss_ce_6: 7.209e-05  loss_mask_6: 0.1145  loss_dice_6: 0.1724  loss_ce_7: 0.0001143  loss_mask_7: 0.1168  loss_dice_7: 0.1721  loss_ce_8: 0.0001508  loss_mask_8: 0.1102  loss_dice_8: 0.1595  time: 0.6951  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:01:42] d2.utils.events INFO:  eta: 2:52:47  iter: 18419  total_loss: 2.895  loss_ce: 8.336e-05  loss_mask: 0.1106  loss_dice: 0.1645  loss_ce_0: 0.1159  loss_mask_0: 0.1216  loss_dice_0: 0.1745  loss_ce_1: 0.0001164  loss_mask_1: 0.1153  loss_dice_1: 0.1667  loss_ce_2: 0.0001201  loss_mask_2: 0.1152  loss_dice_2: 0.1622  loss_ce_3: 0.0001164  loss_mask_3: 0.1161  loss_dice_3: 0.1689  loss_ce_4: 0.000114  loss_mask_4: 0.112  loss_dice_4: 0.1676  loss_ce_5: 0.0001232  loss_mask_5: 0.1182  loss_dice_5: 0.1658  loss_ce_6: 8.048e-05  loss_mask_6: 0.117  loss_dice_6: 0.1695  loss_ce_7: 0.0001071  loss_mask_7: 0.1124  loss_dice_7: 0.1635  loss_ce_8: 0.0001381  loss_mask_8: 0.1202  loss_dice_8: 0.1705  time: 0.6950  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:01:54] d2.utils.events INFO:  eta: 2:52:32  iter: 18439  total_loss: 2.863  loss_ce: 0.0001419  loss_mask: 0.108  loss_dice: 0.1568  loss_ce_0: 0.1253  loss_mask_0: 0.1074  loss_dice_0: 0.156  loss_ce_1: 0.0001158  loss_mask_1: 0.1068  loss_dice_1: 0.1619  loss_ce_2: 0.0001723  loss_mask_2: 0.1075  loss_dice_2: 0.1587  loss_ce_3: 0.0001009  loss_mask_3: 0.1051  loss_dice_3: 0.1591  loss_ce_4: 9.793e-05  loss_mask_4: 0.1072  loss_dice_4: 0.1558  loss_ce_5: 0.0001808  loss_mask_5: 0.1077  loss_dice_5: 0.1589  loss_ce_6: 0.0001011  loss_mask_6: 0.11  loss_dice_6: 0.1635  loss_ce_7: 0.0001117  loss_mask_7: 0.1073  loss_dice_7: 0.1637  loss_ce_8: 0.0001467  loss_mask_8: 0.1108  loss_dice_8: 0.1581  time: 0.6950  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:02:07] d2.utils.events INFO:  eta: 2:52:19  iter: 18459  total_loss: 2.88  loss_ce: 0.0001446  loss_mask: 0.1114  loss_dice: 0.1618  loss_ce_0: 0.1249  loss_mask_0: 0.112  loss_dice_0: 0.1647  loss_ce_1: 0.0001412  loss_mask_1: 0.1112  loss_dice_1: 0.1659  loss_ce_2: 0.0001832  loss_mask_2: 0.1099  loss_dice_2: 0.1634  loss_ce_3: 0.0001049  loss_mask_3: 0.1102  loss_dice_3: 0.1614  loss_ce_4: 0.0001053  loss_mask_4: 0.11  loss_dice_4: 0.1574  loss_ce_5: 0.0001699  loss_mask_5: 0.1111  loss_dice_5: 0.1618  loss_ce_6: 0.0001037  loss_mask_6: 0.1105  loss_dice_6: 0.1647  loss_ce_7: 0.0001478  loss_mask_7: 0.1118  loss_dice_7: 0.1661  loss_ce_8: 0.0001791  loss_mask_8: 0.1104  loss_dice_8: 0.1659  time: 0.6949  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:02:19] d2.utils.events INFO:  eta: 2:52:07  iter: 18479  total_loss: 2.81  loss_ce: 0.0001123  loss_mask: 0.1087  loss_dice: 0.163  loss_ce_0: 0.1211  loss_mask_0: 0.1094  loss_dice_0: 0.1573  loss_ce_1: 0.0001158  loss_mask_1: 0.1115  loss_dice_1: 0.1628  loss_ce_2: 0.000136  loss_mask_2: 0.108  loss_dice_2: 0.162  loss_ce_3: 9.756e-05  loss_mask_3: 0.1125  loss_dice_3: 0.1605  loss_ce_4: 0.0001048  loss_mask_4: 0.1099  loss_dice_4: 0.1648  loss_ce_5: 0.0001439  loss_mask_5: 0.1117  loss_dice_5: 0.1659  loss_ce_6: 8.686e-05  loss_mask_6: 0.1121  loss_dice_6: 0.1662  loss_ce_7: 0.0001066  loss_mask_7: 0.1112  loss_dice_7: 0.1581  loss_ce_8: 0.0001298  loss_mask_8: 0.1128  loss_dice_8: 0.1655  time: 0.6948  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 21:02:32] d2.utils.events INFO:  eta: 2:51:53  iter: 18499  total_loss: 3.039  loss_ce: 0.0001104  loss_mask: 0.1128  loss_dice: 0.1759  loss_ce_0: 0.1207  loss_mask_0: 0.1155  loss_dice_0: 0.1783  loss_ce_1: 0.000108  loss_mask_1: 0.1142  loss_dice_1: 0.181  loss_ce_2: 0.0001457  loss_mask_2: 0.1191  loss_dice_2: 0.1819  loss_ce_3: 8.688e-05  loss_mask_3: 0.1118  loss_dice_3: 0.1736  loss_ce_4: 9.214e-05  loss_mask_4: 0.1145  loss_dice_4: 0.1754  loss_ce_5: 0.0001375  loss_mask_5: 0.1158  loss_dice_5: 0.1787  loss_ce_6: 7.413e-05  loss_mask_6: 0.1127  loss_dice_6: 0.1737  loss_ce_7: 9.486e-05  loss_mask_7: 0.1142  loss_dice_7: 0.1722  loss_ce_8: 0.0001254  loss_mask_8: 0.1147  loss_dice_8: 0.1807  time: 0.6948  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:02:44] d2.utils.events INFO:  eta: 2:51:40  iter: 18519  total_loss: 2.965  loss_ce: 0.0001013  loss_mask: 0.1121  loss_dice: 0.1615  loss_ce_0: 0.116  loss_mask_0: 0.1126  loss_dice_0: 0.1679  loss_ce_1: 0.0001084  loss_mask_1: 0.1161  loss_dice_1: 0.1712  loss_ce_2: 0.0001053  loss_mask_2: 0.1144  loss_dice_2: 0.1687  loss_ce_3: 0.0001071  loss_mask_3: 0.1141  loss_dice_3: 0.1678  loss_ce_4: 0.0001142  loss_mask_4: 0.1099  loss_dice_4: 0.162  loss_ce_5: 0.0001098  loss_mask_5: 0.1128  loss_dice_5: 0.1688  loss_ce_6: 7.843e-05  loss_mask_6: 0.1144  loss_dice_6: 0.1691  loss_ce_7: 0.0001039  loss_mask_7: 0.1119  loss_dice_7: 0.166  loss_ce_8: 0.0001155  loss_mask_8: 0.1124  loss_dice_8: 0.1673  time: 0.6947  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:02:57] d2.utils.events INFO:  eta: 2:51:26  iter: 18539  total_loss: 2.916  loss_ce: 0.0001048  loss_mask: 0.1107  loss_dice: 0.159  loss_ce_0: 0.1278  loss_mask_0: 0.1145  loss_dice_0: 0.162  loss_ce_1: 0.0001011  loss_mask_1: 0.1155  loss_dice_1: 0.1644  loss_ce_2: 0.0001297  loss_mask_2: 0.1162  loss_dice_2: 0.1675  loss_ce_3: 8.923e-05  loss_mask_3: 0.1148  loss_dice_3: 0.1649  loss_ce_4: 9.192e-05  loss_mask_4: 0.1111  loss_dice_4: 0.1602  loss_ce_5: 0.0001275  loss_mask_5: 0.1153  loss_dice_5: 0.1631  loss_ce_6: 8.614e-05  loss_mask_6: 0.1122  loss_dice_6: 0.1599  loss_ce_7: 9.002e-05  loss_mask_7: 0.1144  loss_dice_7: 0.1633  loss_ce_8: 0.0001129  loss_mask_8: 0.1161  loss_dice_8: 0.1663  time: 0.6946  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:03:09] d2.utils.events INFO:  eta: 2:51:04  iter: 18559  total_loss: 2.893  loss_ce: 0.0001072  loss_mask: 0.1146  loss_dice: 0.1623  loss_ce_0: 0.1164  loss_mask_0: 0.1147  loss_dice_0: 0.1663  loss_ce_1: 9.502e-05  loss_mask_1: 0.1148  loss_dice_1: 0.1638  loss_ce_2: 0.0001341  loss_mask_2: 0.1124  loss_dice_2: 0.163  loss_ce_3: 0.0001239  loss_mask_3: 0.1157  loss_dice_3: 0.1644  loss_ce_4: 0.000141  loss_mask_4: 0.1143  loss_dice_4: 0.1625  loss_ce_5: 0.0001551  loss_mask_5: 0.1129  loss_dice_5: 0.1642  loss_ce_6: 9.517e-05  loss_mask_6: 0.1149  loss_dice_6: 0.1635  loss_ce_7: 0.0001167  loss_mask_7: 0.1133  loss_dice_7: 0.1641  loss_ce_8: 0.0001153  loss_mask_8: 0.1136  loss_dice_8: 0.163  time: 0.6945  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:03:22] d2.utils.events INFO:  eta: 2:50:52  iter: 18579  total_loss: 2.993  loss_ce: 9.341e-05  loss_mask: 0.113  loss_dice: 0.1682  loss_ce_0: 0.1313  loss_mask_0: 0.1102  loss_dice_0: 0.1653  loss_ce_1: 8.746e-05  loss_mask_1: 0.1167  loss_dice_1: 0.173  loss_ce_2: 0.0001143  loss_mask_2: 0.1148  loss_dice_2: 0.1714  loss_ce_3: 8.081e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1697  loss_ce_4: 8.37e-05  loss_mask_4: 0.1108  loss_dice_4: 0.1627  loss_ce_5: 0.0001048  loss_mask_5: 0.1138  loss_dice_5: 0.1637  loss_ce_6: 7.039e-05  loss_mask_6: 0.1128  loss_dice_6: 0.1668  loss_ce_7: 7.983e-05  loss_mask_7: 0.1105  loss_dice_7: 0.1687  loss_ce_8: 9.721e-05  loss_mask_8: 0.1134  loss_dice_8: 0.1702  time: 0.6944  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 21:03:34] d2.utils.events INFO:  eta: 2:50:39  iter: 18599  total_loss: 3.002  loss_ce: 5.495e-05  loss_mask: 0.1204  loss_dice: 0.1723  loss_ce_0: 0.1337  loss_mask_0: 0.1196  loss_dice_0: 0.168  loss_ce_1: 6.751e-05  loss_mask_1: 0.1127  loss_dice_1: 0.1666  loss_ce_2: 6.712e-05  loss_mask_2: 0.1224  loss_dice_2: 0.1718  loss_ce_3: 6.53e-05  loss_mask_3: 0.1183  loss_dice_3: 0.1665  loss_ce_4: 7.093e-05  loss_mask_4: 0.1183  loss_dice_4: 0.1636  loss_ce_5: 7.842e-05  loss_mask_5: 0.1172  loss_dice_5: 0.1704  loss_ce_6: 5.315e-05  loss_mask_6: 0.1188  loss_dice_6: 0.1732  loss_ce_7: 6.043e-05  loss_mask_7: 0.1213  loss_dice_7: 0.1724  loss_ce_8: 6.814e-05  loss_mask_8: 0.1158  loss_dice_8: 0.1679  time: 0.6944  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:03:45] d2.utils.events INFO:  eta: 2:50:14  iter: 18619  total_loss: 3.258  loss_ce: 8.402e-05  loss_mask: 0.116  loss_dice: 0.2  loss_ce_0: 0.1293  loss_mask_0: 0.1158  loss_dice_0: 0.2072  loss_ce_1: 6.654e-05  loss_mask_1: 0.1178  loss_dice_1: 0.2  loss_ce_2: 8.81e-05  loss_mask_2: 0.1104  loss_dice_2: 0.1973  loss_ce_3: 7.085e-05  loss_mask_3: 0.1115  loss_dice_3: 0.1979  loss_ce_4: 6.667e-05  loss_mask_4: 0.1174  loss_dice_4: 0.199  loss_ce_5: 9.066e-05  loss_mask_5: 0.115  loss_dice_5: 0.1924  loss_ce_6: 6.284e-05  loss_mask_6: 0.1135  loss_dice_6: 0.2021  loss_ce_7: 7.004e-05  loss_mask_7: 0.1166  loss_dice_7: 0.2034  loss_ce_8: 8.525e-05  loss_mask_8: 0.1187  loss_dice_8: 0.1912  time: 0.6942  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:03:57] d2.utils.events INFO:  eta: 2:49:49  iter: 18639  total_loss: 3.019  loss_ce: 7.752e-05  loss_mask: 0.1194  loss_dice: 0.172  loss_ce_0: 0.1232  loss_mask_0: 0.1132  loss_dice_0: 0.1667  loss_ce_1: 9.055e-05  loss_mask_1: 0.1159  loss_dice_1: 0.1673  loss_ce_2: 9.832e-05  loss_mask_2: 0.1176  loss_dice_2: 0.1702  loss_ce_3: 9.73e-05  loss_mask_3: 0.1182  loss_dice_3: 0.1701  loss_ce_4: 8.975e-05  loss_mask_4: 0.1105  loss_dice_4: 0.1658  loss_ce_5: 0.0001014  loss_mask_5: 0.1154  loss_dice_5: 0.165  loss_ce_6: 8.122e-05  loss_mask_6: 0.117  loss_dice_6: 0.1698  loss_ce_7: 9.665e-05  loss_mask_7: 0.118  loss_dice_7: 0.171  loss_ce_8: 0.0001082  loss_mask_8: 0.1138  loss_dice_8: 0.1696  time: 0.6941  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:04:08] d2.utils.events INFO:  eta: 2:49:23  iter: 18659  total_loss: 3.086  loss_ce: 7.034e-05  loss_mask: 0.1203  loss_dice: 0.1754  loss_ce_0: 0.1207  loss_mask_0: 0.115  loss_dice_0: 0.1779  loss_ce_1: 7.229e-05  loss_mask_1: 0.1181  loss_dice_1: 0.1815  loss_ce_2: 7.978e-05  loss_mask_2: 0.1144  loss_dice_2: 0.1736  loss_ce_3: 7.803e-05  loss_mask_3: 0.1192  loss_dice_3: 0.1737  loss_ce_4: 7.745e-05  loss_mask_4: 0.1137  loss_dice_4: 0.1796  loss_ce_5: 8.584e-05  loss_mask_5: 0.1191  loss_dice_5: 0.178  loss_ce_6: 4.395e-05  loss_mask_6: 0.1148  loss_dice_6: 0.1707  loss_ce_7: 7.004e-05  loss_mask_7: 0.1128  loss_dice_7: 0.1766  loss_ce_8: 8.569e-05  loss_mask_8: 0.1147  loss_dice_8: 0.1681  time: 0.6939  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:04:19] d2.utils.events INFO:  eta: 2:48:51  iter: 18679  total_loss: 2.926  loss_ce: 5.955e-05  loss_mask: 0.1139  loss_dice: 0.1626  loss_ce_0: 0.1166  loss_mask_0: 0.1135  loss_dice_0: 0.1713  loss_ce_1: 6.914e-05  loss_mask_1: 0.1132  loss_dice_1: 0.1673  loss_ce_2: 7.731e-05  loss_mask_2: 0.1104  loss_dice_2: 0.1639  loss_ce_3: 7.842e-05  loss_mask_3: 0.1161  loss_dice_3: 0.173  loss_ce_4: 7.365e-05  loss_mask_4: 0.1125  loss_dice_4: 0.1662  loss_ce_5: 8.155e-05  loss_mask_5: 0.1126  loss_dice_5: 0.1654  loss_ce_6: 3.554e-05  loss_mask_6: 0.1147  loss_dice_6: 0.1706  loss_ce_7: 5.776e-05  loss_mask_7: 0.1126  loss_dice_7: 0.162  loss_ce_8: 8.228e-05  loss_mask_8: 0.1115  loss_dice_8: 0.1622  time: 0.6938  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:04:31] d2.utils.events INFO:  eta: 2:48:25  iter: 18699  total_loss: 2.918  loss_ce: 6.058e-05  loss_mask: 0.1044  loss_dice: 0.1662  loss_ce_0: 0.1174  loss_mask_0: 0.1076  loss_dice_0: 0.1649  loss_ce_1: 6.98e-05  loss_mask_1: 0.1109  loss_dice_1: 0.1643  loss_ce_2: 8.597e-05  loss_mask_2: 0.1113  loss_dice_2: 0.1668  loss_ce_3: 7.357e-05  loss_mask_3: 0.111  loss_dice_3: 0.1667  loss_ce_4: 7.321e-05  loss_mask_4: 0.1102  loss_dice_4: 0.1705  loss_ce_5: 9.235e-05  loss_mask_5: 0.1098  loss_dice_5: 0.1662  loss_ce_6: 3.734e-05  loss_mask_6: 0.1114  loss_dice_6: 0.1744  loss_ce_7: 6.988e-05  loss_mask_7: 0.1145  loss_dice_7: 0.1742  loss_ce_8: 0.0001002  loss_mask_8: 0.1074  loss_dice_8: 0.162  time: 0.6937  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:04:42] d2.utils.events INFO:  eta: 2:47:59  iter: 18719  total_loss: 3.065  loss_ce: 0.0001106  loss_mask: 0.117  loss_dice: 0.1758  loss_ce_0: 0.1181  loss_mask_0: 0.1211  loss_dice_0: 0.1789  loss_ce_1: 8.68e-05  loss_mask_1: 0.1174  loss_dice_1: 0.1797  loss_ce_2: 0.0001165  loss_mask_2: 0.1141  loss_dice_2: 0.1727  loss_ce_3: 9.049e-05  loss_mask_3: 0.1154  loss_dice_3: 0.1739  loss_ce_4: 7.793e-05  loss_mask_4: 0.1158  loss_dice_4: 0.1758  loss_ce_5: 0.0001136  loss_mask_5: 0.1182  loss_dice_5: 0.1768  loss_ce_6: 9.069e-05  loss_mask_6: 0.1226  loss_dice_6: 0.1795  loss_ce_7: 8.897e-05  loss_mask_7: 0.116  loss_dice_7: 0.1789  loss_ce_8: 0.0001153  loss_mask_8: 0.117  loss_dice_8: 0.1778  time: 0.6935  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:04:53] d2.utils.events INFO:  eta: 2:47:33  iter: 18739  total_loss: 3.033  loss_ce: 6.412e-05  loss_mask: 0.1214  loss_dice: 0.1727  loss_ce_0: 0.1141  loss_mask_0: 0.1207  loss_dice_0: 0.1696  loss_ce_1: 8.144e-05  loss_mask_1: 0.1203  loss_dice_1: 0.1776  loss_ce_2: 8.038e-05  loss_mask_2: 0.1203  loss_dice_2: 0.171  loss_ce_3: 7.36e-05  loss_mask_3: 0.1222  loss_dice_3: 0.1732  loss_ce_4: 6.587e-05  loss_mask_4: 0.1201  loss_dice_4: 0.17  loss_ce_5: 8.492e-05  loss_mask_5: 0.12  loss_dice_5: 0.172  loss_ce_6: 4.624e-05  loss_mask_6: 0.1255  loss_dice_6: 0.1799  loss_ce_7: 6.639e-05  loss_mask_7: 0.1222  loss_dice_7: 0.1752  loss_ce_8: 9.307e-05  loss_mask_8: 0.1208  loss_dice_8: 0.172  time: 0.6934  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:05:05] d2.utils.events INFO:  eta: 2:47:07  iter: 18759  total_loss: 2.863  loss_ce: 9.642e-05  loss_mask: 0.1104  loss_dice: 0.17  loss_ce_0: 0.1257  loss_mask_0: 0.1127  loss_dice_0: 0.1744  loss_ce_1: 8.4e-05  loss_mask_1: 0.1118  loss_dice_1: 0.1705  loss_ce_2: 0.0001101  loss_mask_2: 0.1113  loss_dice_2: 0.1705  loss_ce_3: 7.231e-05  loss_mask_3: 0.1142  loss_dice_3: 0.1711  loss_ce_4: 7.126e-05  loss_mask_4: 0.1085  loss_dice_4: 0.1638  loss_ce_5: 0.0001058  loss_mask_5: 0.1113  loss_dice_5: 0.1662  loss_ce_6: 8.39e-05  loss_mask_6: 0.1109  loss_dice_6: 0.1646  loss_ce_7: 8.231e-05  loss_mask_7: 0.1134  loss_dice_7: 0.1718  loss_ce_8: 0.0001105  loss_mask_8: 0.1108  loss_dice_8: 0.1598  time: 0.6933  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:05:16] d2.utils.events INFO:  eta: 2:46:42  iter: 18779  total_loss: 3.189  loss_ce: 5.761e-05  loss_mask: 0.1218  loss_dice: 0.1823  loss_ce_0: 0.1252  loss_mask_0: 0.1254  loss_dice_0: 0.1807  loss_ce_1: 6.33e-05  loss_mask_1: 0.1204  loss_dice_1: 0.1853  loss_ce_2: 7.657e-05  loss_mask_2: 0.1214  loss_dice_2: 0.1811  loss_ce_3: 6.052e-05  loss_mask_3: 0.1207  loss_dice_3: 0.1827  loss_ce_4: 6.779e-05  loss_mask_4: 0.1239  loss_dice_4: 0.1799  loss_ce_5: 7.985e-05  loss_mask_5: 0.1248  loss_dice_5: 0.1844  loss_ce_6: 5.777e-05  loss_mask_6: 0.1231  loss_dice_6: 0.1804  loss_ce_7: 6.948e-05  loss_mask_7: 0.1211  loss_dice_7: 0.1867  loss_ce_8: 8.626e-05  loss_mask_8: 0.1252  loss_dice_8: 0.1845  time: 0.6931  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:05:27] d2.utils.events INFO:  eta: 2:46:18  iter: 18799  total_loss: 3.107  loss_ce: 4.563e-05  loss_mask: 0.1204  loss_dice: 0.174  loss_ce_0: 0.1172  loss_mask_0: 0.1165  loss_dice_0: 0.1758  loss_ce_1: 5.356e-05  loss_mask_1: 0.1223  loss_dice_1: 0.1757  loss_ce_2: 5.532e-05  loss_mask_2: 0.1216  loss_dice_2: 0.1768  loss_ce_3: 5.273e-05  loss_mask_3: 0.1205  loss_dice_3: 0.1781  loss_ce_4: 5.681e-05  loss_mask_4: 0.1225  loss_dice_4: 0.1767  loss_ce_5: 5.703e-05  loss_mask_5: 0.1204  loss_dice_5: 0.1745  loss_ce_6: 3.879e-05  loss_mask_6: 0.1208  loss_dice_6: 0.1727  loss_ce_7: 4.399e-05  loss_mask_7: 0.1213  loss_dice_7: 0.1751  loss_ce_8: 5.47e-05  loss_mask_8: 0.1188  loss_dice_8: 0.1751  time: 0.6930  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:05:39] d2.utils.events INFO:  eta: 2:45:55  iter: 18819  total_loss: 3.034  loss_ce: 6.44e-05  loss_mask: 0.1222  loss_dice: 0.1796  loss_ce_0: 0.1116  loss_mask_0: 0.1175  loss_dice_0: 0.1715  loss_ce_1: 5.805e-05  loss_mask_1: 0.1193  loss_dice_1: 0.1807  loss_ce_2: 7.326e-05  loss_mask_2: 0.1208  loss_dice_2: 0.1746  loss_ce_3: 7.325e-05  loss_mask_3: 0.1197  loss_dice_3: 0.1803  loss_ce_4: 6.91e-05  loss_mask_4: 0.1196  loss_dice_4: 0.1766  loss_ce_5: 8.23e-05  loss_mask_5: 0.1211  loss_dice_5: 0.1748  loss_ce_6: 4.028e-05  loss_mask_6: 0.1188  loss_dice_6: 0.1766  loss_ce_7: 6.936e-05  loss_mask_7: 0.1166  loss_dice_7: 0.1729  loss_ce_8: 8.383e-05  loss_mask_8: 0.1189  loss_dice_8: 0.1742  time: 0.6929  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:05:50] d2.utils.events INFO:  eta: 2:45:28  iter: 18839  total_loss: 2.978  loss_ce: 4.922e-05  loss_mask: 0.117  loss_dice: 0.17  loss_ce_0: 0.09955  loss_mask_0: 0.1143  loss_dice_0: 0.1715  loss_ce_1: 5.274e-05  loss_mask_1: 0.1187  loss_dice_1: 0.1716  loss_ce_2: 6.185e-05  loss_mask_2: 0.1141  loss_dice_2: 0.169  loss_ce_3: 5.726e-05  loss_mask_3: 0.1163  loss_dice_3: 0.1666  loss_ce_4: 5.764e-05  loss_mask_4: 0.1164  loss_dice_4: 0.1727  loss_ce_5: 6.701e-05  loss_mask_5: 0.1173  loss_dice_5: 0.1732  loss_ce_6: 3.658e-05  loss_mask_6: 0.1208  loss_dice_6: 0.1759  loss_ce_7: 5.074e-05  loss_mask_7: 0.1169  loss_dice_7: 0.1708  loss_ce_8: 6.661e-05  loss_mask_8: 0.1148  loss_dice_8: 0.1698  time: 0.6927  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:06:02] d2.utils.events INFO:  eta: 2:44:59  iter: 18859  total_loss: 2.917  loss_ce: 8.883e-05  loss_mask: 0.1126  loss_dice: 0.1697  loss_ce_0: 0.1264  loss_mask_0: 0.1127  loss_dice_0: 0.1658  loss_ce_1: 7.143e-05  loss_mask_1: 0.1107  loss_dice_1: 0.1749  loss_ce_2: 9.256e-05  loss_mask_2: 0.1086  loss_dice_2: 0.1697  loss_ce_3: 5.767e-05  loss_mask_3: 0.1138  loss_dice_3: 0.1669  loss_ce_4: 4.743e-05  loss_mask_4: 0.1103  loss_dice_4: 0.1645  loss_ce_5: 8.635e-05  loss_mask_5: 0.1084  loss_dice_5: 0.1703  loss_ce_6: 7.178e-05  loss_mask_6: 0.1127  loss_dice_6: 0.1729  loss_ce_7: 7.349e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1654  loss_ce_8: 9.242e-05  loss_mask_8: 0.1115  loss_dice_8: 0.1742  time: 0.6926  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:06:13] d2.utils.events INFO:  eta: 2:44:26  iter: 18879  total_loss: 2.986  loss_ce: 7.972e-05  loss_mask: 0.1174  loss_dice: 0.1673  loss_ce_0: 0.123  loss_mask_0: 0.1215  loss_dice_0: 0.1741  loss_ce_1: 7.091e-05  loss_mask_1: 0.1152  loss_dice_1: 0.1686  loss_ce_2: 8.948e-05  loss_mask_2: 0.1145  loss_dice_2: 0.1636  loss_ce_3: 5.683e-05  loss_mask_3: 0.1168  loss_dice_3: 0.1669  loss_ce_4: 5.491e-05  loss_mask_4: 0.1175  loss_dice_4: 0.17  loss_ce_5: 8.64e-05  loss_mask_5: 0.112  loss_dice_5: 0.1658  loss_ce_6: 6.645e-05  loss_mask_6: 0.1164  loss_dice_6: 0.1689  loss_ce_7: 6.98e-05  loss_mask_7: 0.1204  loss_dice_7: 0.1697  loss_ce_8: 8.858e-05  loss_mask_8: 0.1208  loss_dice_8: 0.1727  time: 0.6925  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:06:25] d2.utils.events INFO:  eta: 2:43:56  iter: 18899  total_loss: 2.967  loss_ce: 4.703e-05  loss_mask: 0.1152  loss_dice: 0.1752  loss_ce_0: 0.1156  loss_mask_0: 0.1124  loss_dice_0: 0.1757  loss_ce_1: 5.025e-05  loss_mask_1: 0.1136  loss_dice_1: 0.177  loss_ce_2: 6.403e-05  loss_mask_2: 0.1104  loss_dice_2: 0.1732  loss_ce_3: 5.016e-05  loss_mask_3: 0.1147  loss_dice_3: 0.1756  loss_ce_4: 4.931e-05  loss_mask_4: 0.1151  loss_dice_4: 0.1711  loss_ce_5: 7.148e-05  loss_mask_5: 0.1139  loss_dice_5: 0.1795  loss_ce_6: 3.375e-05  loss_mask_6: 0.1136  loss_dice_6: 0.1817  loss_ce_7: 5.838e-05  loss_mask_7: 0.116  loss_dice_7: 0.1753  loss_ce_8: 7.364e-05  loss_mask_8: 0.1098  loss_dice_8: 0.1704  time: 0.6923  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:06:36] d2.utils.events INFO:  eta: 2:43:24  iter: 18919  total_loss: 2.777  loss_ce: 7.659e-05  loss_mask: 0.1083  loss_dice: 0.1546  loss_ce_0: 0.1174  loss_mask_0: 0.1108  loss_dice_0: 0.1579  loss_ce_1: 6.446e-05  loss_mask_1: 0.1092  loss_dice_1: 0.1554  loss_ce_2: 8.445e-05  loss_mask_2: 0.1047  loss_dice_2: 0.1555  loss_ce_3: 5.385e-05  loss_mask_3: 0.1116  loss_dice_3: 0.1589  loss_ce_4: 5.808e-05  loss_mask_4: 0.1126  loss_dice_4: 0.1599  loss_ce_5: 7.89e-05  loss_mask_5: 0.1068  loss_dice_5: 0.1585  loss_ce_6: 6.302e-05  loss_mask_6: 0.1119  loss_dice_6: 0.1585  loss_ce_7: 6.155e-05  loss_mask_7: 0.1105  loss_dice_7: 0.1589  loss_ce_8: 8.331e-05  loss_mask_8: 0.1096  loss_dice_8: 0.1597  time: 0.6922  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:06:47] d2.utils.events INFO:  eta: 2:42:51  iter: 18939  total_loss: 3.095  loss_ce: 4.176e-05  loss_mask: 0.1206  loss_dice: 0.1699  loss_ce_0: 0.1154  loss_mask_0: 0.1196  loss_dice_0: 0.1823  loss_ce_1: 5.041e-05  loss_mask_1: 0.1222  loss_dice_1: 0.1746  loss_ce_2: 5.164e-05  loss_mask_2: 0.12  loss_dice_2: 0.1682  loss_ce_3: 4.488e-05  loss_mask_3: 0.1236  loss_dice_3: 0.1748  loss_ce_4: 4.81e-05  loss_mask_4: 0.1213  loss_dice_4: 0.1699  loss_ce_5: 5.131e-05  loss_mask_5: 0.1194  loss_dice_5: 0.1731  loss_ce_6: 3.317e-05  loss_mask_6: 0.1181  loss_dice_6: 0.1658  loss_ce_7: 4.247e-05  loss_mask_7: 0.1173  loss_dice_7: 0.1728  loss_ce_8: 5.037e-05  loss_mask_8: 0.1161  loss_dice_8: 0.1702  time: 0.6921  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:06:59] d2.utils.events INFO:  eta: 2:42:25  iter: 18959  total_loss: 2.899  loss_ce: 7.61e-05  loss_mask: 0.1147  loss_dice: 0.1593  loss_ce_0: 0.1334  loss_mask_0: 0.1115  loss_dice_0: 0.1633  loss_ce_1: 6.383e-05  loss_mask_1: 0.1138  loss_dice_1: 0.1673  loss_ce_2: 8.912e-05  loss_mask_2: 0.1129  loss_dice_2: 0.1619  loss_ce_3: 5.923e-05  loss_mask_3: 0.112  loss_dice_3: 0.1601  loss_ce_4: 7.141e-05  loss_mask_4: 0.1127  loss_dice_4: 0.1624  loss_ce_5: 8.577e-05  loss_mask_5: 0.1153  loss_dice_5: 0.1648  loss_ce_6: 7.301e-05  loss_mask_6: 0.1151  loss_dice_6: 0.1643  loss_ce_7: 6.37e-05  loss_mask_7: 0.1131  loss_dice_7: 0.1585  loss_ce_8: 8.195e-05  loss_mask_8: 0.1149  loss_dice_8: 0.1605  time: 0.6919  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:07:10] d2.utils.events INFO:  eta: 2:41:51  iter: 18979  total_loss: 3.176  loss_ce: 4.768e-05  loss_mask: 0.1179  loss_dice: 0.1749  loss_ce_0: 0.1253  loss_mask_0: 0.1186  loss_dice_0: 0.1751  loss_ce_1: 5.114e-05  loss_mask_1: 0.1136  loss_dice_1: 0.1742  loss_ce_2: 6.182e-05  loss_mask_2: 0.1172  loss_dice_2: 0.1832  loss_ce_3: 4.982e-05  loss_mask_3: 0.1189  loss_dice_3: 0.1769  loss_ce_4: 4.748e-05  loss_mask_4: 0.1183  loss_dice_4: 0.1778  loss_ce_5: 6.467e-05  loss_mask_5: 0.1188  loss_dice_5: 0.1816  loss_ce_6: 3.335e-05  loss_mask_6: 0.1245  loss_dice_6: 0.189  loss_ce_7: 5.373e-05  loss_mask_7: 0.1146  loss_dice_7: 0.1755  loss_ce_8: 6.598e-05  loss_mask_8: 0.119  loss_dice_8: 0.1742  time: 0.6918  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:07:21] d2.utils.events INFO:  eta: 2:41:14  iter: 18999  total_loss: 3.013  loss_ce: 4.685e-05  loss_mask: 0.1141  loss_dice: 0.1691  loss_ce_0: 0.1244  loss_mask_0: 0.115  loss_dice_0: 0.1734  loss_ce_1: 5.728e-05  loss_mask_1: 0.114  loss_dice_1: 0.176  loss_ce_2: 6.005e-05  loss_mask_2: 0.119  loss_dice_2: 0.1682  loss_ce_3: 4.841e-05  loss_mask_3: 0.114  loss_dice_3: 0.1741  loss_ce_4: 5.195e-05  loss_mask_4: 0.1205  loss_dice_4: 0.1717  loss_ce_5: 6.425e-05  loss_mask_5: 0.1158  loss_dice_5: 0.1722  loss_ce_6: 3.528e-05  loss_mask_6: 0.1173  loss_dice_6: 0.1701  loss_ce_7: 5.162e-05  loss_mask_7: 0.1181  loss_dice_7: 0.1681  loss_ce_8: 6.534e-05  loss_mask_8: 0.1185  loss_dice_8: 0.1778  time: 0.6917  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:07:33] d2.utils.events INFO:  eta: 2:40:45  iter: 19019  total_loss: 3.028  loss_ce: 5.801e-05  loss_mask: 0.1197  loss_dice: 0.1698  loss_ce_0: 0.1262  loss_mask_0: 0.1176  loss_dice_0: 0.1679  loss_ce_1: 5.702e-05  loss_mask_1: 0.1171  loss_dice_1: 0.1683  loss_ce_2: 6.948e-05  loss_mask_2: 0.1169  loss_dice_2: 0.1673  loss_ce_3: 4.494e-05  loss_mask_3: 0.1169  loss_dice_3: 0.1662  loss_ce_4: 4.828e-05  loss_mask_4: 0.1171  loss_dice_4: 0.1634  loss_ce_5: 6.287e-05  loss_mask_5: 0.1208  loss_dice_5: 0.1716  loss_ce_6: 4.804e-05  loss_mask_6: 0.117  loss_dice_6: 0.1652  loss_ce_7: 4.67e-05  loss_mask_7: 0.1145  loss_dice_7: 0.1692  loss_ce_8: 6.848e-05  loss_mask_8: 0.1179  loss_dice_8: 0.1681  time: 0.6915  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:07:44] d2.utils.events INFO:  eta: 2:40:04  iter: 19039  total_loss: 2.866  loss_ce: 7.111e-05  loss_mask: 0.1114  loss_dice: 0.1671  loss_ce_0: 0.1264  loss_mask_0: 0.1118  loss_dice_0: 0.1596  loss_ce_1: 6.007e-05  loss_mask_1: 0.1139  loss_dice_1: 0.1592  loss_ce_2: 7.432e-05  loss_mask_2: 0.1078  loss_dice_2: 0.1599  loss_ce_3: 5.703e-05  loss_mask_3: 0.1104  loss_dice_3: 0.1589  loss_ce_4: 6.436e-05  loss_mask_4: 0.1113  loss_dice_4: 0.1538  loss_ce_5: 7.456e-05  loss_mask_5: 0.1077  loss_dice_5: 0.1595  loss_ce_6: 8.127e-05  loss_mask_6: 0.109  loss_dice_6: 0.1606  loss_ce_7: 5.837e-05  loss_mask_7: 0.1126  loss_dice_7: 0.1635  loss_ce_8: 7.43e-05  loss_mask_8: 0.1089  loss_dice_8: 0.1602  time: 0.6914  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:07:55] d2.utils.events INFO:  eta: 2:39:33  iter: 19059  total_loss: 2.977  loss_ce: 3.197e-05  loss_mask: 0.1152  loss_dice: 0.172  loss_ce_0: 0.1316  loss_mask_0: 0.1205  loss_dice_0: 0.1671  loss_ce_1: 4.564e-05  loss_mask_1: 0.1165  loss_dice_1: 0.1689  loss_ce_2: 4.59e-05  loss_mask_2: 0.1165  loss_dice_2: 0.172  loss_ce_3: 3.933e-05  loss_mask_3: 0.1147  loss_dice_3: 0.1694  loss_ce_4: 3.888e-05  loss_mask_4: 0.1177  loss_dice_4: 0.1675  loss_ce_5: 4.794e-05  loss_mask_5: 0.1173  loss_dice_5: 0.1765  loss_ce_6: 2.616e-05  loss_mask_6: 0.1197  loss_dice_6: 0.1741  loss_ce_7: 3.461e-05  loss_mask_7: 0.1139  loss_dice_7: 0.1694  loss_ce_8: 4.501e-05  loss_mask_8: 0.1174  loss_dice_8: 0.1698  time: 0.6913  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:08:07] d2.utils.events INFO:  eta: 2:38:58  iter: 19079  total_loss: 3.043  loss_ce: 3.747e-05  loss_mask: 0.1218  loss_dice: 0.1708  loss_ce_0: 0.128  loss_mask_0: 0.119  loss_dice_0: 0.177  loss_ce_1: 4.338e-05  loss_mask_1: 0.1185  loss_dice_1: 0.1723  loss_ce_2: 4.987e-05  loss_mask_2: 0.1203  loss_dice_2: 0.1704  loss_ce_3: 3.419e-05  loss_mask_3: 0.1223  loss_dice_3: 0.1732  loss_ce_4: 3.193e-05  loss_mask_4: 0.1168  loss_dice_4: 0.1668  loss_ce_5: 5.099e-05  loss_mask_5: 0.1215  loss_dice_5: 0.1746  loss_ce_6: 3.252e-05  loss_mask_6: 0.1162  loss_dice_6: 0.175  loss_ce_7: 4.085e-05  loss_mask_7: 0.1183  loss_dice_7: 0.1687  loss_ce_8: 5.002e-05  loss_mask_8: 0.1175  loss_dice_8: 0.1743  time: 0.6912  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:08:18] d2.utils.events INFO:  eta: 2:38:18  iter: 19099  total_loss: 2.798  loss_ce: 4.248e-05  loss_mask: 0.1113  loss_dice: 0.1602  loss_ce_0: 0.1219  loss_mask_0: 0.107  loss_dice_0: 0.159  loss_ce_1: 4.548e-05  loss_mask_1: 0.1087  loss_dice_1: 0.166  loss_ce_2: 5.484e-05  loss_mask_2: 0.1089  loss_dice_2: 0.153  loss_ce_3: 3.354e-05  loss_mask_3: 0.1106  loss_dice_3: 0.1632  loss_ce_4: 3.259e-05  loss_mask_4: 0.1115  loss_dice_4: 0.1612  loss_ce_5: 5.657e-05  loss_mask_5: 0.1105  loss_dice_5: 0.16  loss_ce_6: 3.321e-05  loss_mask_6: 0.1107  loss_dice_6: 0.161  loss_ce_7: 4.163e-05  loss_mask_7: 0.1126  loss_dice_7: 0.1627  loss_ce_8: 5.887e-05  loss_mask_8: 0.1103  loss_dice_8: 0.1595  time: 0.6910  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:08:29] d2.utils.events INFO:  eta: 2:37:28  iter: 19119  total_loss: 3.072  loss_ce: 6.628e-05  loss_mask: 0.115  loss_dice: 0.1793  loss_ce_0: 0.1223  loss_mask_0: 0.1105  loss_dice_0: 0.1671  loss_ce_1: 4.607e-05  loss_mask_1: 0.1154  loss_dice_1: 0.1746  loss_ce_2: 6.208e-05  loss_mask_2: 0.1144  loss_dice_2: 0.1772  loss_ce_3: 6.852e-05  loss_mask_3: 0.114  loss_dice_3: 0.1713  loss_ce_4: 5.71e-05  loss_mask_4: 0.1151  loss_dice_4: 0.1775  loss_ce_5: 5.953e-05  loss_mask_5: 0.1109  loss_dice_5: 0.1788  loss_ce_6: 7.795e-05  loss_mask_6: 0.1123  loss_dice_6: 0.1769  loss_ce_7: 5.787e-05  loss_mask_7: 0.1129  loss_dice_7: 0.1798  loss_ce_8: 6.206e-05  loss_mask_8: 0.1123  loss_dice_8: 0.175  time: 0.6909  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:08:41] d2.utils.events INFO:  eta: 2:36:45  iter: 19139  total_loss: 2.99  loss_ce: 5.548e-05  loss_mask: 0.116  loss_dice: 0.1739  loss_ce_0: 0.1209  loss_mask_0: 0.1176  loss_dice_0: 0.1717  loss_ce_1: 4.42e-05  loss_mask_1: 0.1171  loss_dice_1: 0.1674  loss_ce_2: 5.767e-05  loss_mask_2: 0.1177  loss_dice_2: 0.1692  loss_ce_3: 4.883e-05  loss_mask_3: 0.1156  loss_dice_3: 0.1647  loss_ce_4: 4.88e-05  loss_mask_4: 0.1185  loss_dice_4: 0.1698  loss_ce_5: 5.696e-05  loss_mask_5: 0.1152  loss_dice_5: 0.1665  loss_ce_6: 5.159e-05  loss_mask_6: 0.116  loss_dice_6: 0.1702  loss_ce_7: 5.222e-05  loss_mask_7: 0.1156  loss_dice_7: 0.1645  loss_ce_8: 5.658e-05  loss_mask_8: 0.1191  loss_dice_8: 0.1722  time: 0.6908  data_time: 0.0015  lr: 0.0001  max_mem: 8444M
[08/01 21:08:52] d2.utils.events INFO:  eta: 2:35:53  iter: 19159  total_loss: 2.939  loss_ce: 4.458e-05  loss_mask: 0.117  loss_dice: 0.167  loss_ce_0: 0.1197  loss_mask_0: 0.1154  loss_dice_0: 0.1686  loss_ce_1: 4.862e-05  loss_mask_1: 0.1159  loss_dice_1: 0.1695  loss_ce_2: 5.356e-05  loss_mask_2: 0.1162  loss_dice_2: 0.1705  loss_ce_3: 4.474e-05  loss_mask_3: 0.1125  loss_dice_3: 0.1698  loss_ce_4: 4.569e-05  loss_mask_4: 0.1151  loss_dice_4: 0.1739  loss_ce_5: 5.262e-05  loss_mask_5: 0.1171  loss_dice_5: 0.1729  loss_ce_6: 3.471e-05  loss_mask_6: 0.1169  loss_dice_6: 0.1683  loss_ce_7: 4.797e-05  loss_mask_7: 0.1158  loss_dice_7: 0.1722  loss_ce_8: 5.498e-05  loss_mask_8: 0.113  loss_dice_8: 0.1701  time: 0.6906  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:09:03] d2.utils.events INFO:  eta: 2:35:27  iter: 19179  total_loss: 2.829  loss_ce: 4.459e-05  loss_mask: 0.108  loss_dice: 0.16  loss_ce_0: 0.1241  loss_mask_0: 0.1065  loss_dice_0: 0.1612  loss_ce_1: 4.265e-05  loss_mask_1: 0.1078  loss_dice_1: 0.1638  loss_ce_2: 5.142e-05  loss_mask_2: 0.1123  loss_dice_2: 0.1624  loss_ce_3: 4.506e-05  loss_mask_3: 0.109  loss_dice_3: 0.1566  loss_ce_4: 4.459e-05  loss_mask_4: 0.1089  loss_dice_4: 0.1602  loss_ce_5: 5.358e-05  loss_mask_5: 0.1112  loss_dice_5: 0.1653  loss_ce_6: 3.436e-05  loss_mask_6: 0.112  loss_dice_6: 0.1619  loss_ce_7: 4.473e-05  loss_mask_7: 0.1117  loss_dice_7: 0.1637  loss_ce_8: 5.474e-05  loss_mask_8: 0.109  loss_dice_8: 0.1632  time: 0.6905  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:09:15] d2.utils.events INFO:  eta: 2:35:00  iter: 19199  total_loss: 2.969  loss_ce: 3.51e-05  loss_mask: 0.1134  loss_dice: 0.1702  loss_ce_0: 0.1269  loss_mask_0: 0.1107  loss_dice_0: 0.1785  loss_ce_1: 4.341e-05  loss_mask_1: 0.1156  loss_dice_1: 0.1785  loss_ce_2: 4.649e-05  loss_mask_2: 0.1176  loss_dice_2: 0.1741  loss_ce_3: 3.221e-05  loss_mask_3: 0.113  loss_dice_3: 0.1718  loss_ce_4: 2.502e-05  loss_mask_4: 0.1129  loss_dice_4: 0.1706  loss_ce_5: 4.378e-05  loss_mask_5: 0.1143  loss_dice_5: 0.1733  loss_ce_6: 2.598e-05  loss_mask_6: 0.1155  loss_dice_6: 0.1722  loss_ce_7: 3.093e-05  loss_mask_7: 0.1153  loss_dice_7: 0.1709  loss_ce_8: 4.744e-05  loss_mask_8: 0.1169  loss_dice_8: 0.1754  time: 0.6904  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:09:26] d2.utils.events INFO:  eta: 2:34:20  iter: 19219  total_loss: 3.046  loss_ce: 4.2e-05  loss_mask: 0.1172  loss_dice: 0.1745  loss_ce_0: 0.1239  loss_mask_0: 0.1143  loss_dice_0: 0.1764  loss_ce_1: 4.47e-05  loss_mask_1: 0.1171  loss_dice_1: 0.1833  loss_ce_2: 5.074e-05  loss_mask_2: 0.1095  loss_dice_2: 0.1798  loss_ce_3: 3.984e-05  loss_mask_3: 0.1161  loss_dice_3: 0.1796  loss_ce_4: 3.666e-05  loss_mask_4: 0.1177  loss_dice_4: 0.1812  loss_ce_5: 4.771e-05  loss_mask_5: 0.1152  loss_dice_5: 0.1838  loss_ce_6: 3.081e-05  loss_mask_6: 0.1154  loss_dice_6: 0.1769  loss_ce_7: 3.434e-05  loss_mask_7: 0.1127  loss_dice_7: 0.1771  loss_ce_8: 5.455e-05  loss_mask_8: 0.1172  loss_dice_8: 0.1855  time: 0.6902  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:09:37] d2.utils.events INFO:  eta: 2:33:34  iter: 19239  total_loss: 3.058  loss_ce: 4.345e-05  loss_mask: 0.1146  loss_dice: 0.1718  loss_ce_0: 0.1227  loss_mask_0: 0.1211  loss_dice_0: 0.1864  loss_ce_1: 4.312e-05  loss_mask_1: 0.1171  loss_dice_1: 0.1696  loss_ce_2: 4.893e-05  loss_mask_2: 0.1216  loss_dice_2: 0.1806  loss_ce_3: 4.624e-05  loss_mask_3: 0.1151  loss_dice_3: 0.1671  loss_ce_4: 4.33e-05  loss_mask_4: 0.1155  loss_dice_4: 0.1755  loss_ce_5: 5.196e-05  loss_mask_5: 0.1138  loss_dice_5: 0.1746  loss_ce_6: 4.102e-05  loss_mask_6: 0.1162  loss_dice_6: 0.1671  loss_ce_7: 4.297e-05  loss_mask_7: 0.1175  loss_dice_7: 0.1764  loss_ce_8: 5.181e-05  loss_mask_8: 0.1169  loss_dice_8: 0.1698  time: 0.6901  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:09:49] d2.utils.events INFO:  eta: 2:32:56  iter: 19259  total_loss: 2.975  loss_ce: 4.728e-05  loss_mask: 0.1075  loss_dice: 0.1632  loss_ce_0: 0.1226  loss_mask_0: 0.1111  loss_dice_0: 0.1653  loss_ce_1: 4.04e-05  loss_mask_1: 0.1117  loss_dice_1: 0.1776  loss_ce_2: 5.055e-05  loss_mask_2: 0.1113  loss_dice_2: 0.1725  loss_ce_3: 3.128e-05  loss_mask_3: 0.1103  loss_dice_3: 0.1628  loss_ce_4: 2.74e-05  loss_mask_4: 0.1126  loss_dice_4: 0.1691  loss_ce_5: 4.503e-05  loss_mask_5: 0.1134  loss_dice_5: 0.1685  loss_ce_6: 3.28e-05  loss_mask_6: 0.1111  loss_dice_6: 0.1725  loss_ce_7: 3.138e-05  loss_mask_7: 0.1149  loss_dice_7: 0.1689  loss_ce_8: 5.238e-05  loss_mask_8: 0.1133  loss_dice_8: 0.1689  time: 0.6900  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 21:10:00] d2.utils.events INFO:  eta: 2:32:26  iter: 19279  total_loss: 2.933  loss_ce: 4.713e-05  loss_mask: 0.1108  loss_dice: 0.1671  loss_ce_0: 0.12  loss_mask_0: 0.1141  loss_dice_0: 0.1697  loss_ce_1: 4.216e-05  loss_mask_1: 0.115  loss_dice_1: 0.17  loss_ce_2: 4.955e-05  loss_mask_2: 0.1134  loss_dice_2: 0.1711  loss_ce_3: 3.708e-05  loss_mask_3: 0.1119  loss_dice_3: 0.1683  loss_ce_4: 3.651e-05  loss_mask_4: 0.1109  loss_dice_4: 0.1653  loss_ce_5: 4.351e-05  loss_mask_5: 0.1137  loss_dice_5: 0.1753  loss_ce_6: 3.229e-05  loss_mask_6: 0.1127  loss_dice_6: 0.1698  loss_ce_7: 3.197e-05  loss_mask_7: 0.1178  loss_dice_7: 0.1717  loss_ce_8: 5.198e-05  loss_mask_8: 0.1112  loss_dice_8: 0.1636  time: 0.6899  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:10:11] d2.utils.events INFO:  eta: 2:31:50  iter: 19299  total_loss: 3.065  loss_ce: 4.843e-05  loss_mask: 0.1082  loss_dice: 0.178  loss_ce_0: 0.1225  loss_mask_0: 0.1119  loss_dice_0: 0.1797  loss_ce_1: 4.174e-05  loss_mask_1: 0.109  loss_dice_1: 0.1758  loss_ce_2: 5.145e-05  loss_mask_2: 0.1098  loss_dice_2: 0.1821  loss_ce_3: 4.35e-05  loss_mask_3: 0.1105  loss_dice_3: 0.1866  loss_ce_4: 4.234e-05  loss_mask_4: 0.1104  loss_dice_4: 0.1856  loss_ce_5: 5.17e-05  loss_mask_5: 0.1126  loss_dice_5: 0.1825  loss_ce_6: 3.269e-05  loss_mask_6: 0.1094  loss_dice_6: 0.1792  loss_ce_7: 4.194e-05  loss_mask_7: 0.108  loss_dice_7: 0.1761  loss_ce_8: 5.595e-05  loss_mask_8: 0.1105  loss_dice_8: 0.1822  time: 0.6897  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:10:23] d2.utils.events INFO:  eta: 2:31:15  iter: 19319  total_loss: 3.121  loss_ce: 4.442e-05  loss_mask: 0.1206  loss_dice: 0.1831  loss_ce_0: 0.1264  loss_mask_0: 0.1187  loss_dice_0: 0.1851  loss_ce_1: 3.884e-05  loss_mask_1: 0.117  loss_dice_1: 0.1899  loss_ce_2: 4.351e-05  loss_mask_2: 0.1176  loss_dice_2: 0.1854  loss_ce_3: 3.004e-05  loss_mask_3: 0.1167  loss_dice_3: 0.1792  loss_ce_4: 2.897e-05  loss_mask_4: 0.1136  loss_dice_4: 0.1788  loss_ce_5: 3.984e-05  loss_mask_5: 0.1169  loss_dice_5: 0.1836  loss_ce_6: 2.865e-05  loss_mask_6: 0.1156  loss_dice_6: 0.1854  loss_ce_7: 2.824e-05  loss_mask_7: 0.1168  loss_dice_7: 0.1815  loss_ce_8: 4.482e-05  loss_mask_8: 0.1188  loss_dice_8: 0.1811  time: 0.6896  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:10:34] d2.utils.events INFO:  eta: 2:30:46  iter: 19339  total_loss: 2.952  loss_ce: 3.747e-05  loss_mask: 0.1192  loss_dice: 0.1696  loss_ce_0: 0.1266  loss_mask_0: 0.1166  loss_dice_0: 0.1626  loss_ce_1: 3.709e-05  loss_mask_1: 0.117  loss_dice_1: 0.1699  loss_ce_2: 4.421e-05  loss_mask_2: 0.1171  loss_dice_2: 0.1677  loss_ce_3: 3.608e-05  loss_mask_3: 0.1196  loss_dice_3: 0.1691  loss_ce_4: 3.927e-05  loss_mask_4: 0.1176  loss_dice_4: 0.167  loss_ce_5: 4.393e-05  loss_mask_5: 0.1149  loss_dice_5: 0.162  loss_ce_6: 2.784e-05  loss_mask_6: 0.1208  loss_dice_6: 0.1721  loss_ce_7: 3.656e-05  loss_mask_7: 0.1117  loss_dice_7: 0.1595  loss_ce_8: 4.765e-05  loss_mask_8: 0.1199  loss_dice_8: 0.1662  time: 0.6895  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:10:45] d2.utils.events INFO:  eta: 2:30:20  iter: 19359  total_loss: 3.229  loss_ce: 3.311e-05  loss_mask: 0.1201  loss_dice: 0.1803  loss_ce_0: 0.1256  loss_mask_0: 0.1232  loss_dice_0: 0.1881  loss_ce_1: 3.719e-05  loss_mask_1: 0.1209  loss_dice_1: 0.192  loss_ce_2: 3.937e-05  loss_mask_2: 0.1231  loss_dice_2: 0.1863  loss_ce_3: 2.746e-05  loss_mask_3: 0.1256  loss_dice_3: 0.1856  loss_ce_4: 2.594e-05  loss_mask_4: 0.1234  loss_dice_4: 0.18  loss_ce_5: 3.765e-05  loss_mask_5: 0.1221  loss_dice_5: 0.185  loss_ce_6: 2.797e-05  loss_mask_6: 0.1209  loss_dice_6: 0.1837  loss_ce_7: 2.738e-05  loss_mask_7: 0.1277  loss_dice_7: 0.1911  loss_ce_8: 3.78e-05  loss_mask_8: 0.1209  loss_dice_8: 0.1866  time: 0.6893  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:10:57] d2.utils.events INFO:  eta: 2:29:56  iter: 19379  total_loss: 2.889  loss_ce: 4.311e-05  loss_mask: 0.112  loss_dice: 0.1613  loss_ce_0: 0.1236  loss_mask_0: 0.1117  loss_dice_0: 0.1719  loss_ce_1: 3.599e-05  loss_mask_1: 0.1146  loss_dice_1: 0.1646  loss_ce_2: 3.985e-05  loss_mask_2: 0.1175  loss_dice_2: 0.163  loss_ce_3: 3.784e-05  loss_mask_3: 0.1146  loss_dice_3: 0.1668  loss_ce_4: 3.624e-05  loss_mask_4: 0.1199  loss_dice_4: 0.1677  loss_ce_5: 4.267e-05  loss_mask_5: 0.1141  loss_dice_5: 0.1621  loss_ce_6: 5.506e-05  loss_mask_6: 0.1126  loss_dice_6: 0.167  loss_ce_7: 3.452e-05  loss_mask_7: 0.1138  loss_dice_7: 0.162  loss_ce_8: 4.172e-05  loss_mask_8: 0.1173  loss_dice_8: 0.1661  time: 0.6892  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:11:08] d2.utils.events INFO:  eta: 2:29:29  iter: 19399  total_loss: 2.916  loss_ce: 4.528e-05  loss_mask: 0.112  loss_dice: 0.1633  loss_ce_0: 0.1306  loss_mask_0: 0.11  loss_dice_0: 0.1675  loss_ce_1: 3.688e-05  loss_mask_1: 0.1102  loss_dice_1: 0.1688  loss_ce_2: 4.611e-05  loss_mask_2: 0.1125  loss_dice_2: 0.1662  loss_ce_3: 3.525e-05  loss_mask_3: 0.1099  loss_dice_3: 0.1689  loss_ce_4: 3.243e-05  loss_mask_4: 0.11  loss_dice_4: 0.1718  loss_ce_5: 3.893e-05  loss_mask_5: 0.114  loss_dice_5: 0.1692  loss_ce_6: 3.204e-05  loss_mask_6: 0.1127  loss_dice_6: 0.1725  loss_ce_7: 3.048e-05  loss_mask_7: 0.1119  loss_dice_7: 0.1664  loss_ce_8: 4.759e-05  loss_mask_8: 0.1101  loss_dice_8: 0.168  time: 0.6891  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:11:20] d2.utils.events INFO:  eta: 2:28:56  iter: 19419  total_loss: 2.826  loss_ce: 4.153e-05  loss_mask: 0.1121  loss_dice: 0.1557  loss_ce_0: 0.1231  loss_mask_0: 0.1131  loss_dice_0: 0.1629  loss_ce_1: 3.755e-05  loss_mask_1: 0.1146  loss_dice_1: 0.1595  loss_ce_2: 4.341e-05  loss_mask_2: 0.1112  loss_dice_2: 0.1595  loss_ce_3: 3.884e-05  loss_mask_3: 0.1101  loss_dice_3: 0.1566  loss_ce_4: 4.105e-05  loss_mask_4: 0.1125  loss_dice_4: 0.161  loss_ce_5: 4.696e-05  loss_mask_5: 0.1084  loss_dice_5: 0.159  loss_ce_6: 3.103e-05  loss_mask_6: 0.1099  loss_dice_6: 0.1603  loss_ce_7: 3.871e-05  loss_mask_7: 0.1088  loss_dice_7: 0.1626  loss_ce_8: 4.739e-05  loss_mask_8: 0.1085  loss_dice_8: 0.1528  time: 0.6890  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:11:31] d2.utils.events INFO:  eta: 2:28:22  iter: 19439  total_loss: 2.96  loss_ce: 4.37e-05  loss_mask: 0.1172  loss_dice: 0.1711  loss_ce_0: 0.1266  loss_mask_0: 0.1137  loss_dice_0: 0.1712  loss_ce_1: 3.522e-05  loss_mask_1: 0.1142  loss_dice_1: 0.1773  loss_ce_2: 4.115e-05  loss_mask_2: 0.1155  loss_dice_2: 0.1702  loss_ce_3: 3.311e-05  loss_mask_3: 0.1147  loss_dice_3: 0.1686  loss_ce_4: 3.357e-05  loss_mask_4: 0.1166  loss_dice_4: 0.172  loss_ce_5: 3.794e-05  loss_mask_5: 0.1153  loss_dice_5: 0.1728  loss_ce_6: 3.689e-05  loss_mask_6: 0.1163  loss_dice_6: 0.1761  loss_ce_7: 3.274e-05  loss_mask_7: 0.1164  loss_dice_7: 0.1728  loss_ce_8: 4.342e-05  loss_mask_8: 0.115  loss_dice_8: 0.1709  time: 0.6888  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:11:42] d2.utils.events INFO:  eta: 2:27:47  iter: 19459  total_loss: 3.053  loss_ce: 3.707e-05  loss_mask: 0.1138  loss_dice: 0.1712  loss_ce_0: 0.1244  loss_mask_0: 0.1166  loss_dice_0: 0.182  loss_ce_1: 3.107e-05  loss_mask_1: 0.1168  loss_dice_1: 0.1732  loss_ce_2: 4.041e-05  loss_mask_2: 0.1172  loss_dice_2: 0.176  loss_ce_3: 3.369e-05  loss_mask_3: 0.1163  loss_dice_3: 0.171  loss_ce_4: 3.204e-05  loss_mask_4: 0.1127  loss_dice_4: 0.1733  loss_ce_5: 4.151e-05  loss_mask_5: 0.1165  loss_dice_5: 0.1732  loss_ce_6: 2.7e-05  loss_mask_6: 0.1139  loss_dice_6: 0.1781  loss_ce_7: 3.229e-05  loss_mask_7: 0.1186  loss_dice_7: 0.1729  loss_ce_8: 4.383e-05  loss_mask_8: 0.1174  loss_dice_8: 0.1703  time: 0.6887  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:11:54] d2.utils.events INFO:  eta: 2:27:24  iter: 19479  total_loss: 2.922  loss_ce: 4.052e-05  loss_mask: 0.1116  loss_dice: 0.1615  loss_ce_0: 0.1248  loss_mask_0: 0.1113  loss_dice_0: 0.1628  loss_ce_1: 3.608e-05  loss_mask_1: 0.113  loss_dice_1: 0.165  loss_ce_2: 4.041e-05  loss_mask_2: 0.1166  loss_dice_2: 0.1674  loss_ce_3: 3.57e-05  loss_mask_3: 0.1152  loss_dice_3: 0.1669  loss_ce_4: 3.398e-05  loss_mask_4: 0.1148  loss_dice_4: 0.1644  loss_ce_5: 4.399e-05  loss_mask_5: 0.1144  loss_dice_5: 0.1642  loss_ce_6: 2.787e-05  loss_mask_6: 0.1152  loss_dice_6: 0.1637  loss_ce_7: 3.505e-05  loss_mask_7: 0.1134  loss_dice_7: 0.1661  loss_ce_8: 4.476e-05  loss_mask_8: 0.1146  loss_dice_8: 0.1661  time: 0.6886  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:12:05] d2.utils.events INFO:  eta: 2:26:49  iter: 19499  total_loss: 3.076  loss_ce: 4.094e-05  loss_mask: 0.1131  loss_dice: 0.1767  loss_ce_0: 0.1363  loss_mask_0: 0.1115  loss_dice_0: 0.1842  loss_ce_1: 3.371e-05  loss_mask_1: 0.1128  loss_dice_1: 0.1781  loss_ce_2: 4.078e-05  loss_mask_2: 0.1137  loss_dice_2: 0.1779  loss_ce_3: 3.511e-05  loss_mask_3: 0.1133  loss_dice_3: 0.1816  loss_ce_4: 3.54e-05  loss_mask_4: 0.1145  loss_dice_4: 0.1774  loss_ce_5: 4.451e-05  loss_mask_5: 0.1129  loss_dice_5: 0.1825  loss_ce_6: 4.134e-05  loss_mask_6: 0.1132  loss_dice_6: 0.1757  loss_ce_7: 3.529e-05  loss_mask_7: 0.1137  loss_dice_7: 0.1767  loss_ce_8: 4.311e-05  loss_mask_8: 0.1121  loss_dice_8: 0.1833  time: 0.6885  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:12:16] d2.utils.events INFO:  eta: 2:26:25  iter: 19519  total_loss: 2.952  loss_ce: 3.275e-05  loss_mask: 0.1143  loss_dice: 0.1703  loss_ce_0: 0.1308  loss_mask_0: 0.1132  loss_dice_0: 0.1641  loss_ce_1: 2.709e-05  loss_mask_1: 0.1141  loss_dice_1: 0.1689  loss_ce_2: 3.643e-05  loss_mask_2: 0.1118  loss_dice_2: 0.1695  loss_ce_3: 2.769e-05  loss_mask_3: 0.1117  loss_dice_3: 0.1677  loss_ce_4: 3.009e-05  loss_mask_4: 0.1153  loss_dice_4: 0.1651  loss_ce_5: 3.409e-05  loss_mask_5: 0.111  loss_dice_5: 0.1662  loss_ce_6: 2.287e-05  loss_mask_6: 0.1135  loss_dice_6: 0.1727  loss_ce_7: 2.854e-05  loss_mask_7: 0.1121  loss_dice_7: 0.1685  loss_ce_8: 3.663e-05  loss_mask_8: 0.1113  loss_dice_8: 0.1682  time: 0.6883  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:12:28] d2.utils.events INFO:  eta: 2:26:05  iter: 19539  total_loss: 2.981  loss_ce: 2.924e-05  loss_mask: 0.1159  loss_dice: 0.1714  loss_ce_0: 0.1304  loss_mask_0: 0.1191  loss_dice_0: 0.1697  loss_ce_1: 2.92e-05  loss_mask_1: 0.1144  loss_dice_1: 0.1731  loss_ce_2: 3.663e-05  loss_mask_2: 0.1176  loss_dice_2: 0.1752  loss_ce_3: 2.852e-05  loss_mask_3: 0.1169  loss_dice_3: 0.1673  loss_ce_4: 2.943e-05  loss_mask_4: 0.1137  loss_dice_4: 0.1712  loss_ce_5: 3.304e-05  loss_mask_5: 0.1155  loss_dice_5: 0.1741  loss_ce_6: 2.206e-05  loss_mask_6: 0.1141  loss_dice_6: 0.1736  loss_ce_7: 2.691e-05  loss_mask_7: 0.1144  loss_dice_7: 0.1708  loss_ce_8: 3.797e-05  loss_mask_8: 0.1153  loss_dice_8: 0.1713  time: 0.6882  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:12:39] d2.utils.events INFO:  eta: 2:25:42  iter: 19559  total_loss: 3.138  loss_ce: 2.712e-05  loss_mask: 0.1192  loss_dice: 0.1827  loss_ce_0: 0.1165  loss_mask_0: 0.1196  loss_dice_0: 0.186  loss_ce_1: 3.141e-05  loss_mask_1: 0.1159  loss_dice_1: 0.1798  loss_ce_2: 3.501e-05  loss_mask_2: 0.1208  loss_dice_2: 0.1788  loss_ce_3: 2.908e-05  loss_mask_3: 0.1209  loss_dice_3: 0.18  loss_ce_4: 3.037e-05  loss_mask_4: 0.1163  loss_dice_4: 0.1785  loss_ce_5: 3.322e-05  loss_mask_5: 0.1208  loss_dice_5: 0.1842  loss_ce_6: 2.165e-05  loss_mask_6: 0.1154  loss_dice_6: 0.1843  loss_ce_7: 2.807e-05  loss_mask_7: 0.119  loss_dice_7: 0.1845  loss_ce_8: 3.317e-05  loss_mask_8: 0.1146  loss_dice_8: 0.1778  time: 0.6881  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:12:50] d2.utils.events INFO:  eta: 2:25:18  iter: 19579  total_loss: 2.954  loss_ce: 3.159e-05  loss_mask: 0.1138  loss_dice: 0.166  loss_ce_0: 0.1265  loss_mask_0: 0.1122  loss_dice_0: 0.1703  loss_ce_1: 3.169e-05  loss_mask_1: 0.1169  loss_dice_1: 0.1642  loss_ce_2: 3.671e-05  loss_mask_2: 0.1164  loss_dice_2: 0.1767  loss_ce_3: 2.564e-05  loss_mask_3: 0.1117  loss_dice_3: 0.1567  loss_ce_4: 2.435e-05  loss_mask_4: 0.1153  loss_dice_4: 0.1676  loss_ce_5: 3.126e-05  loss_mask_5: 0.1125  loss_dice_5: 0.1681  loss_ce_6: 2.323e-05  loss_mask_6: 0.1138  loss_dice_6: 0.1641  loss_ce_7: 2.383e-05  loss_mask_7: 0.1138  loss_dice_7: 0.1706  loss_ce_8: 3.877e-05  loss_mask_8: 0.1126  loss_dice_8: 0.1634  time: 0.6880  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:13:02] d2.utils.events INFO:  eta: 2:24:58  iter: 19599  total_loss: 3.004  loss_ce: 3.344e-05  loss_mask: 0.1133  loss_dice: 0.1714  loss_ce_0: 0.12  loss_mask_0: 0.1169  loss_dice_0: 0.1838  loss_ce_1: 3.151e-05  loss_mask_1: 0.1121  loss_dice_1: 0.173  loss_ce_2: 3.732e-05  loss_mask_2: 0.1132  loss_dice_2: 0.166  loss_ce_3: 2.902e-05  loss_mask_3: 0.1132  loss_dice_3: 0.1719  loss_ce_4: 2.951e-05  loss_mask_4: 0.1147  loss_dice_4: 0.1748  loss_ce_5: 3.267e-05  loss_mask_5: 0.1133  loss_dice_5: 0.1738  loss_ce_6: 2.331e-05  loss_mask_6: 0.1156  loss_dice_6: 0.1708  loss_ce_7: 2.951e-05  loss_mask_7: 0.1118  loss_dice_7: 0.1703  loss_ce_8: 3.952e-05  loss_mask_8: 0.116  loss_dice_8: 0.1705  time: 0.6878  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:13:13] d2.utils.events INFO:  eta: 2:24:48  iter: 19619  total_loss: 2.941  loss_ce: 3.013e-05  loss_mask: 0.1145  loss_dice: 0.1645  loss_ce_0: 0.1155  loss_mask_0: 0.1133  loss_dice_0: 0.1651  loss_ce_1: 3.274e-05  loss_mask_1: 0.1157  loss_dice_1: 0.1703  loss_ce_2: 3.366e-05  loss_mask_2: 0.1129  loss_dice_2: 0.1666  loss_ce_3: 2.748e-05  loss_mask_3: 0.114  loss_dice_3: 0.1672  loss_ce_4: 2.803e-05  loss_mask_4: 0.116  loss_dice_4: 0.166  loss_ce_5: 3.212e-05  loss_mask_5: 0.1124  loss_dice_5: 0.1676  loss_ce_6: 2.393e-05  loss_mask_6: 0.113  loss_dice_6: 0.1711  loss_ce_7: 2.726e-05  loss_mask_7: 0.1159  loss_dice_7: 0.1682  loss_ce_8: 3.206e-05  loss_mask_8: 0.1166  loss_dice_8: 0.1694  time: 0.6877  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:13:24] d2.utils.events INFO:  eta: 2:24:37  iter: 19639  total_loss: 3.03  loss_ce: 3.476e-05  loss_mask: 0.118  loss_dice: 0.1727  loss_ce_0: 0.1359  loss_mask_0: 0.1109  loss_dice_0: 0.1686  loss_ce_1: 3.098e-05  loss_mask_1: 0.1153  loss_dice_1: 0.1713  loss_ce_2: 4.077e-05  loss_mask_2: 0.1165  loss_dice_2: 0.1732  loss_ce_3: 2.841e-05  loss_mask_3: 0.112  loss_dice_3: 0.1694  loss_ce_4: 2.881e-05  loss_mask_4: 0.1158  loss_dice_4: 0.1699  loss_ce_5: 4.17e-05  loss_mask_5: 0.1108  loss_dice_5: 0.1634  loss_ce_6: 3.877e-05  loss_mask_6: 0.1138  loss_dice_6: 0.1767  loss_ce_7: 2.948e-05  loss_mask_7: 0.1155  loss_dice_7: 0.1772  loss_ce_8: 3.689e-05  loss_mask_8: 0.112  loss_dice_8: 0.1721  time: 0.6876  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:13:36] d2.utils.events INFO:  eta: 2:24:25  iter: 19659  total_loss: 2.918  loss_ce: 3.114e-05  loss_mask: 0.1116  loss_dice: 0.1669  loss_ce_0: 0.1332  loss_mask_0: 0.1141  loss_dice_0: 0.1574  loss_ce_1: 2.794e-05  loss_mask_1: 0.113  loss_dice_1: 0.1705  loss_ce_2: 3.404e-05  loss_mask_2: 0.1132  loss_dice_2: 0.1745  loss_ce_3: 2.074e-05  loss_mask_3: 0.1122  loss_dice_3: 0.1676  loss_ce_4: 1.976e-05  loss_mask_4: 0.1126  loss_dice_4: 0.1671  loss_ce_5: 2.65e-05  loss_mask_5: 0.114  loss_dice_5: 0.1693  loss_ce_6: 2.254e-05  loss_mask_6: 0.1129  loss_dice_6: 0.1691  loss_ce_7: 1.91e-05  loss_mask_7: 0.1118  loss_dice_7: 0.1646  loss_ce_8: 3.223e-05  loss_mask_8: 0.1121  loss_dice_8: 0.1675  time: 0.6875  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:13:47] d2.utils.events INFO:  eta: 2:24:13  iter: 19679  total_loss: 3.006  loss_ce: 3.245e-05  loss_mask: 0.1192  loss_dice: 0.1789  loss_ce_0: 0.1232  loss_mask_0: 0.1162  loss_dice_0: 0.1717  loss_ce_1: 3.033e-05  loss_mask_1: 0.1116  loss_dice_1: 0.1813  loss_ce_2: 3.549e-05  loss_mask_2: 0.1131  loss_dice_2: 0.1737  loss_ce_3: 3.306e-05  loss_mask_3: 0.1152  loss_dice_3: 0.1752  loss_ce_4: 3.308e-05  loss_mask_4: 0.1132  loss_dice_4: 0.1727  loss_ce_5: 3.966e-05  loss_mask_5: 0.11  loss_dice_5: 0.1806  loss_ce_6: 2.534e-05  loss_mask_6: 0.1128  loss_dice_6: 0.1762  loss_ce_7: 3.276e-05  loss_mask_7: 0.1104  loss_dice_7: 0.1743  loss_ce_8: 3.894e-05  loss_mask_8: 0.1128  loss_dice_8: 0.1737  time: 0.6873  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:13:58] d2.utils.events INFO:  eta: 2:24:00  iter: 19699  total_loss: 3.041  loss_ce: 3.092e-05  loss_mask: 0.1154  loss_dice: 0.1714  loss_ce_0: 0.1263  loss_mask_0: 0.1146  loss_dice_0: 0.1684  loss_ce_1: 2.979e-05  loss_mask_1: 0.1094  loss_dice_1: 0.1698  loss_ce_2: 3.44e-05  loss_mask_2: 0.1162  loss_dice_2: 0.1763  loss_ce_3: 3.02e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1676  loss_ce_4: 3.037e-05  loss_mask_4: 0.1167  loss_dice_4: 0.1758  loss_ce_5: 3.423e-05  loss_mask_5: 0.1112  loss_dice_5: 0.1662  loss_ce_6: 2.203e-05  loss_mask_6: 0.1167  loss_dice_6: 0.1756  loss_ce_7: 2.927e-05  loss_mask_7: 0.113  loss_dice_7: 0.1708  loss_ce_8: 3.343e-05  loss_mask_8: 0.1089  loss_dice_8: 0.167  time: 0.6872  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:14:10] d2.utils.events INFO:  eta: 2:23:47  iter: 19719  total_loss: 2.965  loss_ce: 3.025e-05  loss_mask: 0.1126  loss_dice: 0.173  loss_ce_0: 0.1188  loss_mask_0: 0.1109  loss_dice_0: 0.1757  loss_ce_1: 2.8e-05  loss_mask_1: 0.1152  loss_dice_1: 0.1783  loss_ce_2: 3.569e-05  loss_mask_2: 0.117  loss_dice_2: 0.1798  loss_ce_3: 3.271e-05  loss_mask_3: 0.1158  loss_dice_3: 0.171  loss_ce_4: 3.235e-05  loss_mask_4: 0.1104  loss_dice_4: 0.1709  loss_ce_5: 3.882e-05  loss_mask_5: 0.113  loss_dice_5: 0.1734  loss_ce_6: 2.233e-05  loss_mask_6: 0.1173  loss_dice_6: 0.1746  loss_ce_7: 3.101e-05  loss_mask_7: 0.1141  loss_dice_7: 0.1762  loss_ce_8: 3.583e-05  loss_mask_8: 0.1144  loss_dice_8: 0.1784  time: 0.6871  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:14:21] d2.utils.events INFO:  eta: 2:23:41  iter: 19739  total_loss: 2.854  loss_ce: 2.997e-05  loss_mask: 0.1104  loss_dice: 0.1666  loss_ce_0: 0.1236  loss_mask_0: 0.1105  loss_dice_0: 0.1667  loss_ce_1: 2.826e-05  loss_mask_1: 0.1109  loss_dice_1: 0.1692  loss_ce_2: 3.166e-05  loss_mask_2: 0.1129  loss_dice_2: 0.1666  loss_ce_3: 2.718e-05  loss_mask_3: 0.1111  loss_dice_3: 0.1691  loss_ce_4: 2.756e-05  loss_mask_4: 0.1072  loss_dice_4: 0.1641  loss_ce_5: 3.142e-05  loss_mask_5: 0.1089  loss_dice_5: 0.1712  loss_ce_6: 2.059e-05  loss_mask_6: 0.107  loss_dice_6: 0.1652  loss_ce_7: 2.824e-05  loss_mask_7: 0.1108  loss_dice_7: 0.1705  loss_ce_8: 3.241e-05  loss_mask_8: 0.1065  loss_dice_8: 0.168  time: 0.6870  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:14:32] d2.utils.events INFO:  eta: 2:23:31  iter: 19759  total_loss: 3.06  loss_ce: 2.847e-05  loss_mask: 0.1149  loss_dice: 0.173  loss_ce_0: 0.1245  loss_mask_0: 0.1161  loss_dice_0: 0.1807  loss_ce_1: 2.576e-05  loss_mask_1: 0.117  loss_dice_1: 0.1795  loss_ce_2: 3.117e-05  loss_mask_2: 0.1153  loss_dice_2: 0.1731  loss_ce_3: 2.808e-05  loss_mask_3: 0.1149  loss_dice_3: 0.175  loss_ce_4: 2.678e-05  loss_mask_4: 0.1149  loss_dice_4: 0.1716  loss_ce_5: 3.116e-05  loss_mask_5: 0.1151  loss_dice_5: 0.1763  loss_ce_6: 2.218e-05  loss_mask_6: 0.1141  loss_dice_6: 0.1749  loss_ce_7: 2.653e-05  loss_mask_7: 0.1193  loss_dice_7: 0.1749  loss_ce_8: 3.13e-05  loss_mask_8: 0.1131  loss_dice_8: 0.1719  time: 0.6869  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:14:44] d2.utils.events INFO:  eta: 2:23:20  iter: 19779  total_loss: 2.8  loss_ce: 2.671e-05  loss_mask: 0.1087  loss_dice: 0.1635  loss_ce_0: 0.1242  loss_mask_0: 0.1093  loss_dice_0: 0.1555  loss_ce_1: 2.712e-05  loss_mask_1: 0.1092  loss_dice_1: 0.162  loss_ce_2: 3.066e-05  loss_mask_2: 0.1125  loss_dice_2: 0.1582  loss_ce_3: 2.511e-05  loss_mask_3: 0.1113  loss_dice_3: 0.1624  loss_ce_4: 2.477e-05  loss_mask_4: 0.1104  loss_dice_4: 0.1597  loss_ce_5: 3.048e-05  loss_mask_5: 0.1088  loss_dice_5: 0.1588  loss_ce_6: 2.019e-05  loss_mask_6: 0.1096  loss_dice_6: 0.1638  loss_ce_7: 2.284e-05  loss_mask_7: 0.1095  loss_dice_7: 0.1617  loss_ce_8: 3.094e-05  loss_mask_8: 0.1093  loss_dice_8: 0.1627  time: 0.6867  data_time: 0.0013  lr: 0.0001  max_mem: 8444M
[08/01 21:14:55] d2.utils.events INFO:  eta: 2:23:11  iter: 19799  total_loss: 3.211  loss_ce: 2.561e-05  loss_mask: 0.1191  loss_dice: 0.1928  loss_ce_0: 0.1255  loss_mask_0: 0.1165  loss_dice_0: 0.1837  loss_ce_1: 2.524e-05  loss_mask_1: 0.1176  loss_dice_1: 0.1874  loss_ce_2: 3.048e-05  loss_mask_2: 0.118  loss_dice_2: 0.1937  loss_ce_3: 1.91e-05  loss_mask_3: 0.1196  loss_dice_3: 0.1857  loss_ce_4: 1.665e-05  loss_mask_4: 0.1166  loss_dice_4: 0.1918  loss_ce_5: 2.298e-05  loss_mask_5: 0.1148  loss_dice_5: 0.181  loss_ce_6: 1.955e-05  loss_mask_6: 0.1236  loss_dice_6: 0.1953  loss_ce_7: 1.684e-05  loss_mask_7: 0.1162  loss_dice_7: 0.1827  loss_ce_8: 2.965e-05  loss_mask_8: 0.1183  loss_dice_8: 0.1883  time: 0.6866  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:15:07] d2.utils.events INFO:  eta: 2:22:58  iter: 19819  total_loss: 2.956  loss_ce: 2.732e-05  loss_mask: 0.1193  loss_dice: 0.1684  loss_ce_0: 0.1226  loss_mask_0: 0.1187  loss_dice_0: 0.1675  loss_ce_1: 2.586e-05  loss_mask_1: 0.1181  loss_dice_1: 0.1718  loss_ce_2: 3.115e-05  loss_mask_2: 0.1141  loss_dice_2: 0.1642  loss_ce_3: 1.839e-05  loss_mask_3: 0.1152  loss_dice_3: 0.1728  loss_ce_4: 1.811e-05  loss_mask_4: 0.115  loss_dice_4: 0.1653  loss_ce_5: 2.324e-05  loss_mask_5: 0.116  loss_dice_5: 0.1635  loss_ce_6: 1.958e-05  loss_mask_6: 0.1164  loss_dice_6: 0.1671  loss_ce_7: 1.663e-05  loss_mask_7: 0.1167  loss_dice_7: 0.1634  loss_ce_8: 3.125e-05  loss_mask_8: 0.1151  loss_dice_8: 0.1685  time: 0.6865  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:15:18] d2.utils.events INFO:  eta: 2:22:48  iter: 19839  total_loss: 3.06  loss_ce: 3.033e-05  loss_mask: 0.1172  loss_dice: 0.1758  loss_ce_0: 0.1185  loss_mask_0: 0.1157  loss_dice_0: 0.1903  loss_ce_1: 3.018e-05  loss_mask_1: 0.1132  loss_dice_1: 0.1808  loss_ce_2: 3.201e-05  loss_mask_2: 0.1147  loss_dice_2: 0.1765  loss_ce_3: 2.939e-05  loss_mask_3: 0.1179  loss_dice_3: 0.1756  loss_ce_4: 2.627e-05  loss_mask_4: 0.1147  loss_dice_4: 0.1739  loss_ce_5: 3.123e-05  loss_mask_5: 0.1153  loss_dice_5: 0.1809  loss_ce_6: 2.375e-05  loss_mask_6: 0.1183  loss_dice_6: 0.176  loss_ce_7: 2.812e-05  loss_mask_7: 0.1145  loss_dice_7: 0.1747  loss_ce_8: 3.251e-05  loss_mask_8: 0.1117  loss_dice_8: 0.1755  time: 0.6864  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:15:30] d2.utils.events INFO:  eta: 2:22:33  iter: 19859  total_loss: 2.962  loss_ce: 2.909e-05  loss_mask: 0.117  loss_dice: 0.1702  loss_ce_0: 0.1155  loss_mask_0: 0.1161  loss_dice_0: 0.1679  loss_ce_1: 2.904e-05  loss_mask_1: 0.1178  loss_dice_1: 0.1671  loss_ce_2: 3.07e-05  loss_mask_2: 0.1108  loss_dice_2: 0.1642  loss_ce_3: 2.899e-05  loss_mask_3: 0.1138  loss_dice_3: 0.1697  loss_ce_4: 2.607e-05  loss_mask_4: 0.1178  loss_dice_4: 0.1712  loss_ce_5: 2.897e-05  loss_mask_5: 0.1167  loss_dice_5: 0.1685  loss_ce_6: 2.368e-05  loss_mask_6: 0.1173  loss_dice_6: 0.1684  loss_ce_7: 2.627e-05  loss_mask_7: 0.1155  loss_dice_7: 0.1724  loss_ce_8: 2.92e-05  loss_mask_8: 0.1133  loss_dice_8: 0.1666  time: 0.6863  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:15:41] d2.utils.events INFO:  eta: 2:22:15  iter: 19879  total_loss: 3.211  loss_ce: 2.42e-05  loss_mask: 0.1137  loss_dice: 0.184  loss_ce_0: 0.1133  loss_mask_0: 0.1215  loss_dice_0: 0.1922  loss_ce_1: 2.998e-05  loss_mask_1: 0.1184  loss_dice_1: 0.1891  loss_ce_2: 3.19e-05  loss_mask_2: 0.1235  loss_dice_2: 0.1937  loss_ce_3: 2.687e-05  loss_mask_3: 0.1182  loss_dice_3: 0.1968  loss_ce_4: 2.319e-05  loss_mask_4: 0.1168  loss_dice_4: 0.1845  loss_ce_5: 2.848e-05  loss_mask_5: 0.1182  loss_dice_5: 0.186  loss_ce_6: 1.846e-05  loss_mask_6: 0.1182  loss_dice_6: 0.186  loss_ce_7: 2.384e-05  loss_mask_7: 0.1174  loss_dice_7: 0.1882  loss_ce_8: 2.941e-05  loss_mask_8: 0.1181  loss_dice_8: 0.1854  time: 0.6861  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:15:53] d2.utils.events INFO:  eta: 2:22:11  iter: 19899  total_loss: 3.109  loss_ce: 2.5e-05  loss_mask: 0.1142  loss_dice: 0.1861  loss_ce_0: 0.1089  loss_mask_0: 0.1194  loss_dice_0: 0.1845  loss_ce_1: 2.775e-05  loss_mask_1: 0.1196  loss_dice_1: 0.1967  loss_ce_2: 3.044e-05  loss_mask_2: 0.1187  loss_dice_2: 0.1846  loss_ce_3: 2.479e-05  loss_mask_3: 0.1138  loss_dice_3: 0.1926  loss_ce_4: 2.272e-05  loss_mask_4: 0.1165  loss_dice_4: 0.1841  loss_ce_5: 2.734e-05  loss_mask_5: 0.12  loss_dice_5: 0.1892  loss_ce_6: 2.002e-05  loss_mask_6: 0.1148  loss_dice_6: 0.1877  loss_ce_7: 2.303e-05  loss_mask_7: 0.1125  loss_dice_7: 0.1778  loss_ce_8: 2.916e-05  loss_mask_8: 0.1133  loss_dice_8: 0.1823  time: 0.6861  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:16:06] d2.utils.events INFO:  eta: 2:22:12  iter: 19919  total_loss: 3.114  loss_ce: 2.538e-05  loss_mask: 0.1186  loss_dice: 0.1878  loss_ce_0: 0.1182  loss_mask_0: 0.1181  loss_dice_0: 0.1911  loss_ce_1: 3.09e-05  loss_mask_1: 0.1186  loss_dice_1: 0.1961  loss_ce_2: 2.98e-05  loss_mask_2: 0.1149  loss_dice_2: 0.1942  loss_ce_3: 1.995e-05  loss_mask_3: 0.1175  loss_dice_3: 0.1893  loss_ce_4: 1.82e-05  loss_mask_4: 0.1147  loss_dice_4: 0.1856  loss_ce_5: 2.405e-05  loss_mask_5: 0.1165  loss_dice_5: 0.1845  loss_ce_6: 1.985e-05  loss_mask_6: 0.1214  loss_dice_6: 0.2017  loss_ce_7: 1.926e-05  loss_mask_7: 0.1195  loss_dice_7: 0.191  loss_ce_8: 2.887e-05  loss_mask_8: 0.1116  loss_dice_8: 0.1788  time: 0.6860  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:16:18] d2.utils.events INFO:  eta: 2:22:15  iter: 19939  total_loss: 3.08  loss_ce: 2.495e-05  loss_mask: 0.115  loss_dice: 0.1765  loss_ce_0: 0.1132  loss_mask_0: 0.1186  loss_dice_0: 0.1776  loss_ce_1: 2.627e-05  loss_mask_1: 0.12  loss_dice_1: 0.174  loss_ce_2: 2.946e-05  loss_mask_2: 0.1179  loss_dice_2: 0.1754  loss_ce_3: 2.431e-05  loss_mask_3: 0.1153  loss_dice_3: 0.1767  loss_ce_4: 2.227e-05  loss_mask_4: 0.1145  loss_dice_4: 0.1743  loss_ce_5: 2.663e-05  loss_mask_5: 0.1164  loss_dice_5: 0.1733  loss_ce_6: 2.151e-05  loss_mask_6: 0.1182  loss_dice_6: 0.1771  loss_ce_7: 2.338e-05  loss_mask_7: 0.1201  loss_dice_7: 0.1714  loss_ce_8: 2.743e-05  loss_mask_8: 0.1188  loss_dice_8: 0.1796  time: 0.6860  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:16:31] d2.utils.events INFO:  eta: 2:22:16  iter: 19959  total_loss: 3.077  loss_ce: 2.965e-05  loss_mask: 0.1152  loss_dice: 0.184  loss_ce_0: 0.1193  loss_mask_0: 0.1124  loss_dice_0: 0.1742  loss_ce_1: 2.921e-05  loss_mask_1: 0.1147  loss_dice_1: 0.1827  loss_ce_2: 2.936e-05  loss_mask_2: 0.1112  loss_dice_2: 0.1784  loss_ce_3: 2.524e-05  loss_mask_3: 0.1181  loss_dice_3: 0.1861  loss_ce_4: 2.331e-05  loss_mask_4: 0.1165  loss_dice_4: 0.1902  loss_ce_5: 2.964e-05  loss_mask_5: 0.1132  loss_dice_5: 0.1717  loss_ce_6: 2.146e-05  loss_mask_6: 0.1131  loss_dice_6: 0.1863  loss_ce_7: 2.805e-05  loss_mask_7: 0.1175  loss_dice_7: 0.1828  loss_ce_8: 3.101e-05  loss_mask_8: 0.116  loss_dice_8: 0.1797  time: 0.6859  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:16:43] d2.utils.events INFO:  eta: 2:22:28  iter: 19979  total_loss: 3.032  loss_ce: 2.285e-05  loss_mask: 0.1155  loss_dice: 0.1752  loss_ce_0: 0.116  loss_mask_0: 0.1169  loss_dice_0: 0.1775  loss_ce_1: 2.959e-05  loss_mask_1: 0.1165  loss_dice_1: 0.1712  loss_ce_2: 2.921e-05  loss_mask_2: 0.1136  loss_dice_2: 0.171  loss_ce_3: 2.395e-05  loss_mask_3: 0.1165  loss_dice_3: 0.1742  loss_ce_4: 2.236e-05  loss_mask_4: 0.1182  loss_dice_4: 0.1746  loss_ce_5: 2.786e-05  loss_mask_5: 0.1155  loss_dice_5: 0.1713  loss_ce_6: 1.944e-05  loss_mask_6: 0.1219  loss_dice_6: 0.1773  loss_ce_7: 2.824e-05  loss_mask_7: 0.1135  loss_dice_7: 0.1737  loss_ce_8: 2.753e-05  loss_mask_8: 0.1165  loss_dice_8: 0.1729  time: 0.6858  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:16:56] fvcore.common.checkpoint INFO: Saving checkpoint to ./R101_overlap/model_0019999.pth
[08/01 21:16:56] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(256, 256), max_size=256, sample_style='choice')]
[08/01 21:16:56] d2.data.common INFO: Serializing 535 elements to byte tensors and concatenating them all ...
[08/01 21:16:56] d2.data.common INFO: Serialized dataset takes 0.22 MiB
[08/01 21:16:56] d2.evaluation.evaluator INFO: Start inference on 535 batches
[08/01 21:17:16] d2.evaluation.evaluator INFO: Inference done 11/535. Dataloading: 0.0006 s/iter. Inference: 0.9089 s/iter. Eval: 0.9128 s/iter. Total: 1.8224 s/iter. ETA=0:15:54
[08/01 21:17:22] d2.evaluation.evaluator INFO: Inference done 14/535. Dataloading: 0.0006 s/iter. Inference: 0.9233 s/iter. Eval: 0.9120 s/iter. Total: 1.8360 s/iter. ETA=0:15:56
[08/01 21:17:27] d2.evaluation.evaluator INFO: Inference done 17/535. Dataloading: 0.0006 s/iter. Inference: 0.9099 s/iter. Eval: 0.9133 s/iter. Total: 1.8239 s/iter. ETA=0:15:44
[08/01 21:17:33] d2.evaluation.evaluator INFO: Inference done 20/535. Dataloading: 0.0007 s/iter. Inference: 0.9145 s/iter. Eval: 0.9153 s/iter. Total: 1.8305 s/iter. ETA=0:15:42
[08/01 21:17:38] d2.evaluation.evaluator INFO: Inference done 23/535. Dataloading: 0.0007 s/iter. Inference: 0.9117 s/iter. Eval: 0.9144 s/iter. Total: 1.8269 s/iter. ETA=0:15:35
[08/01 21:17:44] d2.evaluation.evaluator INFO: Inference done 26/535. Dataloading: 0.0007 s/iter. Inference: 0.9151 s/iter. Eval: 0.9140 s/iter. Total: 1.8298 s/iter. ETA=0:15:31
[08/01 21:17:49] d2.evaluation.evaluator INFO: Inference done 29/535. Dataloading: 0.0007 s/iter. Inference: 0.9152 s/iter. Eval: 0.9138 s/iter. Total: 1.8297 s/iter. ETA=0:15:25
[08/01 21:17:55] d2.evaluation.evaluator INFO: Inference done 32/535. Dataloading: 0.0007 s/iter. Inference: 0.9160 s/iter. Eval: 0.9144 s/iter. Total: 1.8311 s/iter. ETA=0:15:21
[08/01 21:18:00] d2.evaluation.evaluator INFO: Inference done 35/535. Dataloading: 0.0007 s/iter. Inference: 0.9147 s/iter. Eval: 0.9140 s/iter. Total: 1.8295 s/iter. ETA=0:15:14
[08/01 21:18:06] d2.evaluation.evaluator INFO: Inference done 38/535. Dataloading: 0.0007 s/iter. Inference: 0.9147 s/iter. Eval: 0.9139 s/iter. Total: 1.8293 s/iter. ETA=0:15:09
[08/01 21:18:11] d2.evaluation.evaluator INFO: Inference done 41/535. Dataloading: 0.0007 s/iter. Inference: 0.9167 s/iter. Eval: 0.9138 s/iter. Total: 1.8312 s/iter. ETA=0:15:04
[08/01 21:18:17] d2.evaluation.evaluator INFO: Inference done 44/535. Dataloading: 0.0007 s/iter. Inference: 0.9149 s/iter. Eval: 0.9155 s/iter. Total: 1.8312 s/iter. ETA=0:14:59
[08/01 21:18:23] d2.evaluation.evaluator INFO: Inference done 47/535. Dataloading: 0.0007 s/iter. Inference: 0.9162 s/iter. Eval: 0.9160 s/iter. Total: 1.8330 s/iter. ETA=0:14:54
[08/01 21:18:28] d2.evaluation.evaluator INFO: Inference done 50/535. Dataloading: 0.0007 s/iter. Inference: 0.9134 s/iter. Eval: 0.9155 s/iter. Total: 1.8297 s/iter. ETA=0:14:47
[08/01 21:18:33] d2.evaluation.evaluator INFO: Inference done 53/535. Dataloading: 0.0007 s/iter. Inference: 0.9151 s/iter. Eval: 0.9148 s/iter. Total: 1.8307 s/iter. ETA=0:14:42
[08/01 21:18:39] d2.evaluation.evaluator INFO: Inference done 56/535. Dataloading: 0.0007 s/iter. Inference: 0.9135 s/iter. Eval: 0.9143 s/iter. Total: 1.8285 s/iter. ETA=0:14:35
[08/01 21:18:44] d2.evaluation.evaluator INFO: Inference done 59/535. Dataloading: 0.0007 s/iter. Inference: 0.9142 s/iter. Eval: 0.9139 s/iter. Total: 1.8288 s/iter. ETA=0:14:30
[08/01 21:18:50] d2.evaluation.evaluator INFO: Inference done 62/535. Dataloading: 0.0007 s/iter. Inference: 0.9149 s/iter. Eval: 0.9138 s/iter. Total: 1.8294 s/iter. ETA=0:14:25
[08/01 21:18:55] d2.evaluation.evaluator INFO: Inference done 65/535. Dataloading: 0.0007 s/iter. Inference: 0.9148 s/iter. Eval: 0.9135 s/iter. Total: 1.8291 s/iter. ETA=0:14:19
[08/01 21:19:01] d2.evaluation.evaluator INFO: Inference done 68/535. Dataloading: 0.0007 s/iter. Inference: 0.9143 s/iter. Eval: 0.9134 s/iter. Total: 1.8285 s/iter. ETA=0:14:13
[08/01 21:19:06] d2.evaluation.evaluator INFO: Inference done 71/535. Dataloading: 0.0007 s/iter. Inference: 0.9137 s/iter. Eval: 0.9134 s/iter. Total: 1.8279 s/iter. ETA=0:14:08
[08/01 21:19:12] d2.evaluation.evaluator INFO: Inference done 74/535. Dataloading: 0.0007 s/iter. Inference: 0.9152 s/iter. Eval: 0.9137 s/iter. Total: 1.8296 s/iter. ETA=0:14:03
[08/01 21:19:17] d2.evaluation.evaluator INFO: Inference done 77/535. Dataloading: 0.0007 s/iter. Inference: 0.9141 s/iter. Eval: 0.9139 s/iter. Total: 1.8287 s/iter. ETA=0:13:57
[08/01 21:19:23] d2.evaluation.evaluator INFO: Inference done 80/535. Dataloading: 0.0007 s/iter. Inference: 0.9149 s/iter. Eval: 0.9139 s/iter. Total: 1.8296 s/iter. ETA=0:13:52
[08/01 21:19:28] d2.evaluation.evaluator INFO: Inference done 83/535. Dataloading: 0.0007 s/iter. Inference: 0.9145 s/iter. Eval: 0.9139 s/iter. Total: 1.8292 s/iter. ETA=0:13:46
[08/01 21:19:34] d2.evaluation.evaluator INFO: Inference done 86/535. Dataloading: 0.0007 s/iter. Inference: 0.9160 s/iter. Eval: 0.9139 s/iter. Total: 1.8307 s/iter. ETA=0:13:41
[08/01 21:19:39] d2.evaluation.evaluator INFO: Inference done 89/535. Dataloading: 0.0007 s/iter. Inference: 0.9145 s/iter. Eval: 0.9138 s/iter. Total: 1.8290 s/iter. ETA=0:13:35
[08/01 21:19:45] d2.evaluation.evaluator INFO: Inference done 92/535. Dataloading: 0.0007 s/iter. Inference: 0.9152 s/iter. Eval: 0.9137 s/iter. Total: 1.8297 s/iter. ETA=0:13:30
[08/01 21:19:50] d2.evaluation.evaluator INFO: Inference done 95/535. Dataloading: 0.0007 s/iter. Inference: 0.9157 s/iter. Eval: 0.9135 s/iter. Total: 1.8299 s/iter. ETA=0:13:25
[08/01 21:19:56] d2.evaluation.evaluator INFO: Inference done 98/535. Dataloading: 0.0007 s/iter. Inference: 0.9155 s/iter. Eval: 0.9137 s/iter. Total: 1.8299 s/iter. ETA=0:13:19
[08/01 21:20:01] d2.evaluation.evaluator INFO: Inference done 101/535. Dataloading: 0.0007 s/iter. Inference: 0.9156 s/iter. Eval: 0.9135 s/iter. Total: 1.8298 s/iter. ETA=0:13:14
[08/01 21:20:07] d2.evaluation.evaluator INFO: Inference done 104/535. Dataloading: 0.0007 s/iter. Inference: 0.9147 s/iter. Eval: 0.9134 s/iter. Total: 1.8289 s/iter. ETA=0:13:08
[08/01 21:20:12] d2.evaluation.evaluator INFO: Inference done 107/535. Dataloading: 0.0007 s/iter. Inference: 0.9153 s/iter. Eval: 0.9134 s/iter. Total: 1.8294 s/iter. ETA=0:13:02
[08/01 21:20:18] d2.evaluation.evaluator INFO: Inference done 110/535. Dataloading: 0.0007 s/iter. Inference: 0.9151 s/iter. Eval: 0.9136 s/iter. Total: 1.8294 s/iter. ETA=0:12:57
[08/01 21:20:23] d2.evaluation.evaluator INFO: Inference done 113/535. Dataloading: 0.0007 s/iter. Inference: 0.9156 s/iter. Eval: 0.9135 s/iter. Total: 1.8299 s/iter. ETA=0:12:52
[08/01 21:20:29] d2.evaluation.evaluator INFO: Inference done 116/535. Dataloading: 0.0007 s/iter. Inference: 0.9152 s/iter. Eval: 0.9133 s/iter. Total: 1.8292 s/iter. ETA=0:12:46
[08/01 21:20:34] d2.evaluation.evaluator INFO: Inference done 119/535. Dataloading: 0.0007 s/iter. Inference: 0.9149 s/iter. Eval: 0.9130 s/iter. Total: 1.8287 s/iter. ETA=0:12:40
[08/01 21:20:40] d2.evaluation.evaluator INFO: Inference done 122/535. Dataloading: 0.0007 s/iter. Inference: 0.9156 s/iter. Eval: 0.9129 s/iter. Total: 1.8293 s/iter. ETA=0:12:35
[08/01 21:20:45] d2.evaluation.evaluator INFO: Inference done 125/535. Dataloading: 0.0007 s/iter. Inference: 0.9141 s/iter. Eval: 0.9129 s/iter. Total: 1.8278 s/iter. ETA=0:12:29
[08/01 21:20:51] d2.evaluation.evaluator INFO: Inference done 128/535. Dataloading: 0.0007 s/iter. Inference: 0.9154 s/iter. Eval: 0.9131 s/iter. Total: 1.8293 s/iter. ETA=0:12:24
[08/01 21:20:56] d2.evaluation.evaluator INFO: Inference done 131/535. Dataloading: 0.0007 s/iter. Inference: 0.9149 s/iter. Eval: 0.9130 s/iter. Total: 1.8288 s/iter. ETA=0:12:18
[08/01 21:21:01] d2.evaluation.evaluator INFO: Inference done 134/535. Dataloading: 0.0007 s/iter. Inference: 0.9155 s/iter. Eval: 0.9128 s/iter. Total: 1.8292 s/iter. ETA=0:12:13
[08/01 21:21:07] d2.evaluation.evaluator INFO: Inference done 137/535. Dataloading: 0.0007 s/iter. Inference: 0.9151 s/iter. Eval: 0.9129 s/iter. Total: 1.8288 s/iter. ETA=0:12:07
[08/01 21:21:12] d2.evaluation.evaluator INFO: Inference done 140/535. Dataloading: 0.0007 s/iter. Inference: 0.9158 s/iter. Eval: 0.9127 s/iter. Total: 1.8293 s/iter. ETA=0:12:02
[08/01 21:21:18] d2.evaluation.evaluator INFO: Inference done 143/535. Dataloading: 0.0007 s/iter. Inference: 0.9148 s/iter. Eval: 0.9126 s/iter. Total: 1.8282 s/iter. ETA=0:11:56
[08/01 21:21:23] d2.evaluation.evaluator INFO: Inference done 146/535. Dataloading: 0.0007 s/iter. Inference: 0.9150 s/iter. Eval: 0.9126 s/iter. Total: 1.8284 s/iter. ETA=0:11:51
[08/01 21:21:29] d2.evaluation.evaluator INFO: Inference done 149/535. Dataloading: 0.0007 s/iter. Inference: 0.9140 s/iter. Eval: 0.9126 s/iter. Total: 1.8274 s/iter. ETA=0:11:45
[08/01 21:21:34] d2.evaluation.evaluator INFO: Inference done 152/535. Dataloading: 0.0007 s/iter. Inference: 0.9131 s/iter. Eval: 0.9125 s/iter. Total: 1.8264 s/iter. ETA=0:11:39
[08/01 21:21:40] d2.evaluation.evaluator INFO: Inference done 155/535. Dataloading: 0.0007 s/iter. Inference: 0.9132 s/iter. Eval: 0.9126 s/iter. Total: 1.8266 s/iter. ETA=0:11:34
[08/01 21:21:45] d2.evaluation.evaluator INFO: Inference done 158/535. Dataloading: 0.0007 s/iter. Inference: 0.9116 s/iter. Eval: 0.9123 s/iter. Total: 1.8247 s/iter. ETA=0:11:27
[08/01 21:21:50] d2.evaluation.evaluator INFO: Inference done 161/535. Dataloading: 0.0007 s/iter. Inference: 0.9113 s/iter. Eval: 0.9124 s/iter. Total: 1.8245 s/iter. ETA=0:11:22
[08/01 21:21:55] d2.evaluation.evaluator INFO: Inference done 164/535. Dataloading: 0.0007 s/iter. Inference: 0.9096 s/iter. Eval: 0.9124 s/iter. Total: 1.8227 s/iter. ETA=0:11:16
[08/01 21:22:01] d2.evaluation.evaluator INFO: Inference done 167/535. Dataloading: 0.0007 s/iter. Inference: 0.9092 s/iter. Eval: 0.9121 s/iter. Total: 1.8221 s/iter. ETA=0:11:10
[08/01 21:22:06] d2.evaluation.evaluator INFO: Inference done 170/535. Dataloading: 0.0007 s/iter. Inference: 0.9082 s/iter. Eval: 0.9119 s/iter. Total: 1.8208 s/iter. ETA=0:11:04
[08/01 21:22:11] d2.evaluation.evaluator INFO: Inference done 173/535. Dataloading: 0.0007 s/iter. Inference: 0.9080 s/iter. Eval: 0.9116 s/iter. Total: 1.8204 s/iter. ETA=0:10:58
[08/01 21:22:17] d2.evaluation.evaluator INFO: Inference done 176/535. Dataloading: 0.0007 s/iter. Inference: 0.9075 s/iter. Eval: 0.9114 s/iter. Total: 1.8197 s/iter. ETA=0:10:53
[08/01 21:22:22] d2.evaluation.evaluator INFO: Inference done 179/535. Dataloading: 0.0007 s/iter. Inference: 0.9066 s/iter. Eval: 0.9112 s/iter. Total: 1.8185 s/iter. ETA=0:10:47
[08/01 21:22:27] d2.evaluation.evaluator INFO: Inference done 182/535. Dataloading: 0.0007 s/iter. Inference: 0.9058 s/iter. Eval: 0.9110 s/iter. Total: 1.8176 s/iter. ETA=0:10:41
[08/01 21:22:33] d2.evaluation.evaluator INFO: Inference done 185/535. Dataloading: 0.0007 s/iter. Inference: 0.9055 s/iter. Eval: 0.9108 s/iter. Total: 1.8171 s/iter. ETA=0:10:35
[08/01 21:22:38] d2.evaluation.evaluator INFO: Inference done 188/535. Dataloading: 0.0007 s/iter. Inference: 0.9049 s/iter. Eval: 0.9110 s/iter. Total: 1.8166 s/iter. ETA=0:10:30
[08/01 21:22:43] d2.evaluation.evaluator INFO: Inference done 191/535. Dataloading: 0.0007 s/iter. Inference: 0.9049 s/iter. Eval: 0.9109 s/iter. Total: 1.8165 s/iter. ETA=0:10:24
[08/01 21:22:49] d2.evaluation.evaluator INFO: Inference done 194/535. Dataloading: 0.0007 s/iter. Inference: 0.9040 s/iter. Eval: 0.9107 s/iter. Total: 1.8155 s/iter. ETA=0:10:19
[08/01 21:22:54] d2.evaluation.evaluator INFO: Inference done 197/535. Dataloading: 0.0007 s/iter. Inference: 0.9035 s/iter. Eval: 0.9106 s/iter. Total: 1.8149 s/iter. ETA=0:10:13
[08/01 21:22:59] d2.evaluation.evaluator INFO: Inference done 200/535. Dataloading: 0.0007 s/iter. Inference: 0.9030 s/iter. Eval: 0.9106 s/iter. Total: 1.8144 s/iter. ETA=0:10:07
[08/01 21:23:05] d2.evaluation.evaluator INFO: Inference done 203/535. Dataloading: 0.0007 s/iter. Inference: 0.9022 s/iter. Eval: 0.9105 s/iter. Total: 1.8135 s/iter. ETA=0:10:02
[08/01 21:23:10] d2.evaluation.evaluator INFO: Inference done 206/535. Dataloading: 0.0007 s/iter. Inference: 0.9014 s/iter. Eval: 0.9104 s/iter. Total: 1.8126 s/iter. ETA=0:09:56
[08/01 21:23:15] d2.evaluation.evaluator INFO: Inference done 209/535. Dataloading: 0.0007 s/iter. Inference: 0.9007 s/iter. Eval: 0.9105 s/iter. Total: 1.8121 s/iter. ETA=0:09:50
[08/01 21:23:21] d2.evaluation.evaluator INFO: Inference done 212/535. Dataloading: 0.0007 s/iter. Inference: 0.9007 s/iter. Eval: 0.9104 s/iter. Total: 1.8119 s/iter. ETA=0:09:45
[08/01 21:23:26] d2.evaluation.evaluator INFO: Inference done 215/535. Dataloading: 0.0007 s/iter. Inference: 0.8991 s/iter. Eval: 0.9106 s/iter. Total: 1.8105 s/iter. ETA=0:09:39
[08/01 21:23:31] d2.evaluation.evaluator INFO: Inference done 218/535. Dataloading: 0.0007 s/iter. Inference: 0.8977 s/iter. Eval: 0.9108 s/iter. Total: 1.8093 s/iter. ETA=0:09:33
[08/01 21:23:36] d2.evaluation.evaluator INFO: Inference done 221/535. Dataloading: 0.0007 s/iter. Inference: 0.8966 s/iter. Eval: 0.9111 s/iter. Total: 1.8085 s/iter. ETA=0:09:27
[08/01 21:23:41] d2.evaluation.evaluator INFO: Inference done 224/535. Dataloading: 0.0007 s/iter. Inference: 0.8951 s/iter. Eval: 0.9114 s/iter. Total: 1.8073 s/iter. ETA=0:09:22
[08/01 21:23:47] d2.evaluation.evaluator INFO: Inference done 227/535. Dataloading: 0.0007 s/iter. Inference: 0.8944 s/iter. Eval: 0.9116 s/iter. Total: 1.8067 s/iter. ETA=0:09:16
[08/01 21:23:52] d2.evaluation.evaluator INFO: Inference done 230/535. Dataloading: 0.0007 s/iter. Inference: 0.8926 s/iter. Eval: 0.9117 s/iter. Total: 1.8052 s/iter. ETA=0:09:10
[08/01 21:23:57] d2.evaluation.evaluator INFO: Inference done 233/535. Dataloading: 0.0007 s/iter. Inference: 0.8920 s/iter. Eval: 0.9119 s/iter. Total: 1.8047 s/iter. ETA=0:09:05
[08/01 21:24:02] d2.evaluation.evaluator INFO: Inference done 236/535. Dataloading: 0.0007 s/iter. Inference: 0.8907 s/iter. Eval: 0.9121 s/iter. Total: 1.8036 s/iter. ETA=0:08:59
[08/01 21:24:07] d2.evaluation.evaluator INFO: Inference done 239/535. Dataloading: 0.0007 s/iter. Inference: 0.8898 s/iter. Eval: 0.9122 s/iter. Total: 1.8028 s/iter. ETA=0:08:53
[08/01 21:24:13] d2.evaluation.evaluator INFO: Inference done 242/535. Dataloading: 0.0007 s/iter. Inference: 0.8890 s/iter. Eval: 0.9124 s/iter. Total: 1.8022 s/iter. ETA=0:08:48
[08/01 21:24:18] d2.evaluation.evaluator INFO: Inference done 245/535. Dataloading: 0.0007 s/iter. Inference: 0.8875 s/iter. Eval: 0.9126 s/iter. Total: 1.8008 s/iter. ETA=0:08:42
[08/01 21:24:23] d2.evaluation.evaluator INFO: Inference done 248/535. Dataloading: 0.0007 s/iter. Inference: 0.8867 s/iter. Eval: 0.9127 s/iter. Total: 1.8002 s/iter. ETA=0:08:36
[08/01 21:24:28] d2.evaluation.evaluator INFO: Inference done 251/535. Dataloading: 0.0007 s/iter. Inference: 0.8854 s/iter. Eval: 0.9129 s/iter. Total: 1.7991 s/iter. ETA=0:08:30
[08/01 21:24:33] d2.evaluation.evaluator INFO: Inference done 254/535. Dataloading: 0.0007 s/iter. Inference: 0.8845 s/iter. Eval: 0.9131 s/iter. Total: 1.7984 s/iter. ETA=0:08:25
[08/01 21:24:39] d2.evaluation.evaluator INFO: Inference done 257/535. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.9132 s/iter. Total: 1.7976 s/iter. ETA=0:08:19
[08/01 21:24:44] d2.evaluation.evaluator INFO: Inference done 260/535. Dataloading: 0.0007 s/iter. Inference: 0.8827 s/iter. Eval: 0.9133 s/iter. Total: 1.7968 s/iter. ETA=0:08:14
[08/01 21:24:49] d2.evaluation.evaluator INFO: Inference done 263/535. Dataloading: 0.0007 s/iter. Inference: 0.8821 s/iter. Eval: 0.9134 s/iter. Total: 1.7963 s/iter. ETA=0:08:08
[08/01 21:24:54] d2.evaluation.evaluator INFO: Inference done 266/535. Dataloading: 0.0007 s/iter. Inference: 0.8808 s/iter. Eval: 0.9135 s/iter. Total: 1.7952 s/iter. ETA=0:08:02
[08/01 21:24:59] d2.evaluation.evaluator INFO: Inference done 269/535. Dataloading: 0.0007 s/iter. Inference: 0.8803 s/iter. Eval: 0.9136 s/iter. Total: 1.7947 s/iter. ETA=0:07:57
[08/01 21:25:04] d2.evaluation.evaluator INFO: Inference done 272/535. Dataloading: 0.0007 s/iter. Inference: 0.8790 s/iter. Eval: 0.9137 s/iter. Total: 1.7935 s/iter. ETA=0:07:51
[08/01 21:25:10] d2.evaluation.evaluator INFO: Inference done 275/535. Dataloading: 0.0007 s/iter. Inference: 0.8784 s/iter. Eval: 0.9140 s/iter. Total: 1.7931 s/iter. ETA=0:07:46
[08/01 21:25:15] d2.evaluation.evaluator INFO: Inference done 278/535. Dataloading: 0.0007 s/iter. Inference: 0.8779 s/iter. Eval: 0.9142 s/iter. Total: 1.7929 s/iter. ETA=0:07:40
[08/01 21:25:20] d2.evaluation.evaluator INFO: Inference done 281/535. Dataloading: 0.0007 s/iter. Inference: 0.8767 s/iter. Eval: 0.9144 s/iter. Total: 1.7919 s/iter. ETA=0:07:35
[08/01 21:25:25] d2.evaluation.evaluator INFO: Inference done 284/535. Dataloading: 0.0007 s/iter. Inference: 0.8762 s/iter. Eval: 0.9146 s/iter. Total: 1.7916 s/iter. ETA=0:07:29
[08/01 21:25:30] d2.evaluation.evaluator INFO: Inference done 287/535. Dataloading: 0.0007 s/iter. Inference: 0.8751 s/iter. Eval: 0.9147 s/iter. Total: 1.7906 s/iter. ETA=0:07:24
[08/01 21:25:36] d2.evaluation.evaluator INFO: Inference done 290/535. Dataloading: 0.0007 s/iter. Inference: 0.8747 s/iter. Eval: 0.9148 s/iter. Total: 1.7903 s/iter. ETA=0:07:18
[08/01 21:25:41] d2.evaluation.evaluator INFO: Inference done 293/535. Dataloading: 0.0007 s/iter. Inference: 0.8740 s/iter. Eval: 0.9150 s/iter. Total: 1.7898 s/iter. ETA=0:07:13
[08/01 21:25:46] d2.evaluation.evaluator INFO: Inference done 296/535. Dataloading: 0.0007 s/iter. Inference: 0.8734 s/iter. Eval: 0.9152 s/iter. Total: 1.7894 s/iter. ETA=0:07:07
[08/01 21:25:52] d2.evaluation.evaluator INFO: Inference done 299/535. Dataloading: 0.0007 s/iter. Inference: 0.8730 s/iter. Eval: 0.9153 s/iter. Total: 1.7891 s/iter. ETA=0:07:02
[08/01 21:25:57] d2.evaluation.evaluator INFO: Inference done 302/535. Dataloading: 0.0007 s/iter. Inference: 0.8722 s/iter. Eval: 0.9154 s/iter. Total: 1.7884 s/iter. ETA=0:06:56
[08/01 21:26:02] d2.evaluation.evaluator INFO: Inference done 305/535. Dataloading: 0.0007 s/iter. Inference: 0.8719 s/iter. Eval: 0.9156 s/iter. Total: 1.7882 s/iter. ETA=0:06:51
[08/01 21:26:07] d2.evaluation.evaluator INFO: Inference done 308/535. Dataloading: 0.0007 s/iter. Inference: 0.8708 s/iter. Eval: 0.9157 s/iter. Total: 1.7874 s/iter. ETA=0:06:45
[08/01 21:26:12] d2.evaluation.evaluator INFO: Inference done 311/535. Dataloading: 0.0007 s/iter. Inference: 0.8705 s/iter. Eval: 0.9159 s/iter. Total: 1.7871 s/iter. ETA=0:06:40
[08/01 21:26:18] d2.evaluation.evaluator INFO: Inference done 314/535. Dataloading: 0.0007 s/iter. Inference: 0.8697 s/iter. Eval: 0.9159 s/iter. Total: 1.7865 s/iter. ETA=0:06:34
[08/01 21:26:23] d2.evaluation.evaluator INFO: Inference done 317/535. Dataloading: 0.0007 s/iter. Inference: 0.8690 s/iter. Eval: 0.9161 s/iter. Total: 1.7858 s/iter. ETA=0:06:29
[08/01 21:26:28] d2.evaluation.evaluator INFO: Inference done 320/535. Dataloading: 0.0007 s/iter. Inference: 0.8682 s/iter. Eval: 0.9161 s/iter. Total: 1.7851 s/iter. ETA=0:06:23
[08/01 21:26:33] d2.evaluation.evaluator INFO: Inference done 323/535. Dataloading: 0.0007 s/iter. Inference: 0.8672 s/iter. Eval: 0.9162 s/iter. Total: 1.7841 s/iter. ETA=0:06:18
[08/01 21:26:38] d2.evaluation.evaluator INFO: Inference done 326/535. Dataloading: 0.0007 s/iter. Inference: 0.8669 s/iter. Eval: 0.9163 s/iter. Total: 1.7839 s/iter. ETA=0:06:12
[08/01 21:26:43] d2.evaluation.evaluator INFO: Inference done 329/535. Dataloading: 0.0007 s/iter. Inference: 0.8660 s/iter. Eval: 0.9164 s/iter. Total: 1.7832 s/iter. ETA=0:06:07
[08/01 21:26:49] d2.evaluation.evaluator INFO: Inference done 332/535. Dataloading: 0.0007 s/iter. Inference: 0.8659 s/iter. Eval: 0.9166 s/iter. Total: 1.7833 s/iter. ETA=0:06:02
[08/01 21:26:54] d2.evaluation.evaluator INFO: Inference done 335/535. Dataloading: 0.0007 s/iter. Inference: 0.8651 s/iter. Eval: 0.9167 s/iter. Total: 1.7826 s/iter. ETA=0:05:56
[08/01 21:26:59] d2.evaluation.evaluator INFO: Inference done 338/535. Dataloading: 0.0007 s/iter. Inference: 0.8647 s/iter. Eval: 0.9169 s/iter. Total: 1.7824 s/iter. ETA=0:05:51
[08/01 21:27:04] d2.evaluation.evaluator INFO: Inference done 341/535. Dataloading: 0.0007 s/iter. Inference: 0.8642 s/iter. Eval: 0.9169 s/iter. Total: 1.7819 s/iter. ETA=0:05:45
[08/01 21:27:09] d2.evaluation.evaluator INFO: Inference done 344/535. Dataloading: 0.0007 s/iter. Inference: 0.8634 s/iter. Eval: 0.9170 s/iter. Total: 1.7812 s/iter. ETA=0:05:40
[08/01 21:27:15] d2.evaluation.evaluator INFO: Inference done 347/535. Dataloading: 0.0007 s/iter. Inference: 0.8633 s/iter. Eval: 0.9171 s/iter. Total: 1.7812 s/iter. ETA=0:05:34
[08/01 21:27:20] d2.evaluation.evaluator INFO: Inference done 350/535. Dataloading: 0.0007 s/iter. Inference: 0.8625 s/iter. Eval: 0.9171 s/iter. Total: 1.7804 s/iter. ETA=0:05:29
[08/01 21:27:25] d2.evaluation.evaluator INFO: Inference done 353/535. Dataloading: 0.0007 s/iter. Inference: 0.8621 s/iter. Eval: 0.9171 s/iter. Total: 1.7800 s/iter. ETA=0:05:23
[08/01 21:27:30] d2.evaluation.evaluator INFO: Inference done 356/535. Dataloading: 0.0007 s/iter. Inference: 0.8613 s/iter. Eval: 0.9173 s/iter. Total: 1.7795 s/iter. ETA=0:05:18
[08/01 21:27:35] d2.evaluation.evaluator INFO: Inference done 359/535. Dataloading: 0.0007 s/iter. Inference: 0.8610 s/iter. Eval: 0.9174 s/iter. Total: 1.7792 s/iter. ETA=0:05:13
[08/01 21:27:41] d2.evaluation.evaluator INFO: Inference done 362/535. Dataloading: 0.0007 s/iter. Inference: 0.8607 s/iter. Eval: 0.9175 s/iter. Total: 1.7790 s/iter. ETA=0:05:07
[08/01 21:27:46] d2.evaluation.evaluator INFO: Inference done 365/535. Dataloading: 0.0007 s/iter. Inference: 0.8600 s/iter. Eval: 0.9176 s/iter. Total: 1.7785 s/iter. ETA=0:05:02
[08/01 21:27:51] d2.evaluation.evaluator INFO: Inference done 368/535. Dataloading: 0.0007 s/iter. Inference: 0.8598 s/iter. Eval: 0.9179 s/iter. Total: 1.7785 s/iter. ETA=0:04:57
[08/01 21:27:56] d2.evaluation.evaluator INFO: Inference done 371/535. Dataloading: 0.0007 s/iter. Inference: 0.8592 s/iter. Eval: 0.9180 s/iter. Total: 1.7780 s/iter. ETA=0:04:51
[08/01 21:28:02] d2.evaluation.evaluator INFO: Inference done 374/535. Dataloading: 0.0007 s/iter. Inference: 0.8588 s/iter. Eval: 0.9181 s/iter. Total: 1.7777 s/iter. ETA=0:04:46
[08/01 21:28:07] d2.evaluation.evaluator INFO: Inference done 377/535. Dataloading: 0.0007 s/iter. Inference: 0.8583 s/iter. Eval: 0.9182 s/iter. Total: 1.7773 s/iter. ETA=0:04:40
[08/01 21:28:12] d2.evaluation.evaluator INFO: Inference done 380/535. Dataloading: 0.0007 s/iter. Inference: 0.8579 s/iter. Eval: 0.9182 s/iter. Total: 1.7769 s/iter. ETA=0:04:35
[08/01 21:28:17] d2.evaluation.evaluator INFO: Inference done 383/535. Dataloading: 0.0007 s/iter. Inference: 0.8576 s/iter. Eval: 0.9183 s/iter. Total: 1.7766 s/iter. ETA=0:04:30
[08/01 21:28:22] d2.evaluation.evaluator INFO: Inference done 386/535. Dataloading: 0.0007 s/iter. Inference: 0.8569 s/iter. Eval: 0.9184 s/iter. Total: 1.7760 s/iter. ETA=0:04:24
[08/01 21:28:27] d2.evaluation.evaluator INFO: Inference done 389/535. Dataloading: 0.0007 s/iter. Inference: 0.8566 s/iter. Eval: 0.9184 s/iter. Total: 1.7758 s/iter. ETA=0:04:19
[08/01 21:28:33] d2.evaluation.evaluator INFO: Inference done 392/535. Dataloading: 0.0007 s/iter. Inference: 0.8561 s/iter. Eval: 0.9184 s/iter. Total: 1.7753 s/iter. ETA=0:04:13
[08/01 21:28:38] d2.evaluation.evaluator INFO: Inference done 395/535. Dataloading: 0.0007 s/iter. Inference: 0.8556 s/iter. Eval: 0.9185 s/iter. Total: 1.7748 s/iter. ETA=0:04:08
[08/01 21:28:43] d2.evaluation.evaluator INFO: Inference done 398/535. Dataloading: 0.0007 s/iter. Inference: 0.8555 s/iter. Eval: 0.9186 s/iter. Total: 1.7749 s/iter. ETA=0:04:03
[08/01 21:28:48] d2.evaluation.evaluator INFO: Inference done 401/535. Dataloading: 0.0007 s/iter. Inference: 0.8549 s/iter. Eval: 0.9186 s/iter. Total: 1.7743 s/iter. ETA=0:03:57
[08/01 21:28:53] d2.evaluation.evaluator INFO: Inference done 404/535. Dataloading: 0.0007 s/iter. Inference: 0.8548 s/iter. Eval: 0.9188 s/iter. Total: 1.7743 s/iter. ETA=0:03:52
[08/01 21:28:59] d2.evaluation.evaluator INFO: Inference done 407/535. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.9188 s/iter. Total: 1.7738 s/iter. ETA=0:03:47
[08/01 21:29:04] d2.evaluation.evaluator INFO: Inference done 410/535. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.9189 s/iter. Total: 1.7737 s/iter. ETA=0:03:41
[08/01 21:29:09] d2.evaluation.evaluator INFO: Inference done 413/535. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.9190 s/iter. Total: 1.7735 s/iter. ETA=0:03:36
[08/01 21:29:14] d2.evaluation.evaluator INFO: Inference done 416/535. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.9191 s/iter. Total: 1.7731 s/iter. ETA=0:03:30
[08/01 21:29:20] d2.evaluation.evaluator INFO: Inference done 419/535. Dataloading: 0.0007 s/iter. Inference: 0.8531 s/iter. Eval: 0.9191 s/iter. Total: 1.7730 s/iter. ETA=0:03:25
[08/01 21:29:25] d2.evaluation.evaluator INFO: Inference done 422/535. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.9192 s/iter. Total: 1.7724 s/iter. ETA=0:03:20
[08/01 21:29:30] d2.evaluation.evaluator INFO: Inference done 425/535. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.9194 s/iter. Total: 1.7724 s/iter. ETA=0:03:14
[08/01 21:29:35] d2.evaluation.evaluator INFO: Inference done 428/535. Dataloading: 0.0007 s/iter. Inference: 0.8517 s/iter. Eval: 0.9195 s/iter. Total: 1.7720 s/iter. ETA=0:03:09
[08/01 21:29:40] d2.evaluation.evaluator INFO: Inference done 431/535. Dataloading: 0.0007 s/iter. Inference: 0.8514 s/iter. Eval: 0.9196 s/iter. Total: 1.7718 s/iter. ETA=0:03:04
[08/01 21:29:46] d2.evaluation.evaluator INFO: Inference done 434/535. Dataloading: 0.0007 s/iter. Inference: 0.8513 s/iter. Eval: 0.9197 s/iter. Total: 1.7718 s/iter. ETA=0:02:58
[08/01 21:29:51] d2.evaluation.evaluator INFO: Inference done 437/535. Dataloading: 0.0007 s/iter. Inference: 0.8507 s/iter. Eval: 0.9197 s/iter. Total: 1.7713 s/iter. ETA=0:02:53
[08/01 21:29:56] d2.evaluation.evaluator INFO: Inference done 440/535. Dataloading: 0.0007 s/iter. Inference: 0.8507 s/iter. Eval: 0.9199 s/iter. Total: 1.7714 s/iter. ETA=0:02:48
[08/01 21:30:01] d2.evaluation.evaluator INFO: Inference done 443/535. Dataloading: 0.0007 s/iter. Inference: 0.8501 s/iter. Eval: 0.9199 s/iter. Total: 1.7708 s/iter. ETA=0:02:42
[08/01 21:30:06] d2.evaluation.evaluator INFO: Inference done 446/535. Dataloading: 0.0007 s/iter. Inference: 0.8500 s/iter. Eval: 0.9199 s/iter. Total: 1.7707 s/iter. ETA=0:02:37
[08/01 21:30:12] d2.evaluation.evaluator INFO: Inference done 449/535. Dataloading: 0.0007 s/iter. Inference: 0.8497 s/iter. Eval: 0.9200 s/iter. Total: 1.7705 s/iter. ETA=0:02:32
[08/01 21:30:17] d2.evaluation.evaluator INFO: Inference done 452/535. Dataloading: 0.0007 s/iter. Inference: 0.8493 s/iter. Eval: 0.9201 s/iter. Total: 1.7702 s/iter. ETA=0:02:26
[08/01 21:30:22] d2.evaluation.evaluator INFO: Inference done 455/535. Dataloading: 0.0007 s/iter. Inference: 0.8493 s/iter. Eval: 0.9203 s/iter. Total: 1.7703 s/iter. ETA=0:02:21
[08/01 21:30:27] d2.evaluation.evaluator INFO: Inference done 458/535. Dataloading: 0.0007 s/iter. Inference: 0.8488 s/iter. Eval: 0.9203 s/iter. Total: 1.7699 s/iter. ETA=0:02:16
[08/01 21:30:33] d2.evaluation.evaluator INFO: Inference done 461/535. Dataloading: 0.0007 s/iter. Inference: 0.8486 s/iter. Eval: 0.9203 s/iter. Total: 1.7697 s/iter. ETA=0:02:10
[08/01 21:30:38] d2.evaluation.evaluator INFO: Inference done 464/535. Dataloading: 0.0007 s/iter. Inference: 0.8482 s/iter. Eval: 0.9204 s/iter. Total: 1.7694 s/iter. ETA=0:02:05
[08/01 21:30:43] d2.evaluation.evaluator INFO: Inference done 467/535. Dataloading: 0.0007 s/iter. Inference: 0.8478 s/iter. Eval: 0.9204 s/iter. Total: 1.7691 s/iter. ETA=0:02:00
[08/01 21:30:48] d2.evaluation.evaluator INFO: Inference done 470/535. Dataloading: 0.0007 s/iter. Inference: 0.8476 s/iter. Eval: 0.9205 s/iter. Total: 1.7689 s/iter. ETA=0:01:54
[08/01 21:30:53] d2.evaluation.evaluator INFO: Inference done 473/535. Dataloading: 0.0007 s/iter. Inference: 0.8471 s/iter. Eval: 0.9205 s/iter. Total: 1.7684 s/iter. ETA=0:01:49
[08/01 21:30:58] d2.evaluation.evaluator INFO: Inference done 476/535. Dataloading: 0.0007 s/iter. Inference: 0.8471 s/iter. Eval: 0.9206 s/iter. Total: 1.7685 s/iter. ETA=0:01:44
[08/01 21:31:04] d2.evaluation.evaluator INFO: Inference done 479/535. Dataloading: 0.0007 s/iter. Inference: 0.8467 s/iter. Eval: 0.9207 s/iter. Total: 1.7682 s/iter. ETA=0:01:39
[08/01 21:31:09] d2.evaluation.evaluator INFO: Inference done 482/535. Dataloading: 0.0007 s/iter. Inference: 0.8465 s/iter. Eval: 0.9208 s/iter. Total: 1.7681 s/iter. ETA=0:01:33
[08/01 21:31:14] d2.evaluation.evaluator INFO: Inference done 485/535. Dataloading: 0.0007 s/iter. Inference: 0.8460 s/iter. Eval: 0.9208 s/iter. Total: 1.7676 s/iter. ETA=0:01:28
[08/01 21:31:19] d2.evaluation.evaluator INFO: Inference done 488/535. Dataloading: 0.0007 s/iter. Inference: 0.8456 s/iter. Eval: 0.9208 s/iter. Total: 1.7672 s/iter. ETA=0:01:23
[08/01 21:31:24] d2.evaluation.evaluator INFO: Inference done 491/535. Dataloading: 0.0007 s/iter. Inference: 0.8457 s/iter. Eval: 0.9208 s/iter. Total: 1.7673 s/iter. ETA=0:01:17
[08/01 21:31:30] d2.evaluation.evaluator INFO: Inference done 494/535. Dataloading: 0.0007 s/iter. Inference: 0.8454 s/iter. Eval: 0.9209 s/iter. Total: 1.7670 s/iter. ETA=0:01:12
[08/01 21:31:35] d2.evaluation.evaluator INFO: Inference done 497/535. Dataloading: 0.0007 s/iter. Inference: 0.8453 s/iter. Eval: 0.9209 s/iter. Total: 1.7670 s/iter. ETA=0:01:07
[08/01 21:31:40] d2.evaluation.evaluator INFO: Inference done 500/535. Dataloading: 0.0007 s/iter. Inference: 0.8451 s/iter. Eval: 0.9209 s/iter. Total: 1.7668 s/iter. ETA=0:01:01
[08/01 21:31:45] d2.evaluation.evaluator INFO: Inference done 503/535. Dataloading: 0.0007 s/iter. Inference: 0.8452 s/iter. Eval: 0.9210 s/iter. Total: 1.7670 s/iter. ETA=0:00:56
[08/01 21:31:51] d2.evaluation.evaluator INFO: Inference done 506/535. Dataloading: 0.0007 s/iter. Inference: 0.8451 s/iter. Eval: 0.9210 s/iter. Total: 1.7668 s/iter. ETA=0:00:51
[08/01 21:31:56] d2.evaluation.evaluator INFO: Inference done 509/535. Dataloading: 0.0007 s/iter. Inference: 0.8450 s/iter. Eval: 0.9210 s/iter. Total: 1.7668 s/iter. ETA=0:00:45
[08/01 21:32:01] d2.evaluation.evaluator INFO: Inference done 512/535. Dataloading: 0.0007 s/iter. Inference: 0.8450 s/iter. Eval: 0.9210 s/iter. Total: 1.7668 s/iter. ETA=0:00:40
[08/01 21:32:06] d2.evaluation.evaluator INFO: Inference done 515/535. Dataloading: 0.0007 s/iter. Inference: 0.8448 s/iter. Eval: 0.9210 s/iter. Total: 1.7666 s/iter. ETA=0:00:35
[08/01 21:32:12] d2.evaluation.evaluator INFO: Inference done 518/535. Dataloading: 0.0007 s/iter. Inference: 0.8452 s/iter. Eval: 0.9211 s/iter. Total: 1.7671 s/iter. ETA=0:00:30
[08/01 21:32:17] d2.evaluation.evaluator INFO: Inference done 521/535. Dataloading: 0.0007 s/iter. Inference: 0.8449 s/iter. Eval: 0.9214 s/iter. Total: 1.7671 s/iter. ETA=0:00:24
[08/01 21:32:23] d2.evaluation.evaluator INFO: Inference done 524/535. Dataloading: 0.0007 s/iter. Inference: 0.8449 s/iter. Eval: 0.9214 s/iter. Total: 1.7671 s/iter. ETA=0:00:19
[08/01 21:32:28] d2.evaluation.evaluator INFO: Inference done 527/535. Dataloading: 0.0007 s/iter. Inference: 0.8447 s/iter. Eval: 0.9214 s/iter. Total: 1.7669 s/iter. ETA=0:00:14
[08/01 21:32:33] d2.evaluation.evaluator INFO: Inference done 530/535. Dataloading: 0.0007 s/iter. Inference: 0.8448 s/iter. Eval: 0.9212 s/iter. Total: 1.7668 s/iter. ETA=0:00:08
[08/01 21:32:38] d2.evaluation.evaluator INFO: Inference done 533/535. Dataloading: 0.0007 s/iter. Inference: 0.8444 s/iter. Eval: 0.9210 s/iter. Total: 1.7663 s/iter. ETA=0:00:03
[08/01 21:32:42] d2.evaluation.evaluator INFO: Total inference time: 0:15:36.136435 (1.766295 s / iter per device, on 1 devices)
[08/01 21:32:42] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:07:27 (0.844390 s / iter per device, on 1 devices)
[08/01 21:32:42] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[08/01 21:32:42] d2.evaluation.coco_evaluation INFO: Saving results to ./R101_overlap/inference/coco_instances_results.json
[08/01 21:32:43] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[08/01 21:32:45] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 |  nan  | 0.000 |
[08/01 21:32:45] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 21:32:45] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| normal     | 0.000 | defect     | 0.000 |
[08/01 21:32:51] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75   |  APs   |  APm  |  APl   |
|:------:|:-------:|:-------:|:------:|:-----:|:------:|
| 99.002 | 100.000 | 100.000 | 94.490 |  nan  | 99.002 |
[08/01 21:32:51] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 21:32:51] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| normal     | 99.246 | defect     | 98.759 |
[08/01 21:32:51] d2.engine.defaults INFO: Evaluation results for front2class_2017_val_overlap_panoptic in csv format:
[08/01 21:32:51] d2.evaluation.testing INFO: copypaste: Task: bbox
[08/01 21:32:51] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 21:32:51] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,nan,0.0000
[08/01 21:32:51] d2.evaluation.testing INFO: copypaste: Task: segm
[08/01 21:32:51] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 21:32:51] d2.evaluation.testing INFO: copypaste: 99.0024,100.0000,100.0000,94.4896,nan,99.0024
[08/01 21:32:51] d2.utils.events INFO:  eta: 2:22:28  iter: 19999  total_loss: 3.147  loss_ce: 2.88e-05  loss_mask: 0.1157  loss_dice: 0.1793  loss_ce_0: 0.1342  loss_mask_0: 0.1095  loss_dice_0: 0.1763  loss_ce_1: 2.866e-05  loss_mask_1: 0.1167  loss_dice_1: 0.1847  loss_ce_2: 3.532e-05  loss_mask_2: 0.1126  loss_dice_2: 0.1767  loss_ce_3: 2.955e-05  loss_mask_3: 0.1115  loss_dice_3: 0.1788  loss_ce_4: 2.737e-05  loss_mask_4: 0.1115  loss_dice_4: 0.1807  loss_ce_5: 3.457e-05  loss_mask_5: 0.1135  loss_dice_5: 0.1849  loss_ce_6: 3.29e-05  loss_mask_6: 0.1167  loss_dice_6: 0.1884  loss_ce_7: 2.896e-05  loss_mask_7: 0.1123  loss_dice_7: 0.1779  loss_ce_8: 3.158e-05  loss_mask_8: 0.1195  loss_dice_8: 0.1844  time: 0.6858  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:32:51] fvcore.common.checkpoint INFO: Saving checkpoint to ./R101_overlap/model_best.pth
[08/01 21:32:51] d2.engine.hooks INFO: Saved best model as latest eval score for total_loss is2.85451, better than last best score 3.09764 @ iteration 9999.
[08/01 21:33:03] d2.utils.events INFO:  eta: 2:22:22  iter: 20019  total_loss: 2.996  loss_ce: 2.347e-05  loss_mask: 0.1108  loss_dice: 0.1722  loss_ce_0: 0.1241  loss_mask_0: 0.1134  loss_dice_0: 0.1734  loss_ce_1: 2.763e-05  loss_mask_1: 0.1153  loss_dice_1: 0.1758  loss_ce_2: 2.863e-05  loss_mask_2: 0.1138  loss_dice_2: 0.1632  loss_ce_3: 2.29e-05  loss_mask_3: 0.1149  loss_dice_3: 0.1731  loss_ce_4: 2.093e-05  loss_mask_4: 0.1146  loss_dice_4: 0.1671  loss_ce_5: 2.625e-05  loss_mask_5: 0.1125  loss_dice_5: 0.1656  loss_ce_6: 1.666e-05  loss_mask_6: 0.1194  loss_dice_6: 0.1731  loss_ce_7: 2.414e-05  loss_mask_7: 0.114  loss_dice_7: 0.1708  loss_ce_8: 2.683e-05  loss_mask_8: 0.1136  loss_dice_8: 0.1666  time: 0.6857  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:33:12] d2.utils.events INFO:  eta: 2:22:00  iter: 20039  total_loss: 3.224  loss_ce: 2.734e-05  loss_mask: 0.1194  loss_dice: 0.186  loss_ce_0: 0.1288  loss_mask_0: 0.1211  loss_dice_0: 0.1947  loss_ce_1: 2.605e-05  loss_mask_1: 0.1178  loss_dice_1: 0.1852  loss_ce_2: 2.93e-05  loss_mask_2: 0.1221  loss_dice_2: 0.199  loss_ce_3: 2.454e-05  loss_mask_3: 0.1175  loss_dice_3: 0.1864  loss_ce_4: 2.137e-05  loss_mask_4: 0.1187  loss_dice_4: 0.1849  loss_ce_5: 2.796e-05  loss_mask_5: 0.119  loss_dice_5: 0.1847  loss_ce_6: 1.97e-05  loss_mask_6: 0.1177  loss_dice_6: 0.1796  loss_ce_7: 2.403e-05  loss_mask_7: 0.1165  loss_dice_7: 0.186  loss_ce_8: 2.788e-05  loss_mask_8: 0.1206  loss_dice_8: 0.1849  time: 0.6854  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:33:20] d2.utils.events INFO:  eta: 2:21:28  iter: 20059  total_loss: 2.948  loss_ce: 2.562e-05  loss_mask: 0.1133  loss_dice: 0.1641  loss_ce_0: 0.1287  loss_mask_0: 0.111  loss_dice_0: 0.1742  loss_ce_1: 2.465e-05  loss_mask_1: 0.1137  loss_dice_1: 0.1669  loss_ce_2: 2.705e-05  loss_mask_2: 0.1122  loss_dice_2: 0.1729  loss_ce_3: 2.23e-05  loss_mask_3: 0.111  loss_dice_3: 0.1688  loss_ce_4: 2.195e-05  loss_mask_4: 0.111  loss_dice_4: 0.1674  loss_ce_5: 2.855e-05  loss_mask_5: 0.1126  loss_dice_5: 0.1693  loss_ce_6: 1.894e-05  loss_mask_6: 0.113  loss_dice_6: 0.1656  loss_ce_7: 2.511e-05  loss_mask_7: 0.1122  loss_dice_7: 0.1654  loss_ce_8: 2.754e-05  loss_mask_8: 0.1123  loss_dice_8: 0.168  time: 0.6851  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:33:28] d2.utils.events INFO:  eta: 2:21:01  iter: 20079  total_loss: 2.985  loss_ce: 2.857e-05  loss_mask: 0.117  loss_dice: 0.1733  loss_ce_0: 0.1227  loss_mask_0: 0.115  loss_dice_0: 0.169  loss_ce_1: 3.556e-05  loss_mask_1: 0.122  loss_dice_1: 0.174  loss_ce_2: 3.229e-05  loss_mask_2: 0.1214  loss_dice_2: 0.1748  loss_ce_3: 3.323e-05  loss_mask_3: 0.1162  loss_dice_3: 0.1702  loss_ce_4: 2.867e-05  loss_mask_4: 0.1144  loss_dice_4: 0.1746  loss_ce_5: 3.408e-05  loss_mask_5: 0.112  loss_dice_5: 0.1721  loss_ce_6: 3.05e-05  loss_mask_6: 0.1204  loss_dice_6: 0.1681  loss_ce_7: 3.158e-05  loss_mask_7: 0.1162  loss_dice_7: 0.1702  loss_ce_8: 3.107e-05  loss_mask_8: 0.1203  loss_dice_8: 0.1711  time: 0.6849  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:33:36] d2.utils.events INFO:  eta: 2:20:35  iter: 20099  total_loss: 3.23  loss_ce: 6.369e-05  loss_mask: 0.1141  loss_dice: 0.1882  loss_ce_0: 0.1318  loss_mask_0: 0.1138  loss_dice_0: 0.1809  loss_ce_1: 0.0001964  loss_mask_1: 0.1152  loss_dice_1: 0.1906  loss_ce_2: 5.118e-05  loss_mask_2: 0.1148  loss_dice_2: 0.1908  loss_ce_3: 8.932e-05  loss_mask_3: 0.1162  loss_dice_3: 0.1837  loss_ce_4: 7.196e-05  loss_mask_4: 0.1214  loss_dice_4: 0.1866  loss_ce_5: 5.779e-05  loss_mask_5: 0.1192  loss_dice_5: 0.197  loss_ce_6: 7.56e-05  loss_mask_6: 0.1187  loss_dice_6: 0.1933  loss_ce_7: 7.379e-05  loss_mask_7: 0.1123  loss_dice_7: 0.1894  loss_ce_8: 4.934e-05  loss_mask_8: 0.1182  loss_dice_8: 0.1885  time: 0.6846  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:33:44] d2.utils.events INFO:  eta: 2:20:15  iter: 20119  total_loss: 3.101  loss_ce: 7.328e-05  loss_mask: 0.1109  loss_dice: 0.1752  loss_ce_0: 0.1302  loss_mask_0: 0.115  loss_dice_0: 0.1689  loss_ce_1: 0.0001093  loss_mask_1: 0.1118  loss_dice_1: 0.1835  loss_ce_2: 5.196e-05  loss_mask_2: 0.1169  loss_dice_2: 0.1761  loss_ce_3: 5.304e-05  loss_mask_3: 0.1092  loss_dice_3: 0.1771  loss_ce_4: 8.347e-05  loss_mask_4: 0.1113  loss_dice_4: 0.1696  loss_ce_5: 5.375e-05  loss_mask_5: 0.1155  loss_dice_5: 0.1842  loss_ce_6: 6.358e-05  loss_mask_6: 0.1136  loss_dice_6: 0.1753  loss_ce_7: 8.578e-05  loss_mask_7: 0.1079  loss_dice_7: 0.175  loss_ce_8: 5.216e-05  loss_mask_8: 0.1109  loss_dice_8: 0.1769  time: 0.6843  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:33:52] d2.utils.events INFO:  eta: 2:19:49  iter: 20139  total_loss: 3.506  loss_ce: 0.001159  loss_mask: 0.1196  loss_dice: 0.2026  loss_ce_0: 0.1201  loss_mask_0: 0.1196  loss_dice_0: 0.1999  loss_ce_1: 0.0004702  loss_mask_1: 0.1235  loss_dice_1: 0.2045  loss_ce_2: 0.0004705  loss_mask_2: 0.1246  loss_dice_2: 0.1997  loss_ce_3: 0.0007105  loss_mask_3: 0.1205  loss_dice_3: 0.201  loss_ce_4: 0.0005733  loss_mask_4: 0.1218  loss_dice_4: 0.2035  loss_ce_5: 0.0002952  loss_mask_5: 0.1228  loss_dice_5: 0.1915  loss_ce_6: 0.0006067  loss_mask_6: 0.1208  loss_dice_6: 0.1959  loss_ce_7: 0.0009209  loss_mask_7: 0.1205  loss_dice_7: 0.1976  loss_ce_8: 0.0003831  loss_mask_8: 0.1205  loss_dice_8: 0.198  time: 0.6840  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:34:00] d2.utils.events INFO:  eta: 2:19:23  iter: 20159  total_loss: 3.041  loss_ce: 0.00149  loss_mask: 0.1183  loss_dice: 0.1745  loss_ce_0: 0.1196  loss_mask_0: 0.116  loss_dice_0: 0.1684  loss_ce_1: 0.0002986  loss_mask_1: 0.1129  loss_dice_1: 0.166  loss_ce_2: 0.000588  loss_mask_2: 0.1183  loss_dice_2: 0.1677  loss_ce_3: 0.0007359  loss_mask_3: 0.1146  loss_dice_3: 0.1668  loss_ce_4: 0.0005882  loss_mask_4: 0.1101  loss_dice_4: 0.1717  loss_ce_5: 0.0005743  loss_mask_5: 0.1114  loss_dice_5: 0.1711  loss_ce_6: 0.000537  loss_mask_6: 0.1151  loss_dice_6: 0.1684  loss_ce_7: 0.001027  loss_mask_7: 0.1104  loss_dice_7: 0.163  loss_ce_8: 0.0008196  loss_mask_8: 0.1167  loss_dice_8: 0.1666  time: 0.6837  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:34:08] d2.utils.events INFO:  eta: 2:18:52  iter: 20179  total_loss: 3.335  loss_ce: 0.00107  loss_mask: 0.1216  loss_dice: 0.1801  loss_ce_0: 0.1174  loss_mask_0: 0.121  loss_dice_0: 0.188  loss_ce_1: 0.0007642  loss_mask_1: 0.1207  loss_dice_1: 0.193  loss_ce_2: 0.001168  loss_mask_2: 0.1253  loss_dice_2: 0.1919  loss_ce_3: 0.001281  loss_mask_3: 0.1226  loss_dice_3: 0.1929  loss_ce_4: 0.0004667  loss_mask_4: 0.1205  loss_dice_4: 0.1884  loss_ce_5: 0.001181  loss_mask_5: 0.123  loss_dice_5: 0.1893  loss_ce_6: 0.001349  loss_mask_6: 0.1195  loss_dice_6: 0.1888  loss_ce_7: 0.0006289  loss_mask_7: 0.1207  loss_dice_7: 0.1935  loss_ce_8: 0.0009037  loss_mask_8: 0.1213  loss_dice_8: 0.1881  time: 0.6834  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:34:16] d2.utils.events INFO:  eta: 2:18:27  iter: 20199  total_loss: 3.005  loss_ce: 0.0002379  loss_mask: 0.1129  loss_dice: 0.1695  loss_ce_0: 0.1179  loss_mask_0: 0.1121  loss_dice_0: 0.1642  loss_ce_1: 0.0002254  loss_mask_1: 0.1112  loss_dice_1: 0.1695  loss_ce_2: 0.000472  loss_mask_2: 0.1152  loss_dice_2: 0.172  loss_ce_3: 0.0002439  loss_mask_3: 0.111  loss_dice_3: 0.1651  loss_ce_4: 0.0001626  loss_mask_4: 0.1068  loss_dice_4: 0.1692  loss_ce_5: 0.0004124  loss_mask_5: 0.1108  loss_dice_5: 0.163  loss_ce_6: 0.0003876  loss_mask_6: 0.1146  loss_dice_6: 0.1694  loss_ce_7: 0.0002639  loss_mask_7: 0.1131  loss_dice_7: 0.1639  loss_ce_8: 0.0003912  loss_mask_8: 0.1124  loss_dice_8: 0.1639  time: 0.6831  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:34:23] d2.utils.events INFO:  eta: 2:18:03  iter: 20219  total_loss: 2.929  loss_ce: 0.0002301  loss_mask: 0.1114  loss_dice: 0.1636  loss_ce_0: 0.1074  loss_mask_0: 0.1141  loss_dice_0: 0.1644  loss_ce_1: 0.0003148  loss_mask_1: 0.1089  loss_dice_1: 0.1598  loss_ce_2: 0.0005243  loss_mask_2: 0.1164  loss_dice_2: 0.1655  loss_ce_3: 0.0002092  loss_mask_3: 0.1147  loss_dice_3: 0.1625  loss_ce_4: 0.0001814  loss_mask_4: 0.1137  loss_dice_4: 0.1666  loss_ce_5: 0.0004262  loss_mask_5: 0.1131  loss_dice_5: 0.1623  loss_ce_6: 0.0003572  loss_mask_6: 0.112  loss_dice_6: 0.1619  loss_ce_7: 0.0003135  loss_mask_7: 0.1129  loss_dice_7: 0.1625  loss_ce_8: 0.000571  loss_mask_8: 0.1162  loss_dice_8: 0.164  time: 0.6828  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:34:31] d2.utils.events INFO:  eta: 2:17:23  iter: 20239  total_loss: 3.378  loss_ce: 0.002867  loss_mask: 0.1179  loss_dice: 0.1928  loss_ce_0: 0.1328  loss_mask_0: 0.1161  loss_dice_0: 0.1693  loss_ce_1: 0.0006114  loss_mask_1: 0.1178  loss_dice_1: 0.1812  loss_ce_2: 0.0005004  loss_mask_2: 0.1116  loss_dice_2: 0.176  loss_ce_3: 0.0005982  loss_mask_3: 0.1124  loss_dice_3: 0.1798  loss_ce_4: 0.000387  loss_mask_4: 0.109  loss_dice_4: 0.1839  loss_ce_5: 0.0003081  loss_mask_5: 0.1137  loss_dice_5: 0.1845  loss_ce_6: 0.001177  loss_mask_6: 0.1116  loss_dice_6: 0.1739  loss_ce_7: 0.0005482  loss_mask_7: 0.1125  loss_dice_7: 0.1839  loss_ce_8: 0.0008794  loss_mask_8: 0.1172  loss_dice_8: 0.1923  time: 0.6826  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:34:39] d2.utils.events INFO:  eta: 2:16:57  iter: 20259  total_loss: 3.754  loss_ce: 0.0006788  loss_mask: 0.1227  loss_dice: 0.2019  loss_ce_0: 0.1214  loss_mask_0: 0.1167  loss_dice_0: 0.2125  loss_ce_1: 0.0008356  loss_mask_1: 0.1234  loss_dice_1: 0.2162  loss_ce_2: 0.00259  loss_mask_2: 0.1212  loss_dice_2: 0.2093  loss_ce_3: 0.002235  loss_mask_3: 0.1206  loss_dice_3: 0.2134  loss_ce_4: 0.0002262  loss_mask_4: 0.1181  loss_dice_4: 0.212  loss_ce_5: 0.001046  loss_mask_5: 0.1228  loss_dice_5: 0.2151  loss_ce_6: 0.004885  loss_mask_6: 0.1212  loss_dice_6: 0.2103  loss_ce_7: 0.005051  loss_mask_7: 0.1255  loss_dice_7: 0.2023  loss_ce_8: 0.004828  loss_mask_8: 0.1266  loss_dice_8: 0.2176  time: 0.6823  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:34:47] d2.utils.events INFO:  eta: 2:16:33  iter: 20279  total_loss: 3.061  loss_ce: 0.0006381  loss_mask: 0.116  loss_dice: 0.1726  loss_ce_0: 0.1323  loss_mask_0: 0.1154  loss_dice_0: 0.1816  loss_ce_1: 0.001124  loss_mask_1: 0.115  loss_dice_1: 0.1735  loss_ce_2: 0.0005775  loss_mask_2: 0.1173  loss_dice_2: 0.1761  loss_ce_3: 0.0003282  loss_mask_3: 0.1196  loss_dice_3: 0.1767  loss_ce_4: 0.0003218  loss_mask_4: 0.1156  loss_dice_4: 0.1796  loss_ce_5: 0.0003401  loss_mask_5: 0.1156  loss_dice_5: 0.1728  loss_ce_6: 0.001879  loss_mask_6: 0.1149  loss_dice_6: 0.1778  loss_ce_7: 0.001342  loss_mask_7: 0.117  loss_dice_7: 0.1766  loss_ce_8: 0.002327  loss_mask_8: 0.1132  loss_dice_8: 0.1724  time: 0.6820  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:34:55] d2.utils.events INFO:  eta: 2:16:04  iter: 20299  total_loss: 3.129  loss_ce: 0.0004123  loss_mask: 0.1204  loss_dice: 0.1749  loss_ce_0: 0.1253  loss_mask_0: 0.1195  loss_dice_0: 0.1766  loss_ce_1: 0.0002712  loss_mask_1: 0.1206  loss_dice_1: 0.184  loss_ce_2: 0.0005263  loss_mask_2: 0.1166  loss_dice_2: 0.1846  loss_ce_3: 0.0001694  loss_mask_3: 0.1169  loss_dice_3: 0.1812  loss_ce_4: 0.0002499  loss_mask_4: 0.1168  loss_dice_4: 0.1795  loss_ce_5: 0.0003003  loss_mask_5: 0.1176  loss_dice_5: 0.1823  loss_ce_6: 0.0006429  loss_mask_6: 0.1224  loss_dice_6: 0.1811  loss_ce_7: 0.0005643  loss_mask_7: 0.1244  loss_dice_7: 0.1836  loss_ce_8: 0.0007566  loss_mask_8: 0.1189  loss_dice_8: 0.1861  time: 0.6817  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:35:03] d2.utils.events INFO:  eta: 2:15:33  iter: 20319  total_loss: 3.092  loss_ce: 0.0003062  loss_mask: 0.1191  loss_dice: 0.1825  loss_ce_0: 0.1249  loss_mask_0: 0.1156  loss_dice_0: 0.1746  loss_ce_1: 0.0003283  loss_mask_1: 0.1142  loss_dice_1: 0.1852  loss_ce_2: 0.0004168  loss_mask_2: 0.1149  loss_dice_2: 0.1828  loss_ce_3: 0.0001791  loss_mask_3: 0.1105  loss_dice_3: 0.1707  loss_ce_4: 0.0001144  loss_mask_4: 0.1162  loss_dice_4: 0.1791  loss_ce_5: 0.0002618  loss_mask_5: 0.1101  loss_dice_5: 0.1736  loss_ce_6: 0.0001989  loss_mask_6: 0.1166  loss_dice_6: 0.1779  loss_ce_7: 0.000506  loss_mask_7: 0.1106  loss_dice_7: 0.1791  loss_ce_8: 0.0005505  loss_mask_8: 0.1164  loss_dice_8: 0.1792  time: 0.6814  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:35:11] d2.utils.events INFO:  eta: 2:14:47  iter: 20339  total_loss: 3.159  loss_ce: 0.0002179  loss_mask: 0.1162  loss_dice: 0.1875  loss_ce_0: 0.1186  loss_mask_0: 0.1183  loss_dice_0: 0.1866  loss_ce_1: 0.0002895  loss_mask_1: 0.1136  loss_dice_1: 0.1787  loss_ce_2: 0.0003814  loss_mask_2: 0.1142  loss_dice_2: 0.1799  loss_ce_3: 0.0001877  loss_mask_3: 0.1138  loss_dice_3: 0.1808  loss_ce_4: 0.0001043  loss_mask_4: 0.1162  loss_dice_4: 0.1899  loss_ce_5: 0.0002495  loss_mask_5: 0.12  loss_dice_5: 0.1895  loss_ce_6: 0.0002996  loss_mask_6: 0.1161  loss_dice_6: 0.1841  loss_ce_7: 0.000465  loss_mask_7: 0.1186  loss_dice_7: 0.1805  loss_ce_8: 0.0004965  loss_mask_8: 0.1145  loss_dice_8: 0.1866  time: 0.6812  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:35:19] d2.utils.events INFO:  eta: 2:14:16  iter: 20359  total_loss: 3.032  loss_ce: 0.0002138  loss_mask: 0.1115  loss_dice: 0.1732  loss_ce_0: 0.1282  loss_mask_0: 0.1089  loss_dice_0: 0.1673  loss_ce_1: 0.0001471  loss_mask_1: 0.1085  loss_dice_1: 0.1647  loss_ce_2: 0.0002833  loss_mask_2: 0.1156  loss_dice_2: 0.1748  loss_ce_3: 0.0001156  loss_mask_3: 0.1125  loss_dice_3: 0.174  loss_ce_4: 7.837e-05  loss_mask_4: 0.1118  loss_dice_4: 0.1712  loss_ce_5: 0.0001985  loss_mask_5: 0.115  loss_dice_5: 0.172  loss_ce_6: 0.0001652  loss_mask_6: 0.115  loss_dice_6: 0.1807  loss_ce_7: 0.0004047  loss_mask_7: 0.1126  loss_dice_7: 0.1736  loss_ce_8: 0.0004496  loss_mask_8: 0.1145  loss_dice_8: 0.1779  time: 0.6809  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:35:27] d2.utils.events INFO:  eta: 2:13:23  iter: 20379  total_loss: 3.058  loss_ce: 0.0001421  loss_mask: 0.116  loss_dice: 0.1901  loss_ce_0: 0.1201  loss_mask_0: 0.1156  loss_dice_0: 0.1837  loss_ce_1: 9.203e-05  loss_mask_1: 0.1136  loss_dice_1: 0.1832  loss_ce_2: 0.00026  loss_mask_2: 0.115  loss_dice_2: 0.1898  loss_ce_3: 0.0001174  loss_mask_3: 0.1112  loss_dice_3: 0.1842  loss_ce_4: 7.154e-05  loss_mask_4: 0.1147  loss_dice_4: 0.1843  loss_ce_5: 0.0001832  loss_mask_5: 0.1121  loss_dice_5: 0.1838  loss_ce_6: 0.0001705  loss_mask_6: 0.1167  loss_dice_6: 0.1848  loss_ce_7: 0.0003729  loss_mask_7: 0.112  loss_dice_7: 0.1903  loss_ce_8: 0.0003927  loss_mask_8: 0.1123  loss_dice_8: 0.1871  time: 0.6806  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:35:35] d2.utils.events INFO:  eta: 2:12:36  iter: 20399  total_loss: 3.304  loss_ce: 0.0001456  loss_mask: 0.1135  loss_dice: 0.1974  loss_ce_0: 0.1224  loss_mask_0: 0.1206  loss_dice_0: 0.1959  loss_ce_1: 0.0001023  loss_mask_1: 0.1217  loss_dice_1: 0.2097  loss_ce_2: 0.0002038  loss_mask_2: 0.1156  loss_dice_2: 0.2019  loss_ce_3: 0.0001064  loss_mask_3: 0.1192  loss_dice_3: 0.1978  loss_ce_4: 6.849e-05  loss_mask_4: 0.1157  loss_dice_4: 0.201  loss_ce_5: 0.0001723  loss_mask_5: 0.1191  loss_dice_5: 0.2014  loss_ce_6: 0.0001597  loss_mask_6: 0.1145  loss_dice_6: 0.2004  loss_ce_7: 0.0003299  loss_mask_7: 0.1202  loss_dice_7: 0.207  loss_ce_8: 0.0003759  loss_mask_8: 0.1134  loss_dice_8: 0.191  time: 0.6803  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:35:43] d2.utils.events INFO:  eta: 2:11:43  iter: 20419  total_loss: 3.082  loss_ce: 0.0001373  loss_mask: 0.1191  loss_dice: 0.1788  loss_ce_0: 0.1215  loss_mask_0: 0.12  loss_dice_0: 0.1767  loss_ce_1: 9.697e-05  loss_mask_1: 0.1179  loss_dice_1: 0.18  loss_ce_2: 0.0002043  loss_mask_2: 0.1188  loss_dice_2: 0.1819  loss_ce_3: 0.0001098  loss_mask_3: 0.1171  loss_dice_3: 0.1682  loss_ce_4: 6.911e-05  loss_mask_4: 0.1189  loss_dice_4: 0.1764  loss_ce_5: 0.0001813  loss_mask_5: 0.1189  loss_dice_5: 0.1764  loss_ce_6: 0.0001545  loss_mask_6: 0.1188  loss_dice_6: 0.1787  loss_ce_7: 0.0003101  loss_mask_7: 0.1167  loss_dice_7: 0.1843  loss_ce_8: 0.0003356  loss_mask_8: 0.1161  loss_dice_8: 0.1738  time: 0.6800  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:35:51] d2.utils.events INFO:  eta: 2:11:04  iter: 20439  total_loss: 3.147  loss_ce: 0.000127  loss_mask: 0.1194  loss_dice: 0.1788  loss_ce_0: 0.113  loss_mask_0: 0.1257  loss_dice_0: 0.1874  loss_ce_1: 7.692e-05  loss_mask_1: 0.1183  loss_dice_1: 0.1759  loss_ce_2: 0.0002135  loss_mask_2: 0.1228  loss_dice_2: 0.1828  loss_ce_3: 9.701e-05  loss_mask_3: 0.1193  loss_dice_3: 0.1798  loss_ce_4: 5.929e-05  loss_mask_4: 0.1224  loss_dice_4: 0.1823  loss_ce_5: 0.0001495  loss_mask_5: 0.1226  loss_dice_5: 0.1763  loss_ce_6: 0.0001561  loss_mask_6: 0.1193  loss_dice_6: 0.1794  loss_ce_7: 0.0002771  loss_mask_7: 0.1208  loss_dice_7: 0.1809  loss_ce_8: 0.00031  loss_mask_8: 0.1208  loss_dice_8: 0.1794  time: 0.6798  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:35:59] d2.utils.events INFO:  eta: 2:09:54  iter: 20459  total_loss: 3.17  loss_ce: 0.0001328  loss_mask: 0.1155  loss_dice: 0.1873  loss_ce_0: 0.1169  loss_mask_0: 0.1154  loss_dice_0: 0.1913  loss_ce_1: 9.63e-05  loss_mask_1: 0.1119  loss_dice_1: 0.1847  loss_ce_2: 0.0001973  loss_mask_2: 0.1163  loss_dice_2: 0.1896  loss_ce_3: 0.0001042  loss_mask_3: 0.1146  loss_dice_3: 0.191  loss_ce_4: 5.704e-05  loss_mask_4: 0.112  loss_dice_4: 0.1859  loss_ce_5: 0.0001405  loss_mask_5: 0.1155  loss_dice_5: 0.1871  loss_ce_6: 0.000145  loss_mask_6: 0.1115  loss_dice_6: 0.1843  loss_ce_7: 0.0002507  loss_mask_7: 0.1109  loss_dice_7: 0.1903  loss_ce_8: 0.0002878  loss_mask_8: 0.1138  loss_dice_8: 0.1945  time: 0.6795  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:36:06] d2.utils.events INFO:  eta: 2:08:38  iter: 20479  total_loss: 3.413  loss_ce: 0.0001191  loss_mask: 0.1173  loss_dice: 0.2034  loss_ce_0: 0.1155  loss_mask_0: 0.1189  loss_dice_0: 0.2101  loss_ce_1: 8.083e-05  loss_mask_1: 0.1223  loss_dice_1: 0.2127  loss_ce_2: 0.0001378  loss_mask_2: 0.1154  loss_dice_2: 0.1997  loss_ce_3: 9.617e-05  loss_mask_3: 0.121  loss_dice_3: 0.2098  loss_ce_4: 5.654e-05  loss_mask_4: 0.1142  loss_dice_4: 0.2069  loss_ce_5: 0.0001613  loss_mask_5: 0.1187  loss_dice_5: 0.2021  loss_ce_6: 0.0001473  loss_mask_6: 0.1253  loss_dice_6: 0.2106  loss_ce_7: 0.0002225  loss_mask_7: 0.1218  loss_dice_7: 0.2075  loss_ce_8: 0.0002689  loss_mask_8: 0.1197  loss_dice_8: 0.2134  time: 0.6792  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:36:14] d2.utils.events INFO:  eta: 2:07:29  iter: 20499  total_loss: 3.123  loss_ce: 0.0001002  loss_mask: 0.1172  loss_dice: 0.1864  loss_ce_0: 0.1144  loss_mask_0: 0.1155  loss_dice_0: 0.1888  loss_ce_1: 6.488e-05  loss_mask_1: 0.1147  loss_dice_1: 0.1856  loss_ce_2: 0.0001784  loss_mask_2: 0.1165  loss_dice_2: 0.1899  loss_ce_3: 7.569e-05  loss_mask_3: 0.1198  loss_dice_3: 0.1964  loss_ce_4: 4.891e-05  loss_mask_4: 0.1217  loss_dice_4: 0.1893  loss_ce_5: 0.0001253  loss_mask_5: 0.1168  loss_dice_5: 0.1855  loss_ce_6: 0.0001052  loss_mask_6: 0.1148  loss_dice_6: 0.1878  loss_ce_7: 0.000199  loss_mask_7: 0.1174  loss_dice_7: 0.1885  loss_ce_8: 0.0002533  loss_mask_8: 0.1182  loss_dice_8: 0.1849  time: 0.6789  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:36:22] d2.utils.events INFO:  eta: 2:05:11  iter: 20519  total_loss: 3.155  loss_ce: 0.000111  loss_mask: 0.1197  loss_dice: 0.1849  loss_ce_0: 0.1256  loss_mask_0: 0.1218  loss_dice_0: 0.1852  loss_ce_1: 6.727e-05  loss_mask_1: 0.1159  loss_dice_1: 0.1844  loss_ce_2: 0.0001486  loss_mask_2: 0.1176  loss_dice_2: 0.179  loss_ce_3: 7.139e-05  loss_mask_3: 0.1178  loss_dice_3: 0.1837  loss_ce_4: 5.159e-05  loss_mask_4: 0.1198  loss_dice_4: 0.1796  loss_ce_5: 0.0001269  loss_mask_5: 0.118  loss_dice_5: 0.1844  loss_ce_6: 9.651e-05  loss_mask_6: 0.12  loss_dice_6: 0.184  loss_ce_7: 0.0001807  loss_mask_7: 0.1188  loss_dice_7: 0.1828  loss_ce_8: 0.0002201  loss_mask_8: 0.1194  loss_dice_8: 0.1894  time: 0.6786  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:36:30] d2.utils.events INFO:  eta: 1:45:27  iter: 20539  total_loss: 3.194  loss_ce: 0.0001045  loss_mask: 0.1135  loss_dice: 0.1835  loss_ce_0: 0.1136  loss_mask_0: 0.1101  loss_dice_0: 0.187  loss_ce_1: 6.836e-05  loss_mask_1: 0.1119  loss_dice_1: 0.1902  loss_ce_2: 0.0001414  loss_mask_2: 0.1135  loss_dice_2: 0.189  loss_ce_3: 6.629e-05  loss_mask_3: 0.1174  loss_dice_3: 0.1883  loss_ce_4: 4.733e-05  loss_mask_4: 0.1157  loss_dice_4: 0.1809  loss_ce_5: 0.0001213  loss_mask_5: 0.1201  loss_dice_5: 0.1855  loss_ce_6: 8.603e-05  loss_mask_6: 0.1157  loss_dice_6: 0.1818  loss_ce_7: 0.0001796  loss_mask_7: 0.1105  loss_dice_7: 0.1819  loss_ce_8: 0.0002267  loss_mask_8: 0.1151  loss_dice_8: 0.189  time: 0.6784  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:36:38] d2.utils.events INFO:  eta: 1:43:42  iter: 20559  total_loss: 2.943  loss_ce: 0.0001039  loss_mask: 0.1167  loss_dice: 0.1765  loss_ce_0: 0.1354  loss_mask_0: 0.1171  loss_dice_0: 0.1712  loss_ce_1: 6.982e-05  loss_mask_1: 0.1191  loss_dice_1: 0.1775  loss_ce_2: 0.0001169  loss_mask_2: 0.1174  loss_dice_2: 0.1715  loss_ce_3: 8.607e-05  loss_mask_3: 0.1137  loss_dice_3: 0.1756  loss_ce_4: 6.132e-05  loss_mask_4: 0.1135  loss_dice_4: 0.1789  loss_ce_5: 0.0001399  loss_mask_5: 0.117  loss_dice_5: 0.1751  loss_ce_6: 0.0001198  loss_mask_6: 0.113  loss_dice_6: 0.1689  loss_ce_7: 0.0001828  loss_mask_7: 0.115  loss_dice_7: 0.1707  loss_ce_8: 0.0002047  loss_mask_8: 0.1094  loss_dice_8: 0.1691  time: 0.6781  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:36:46] d2.utils.events INFO:  eta: 1:42:44  iter: 20579  total_loss: 3.142  loss_ce: 0.0001067  loss_mask: 0.1167  loss_dice: 0.1724  loss_ce_0: 0.1241  loss_mask_0: 0.1162  loss_dice_0: 0.1737  loss_ce_1: 7.7e-05  loss_mask_1: 0.1163  loss_dice_1: 0.1689  loss_ce_2: 0.0001519  loss_mask_2: 0.1192  loss_dice_2: 0.1695  loss_ce_3: 7.711e-05  loss_mask_3: 0.1132  loss_dice_3: 0.1702  loss_ce_4: 5.069e-05  loss_mask_4: 0.1172  loss_dice_4: 0.1709  loss_ce_5: 0.0001246  loss_mask_5: 0.1168  loss_dice_5: 0.1709  loss_ce_6: 0.0001299  loss_mask_6: 0.1225  loss_dice_6: 0.1739  loss_ce_7: 0.000181  loss_mask_7: 0.118  loss_dice_7: 0.1719  loss_ce_8: 0.0001972  loss_mask_8: 0.1138  loss_dice_8: 0.1715  time: 0.6778  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:36:54] d2.utils.events INFO:  eta: 1:41:49  iter: 20599  total_loss: 2.905  loss_ce: 0.0002539  loss_mask: 0.1124  loss_dice: 0.1656  loss_ce_0: 0.1328  loss_mask_0: 0.1149  loss_dice_0: 0.167  loss_ce_1: 0.0001136  loss_mask_1: 0.1122  loss_dice_1: 0.1666  loss_ce_2: 0.0002492  loss_mask_2: 0.1131  loss_dice_2: 0.169  loss_ce_3: 0.0002229  loss_mask_3: 0.1138  loss_dice_3: 0.1656  loss_ce_4: 6.25e-05  loss_mask_4: 0.1119  loss_dice_4: 0.1647  loss_ce_5: 0.0001914  loss_mask_5: 0.1122  loss_dice_5: 0.1631  loss_ce_6: 0.0002463  loss_mask_6: 0.1131  loss_dice_6: 0.1601  loss_ce_7: 0.0003132  loss_mask_7: 0.1093  loss_dice_7: 0.164  loss_ce_8: 0.0002093  loss_mask_8: 0.1138  loss_dice_8: 0.1685  time: 0.6775  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:37:02] d2.utils.events INFO:  eta: 1:40:58  iter: 20619  total_loss: 2.892  loss_ce: 0.0001337  loss_mask: 0.1129  loss_dice: 0.169  loss_ce_0: 0.1313  loss_mask_0: 0.1126  loss_dice_0: 0.1672  loss_ce_1: 8.46e-05  loss_mask_1: 0.1148  loss_dice_1: 0.1687  loss_ce_2: 0.0001535  loss_mask_2: 0.1103  loss_dice_2: 0.1679  loss_ce_3: 0.0001318  loss_mask_3: 0.1146  loss_dice_3: 0.1634  loss_ce_4: 5.215e-05  loss_mask_4: 0.1119  loss_dice_4: 0.1643  loss_ce_5: 0.0001451  loss_mask_5: 0.1128  loss_dice_5: 0.1683  loss_ce_6: 0.0001146  loss_mask_6: 0.1132  loss_dice_6: 0.1668  loss_ce_7: 0.0001467  loss_mask_7: 0.1168  loss_dice_7: 0.1691  loss_ce_8: 0.0001798  loss_mask_8: 0.1139  loss_dice_8: 0.1687  time: 0.6773  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:37:09] d2.utils.events INFO:  eta: 1:40:14  iter: 20639  total_loss: 2.998  loss_ce: 0.0001608  loss_mask: 0.1114  loss_dice: 0.1785  loss_ce_0: 0.1279  loss_mask_0: 0.1105  loss_dice_0: 0.1726  loss_ce_1: 9.624e-05  loss_mask_1: 0.1083  loss_dice_1: 0.17  loss_ce_2: 0.0001379  loss_mask_2: 0.1139  loss_dice_2: 0.1797  loss_ce_3: 0.0001146  loss_mask_3: 0.1102  loss_dice_3: 0.1745  loss_ce_4: 6.807e-05  loss_mask_4: 0.1109  loss_dice_4: 0.1731  loss_ce_5: 0.0001609  loss_mask_5: 0.1115  loss_dice_5: 0.1788  loss_ce_6: 0.0001354  loss_mask_6: 0.1118  loss_dice_6: 0.178  loss_ce_7: 0.000168  loss_mask_7: 0.1105  loss_dice_7: 0.1786  loss_ce_8: 0.0001857  loss_mask_8: 0.1105  loss_dice_8: 0.1716  time: 0.6770  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:37:17] d2.utils.events INFO:  eta: 1:39:43  iter: 20659  total_loss: 2.943  loss_ce: 0.0001071  loss_mask: 0.1116  loss_dice: 0.1637  loss_ce_0: 0.1267  loss_mask_0: 0.1121  loss_dice_0: 0.163  loss_ce_1: 7.155e-05  loss_mask_1: 0.1129  loss_dice_1: 0.158  loss_ce_2: 0.0001063  loss_mask_2: 0.1123  loss_dice_2: 0.1683  loss_ce_3: 7.62e-05  loss_mask_3: 0.1137  loss_dice_3: 0.1633  loss_ce_4: 3.839e-05  loss_mask_4: 0.1074  loss_dice_4: 0.1597  loss_ce_5: 0.0001061  loss_mask_5: 0.1087  loss_dice_5: 0.1621  loss_ce_6: 5.893e-05  loss_mask_6: 0.1111  loss_dice_6: 0.1671  loss_ce_7: 7.968e-05  loss_mask_7: 0.1131  loss_dice_7: 0.165  loss_ce_8: 0.0001344  loss_mask_8: 0.1122  loss_dice_8: 0.1625  time: 0.6767  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:37:25] d2.utils.events INFO:  eta: 1:38:46  iter: 20679  total_loss: 3.184  loss_ce: 0.0001447  loss_mask: 0.1161  loss_dice: 0.1894  loss_ce_0: 0.1236  loss_mask_0: 0.1117  loss_dice_0: 0.1782  loss_ce_1: 7.694e-05  loss_mask_1: 0.1178  loss_dice_1: 0.1895  loss_ce_2: 0.0001219  loss_mask_2: 0.11  loss_dice_2: 0.1959  loss_ce_3: 6.029e-05  loss_mask_3: 0.1127  loss_dice_3: 0.1839  loss_ce_4: 6.684e-05  loss_mask_4: 0.1114  loss_dice_4: 0.1852  loss_ce_5: 0.0001527  loss_mask_5: 0.115  loss_dice_5: 0.1843  loss_ce_6: 0.0001296  loss_mask_6: 0.1155  loss_dice_6: 0.1845  loss_ce_7: 0.0001583  loss_mask_7: 0.1125  loss_dice_7: 0.1951  loss_ce_8: 0.0001752  loss_mask_8: 0.1153  loss_dice_8: 0.186  time: 0.6764  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:37:33] d2.utils.events INFO:  eta: 1:38:10  iter: 20699  total_loss: 3.12  loss_ce: 8.344e-05  loss_mask: 0.1142  loss_dice: 0.1821  loss_ce_0: 0.1288  loss_mask_0: 0.1191  loss_dice_0: 0.1874  loss_ce_1: 4.387e-05  loss_mask_1: 0.1139  loss_dice_1: 0.1798  loss_ce_2: 8.538e-05  loss_mask_2: 0.1122  loss_dice_2: 0.1774  loss_ce_3: 4.721e-05  loss_mask_3: 0.1157  loss_dice_3: 0.1829  loss_ce_4: 3.32e-05  loss_mask_4: 0.1161  loss_dice_4: 0.1853  loss_ce_5: 9.525e-05  loss_mask_5: 0.1149  loss_dice_5: 0.185  loss_ce_6: 6.928e-05  loss_mask_6: 0.1168  loss_dice_6: 0.1835  loss_ce_7: 6.246e-05  loss_mask_7: 0.1152  loss_dice_7: 0.1839  loss_ce_8: 0.0001108  loss_mask_8: 0.1124  loss_dice_8: 0.1819  time: 0.6762  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:37:41] d2.utils.events INFO:  eta: 1:37:26  iter: 20719  total_loss: 3.446  loss_ce: 8.298e-05  loss_mask: 0.1214  loss_dice: 0.2069  loss_ce_0: 0.1258  loss_mask_0: 0.1185  loss_dice_0: 0.205  loss_ce_1: 5.709e-05  loss_mask_1: 0.1229  loss_dice_1: 0.2191  loss_ce_2: 0.0001209  loss_mask_2: 0.1173  loss_dice_2: 0.2071  loss_ce_3: 8.543e-05  loss_mask_3: 0.1184  loss_dice_3: 0.2063  loss_ce_4: 4.815e-05  loss_mask_4: 0.1151  loss_dice_4: 0.2086  loss_ce_5: 9.726e-05  loss_mask_5: 0.1189  loss_dice_5: 0.2042  loss_ce_6: 8.759e-05  loss_mask_6: 0.1202  loss_dice_6: 0.22  loss_ce_7: 0.0001337  loss_mask_7: 0.1205  loss_dice_7: 0.2103  loss_ce_8: 0.0001438  loss_mask_8: 0.1185  loss_dice_8: 0.2109  time: 0.6759  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:37:49] d2.utils.events INFO:  eta: 1:36:44  iter: 20739  total_loss: 2.923  loss_ce: 8.887e-05  loss_mask: 0.1147  loss_dice: 0.1675  loss_ce_0: 0.1239  loss_mask_0: 0.1102  loss_dice_0: 0.1656  loss_ce_1: 6.96e-05  loss_mask_1: 0.1147  loss_dice_1: 0.1648  loss_ce_2: 0.0001123  loss_mask_2: 0.1129  loss_dice_2: 0.1689  loss_ce_3: 5.801e-05  loss_mask_3: 0.1108  loss_dice_3: 0.1694  loss_ce_4: 5.316e-05  loss_mask_4: 0.1127  loss_dice_4: 0.1707  loss_ce_5: 0.0001395  loss_mask_5: 0.1123  loss_dice_5: 0.1697  loss_ce_6: 0.0001177  loss_mask_6: 0.1159  loss_dice_6: 0.171  loss_ce_7: 0.0001235  loss_mask_7: 0.1128  loss_dice_7: 0.1707  loss_ce_8: 0.0001515  loss_mask_8: 0.1067  loss_dice_8: 0.1673  time: 0.6756  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:37:57] d2.utils.events INFO:  eta: 1:36:09  iter: 20759  total_loss: 3.101  loss_ce: 7.301e-05  loss_mask: 0.1195  loss_dice: 0.1853  loss_ce_0: 0.1278  loss_mask_0: 0.1141  loss_dice_0: 0.1785  loss_ce_1: 5.537e-05  loss_mask_1: 0.1155  loss_dice_1: 0.1778  loss_ce_2: 7.928e-05  loss_mask_2: 0.1145  loss_dice_2: 0.1784  loss_ce_3: 4.618e-05  loss_mask_3: 0.1164  loss_dice_3: 0.1739  loss_ce_4: 3.395e-05  loss_mask_4: 0.116  loss_dice_4: 0.1777  loss_ce_5: 8.432e-05  loss_mask_5: 0.1155  loss_dice_5: 0.1781  loss_ce_6: 5.489e-05  loss_mask_6: 0.1198  loss_dice_6: 0.1784  loss_ce_7: 5.609e-05  loss_mask_7: 0.1212  loss_dice_7: 0.1839  loss_ce_8: 0.0001053  loss_mask_8: 0.1155  loss_dice_8: 0.1848  time: 0.6754  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:38:05] d2.utils.events INFO:  eta: 1:35:43  iter: 20779  total_loss: 3.024  loss_ce: 9.969e-05  loss_mask: 0.1187  loss_dice: 0.1636  loss_ce_0: 0.1299  loss_mask_0: 0.1171  loss_dice_0: 0.176  loss_ce_1: 7.356e-05  loss_mask_1: 0.1173  loss_dice_1: 0.1669  loss_ce_2: 0.000112  loss_mask_2: 0.1191  loss_dice_2: 0.1694  loss_ce_3: 6.216e-05  loss_mask_3: 0.1238  loss_dice_3: 0.1762  loss_ce_4: 5.206e-05  loss_mask_4: 0.1179  loss_dice_4: 0.174  loss_ce_5: 0.0001299  loss_mask_5: 0.1155  loss_dice_5: 0.173  loss_ce_6: 9.952e-05  loss_mask_6: 0.1153  loss_dice_6: 0.1604  loss_ce_7: 0.000119  loss_mask_7: 0.1195  loss_dice_7: 0.1753  loss_ce_8: 0.0001432  loss_mask_8: 0.12  loss_dice_8: 0.168  time: 0.6751  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:38:13] d2.utils.events INFO:  eta: 1:35:23  iter: 20799  total_loss: 2.89  loss_ce: 9.063e-05  loss_mask: 0.1148  loss_dice: 0.1666  loss_ce_0: 0.1271  loss_mask_0: 0.1155  loss_dice_0: 0.1706  loss_ce_1: 6.951e-05  loss_mask_1: 0.112  loss_dice_1: 0.1628  loss_ce_2: 0.0001011  loss_mask_2: 0.1109  loss_dice_2: 0.168  loss_ce_3: 5.197e-05  loss_mask_3: 0.1104  loss_dice_3: 0.1721  loss_ce_4: 4.873e-05  loss_mask_4: 0.1111  loss_dice_4: 0.1717  loss_ce_5: 0.0001266  loss_mask_5: 0.1135  loss_dice_5: 0.171  loss_ce_6: 9.486e-05  loss_mask_6: 0.1115  loss_dice_6: 0.1691  loss_ce_7: 0.000109  loss_mask_7: 0.1104  loss_dice_7: 0.1703  loss_ce_8: 0.0001391  loss_mask_8: 0.1115  loss_dice_8: 0.1667  time: 0.6748  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:38:21] d2.utils.events INFO:  eta: 1:35:04  iter: 20819  total_loss: 2.924  loss_ce: 6.407e-05  loss_mask: 0.1075  loss_dice: 0.1626  loss_ce_0: 0.1244  loss_mask_0: 0.1157  loss_dice_0: 0.169  loss_ce_1: 6.569e-05  loss_mask_1: 0.1185  loss_dice_1: 0.169  loss_ce_2: 9.802e-05  loss_mask_2: 0.1177  loss_dice_2: 0.1711  loss_ce_3: 4.969e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1714  loss_ce_4: 4.861e-05  loss_mask_4: 0.114  loss_dice_4: 0.1699  loss_ce_5: 0.0001011  loss_mask_5: 0.1129  loss_dice_5: 0.1662  loss_ce_6: 6.499e-05  loss_mask_6: 0.1155  loss_dice_6: 0.1669  loss_ce_7: 0.0001062  loss_mask_7: 0.1117  loss_dice_7: 0.1683  loss_ce_8: 0.0001292  loss_mask_8: 0.1131  loss_dice_8: 0.1689  time: 0.6745  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:38:29] d2.utils.events INFO:  eta: 1:34:39  iter: 20839  total_loss: 2.963  loss_ce: 6.184e-05  loss_mask: 0.1212  loss_dice: 0.1702  loss_ce_0: 0.1285  loss_mask_0: 0.1163  loss_dice_0: 0.1675  loss_ce_1: 5.214e-05  loss_mask_1: 0.1189  loss_dice_1: 0.1677  loss_ce_2: 7.204e-05  loss_mask_2: 0.1169  loss_dice_2: 0.1756  loss_ce_3: 3.127e-05  loss_mask_3: 0.118  loss_dice_3: 0.1659  loss_ce_4: 2.931e-05  loss_mask_4: 0.1193  loss_dice_4: 0.1687  loss_ce_5: 7.376e-05  loss_mask_5: 0.1173  loss_dice_5: 0.1673  loss_ce_6: 5.351e-05  loss_mask_6: 0.1149  loss_dice_6: 0.1654  loss_ce_7: 4.545e-05  loss_mask_7: 0.1176  loss_dice_7: 0.1713  loss_ce_8: 9.733e-05  loss_mask_8: 0.1156  loss_dice_8: 0.1684  time: 0.6743  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:38:37] d2.utils.events INFO:  eta: 1:34:13  iter: 20859  total_loss: 3.008  loss_ce: 8.949e-05  loss_mask: 0.114  loss_dice: 0.169  loss_ce_0: 0.1237  loss_mask_0: 0.1146  loss_dice_0: 0.167  loss_ce_1: 5.389e-05  loss_mask_1: 0.1158  loss_dice_1: 0.1751  loss_ce_2: 9.328e-05  loss_mask_2: 0.115  loss_dice_2: 0.1706  loss_ce_3: 4.841e-05  loss_mask_3: 0.1143  loss_dice_3: 0.1706  loss_ce_4: 3.86e-05  loss_mask_4: 0.1119  loss_dice_4: 0.1688  loss_ce_5: 8.169e-05  loss_mask_5: 0.1224  loss_dice_5: 0.1783  loss_ce_6: 5.06e-05  loss_mask_6: 0.1167  loss_dice_6: 0.1691  loss_ce_7: 9.947e-05  loss_mask_7: 0.1144  loss_dice_7: 0.1705  loss_ce_8: 0.00012  loss_mask_8: 0.1164  loss_dice_8: 0.1714  time: 0.6740  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:38:44] d2.utils.events INFO:  eta: 1:33:55  iter: 20879  total_loss: 2.915  loss_ce: 5.842e-05  loss_mask: 0.1122  loss_dice: 0.1668  loss_ce_0: 0.1226  loss_mask_0: 0.1138  loss_dice_0: 0.1679  loss_ce_1: 6.415e-05  loss_mask_1: 0.1102  loss_dice_1: 0.165  loss_ce_2: 9.397e-05  loss_mask_2: 0.1126  loss_dice_2: 0.1726  loss_ce_3: 4.726e-05  loss_mask_3: 0.113  loss_dice_3: 0.1761  loss_ce_4: 4.391e-05  loss_mask_4: 0.108  loss_dice_4: 0.1655  loss_ce_5: 0.0001122  loss_mask_5: 0.1092  loss_dice_5: 0.1636  loss_ce_6: 7.414e-05  loss_mask_6: 0.1137  loss_dice_6: 0.1666  loss_ce_7: 0.0001003  loss_mask_7: 0.1102  loss_dice_7: 0.1676  loss_ce_8: 0.0001221  loss_mask_8: 0.1122  loss_dice_8: 0.1755  time: 0.6737  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:38:51] d2.utils.events INFO:  eta: 1:33:36  iter: 20899  total_loss: 3.024  loss_ce: 5.422e-05  loss_mask: 0.1168  loss_dice: 0.1716  loss_ce_0: 0.123  loss_mask_0: 0.1169  loss_dice_0: 0.1735  loss_ce_1: 5.423e-05  loss_mask_1: 0.116  loss_dice_1: 0.1682  loss_ce_2: 7.136e-05  loss_mask_2: 0.1129  loss_dice_2: 0.1707  loss_ce_3: 2.752e-05  loss_mask_3: 0.1163  loss_dice_3: 0.1646  loss_ce_4: 2.812e-05  loss_mask_4: 0.1104  loss_dice_4: 0.1691  loss_ce_5: 6.522e-05  loss_mask_5: 0.1143  loss_dice_5: 0.1651  loss_ce_6: 4.711e-05  loss_mask_6: 0.1189  loss_dice_6: 0.177  loss_ce_7: 4.098e-05  loss_mask_7: 0.1131  loss_dice_7: 0.1738  loss_ce_8: 7.778e-05  loss_mask_8: 0.1155  loss_dice_8: 0.1708  time: 0.6734  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:38:59] d2.utils.events INFO:  eta: 1:33:13  iter: 20919  total_loss: 2.962  loss_ce: 6.042e-05  loss_mask: 0.1157  loss_dice: 0.1723  loss_ce_0: 0.1247  loss_mask_0: 0.1165  loss_dice_0: 0.1725  loss_ce_1: 5.141e-05  loss_mask_1: 0.1158  loss_dice_1: 0.1753  loss_ce_2: 9.167e-05  loss_mask_2: 0.1161  loss_dice_2: 0.1704  loss_ce_3: 4.994e-05  loss_mask_3: 0.1126  loss_dice_3: 0.175  loss_ce_4: 4.689e-05  loss_mask_4: 0.115  loss_dice_4: 0.1709  loss_ce_5: 0.0001082  loss_mask_5: 0.1133  loss_dice_5: 0.1649  loss_ce_6: 7.092e-05  loss_mask_6: 0.1115  loss_dice_6: 0.1737  loss_ce_7: 0.0001005  loss_mask_7: 0.1149  loss_dice_7: 0.1638  loss_ce_8: 0.0001178  loss_mask_8: 0.1153  loss_dice_8: 0.1692  time: 0.6731  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:39:07] d2.utils.events INFO:  eta: 1:32:58  iter: 20939  total_loss: 2.937  loss_ce: 7.137e-05  loss_mask: 0.1165  loss_dice: 0.1672  loss_ce_0: 0.1222  loss_mask_0: 0.1221  loss_dice_0: 0.1749  loss_ce_1: 5.51e-05  loss_mask_1: 0.1173  loss_dice_1: 0.1699  loss_ce_2: 9.439e-05  loss_mask_2: 0.1163  loss_dice_2: 0.1665  loss_ce_3: 5.386e-05  loss_mask_3: 0.1134  loss_dice_3: 0.1632  loss_ce_4: 4.129e-05  loss_mask_4: 0.1141  loss_dice_4: 0.1631  loss_ce_5: 9.807e-05  loss_mask_5: 0.1134  loss_dice_5: 0.1605  loss_ce_6: 7.705e-05  loss_mask_6: 0.1156  loss_dice_6: 0.1636  loss_ce_7: 9.381e-05  loss_mask_7: 0.1105  loss_dice_7: 0.1663  loss_ce_8: 0.0001137  loss_mask_8: 0.1108  loss_dice_8: 0.1608  time: 0.6729  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:39:15] d2.utils.events INFO:  eta: 1:32:33  iter: 20959  total_loss: 2.854  loss_ce: 7.526e-05  loss_mask: 0.1139  loss_dice: 0.163  loss_ce_0: 0.1323  loss_mask_0: 0.1121  loss_dice_0: 0.165  loss_ce_1: 5.022e-05  loss_mask_1: 0.1086  loss_dice_1: 0.1619  loss_ce_2: 8.484e-05  loss_mask_2: 0.1112  loss_dice_2: 0.1658  loss_ce_3: 4.405e-05  loss_mask_3: 0.1131  loss_dice_3: 0.1639  loss_ce_4: 5.565e-05  loss_mask_4: 0.1141  loss_dice_4: 0.1581  loss_ce_5: 0.0001242  loss_mask_5: 0.1114  loss_dice_5: 0.1624  loss_ce_6: 8.427e-05  loss_mask_6: 0.1128  loss_dice_6: 0.164  loss_ce_7: 9.46e-05  loss_mask_7: 0.1124  loss_dice_7: 0.1607  loss_ce_8: 0.0001268  loss_mask_8: 0.1135  loss_dice_8: 0.1662  time: 0.6726  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:39:23] d2.utils.events INFO:  eta: 1:32:16  iter: 20979  total_loss: 3.028  loss_ce: 7.398e-05  loss_mask: 0.1139  loss_dice: 0.1784  loss_ce_0: 0.1262  loss_mask_0: 0.112  loss_dice_0: 0.1765  loss_ce_1: 4.862e-05  loss_mask_1: 0.1154  loss_dice_1: 0.1723  loss_ce_2: 9.356e-05  loss_mask_2: 0.1142  loss_dice_2: 0.1747  loss_ce_3: 4.475e-05  loss_mask_3: 0.1146  loss_dice_3: 0.1759  loss_ce_4: 3.821e-05  loss_mask_4: 0.1117  loss_dice_4: 0.1715  loss_ce_5: 7.68e-05  loss_mask_5: 0.1147  loss_dice_5: 0.1714  loss_ce_6: 5.164e-05  loss_mask_6: 0.1121  loss_dice_6: 0.1713  loss_ce_7: 8.499e-05  loss_mask_7: 0.1133  loss_dice_7: 0.1749  loss_ce_8: 0.0001063  loss_mask_8: 0.1129  loss_dice_8: 0.1667  time: 0.6724  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:39:31] d2.utils.events INFO:  eta: 1:31:52  iter: 20999  total_loss: 3.039  loss_ce: 7.953e-05  loss_mask: 0.111  loss_dice: 0.1755  loss_ce_0: 0.1179  loss_mask_0: 0.1103  loss_dice_0: 0.1741  loss_ce_1: 5.698e-05  loss_mask_1: 0.1123  loss_dice_1: 0.1762  loss_ce_2: 0.0001101  loss_mask_2: 0.1111  loss_dice_2: 0.1734  loss_ce_3: 4.804e-05  loss_mask_3: 0.1117  loss_dice_3: 0.176  loss_ce_4: 4.653e-05  loss_mask_4: 0.1087  loss_dice_4: 0.1755  loss_ce_5: 8.99e-05  loss_mask_5: 0.113  loss_dice_5: 0.1758  loss_ce_6: 7.935e-05  loss_mask_6: 0.112  loss_dice_6: 0.1772  loss_ce_7: 0.0001457  loss_mask_7: 0.1099  loss_dice_7: 0.1689  loss_ce_8: 0.0001133  loss_mask_8: 0.1127  loss_dice_8: 0.1781  time: 0.6721  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:39:38] d2.utils.events INFO:  eta: 1:31:36  iter: 21019  total_loss: 2.938  loss_ce: 6.39e-05  loss_mask: 0.1165  loss_dice: 0.1738  loss_ce_0: 0.1301  loss_mask_0: 0.1132  loss_dice_0: 0.1692  loss_ce_1: 6.119e-05  loss_mask_1: 0.1148  loss_dice_1: 0.1759  loss_ce_2: 0.0001179  loss_mask_2: 0.1169  loss_dice_2: 0.1719  loss_ce_3: 4.926e-05  loss_mask_3: 0.1158  loss_dice_3: 0.1687  loss_ce_4: 3.93e-05  loss_mask_4: 0.1137  loss_dice_4: 0.1716  loss_ce_5: 8.29e-05  loss_mask_5: 0.1143  loss_dice_5: 0.17  loss_ce_6: 7.296e-05  loss_mask_6: 0.1157  loss_dice_6: 0.1768  loss_ce_7: 0.0002057  loss_mask_7: 0.1167  loss_dice_7: 0.174  loss_ce_8: 0.0001028  loss_mask_8: 0.1149  loss_dice_8: 0.1743  time: 0.6718  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:39:46] d2.utils.events INFO:  eta: 1:31:25  iter: 21039  total_loss: 3.029  loss_ce: 0.000163  loss_mask: 0.1119  loss_dice: 0.1686  loss_ce_0: 0.1314  loss_mask_0: 0.1095  loss_dice_0: 0.1644  loss_ce_1: 6.045e-05  loss_mask_1: 0.1099  loss_dice_1: 0.1586  loss_ce_2: 0.0001104  loss_mask_2: 0.1135  loss_dice_2: 0.1645  loss_ce_3: 0.0001192  loss_mask_3: 0.1107  loss_dice_3: 0.1607  loss_ce_4: 7.74e-05  loss_mask_4: 0.1135  loss_dice_4: 0.1617  loss_ce_5: 0.0001014  loss_mask_5: 0.1159  loss_dice_5: 0.1707  loss_ce_6: 0.0001071  loss_mask_6: 0.1126  loss_dice_6: 0.1651  loss_ce_7: 0.0002061  loss_mask_7: 0.1137  loss_dice_7: 0.1559  loss_ce_8: 0.0001963  loss_mask_8: 0.113  loss_dice_8: 0.1642  time: 0.6715  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:39:54] d2.utils.events INFO:  eta: 1:31:19  iter: 21059  total_loss: 3.141  loss_ce: 0.001077  loss_mask: 0.1208  loss_dice: 0.1819  loss_ce_0: 0.1183  loss_mask_0: 0.1207  loss_dice_0: 0.1782  loss_ce_1: 0.0001028  loss_mask_1: 0.1174  loss_dice_1: 0.1817  loss_ce_2: 0.0001352  loss_mask_2: 0.1138  loss_dice_2: 0.1783  loss_ce_3: 0.0008832  loss_mask_3: 0.1153  loss_dice_3: 0.1783  loss_ce_4: 0.0003224  loss_mask_4: 0.1176  loss_dice_4: 0.1796  loss_ce_5: 0.0001672  loss_mask_5: 0.118  loss_dice_5: 0.177  loss_ce_6: 0.0002206  loss_mask_6: 0.1153  loss_dice_6: 0.1801  loss_ce_7: 0.0003148  loss_mask_7: 0.1195  loss_dice_7: 0.1808  loss_ce_8: 0.001297  loss_mask_8: 0.1168  loss_dice_8: 0.1759  time: 0.6713  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:40:02] d2.utils.events INFO:  eta: 1:31:12  iter: 21079  total_loss: 2.892  loss_ce: 0.0004874  loss_mask: 0.1142  loss_dice: 0.1648  loss_ce_0: 0.1305  loss_mask_0: 0.1126  loss_dice_0: 0.1641  loss_ce_1: 9.852e-05  loss_mask_1: 0.1149  loss_dice_1: 0.1665  loss_ce_2: 0.0001092  loss_mask_2: 0.1141  loss_dice_2: 0.1681  loss_ce_3: 0.0003222  loss_mask_3: 0.1174  loss_dice_3: 0.1664  loss_ce_4: 0.000389  loss_mask_4: 0.114  loss_dice_4: 0.1651  loss_ce_5: 0.0001573  loss_mask_5: 0.1149  loss_dice_5: 0.1688  loss_ce_6: 0.0001719  loss_mask_6: 0.1136  loss_dice_6: 0.1642  loss_ce_7: 0.000238  loss_mask_7: 0.1149  loss_dice_7: 0.1649  loss_ce_8: 0.0004649  loss_mask_8: 0.1192  loss_dice_8: 0.1659  time: 0.6710  data_time: 0.0010  lr: 0.0001  max_mem: 8444M
[08/01 21:40:10] d2.utils.events INFO:  eta: 1:31:05  iter: 21099  total_loss: 2.977  loss_ce: 0.0002578  loss_mask: 0.1094  loss_dice: 0.1729  loss_ce_0: 0.1287  loss_mask_0: 0.1129  loss_dice_0: 0.1721  loss_ce_1: 0.0001066  loss_mask_1: 0.1124  loss_dice_1: 0.1697  loss_ce_2: 0.0001015  loss_mask_2: 0.1147  loss_dice_2: 0.1766  loss_ce_3: 0.0001839  loss_mask_3: 0.1131  loss_dice_3: 0.168  loss_ce_4: 0.0002385  loss_mask_4: 0.1131  loss_dice_4: 0.1748  loss_ce_5: 0.0002534  loss_mask_5: 0.1129  loss_dice_5: 0.1758  loss_ce_6: 0.0002759  loss_mask_6: 0.1103  loss_dice_6: 0.1722  loss_ce_7: 0.000232  loss_mask_7: 0.1111  loss_dice_7: 0.1756  loss_ce_8: 0.0003273  loss_mask_8: 0.1146  loss_dice_8: 0.1792  time: 0.6708  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:40:18] d2.utils.events INFO:  eta: 1:30:57  iter: 21119  total_loss: 3.036  loss_ce: 0.0001426  loss_mask: 0.1133  loss_dice: 0.1766  loss_ce_0: 0.1318  loss_mask_0: 0.1116  loss_dice_0: 0.1752  loss_ce_1: 7.739e-05  loss_mask_1: 0.1171  loss_dice_1: 0.1735  loss_ce_2: 6.377e-05  loss_mask_2: 0.114  loss_dice_2: 0.1741  loss_ce_3: 0.0001473  loss_mask_3: 0.112  loss_dice_3: 0.1619  loss_ce_4: 0.0001877  loss_mask_4: 0.1142  loss_dice_4: 0.1702  loss_ce_5: 9.642e-05  loss_mask_5: 0.1122  loss_dice_5: 0.1728  loss_ce_6: 7.435e-05  loss_mask_6: 0.1129  loss_dice_6: 0.1756  loss_ce_7: 4.369e-05  loss_mask_7: 0.1146  loss_dice_7: 0.1719  loss_ce_8: 0.0001213  loss_mask_8: 0.1142  loss_dice_8: 0.1716  time: 0.6705  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:40:24] d2.utils.events INFO:  eta: 1:30:46  iter: 21139  total_loss: 3.179  loss_ce: 0.0001742  loss_mask: 0.1174  loss_dice: 0.1881  loss_ce_0: 0.1256  loss_mask_0: 0.1163  loss_dice_0: 0.1964  loss_ce_1: 7.816e-05  loss_mask_1: 0.1178  loss_dice_1: 0.1859  loss_ce_2: 9.261e-05  loss_mask_2: 0.119  loss_dice_2: 0.1883  loss_ce_3: 0.0001301  loss_mask_3: 0.1137  loss_dice_3: 0.1835  loss_ce_4: 0.0001622  loss_mask_4: 0.119  loss_dice_4: 0.1848  loss_ce_5: 0.0001345  loss_mask_5: 0.1189  loss_dice_5: 0.1928  loss_ce_6: 0.0001184  loss_mask_6: 0.1207  loss_dice_6: 0.1899  loss_ce_7: 0.0001587  loss_mask_7: 0.113  loss_dice_7: 0.1786  loss_ce_8: 0.0002137  loss_mask_8: 0.1161  loss_dice_8: 0.1804  time: 0.6701  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:40:28] d2.utils.events INFO:  eta: 1:30:33  iter: 21159  total_loss: 3.178  loss_ce: 0.0001569  loss_mask: 0.1185  loss_dice: 0.1811  loss_ce_0: 0.1239  loss_mask_0: 0.1208  loss_dice_0: 0.1881  loss_ce_1: 9.512e-05  loss_mask_1: 0.1189  loss_dice_1: 0.1895  loss_ce_2: 0.0001011  loss_mask_2: 0.1184  loss_dice_2: 0.186  loss_ce_3: 9.729e-05  loss_mask_3: 0.1197  loss_dice_3: 0.1879  loss_ce_4: 0.0001386  loss_mask_4: 0.119  loss_dice_4: 0.1871  loss_ce_5: 0.0001972  loss_mask_5: 0.1183  loss_dice_5: 0.189  loss_ce_6: 0.0001531  loss_mask_6: 0.1152  loss_dice_6: 0.1895  loss_ce_7: 0.0002004  loss_mask_7: 0.1203  loss_dice_7: 0.194  loss_ce_8: 0.0002173  loss_mask_8: 0.1196  loss_dice_8: 0.1828  time: 0.6697  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:40:33] d2.utils.events INFO:  eta: 1:30:16  iter: 21179  total_loss: 3.03  loss_ce: 0.0001413  loss_mask: 0.1153  loss_dice: 0.174  loss_ce_0: 0.122  loss_mask_0: 0.1182  loss_dice_0: 0.177  loss_ce_1: 7.599e-05  loss_mask_1: 0.1178  loss_dice_1: 0.1739  loss_ce_2: 8.698e-05  loss_mask_2: 0.1176  loss_dice_2: 0.1715  loss_ce_3: 8.629e-05  loss_mask_3: 0.1164  loss_dice_3: 0.1742  loss_ce_4: 0.0001109  loss_mask_4: 0.1144  loss_dice_4: 0.1697  loss_ce_5: 0.0001784  loss_mask_5: 0.1183  loss_dice_5: 0.1735  loss_ce_6: 0.0001162  loss_mask_6: 0.1149  loss_dice_6: 0.1701  loss_ce_7: 0.0001577  loss_mask_7: 0.1145  loss_dice_7: 0.1715  loss_ce_8: 0.0001831  loss_mask_8: 0.118  loss_dice_8: 0.1737  time: 0.6693  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:40:37] d2.utils.events INFO:  eta: 1:29:59  iter: 21199  total_loss: 3.012  loss_ce: 0.0001264  loss_mask: 0.116  loss_dice: 0.167  loss_ce_0: 0.1214  loss_mask_0: 0.116  loss_dice_0: 0.1671  loss_ce_1: 7.3e-05  loss_mask_1: 0.1177  loss_dice_1: 0.1702  loss_ce_2: 9.793e-05  loss_mask_2: 0.1207  loss_dice_2: 0.1714  loss_ce_3: 9.023e-05  loss_mask_3: 0.1192  loss_dice_3: 0.1612  loss_ce_4: 0.0001076  loss_mask_4: 0.1199  loss_dice_4: 0.1689  loss_ce_5: 0.0001121  loss_mask_5: 0.1154  loss_dice_5: 0.1618  loss_ce_6: 8.42e-05  loss_mask_6: 0.1228  loss_dice_6: 0.1696  loss_ce_7: 0.0001118  loss_mask_7: 0.1171  loss_dice_7: 0.1655  loss_ce_8: 0.0001654  loss_mask_8: 0.1201  loss_dice_8: 0.1717  time: 0.6689  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:40:42] d2.utils.events INFO:  eta: 1:29:36  iter: 21219  total_loss: 2.816  loss_ce: 0.0001212  loss_mask: 0.1116  loss_dice: 0.154  loss_ce_0: 0.1235  loss_mask_0: 0.1099  loss_dice_0: 0.1537  loss_ce_1: 7.824e-05  loss_mask_1: 0.1103  loss_dice_1: 0.1541  loss_ce_2: 9.088e-05  loss_mask_2: 0.1103  loss_dice_2: 0.1568  loss_ce_3: 7.308e-05  loss_mask_3: 0.1117  loss_dice_3: 0.1584  loss_ce_4: 0.0001003  loss_mask_4: 0.1099  loss_dice_4: 0.1545  loss_ce_5: 0.0001667  loss_mask_5: 0.1098  loss_dice_5: 0.1553  loss_ce_6: 0.0001192  loss_mask_6: 0.1077  loss_dice_6: 0.1578  loss_ce_7: 0.0001741  loss_mask_7: 0.1097  loss_dice_7: 0.1552  loss_ce_8: 0.0001755  loss_mask_8: 0.1113  loss_dice_8: 0.1588  time: 0.6685  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:40:46] d2.utils.events INFO:  eta: 1:29:17  iter: 21239  total_loss: 2.869  loss_ce: 0.0001092  loss_mask: 0.1124  loss_dice: 0.1655  loss_ce_0: 0.1243  loss_mask_0: 0.1151  loss_dice_0: 0.1738  loss_ce_1: 5.895e-05  loss_mask_1: 0.1118  loss_dice_1: 0.1693  loss_ce_2: 8.249e-05  loss_mask_2: 0.1121  loss_dice_2: 0.1685  loss_ce_3: 7.84e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1658  loss_ce_4: 8.528e-05  loss_mask_4: 0.1124  loss_dice_4: 0.1683  loss_ce_5: 0.0001071  loss_mask_5: 0.1125  loss_dice_5: 0.1602  loss_ce_6: 7.516e-05  loss_mask_6: 0.1088  loss_dice_6: 0.1644  loss_ce_7: 0.0001011  loss_mask_7: 0.1118  loss_dice_7: 0.166  loss_ce_8: 0.0001557  loss_mask_8: 0.1095  loss_dice_8: 0.1658  time: 0.6680  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:40:51] d2.utils.events INFO:  eta: 1:28:59  iter: 21259  total_loss: 3.067  loss_ce: 0.0001651  loss_mask: 0.1165  loss_dice: 0.1737  loss_ce_0: 0.1211  loss_mask_0: 0.1156  loss_dice_0: 0.1749  loss_ce_1: 6.871e-05  loss_mask_1: 0.1147  loss_dice_1: 0.1753  loss_ce_2: 9.156e-05  loss_mask_2: 0.1163  loss_dice_2: 0.1761  loss_ce_3: 7.705e-05  loss_mask_3: 0.1177  loss_dice_3: 0.1765  loss_ce_4: 9.606e-05  loss_mask_4: 0.1217  loss_dice_4: 0.1751  loss_ce_5: 0.0001197  loss_mask_5: 0.1093  loss_dice_5: 0.1748  loss_ce_6: 4.685e-05  loss_mask_6: 0.1144  loss_dice_6: 0.1732  loss_ce_7: 5.29e-05  loss_mask_7: 0.1164  loss_dice_7: 0.1728  loss_ce_8: 9.68e-05  loss_mask_8: 0.1171  loss_dice_8: 0.1716  time: 0.6676  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:40:55] d2.utils.events INFO:  eta: 1:28:40  iter: 21279  total_loss: 3.019  loss_ce: 0.0001304  loss_mask: 0.1122  loss_dice: 0.1723  loss_ce_0: 0.1213  loss_mask_0: 0.1166  loss_dice_0: 0.175  loss_ce_1: 0.0001172  loss_mask_1: 0.113  loss_dice_1: 0.1754  loss_ce_2: 0.0001471  loss_mask_2: 0.1149  loss_dice_2: 0.1712  loss_ce_3: 9.733e-05  loss_mask_3: 0.1138  loss_dice_3: 0.1683  loss_ce_4: 0.0001355  loss_mask_4: 0.115  loss_dice_4: 0.1714  loss_ce_5: 0.000232  loss_mask_5: 0.1151  loss_dice_5: 0.1681  loss_ce_6: 0.0001203  loss_mask_6: 0.1135  loss_dice_6: 0.1708  loss_ce_7: 0.0001836  loss_mask_7: 0.1148  loss_dice_7: 0.1697  loss_ce_8: 0.0002094  loss_mask_8: 0.1145  loss_dice_8: 0.1751  time: 0.6672  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:41:00] d2.utils.events INFO:  eta: 1:28:21  iter: 21299  total_loss: 3.003  loss_ce: 0.0002144  loss_mask: 0.1115  loss_dice: 0.1735  loss_ce_0: 0.1131  loss_mask_0: 0.1114  loss_dice_0: 0.184  loss_ce_1: 0.0001122  loss_mask_1: 0.1104  loss_dice_1: 0.1726  loss_ce_2: 0.0001331  loss_mask_2: 0.1122  loss_dice_2: 0.1702  loss_ce_3: 0.0001251  loss_mask_3: 0.1112  loss_dice_3: 0.1696  loss_ce_4: 0.0001243  loss_mask_4: 0.1094  loss_dice_4: 0.1679  loss_ce_5: 0.0001901  loss_mask_5: 0.1089  loss_dice_5: 0.1685  loss_ce_6: 0.0001079  loss_mask_6: 0.1121  loss_dice_6: 0.1742  loss_ce_7: 0.0001367  loss_mask_7: 0.113  loss_dice_7: 0.1649  loss_ce_8: 0.0002056  loss_mask_8: 0.1138  loss_dice_8: 0.1724  time: 0.6668  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:41:04] d2.utils.events INFO:  eta: 1:28:00  iter: 21319  total_loss: 2.868  loss_ce: 0.000107  loss_mask: 0.1111  loss_dice: 0.1575  loss_ce_0: 0.1272  loss_mask_0: 0.1085  loss_dice_0: 0.162  loss_ce_1: 0.0001222  loss_mask_1: 0.1126  loss_dice_1: 0.1621  loss_ce_2: 0.000154  loss_mask_2: 0.1109  loss_dice_2: 0.1594  loss_ce_3: 9.714e-05  loss_mask_3: 0.1112  loss_dice_3: 0.1628  loss_ce_4: 0.000139  loss_mask_4: 0.1124  loss_dice_4: 0.1654  loss_ce_5: 0.0002452  loss_mask_5: 0.1102  loss_dice_5: 0.1578  loss_ce_6: 0.0001067  loss_mask_6: 0.111  loss_dice_6: 0.1638  loss_ce_7: 0.0002157  loss_mask_7: 0.1147  loss_dice_7: 0.1702  loss_ce_8: 0.0002045  loss_mask_8: 0.1106  loss_dice_8: 0.1628  time: 0.6664  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:41:09] d2.utils.events INFO:  eta: 1:27:37  iter: 21339  total_loss: 3.026  loss_ce: 9.879e-05  loss_mask: 0.1153  loss_dice: 0.1682  loss_ce_0: 0.1195  loss_mask_0: 0.1124  loss_dice_0: 0.1734  loss_ce_1: 0.000106  loss_mask_1: 0.1165  loss_dice_1: 0.1757  loss_ce_2: 0.0001343  loss_mask_2: 0.116  loss_dice_2: 0.1708  loss_ce_3: 8.246e-05  loss_mask_3: 0.1108  loss_dice_3: 0.1677  loss_ce_4: 0.0001115  loss_mask_4: 0.1148  loss_dice_4: 0.1758  loss_ce_5: 0.0001922  loss_mask_5: 0.1111  loss_dice_5: 0.1742  loss_ce_6: 8.633e-05  loss_mask_6: 0.1093  loss_dice_6: 0.1709  loss_ce_7: 0.0001112  loss_mask_7: 0.1118  loss_dice_7: 0.1679  loss_ce_8: 0.0001863  loss_mask_8: 0.1139  loss_dice_8: 0.1763  time: 0.6660  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:41:13] d2.utils.events INFO:  eta: 1:27:10  iter: 21359  total_loss: 2.972  loss_ce: 9.977e-05  loss_mask: 0.1158  loss_dice: 0.1763  loss_ce_0: 0.1184  loss_mask_0: 0.1153  loss_dice_0: 0.172  loss_ce_1: 7.055e-05  loss_mask_1: 0.1132  loss_dice_1: 0.178  loss_ce_2: 9.529e-05  loss_mask_2: 0.1134  loss_dice_2: 0.1711  loss_ce_3: 7.805e-05  loss_mask_3: 0.1139  loss_dice_3: 0.1731  loss_ce_4: 9.225e-05  loss_mask_4: 0.1127  loss_dice_4: 0.1745  loss_ce_5: 0.0001232  loss_mask_5: 0.1154  loss_dice_5: 0.1713  loss_ce_6: 5.576e-05  loss_mask_6: 0.1117  loss_dice_6: 0.1712  loss_ce_7: 6.624e-05  loss_mask_7: 0.1128  loss_dice_7: 0.1684  loss_ce_8: 0.0001316  loss_mask_8: 0.1144  loss_dice_8: 0.1738  time: 0.6655  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:41:18] d2.utils.events INFO:  eta: 1:26:40  iter: 21379  total_loss: 3.037  loss_ce: 8.469e-05  loss_mask: 0.1161  loss_dice: 0.181  loss_ce_0: 0.1174  loss_mask_0: 0.1115  loss_dice_0: 0.169  loss_ce_1: 6.739e-05  loss_mask_1: 0.1127  loss_dice_1: 0.1745  loss_ce_2: 7.142e-05  loss_mask_2: 0.1156  loss_dice_2: 0.175  loss_ce_3: 9.242e-05  loss_mask_3: 0.1105  loss_dice_3: 0.1741  loss_ce_4: 8.427e-05  loss_mask_4: 0.1155  loss_dice_4: 0.1778  loss_ce_5: 0.0001288  loss_mask_5: 0.1151  loss_dice_5: 0.1774  loss_ce_6: 8.945e-05  loss_mask_6: 0.1166  loss_dice_6: 0.1754  loss_ce_7: 0.0001282  loss_mask_7: 0.1116  loss_dice_7: 0.1707  loss_ce_8: 0.0001388  loss_mask_8: 0.1151  loss_dice_8: 0.1716  time: 0.6651  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:41:22] d2.utils.events INFO:  eta: 1:26:13  iter: 21399  total_loss: 2.789  loss_ce: 8.069e-05  loss_mask: 0.1125  loss_dice: 0.1648  loss_ce_0: 0.119  loss_mask_0: 0.1149  loss_dice_0: 0.1615  loss_ce_1: 6.212e-05  loss_mask_1: 0.1101  loss_dice_1: 0.1583  loss_ce_2: 6.473e-05  loss_mask_2: 0.1137  loss_dice_2: 0.1586  loss_ce_3: 8.663e-05  loss_mask_3: 0.1097  loss_dice_3: 0.1584  loss_ce_4: 8.716e-05  loss_mask_4: 0.1126  loss_dice_4: 0.1613  loss_ce_5: 0.0001265  loss_mask_5: 0.1072  loss_dice_5: 0.1571  loss_ce_6: 7.044e-05  loss_mask_6: 0.1085  loss_dice_6: 0.1615  loss_ce_7: 0.0001012  loss_mask_7: 0.1119  loss_dice_7: 0.1602  loss_ce_8: 0.0001252  loss_mask_8: 0.1145  loss_dice_8: 0.1592  time: 0.6647  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:41:27] d2.utils.events INFO:  eta: 1:25:43  iter: 21419  total_loss: 2.972  loss_ce: 8.787e-05  loss_mask: 0.1205  loss_dice: 0.1659  loss_ce_0: 0.1211  loss_mask_0: 0.1187  loss_dice_0: 0.1628  loss_ce_1: 8.03e-05  loss_mask_1: 0.1222  loss_dice_1: 0.166  loss_ce_2: 8.498e-05  loss_mask_2: 0.1237  loss_dice_2: 0.1658  loss_ce_3: 6.098e-05  loss_mask_3: 0.1211  loss_dice_3: 0.1639  loss_ce_4: 0.0001005  loss_mask_4: 0.1207  loss_dice_4: 0.1659  loss_ce_5: 0.0001404  loss_mask_5: 0.1211  loss_dice_5: 0.1641  loss_ce_6: 7.737e-05  loss_mask_6: 0.1221  loss_dice_6: 0.1658  loss_ce_7: 0.0001336  loss_mask_7: 0.1166  loss_dice_7: 0.1651  loss_ce_8: 0.000143  loss_mask_8: 0.1211  loss_dice_8: 0.1661  time: 0.6643  data_time: 0.0010  lr: 0.0001  max_mem: 8444M
[08/01 21:41:31] d2.utils.events INFO:  eta: 1:25:14  iter: 21439  total_loss: 2.975  loss_ce: 7.867e-05  loss_mask: 0.1133  loss_dice: 0.1719  loss_ce_0: 0.1287  loss_mask_0: 0.11  loss_dice_0: 0.1695  loss_ce_1: 7.886e-05  loss_mask_1: 0.11  loss_dice_1: 0.1702  loss_ce_2: 0.000102  loss_mask_2: 0.1111  loss_dice_2: 0.1748  loss_ce_3: 6.527e-05  loss_mask_3: 0.1153  loss_dice_3: 0.1728  loss_ce_4: 8.792e-05  loss_mask_4: 0.1116  loss_dice_4: 0.17  loss_ce_5: 0.0001313  loss_mask_5: 0.1114  loss_dice_5: 0.1696  loss_ce_6: 6.714e-05  loss_mask_6: 0.107  loss_dice_6: 0.1627  loss_ce_7: 9.338e-05  loss_mask_7: 0.1136  loss_dice_7: 0.1719  loss_ce_8: 0.0001454  loss_mask_8: 0.111  loss_dice_8: 0.1659  time: 0.6639  data_time: 0.0010  lr: 0.0001  max_mem: 8444M
[08/01 21:41:36] d2.utils.events INFO:  eta: 1:24:47  iter: 21459  total_loss: 2.802  loss_ce: 6.832e-05  loss_mask: 0.113  loss_dice: 0.1613  loss_ce_0: 0.1228  loss_mask_0: 0.1093  loss_dice_0: 0.1604  loss_ce_1: 3.924e-05  loss_mask_1: 0.1104  loss_dice_1: 0.1587  loss_ce_2: 5.218e-05  loss_mask_2: 0.1127  loss_dice_2: 0.1648  loss_ce_3: 5.995e-05  loss_mask_3: 0.1107  loss_dice_3: 0.16  loss_ce_4: 5.919e-05  loss_mask_4: 0.1104  loss_dice_4: 0.1561  loss_ce_5: 4.673e-05  loss_mask_5: 0.1107  loss_dice_5: 0.1542  loss_ce_6: 4.818e-05  loss_mask_6: 0.1092  loss_dice_6: 0.1599  loss_ce_7: 3.185e-05  loss_mask_7: 0.1095  loss_dice_7: 0.1574  loss_ce_8: 5.398e-05  loss_mask_8: 0.1127  loss_dice_8: 0.1641  time: 0.6635  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:41:40] d2.utils.events INFO:  eta: 1:24:24  iter: 21479  total_loss: 2.963  loss_ce: 7.193e-05  loss_mask: 0.1151  loss_dice: 0.1688  loss_ce_0: 0.1276  loss_mask_0: 0.1137  loss_dice_0: 0.1649  loss_ce_1: 6.885e-05  loss_mask_1: 0.1149  loss_dice_1: 0.1693  loss_ce_2: 9.285e-05  loss_mask_2: 0.1138  loss_dice_2: 0.1678  loss_ce_3: 5.257e-05  loss_mask_3: 0.1141  loss_dice_3: 0.167  loss_ce_4: 7.458e-05  loss_mask_4: 0.1151  loss_dice_4: 0.171  loss_ce_5: 0.0001222  loss_mask_5: 0.1142  loss_dice_5: 0.1734  loss_ce_6: 6.281e-05  loss_mask_6: 0.1154  loss_dice_6: 0.1719  loss_ce_7: 8.209e-05  loss_mask_7: 0.1163  loss_dice_7: 0.1661  loss_ce_8: 0.0001316  loss_mask_8: 0.1151  loss_dice_8: 0.1677  time: 0.6631  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:41:45] d2.utils.events INFO:  eta: 1:23:47  iter: 21499  total_loss: 2.947  loss_ce: 6.838e-05  loss_mask: 0.1129  loss_dice: 0.168  loss_ce_0: 0.1236  loss_mask_0: 0.1152  loss_dice_0: 0.1671  loss_ce_1: 5.327e-05  loss_mask_1: 0.1121  loss_dice_1: 0.1675  loss_ce_2: 5.658e-05  loss_mask_2: 0.1115  loss_dice_2: 0.166  loss_ce_3: 7.122e-05  loss_mask_3: 0.1152  loss_dice_3: 0.1636  loss_ce_4: 6.291e-05  loss_mask_4: 0.1131  loss_dice_4: 0.1683  loss_ce_5: 0.0001143  loss_mask_5: 0.1126  loss_dice_5: 0.1685  loss_ce_6: 5.322e-05  loss_mask_6: 0.118  loss_dice_6: 0.1715  loss_ce_7: 8.478e-05  loss_mask_7: 0.1117  loss_dice_7: 0.1725  loss_ce_8: 0.0001094  loss_mask_8: 0.1097  loss_dice_8: 0.1708  time: 0.6627  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:41:49] d2.utils.events INFO:  eta: 1:23:17  iter: 21519  total_loss: 3.061  loss_ce: 6.068e-05  loss_mask: 0.1184  loss_dice: 0.1786  loss_ce_0: 0.1181  loss_mask_0: 0.1202  loss_dice_0: 0.1832  loss_ce_1: 4.9e-05  loss_mask_1: 0.1177  loss_dice_1: 0.1806  loss_ce_2: 5.141e-05  loss_mask_2: 0.1257  loss_dice_2: 0.1815  loss_ce_3: 4.558e-05  loss_mask_3: 0.1196  loss_dice_3: 0.1753  loss_ce_4: 5.512e-05  loss_mask_4: 0.1209  loss_dice_4: 0.1798  loss_ce_5: 7.488e-05  loss_mask_5: 0.1191  loss_dice_5: 0.1826  loss_ce_6: 5.058e-05  loss_mask_6: 0.1164  loss_dice_6: 0.1807  loss_ce_7: 4.951e-05  loss_mask_7: 0.1209  loss_dice_7: 0.1847  loss_ce_8: 8.577e-05  loss_mask_8: 0.1257  loss_dice_8: 0.1811  time: 0.6623  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:41:54] d2.utils.events INFO:  eta: 1:22:38  iter: 21539  total_loss: 3.116  loss_ce: 4.997e-05  loss_mask: 0.1138  loss_dice: 0.1845  loss_ce_0: 0.1229  loss_mask_0: 0.1108  loss_dice_0: 0.1821  loss_ce_1: 3.097e-05  loss_mask_1: 0.1154  loss_dice_1: 0.1871  loss_ce_2: 4.205e-05  loss_mask_2: 0.1104  loss_dice_2: 0.1797  loss_ce_3: 4.497e-05  loss_mask_3: 0.1153  loss_dice_3: 0.1833  loss_ce_4: 5.077e-05  loss_mask_4: 0.1135  loss_dice_4: 0.179  loss_ce_5: 4.318e-05  loss_mask_5: 0.1133  loss_dice_5: 0.1787  loss_ce_6: 3.589e-05  loss_mask_6: 0.1133  loss_dice_6: 0.182  loss_ce_7: 2.581e-05  loss_mask_7: 0.1136  loss_dice_7: 0.1865  loss_ce_8: 5.194e-05  loss_mask_8: 0.112  loss_dice_8: 0.1888  time: 0.6619  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:41:58] d2.utils.events INFO:  eta: 1:21:41  iter: 21559  total_loss: 3.102  loss_ce: 0.0003185  loss_mask: 0.1209  loss_dice: 0.1814  loss_ce_0: 0.1093  loss_mask_0: 0.1186  loss_dice_0: 0.1795  loss_ce_1: 0.0001992  loss_mask_1: 0.1159  loss_dice_1: 0.1736  loss_ce_2: 0.0002207  loss_mask_2: 0.1193  loss_dice_2: 0.179  loss_ce_3: 0.0002009  loss_mask_3: 0.124  loss_dice_3: 0.1786  loss_ce_4: 0.0002483  loss_mask_4: 0.1235  loss_dice_4: 0.1753  loss_ce_5: 0.0002353  loss_mask_5: 0.1193  loss_dice_5: 0.174  loss_ce_6: 0.0005497  loss_mask_6: 0.1217  loss_dice_6: 0.18  loss_ce_7: 0.000212  loss_mask_7: 0.1194  loss_dice_7: 0.1757  loss_ce_8: 0.0002164  loss_mask_8: 0.1206  loss_dice_8: 0.1796  time: 0.6615  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:42:03] d2.utils.events INFO:  eta: 1:20:47  iter: 21579  total_loss: 3.136  loss_ce: 0.0001459  loss_mask: 0.1164  loss_dice: 0.1861  loss_ce_0: 0.111  loss_mask_0: 0.1106  loss_dice_0: 0.1832  loss_ce_1: 0.0001028  loss_mask_1: 0.1119  loss_dice_1: 0.1902  loss_ce_2: 0.0001582  loss_mask_2: 0.1119  loss_dice_2: 0.1872  loss_ce_3: 0.000306  loss_mask_3: 0.1126  loss_dice_3: 0.1839  loss_ce_4: 0.0001309  loss_mask_4: 0.1148  loss_dice_4: 0.1867  loss_ce_5: 0.000237  loss_mask_5: 0.1099  loss_dice_5: 0.1814  loss_ce_6: 0.0001937  loss_mask_6: 0.1089  loss_dice_6: 0.1817  loss_ce_7: 0.0002054  loss_mask_7: 0.1136  loss_dice_7: 0.1859  loss_ce_8: 0.0001875  loss_mask_8: 0.113  loss_dice_8: 0.1849  time: 0.6610  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:42:07] d2.utils.events INFO:  eta: 1:19:14  iter: 21599  total_loss: 2.996  loss_ce: 0.0001496  loss_mask: 0.1096  loss_dice: 0.1703  loss_ce_0: 0.1229  loss_mask_0: 0.1125  loss_dice_0: 0.1645  loss_ce_1: 9.732e-05  loss_mask_1: 0.1144  loss_dice_1: 0.1723  loss_ce_2: 0.0001374  loss_mask_2: 0.1082  loss_dice_2: 0.1648  loss_ce_3: 0.0002595  loss_mask_3: 0.1104  loss_dice_3: 0.1694  loss_ce_4: 0.0001403  loss_mask_4: 0.1109  loss_dice_4: 0.1644  loss_ce_5: 0.0001735  loss_mask_5: 0.1135  loss_dice_5: 0.17  loss_ce_6: 0.0001344  loss_mask_6: 0.1131  loss_dice_6: 0.1719  loss_ce_7: 0.000169  loss_mask_7: 0.1107  loss_dice_7: 0.167  loss_ce_8: 0.0001634  loss_mask_8: 0.1159  loss_dice_8: 0.1704  time: 0.6606  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:42:12] d2.utils.events INFO:  eta: 0:56:08  iter: 21619  total_loss: 3.028  loss_ce: 0.000161  loss_mask: 0.1131  loss_dice: 0.1758  loss_ce_0: 0.133  loss_mask_0: 0.1163  loss_dice_0: 0.1738  loss_ce_1: 0.0001744  loss_mask_1: 0.1137  loss_dice_1: 0.1743  loss_ce_2: 0.0001852  loss_mask_2: 0.1137  loss_dice_2: 0.1789  loss_ce_3: 9.09e-05  loss_mask_3: 0.1162  loss_dice_3: 0.1723  loss_ce_4: 0.0002158  loss_mask_4: 0.1141  loss_dice_4: 0.1697  loss_ce_5: 0.0001989  loss_mask_5: 0.1142  loss_dice_5: 0.1728  loss_ce_6: 0.0001207  loss_mask_6: 0.1154  loss_dice_6: 0.1754  loss_ce_7: 0.0003174  loss_mask_7: 0.1142  loss_dice_7: 0.1767  loss_ce_8: 0.0002753  loss_mask_8: 0.1128  loss_dice_8: 0.1781  time: 0.6602  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:42:16] d2.utils.events INFO:  eta: 0:54:20  iter: 21639  total_loss: 2.959  loss_ce: 7.625e-05  loss_mask: 0.1171  loss_dice: 0.1695  loss_ce_0: 0.1231  loss_mask_0: 0.1144  loss_dice_0: 0.1782  loss_ce_1: 6.014e-05  loss_mask_1: 0.1192  loss_dice_1: 0.1681  loss_ce_2: 8.202e-05  loss_mask_2: 0.1147  loss_dice_2: 0.1683  loss_ce_3: 4.837e-05  loss_mask_3: 0.118  loss_dice_3: 0.1662  loss_ce_4: 7.679e-05  loss_mask_4: 0.114  loss_dice_4: 0.1653  loss_ce_5: 7.147e-05  loss_mask_5: 0.1138  loss_dice_5: 0.1701  loss_ce_6: 2.821e-05  loss_mask_6: 0.1145  loss_dice_6: 0.1653  loss_ce_7: 6.526e-05  loss_mask_7: 0.1162  loss_dice_7: 0.1676  loss_ce_8: 9.86e-05  loss_mask_8: 0.1129  loss_dice_8: 0.17  time: 0.6598  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:42:21] d2.utils.events INFO:  eta: 0:53:57  iter: 21659  total_loss: 3.012  loss_ce: 0.0001269  loss_mask: 0.1166  loss_dice: 0.17  loss_ce_0: 0.1202  loss_mask_0: 0.1153  loss_dice_0: 0.1659  loss_ce_1: 0.0001081  loss_mask_1: 0.1109  loss_dice_1: 0.1675  loss_ce_2: 0.0001377  loss_mask_2: 0.1179  loss_dice_2: 0.1726  loss_ce_3: 0.0001332  loss_mask_3: 0.1157  loss_dice_3: 0.1719  loss_ce_4: 0.0001386  loss_mask_4: 0.1148  loss_dice_4: 0.1673  loss_ce_5: 0.0001451  loss_mask_5: 0.1145  loss_dice_5: 0.1733  loss_ce_6: 0.0001199  loss_mask_6: 0.1163  loss_dice_6: 0.1702  loss_ce_7: 0.0002218  loss_mask_7: 0.1165  loss_dice_7: 0.1764  loss_ce_8: 0.0001785  loss_mask_8: 0.1132  loss_dice_8: 0.1697  time: 0.6594  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:42:25] d2.utils.events INFO:  eta: 0:53:36  iter: 21679  total_loss: 2.981  loss_ce: 0.0001212  loss_mask: 0.1154  loss_dice: 0.1779  loss_ce_0: 0.1213  loss_mask_0: 0.1143  loss_dice_0: 0.1722  loss_ce_1: 0.000118  loss_mask_1: 0.1167  loss_dice_1: 0.1749  loss_ce_2: 0.0001192  loss_mask_2: 0.1155  loss_dice_2: 0.177  loss_ce_3: 8.175e-05  loss_mask_3: 0.1132  loss_dice_3: 0.1715  loss_ce_4: 0.0001431  loss_mask_4: 0.1138  loss_dice_4: 0.1688  loss_ce_5: 0.0001582  loss_mask_5: 0.1163  loss_dice_5: 0.172  loss_ce_6: 8.16e-05  loss_mask_6: 0.1125  loss_dice_6: 0.1736  loss_ce_7: 0.0002226  loss_mask_7: 0.1151  loss_dice_7: 0.1751  loss_ce_8: 0.0001613  loss_mask_8: 0.1172  loss_dice_8: 0.1797  time: 0.6590  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:42:30] d2.utils.events INFO:  eta: 0:53:05  iter: 21699  total_loss: 3.069  loss_ce: 0.0001292  loss_mask: 0.1162  loss_dice: 0.1774  loss_ce_0: 0.1212  loss_mask_0: 0.1186  loss_dice_0: 0.1766  loss_ce_1: 0.0001165  loss_mask_1: 0.1134  loss_dice_1: 0.1758  loss_ce_2: 0.000117  loss_mask_2: 0.113  loss_dice_2: 0.1736  loss_ce_3: 0.0001006  loss_mask_3: 0.1116  loss_dice_3: 0.1702  loss_ce_4: 0.0001378  loss_mask_4: 0.11  loss_dice_4: 0.1717  loss_ce_5: 0.0001491  loss_mask_5: 0.1166  loss_dice_5: 0.1754  loss_ce_6: 0.0001012  loss_mask_6: 0.113  loss_dice_6: 0.1704  loss_ce_7: 0.0001842  loss_mask_7: 0.1166  loss_dice_7: 0.1786  loss_ce_8: 0.0001481  loss_mask_8: 0.1185  loss_dice_8: 0.1751  time: 0.6586  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:42:34] d2.utils.events INFO:  eta: 0:52:47  iter: 21719  total_loss: 2.981  loss_ce: 6.372e-05  loss_mask: 0.1206  loss_dice: 0.1744  loss_ce_0: 0.1198  loss_mask_0: 0.1096  loss_dice_0: 0.1695  loss_ce_1: 4.461e-05  loss_mask_1: 0.118  loss_dice_1: 0.1734  loss_ce_2: 5.98e-05  loss_mask_2: 0.1124  loss_dice_2: 0.1704  loss_ce_3: 4.358e-05  loss_mask_3: 0.1111  loss_dice_3: 0.1708  loss_ce_4: 5.73e-05  loss_mask_4: 0.1105  loss_dice_4: 0.1744  loss_ce_5: 7.421e-05  loss_mask_5: 0.1086  loss_dice_5: 0.1665  loss_ce_6: 4.574e-05  loss_mask_6: 0.113  loss_dice_6: 0.1739  loss_ce_7: 6.838e-05  loss_mask_7: 0.1138  loss_dice_7: 0.1763  loss_ce_8: 8.768e-05  loss_mask_8: 0.1163  loss_dice_8: 0.1711  time: 0.6582  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:42:39] d2.utils.events INFO:  eta: 0:52:34  iter: 21739  total_loss: 2.814  loss_ce: 6.356e-05  loss_mask: 0.1091  loss_dice: 0.1592  loss_ce_0: 0.1272  loss_mask_0: 0.1088  loss_dice_0: 0.1606  loss_ce_1: 4.884e-05  loss_mask_1: 0.1065  loss_dice_1: 0.1599  loss_ce_2: 5.61e-05  loss_mask_2: 0.1118  loss_dice_2: 0.1618  loss_ce_3: 5.031e-05  loss_mask_3: 0.1103  loss_dice_3: 0.1616  loss_ce_4: 5.791e-05  loss_mask_4: 0.1094  loss_dice_4: 0.1584  loss_ce_5: 9.415e-05  loss_mask_5: 0.1071  loss_dice_5: 0.1557  loss_ce_6: 7.252e-05  loss_mask_6: 0.1073  loss_dice_6: 0.1617  loss_ce_7: 0.0001271  loss_mask_7: 0.1071  loss_dice_7: 0.1577  loss_ce_8: 0.0001139  loss_mask_8: 0.1065  loss_dice_8: 0.1633  time: 0.6578  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:42:43] d2.utils.events INFO:  eta: 0:52:18  iter: 21759  total_loss: 2.908  loss_ce: 5.452e-05  loss_mask: 0.111  loss_dice: 0.1659  loss_ce_0: 0.1229  loss_mask_0: 0.1141  loss_dice_0: 0.173  loss_ce_1: 4.212e-05  loss_mask_1: 0.1131  loss_dice_1: 0.164  loss_ce_2: 5.523e-05  loss_mask_2: 0.115  loss_dice_2: 0.164  loss_ce_3: 4.773e-05  loss_mask_3: 0.1129  loss_dice_3: 0.1655  loss_ce_4: 5.27e-05  loss_mask_4: 0.114  loss_dice_4: 0.1713  loss_ce_5: 7.029e-05  loss_mask_5: 0.1164  loss_dice_5: 0.166  loss_ce_6: 3.796e-05  loss_mask_6: 0.1136  loss_dice_6: 0.1618  loss_ce_7: 6.662e-05  loss_mask_7: 0.115  loss_dice_7: 0.1661  loss_ce_8: 7.576e-05  loss_mask_8: 0.1152  loss_dice_8: 0.1714  time: 0.6574  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:42:48] d2.utils.events INFO:  eta: 0:52:06  iter: 21779  total_loss: 2.93  loss_ce: 7.215e-05  loss_mask: 0.1126  loss_dice: 0.1628  loss_ce_0: 0.1241  loss_mask_0: 0.112  loss_dice_0: 0.1648  loss_ce_1: 7.729e-05  loss_mask_1: 0.1117  loss_dice_1: 0.1657  loss_ce_2: 9.518e-05  loss_mask_2: 0.1128  loss_dice_2: 0.167  loss_ce_3: 6.709e-05  loss_mask_3: 0.1109  loss_dice_3: 0.1656  loss_ce_4: 0.0001013  loss_mask_4: 0.1145  loss_dice_4: 0.1706  loss_ce_5: 0.0001236  loss_mask_5: 0.1108  loss_dice_5: 0.1632  loss_ce_6: 5.704e-05  loss_mask_6: 0.1133  loss_dice_6: 0.1692  loss_ce_7: 0.0001357  loss_mask_7: 0.1129  loss_dice_7: 0.1693  loss_ce_8: 0.0001181  loss_mask_8: 0.1107  loss_dice_8: 0.1639  time: 0.6570  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:42:52] d2.utils.events INFO:  eta: 0:51:53  iter: 21799  total_loss: 2.863  loss_ce: 6.713e-05  loss_mask: 0.1104  loss_dice: 0.1621  loss_ce_0: 0.1225  loss_mask_0: 0.1093  loss_dice_0: 0.163  loss_ce_1: 4.795e-05  loss_mask_1: 0.1105  loss_dice_1: 0.1657  loss_ce_2: 5.066e-05  loss_mask_2: 0.1116  loss_dice_2: 0.1673  loss_ce_3: 5.398e-05  loss_mask_3: 0.1106  loss_dice_3: 0.1616  loss_ce_4: 6.609e-05  loss_mask_4: 0.1131  loss_dice_4: 0.1697  loss_ce_5: 8.555e-05  loss_mask_5: 0.1113  loss_dice_5: 0.1649  loss_ce_6: 5.332e-05  loss_mask_6: 0.1112  loss_dice_6: 0.1716  loss_ce_7: 0.0001117  loss_mask_7: 0.1113  loss_dice_7: 0.1614  loss_ce_8: 9.155e-05  loss_mask_8: 0.1086  loss_dice_8: 0.1667  time: 0.6566  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:42:57] d2.utils.events INFO:  eta: 0:51:45  iter: 21819  total_loss: 3.169  loss_ce: 5.994e-05  loss_mask: 0.1213  loss_dice: 0.1816  loss_ce_0: 0.121  loss_mask_0: 0.1215  loss_dice_0: 0.1815  loss_ce_1: 4.13e-05  loss_mask_1: 0.1194  loss_dice_1: 0.1808  loss_ce_2: 5.003e-05  loss_mask_2: 0.1196  loss_dice_2: 0.1796  loss_ce_3: 4.524e-05  loss_mask_3: 0.1181  loss_dice_3: 0.1754  loss_ce_4: 5.067e-05  loss_mask_4: 0.1156  loss_dice_4: 0.1695  loss_ce_5: 8.052e-05  loss_mask_5: 0.1126  loss_dice_5: 0.1812  loss_ce_6: 5.399e-05  loss_mask_6: 0.1145  loss_dice_6: 0.1798  loss_ce_7: 9.069e-05  loss_mask_7: 0.1172  loss_dice_7: 0.1876  loss_ce_8: 9.216e-05  loss_mask_8: 0.1195  loss_dice_8: 0.1742  time: 0.6562  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:43:01] d2.utils.events INFO:  eta: 0:51:33  iter: 21839  total_loss: 2.986  loss_ce: 5.861e-05  loss_mask: 0.1146  loss_dice: 0.1639  loss_ce_0: 0.1263  loss_mask_0: 0.1125  loss_dice_0: 0.1708  loss_ce_1: 4.514e-05  loss_mask_1: 0.1135  loss_dice_1: 0.1671  loss_ce_2: 4.922e-05  loss_mask_2: 0.1132  loss_dice_2: 0.1687  loss_ce_3: 5.278e-05  loss_mask_3: 0.1153  loss_dice_3: 0.1706  loss_ce_4: 5.293e-05  loss_mask_4: 0.1118  loss_dice_4: 0.1681  loss_ce_5: 7.755e-05  loss_mask_5: 0.1151  loss_dice_5: 0.1693  loss_ce_6: 5.964e-05  loss_mask_6: 0.1153  loss_dice_6: 0.1659  loss_ce_7: 9.21e-05  loss_mask_7: 0.1114  loss_dice_7: 0.1672  loss_ce_8: 8.659e-05  loss_mask_8: 0.1173  loss_dice_8: 0.1709  time: 0.6558  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:43:06] d2.utils.events INFO:  eta: 0:51:21  iter: 21859  total_loss: 3.162  loss_ce: 5.517e-05  loss_mask: 0.1173  loss_dice: 0.1825  loss_ce_0: 0.1268  loss_mask_0: 0.1201  loss_dice_0: 0.1946  loss_ce_1: 4.1e-05  loss_mask_1: 0.122  loss_dice_1: 0.181  loss_ce_2: 4.53e-05  loss_mask_2: 0.1194  loss_dice_2: 0.1797  loss_ce_3: 4.116e-05  loss_mask_3: 0.1199  loss_dice_3: 0.1854  loss_ce_4: 4.84e-05  loss_mask_4: 0.1206  loss_dice_4: 0.1887  loss_ce_5: 7.818e-05  loss_mask_5: 0.1232  loss_dice_5: 0.1823  loss_ce_6: 5.763e-05  loss_mask_6: 0.1152  loss_dice_6: 0.1828  loss_ce_7: 7.878e-05  loss_mask_7: 0.1198  loss_dice_7: 0.1842  loss_ce_8: 8.319e-05  loss_mask_8: 0.1185  loss_dice_8: 0.1831  time: 0.6555  data_time: 0.0010  lr: 0.0001  max_mem: 8444M
[08/01 21:43:10] d2.utils.events INFO:  eta: 0:51:11  iter: 21879  total_loss: 2.982  loss_ce: 5.603e-05  loss_mask: 0.1113  loss_dice: 0.1701  loss_ce_0: 0.1262  loss_mask_0: 0.1078  loss_dice_0: 0.1653  loss_ce_1: 4.452e-05  loss_mask_1: 0.1091  loss_dice_1: 0.1682  loss_ce_2: 4.586e-05  loss_mask_2: 0.1105  loss_dice_2: 0.1667  loss_ce_3: 3.636e-05  loss_mask_3: 0.1174  loss_dice_3: 0.178  loss_ce_4: 5.463e-05  loss_mask_4: 0.1109  loss_dice_4: 0.169  loss_ce_5: 8.188e-05  loss_mask_5: 0.1097  loss_dice_5: 0.1629  loss_ce_6: 6.041e-05  loss_mask_6: 0.1102  loss_dice_6: 0.1665  loss_ce_7: 8.218e-05  loss_mask_7: 0.1121  loss_dice_7: 0.1732  loss_ce_8: 8.144e-05  loss_mask_8: 0.1091  loss_dice_8: 0.1681  time: 0.6551  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:43:15] d2.utils.events INFO:  eta: 0:51:03  iter: 21899  total_loss: 3.114  loss_ce: 0.0001959  loss_mask: 0.1196  loss_dice: 0.1794  loss_ce_0: 0.1153  loss_mask_0: 0.1205  loss_dice_0: 0.1792  loss_ce_1: 0.0001643  loss_mask_1: 0.1198  loss_dice_1: 0.1675  loss_ce_2: 0.0005072  loss_mask_2: 0.1212  loss_dice_2: 0.1711  loss_ce_3: 0.0002976  loss_mask_3: 0.1276  loss_dice_3: 0.173  loss_ce_4: 0.0001814  loss_mask_4: 0.1175  loss_dice_4: 0.1697  loss_ce_5: 0.0001777  loss_mask_5: 0.128  loss_dice_5: 0.1779  loss_ce_6: 8.283e-05  loss_mask_6: 0.1161  loss_dice_6: 0.1697  loss_ce_7: 0.0001956  loss_mask_7: 0.1228  loss_dice_7: 0.1776  loss_ce_8: 0.0002189  loss_mask_8: 0.1235  loss_dice_8: 0.1716  time: 0.6547  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:43:19] d2.utils.events INFO:  eta: 0:50:48  iter: 21919  total_loss: 3.22  loss_ce: 0.0001494  loss_mask: 0.113  loss_dice: 0.1878  loss_ce_0: 0.1212  loss_mask_0: 0.1138  loss_dice_0: 0.1917  loss_ce_1: 0.0001828  loss_mask_1: 0.1167  loss_dice_1: 0.1879  loss_ce_2: 0.0005252  loss_mask_2: 0.1148  loss_dice_2: 0.1827  loss_ce_3: 0.000818  loss_mask_3: 0.12  loss_dice_3: 0.1851  loss_ce_4: 0.0002418  loss_mask_4: 0.1148  loss_dice_4: 0.1845  loss_ce_5: 0.0001717  loss_mask_5: 0.1162  loss_dice_5: 0.1932  loss_ce_6: 8.782e-05  loss_mask_6: 0.117  loss_dice_6: 0.1858  loss_ce_7: 0.00018  loss_mask_7: 0.1151  loss_dice_7: 0.1831  loss_ce_8: 0.0002061  loss_mask_8: 0.115  loss_dice_8: 0.1877  time: 0.6543  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:43:24] d2.utils.events INFO:  eta: 0:50:38  iter: 21939  total_loss: 2.914  loss_ce: 6.693e-05  loss_mask: 0.1095  loss_dice: 0.1673  loss_ce_0: 0.1322  loss_mask_0: 0.1094  loss_dice_0: 0.1647  loss_ce_1: 0.0001216  loss_mask_1: 0.1086  loss_dice_1: 0.1679  loss_ce_2: 8.863e-05  loss_mask_2: 0.1108  loss_dice_2: 0.1692  loss_ce_3: 0.0002388  loss_mask_3: 0.1105  loss_dice_3: 0.1679  loss_ce_4: 9.14e-05  loss_mask_4: 0.1105  loss_dice_4: 0.1679  loss_ce_5: 8.71e-05  loss_mask_5: 0.1084  loss_dice_5: 0.1657  loss_ce_6: 6.633e-05  loss_mask_6: 0.1122  loss_dice_6: 0.1652  loss_ce_7: 0.000103  loss_mask_7: 0.1102  loss_dice_7: 0.1601  loss_ce_8: 0.0001123  loss_mask_8: 0.1105  loss_dice_8: 0.1678  time: 0.6539  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:43:28] d2.utils.events INFO:  eta: 0:50:26  iter: 21959  total_loss: 2.891  loss_ce: 0.0001436  loss_mask: 0.1147  loss_dice: 0.1657  loss_ce_0: 0.1265  loss_mask_0: 0.1145  loss_dice_0: 0.1684  loss_ce_1: 9.962e-05  loss_mask_1: 0.115  loss_dice_1: 0.1653  loss_ce_2: 0.0002708  loss_mask_2: 0.1109  loss_dice_2: 0.1653  loss_ce_3: 0.000246  loss_mask_3: 0.1139  loss_dice_3: 0.1629  loss_ce_4: 0.000102  loss_mask_4: 0.1135  loss_dice_4: 0.1635  loss_ce_5: 0.0001056  loss_mask_5: 0.1148  loss_dice_5: 0.1644  loss_ce_6: 5.384e-05  loss_mask_6: 0.1124  loss_dice_6: 0.1617  loss_ce_7: 0.0001158  loss_mask_7: 0.1115  loss_dice_7: 0.164  loss_ce_8: 0.0001265  loss_mask_8: 0.1128  loss_dice_8: 0.1636  time: 0.6535  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:43:33] d2.utils.events INFO:  eta: 0:50:16  iter: 21979  total_loss: 3.085  loss_ce: 9.419e-05  loss_mask: 0.1142  loss_dice: 0.1902  loss_ce_0: 0.1258  loss_mask_0: 0.1127  loss_dice_0: 0.1788  loss_ce_1: 6.529e-05  loss_mask_1: 0.113  loss_dice_1: 0.1897  loss_ce_2: 6.826e-05  loss_mask_2: 0.1111  loss_dice_2: 0.1795  loss_ce_3: 0.0001823  loss_mask_3: 0.1121  loss_dice_3: 0.1801  loss_ce_4: 6.715e-05  loss_mask_4: 0.1104  loss_dice_4: 0.1793  loss_ce_5: 8.022e-05  loss_mask_5: 0.1152  loss_dice_5: 0.1824  loss_ce_6: 6.049e-05  loss_mask_6: 0.1121  loss_dice_6: 0.1867  loss_ce_7: 9.948e-05  loss_mask_7: 0.1119  loss_dice_7: 0.1818  loss_ce_8: 9.579e-05  loss_mask_8: 0.1147  loss_dice_8: 0.1937  time: 0.6531  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:43:37] d2.utils.events INFO:  eta: 0:50:06  iter: 21999  total_loss: 3.469  loss_ce: 0.0001491  loss_mask: 0.1183  loss_dice: 0.2036  loss_ce_0: 0.1223  loss_mask_0: 0.1143  loss_dice_0: 0.1962  loss_ce_1: 7.984e-05  loss_mask_1: 0.114  loss_dice_1: 0.1939  loss_ce_2: 0.0002081  loss_mask_2: 0.1158  loss_dice_2: 0.1962  loss_ce_3: 0.0002711  loss_mask_3: 0.1188  loss_dice_3: 0.1906  loss_ce_4: 0.0001196  loss_mask_4: 0.1201  loss_dice_4: 0.1854  loss_ce_5: 0.0001359  loss_mask_5: 0.1148  loss_dice_5: 0.1986  loss_ce_6: 7.691e-05  loss_mask_6: 0.1145  loss_dice_6: 0.1982  loss_ce_7: 0.0001304  loss_mask_7: 0.1217  loss_dice_7: 0.2016  loss_ce_8: 0.0001622  loss_mask_8: 0.1209  loss_dice_8: 0.1915  time: 0.6527  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:43:42] d2.utils.events INFO:  eta: 0:49:55  iter: 22019  total_loss: 3.19  loss_ce: 9.687e-05  loss_mask: 0.1169  loss_dice: 0.1838  loss_ce_0: 0.1258  loss_mask_0: 0.1158  loss_dice_0: 0.1843  loss_ce_1: 0.0001512  loss_mask_1: 0.1159  loss_dice_1: 0.183  loss_ce_2: 0.0003853  loss_mask_2: 0.1156  loss_dice_2: 0.1781  loss_ce_3: 6.483e-05  loss_mask_3: 0.1197  loss_dice_3: 0.1852  loss_ce_4: 8.222e-05  loss_mask_4: 0.1139  loss_dice_4: 0.1832  loss_ce_5: 0.0001296  loss_mask_5: 0.1196  loss_dice_5: 0.1837  loss_ce_6: 0.0001363  loss_mask_6: 0.1165  loss_dice_6: 0.1786  loss_ce_7: 0.0001371  loss_mask_7: 0.1149  loss_dice_7: 0.1871  loss_ce_8: 0.0001249  loss_mask_8: 0.1168  loss_dice_8: 0.1809  time: 0.6523  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:43:46] d2.utils.events INFO:  eta: 0:49:42  iter: 22039  total_loss: 2.9  loss_ce: 0.0001041  loss_mask: 0.111  loss_dice: 0.1594  loss_ce_0: 0.1247  loss_mask_0: 0.1136  loss_dice_0: 0.1713  loss_ce_1: 0.0001103  loss_mask_1: 0.1132  loss_dice_1: 0.169  loss_ce_2: 0.0001599  loss_mask_2: 0.1138  loss_dice_2: 0.17  loss_ce_3: 8.895e-05  loss_mask_3: 0.1151  loss_dice_3: 0.1695  loss_ce_4: 0.0001152  loss_mask_4: 0.113  loss_dice_4: 0.1735  loss_ce_5: 0.000125  loss_mask_5: 0.1108  loss_dice_5: 0.1651  loss_ce_6: 7.811e-05  loss_mask_6: 0.1173  loss_dice_6: 0.1698  loss_ce_7: 0.0001359  loss_mask_7: 0.109  loss_dice_7: 0.1646  loss_ce_8: 0.0001282  loss_mask_8: 0.111  loss_dice_8: 0.1724  time: 0.6519  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:43:51] d2.utils.events INFO:  eta: 0:49:32  iter: 22059  total_loss: 3.538  loss_ce: 0.0004207  loss_mask: 0.1214  loss_dice: 0.193  loss_ce_0: 0.1284  loss_mask_0: 0.1224  loss_dice_0: 0.1858  loss_ce_1: 0.002782  loss_mask_1: 0.1243  loss_dice_1: 0.1961  loss_ce_2: 0.001673  loss_mask_2: 0.1183  loss_dice_2: 0.187  loss_ce_3: 0.002218  loss_mask_3: 0.119  loss_dice_3: 0.1875  loss_ce_4: 0.007429  loss_mask_4: 0.1177  loss_dice_4: 0.1861  loss_ce_5: 0.001192  loss_mask_5: 0.1225  loss_dice_5: 0.1905  loss_ce_6: 0.006018  loss_mask_6: 0.1218  loss_dice_6: 0.1926  loss_ce_7: 0.001053  loss_mask_7: 0.1177  loss_dice_7: 0.1985  loss_ce_8: 0.0003767  loss_mask_8: 0.126  loss_dice_8: 0.1907  time: 0.6516  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:43:56] d2.utils.events INFO:  eta: 0:49:14  iter: 22079  total_loss: 3.164  loss_ce: 0.002105  loss_mask: 0.1214  loss_dice: 0.1777  loss_ce_0: 0.1249  loss_mask_0: 0.1204  loss_dice_0: 0.1792  loss_ce_1: 0.00283  loss_mask_1: 0.1206  loss_dice_1: 0.1767  loss_ce_2: 0.001425  loss_mask_2: 0.1212  loss_dice_2: 0.1729  loss_ce_3: 0.0009626  loss_mask_3: 0.1212  loss_dice_3: 0.1766  loss_ce_4: 0.001605  loss_mask_4: 0.1194  loss_dice_4: 0.1741  loss_ce_5: 0.002491  loss_mask_5: 0.1189  loss_dice_5: 0.182  loss_ce_6: 0.0002531  loss_mask_6: 0.1175  loss_dice_6: 0.1732  loss_ce_7: 0.001946  loss_mask_7: 0.12  loss_dice_7: 0.1782  loss_ce_8: 0.002834  loss_mask_8: 0.1213  loss_dice_8: 0.1791  time: 0.6512  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:00] d2.utils.events INFO:  eta: 0:49:00  iter: 22099  total_loss: 3.095  loss_ce: 0.0007125  loss_mask: 0.1165  loss_dice: 0.171  loss_ce_0: 0.1234  loss_mask_0: 0.1185  loss_dice_0: 0.1786  loss_ce_1: 0.0005392  loss_mask_1: 0.1159  loss_dice_1: 0.1823  loss_ce_2: 0.0006526  loss_mask_2: 0.1192  loss_dice_2: 0.179  loss_ce_3: 0.0003603  loss_mask_3: 0.1149  loss_dice_3: 0.1778  loss_ce_4: 0.0005304  loss_mask_4: 0.1175  loss_dice_4: 0.1786  loss_ce_5: 0.001059  loss_mask_5: 0.1183  loss_dice_5: 0.1707  loss_ce_6: 0.0001201  loss_mask_6: 0.1197  loss_dice_6: 0.177  loss_ce_7: 0.0009469  loss_mask_7: 0.1155  loss_dice_7: 0.1786  loss_ce_8: 0.001344  loss_mask_8: 0.1165  loss_dice_8: 0.1773  time: 0.6508  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:05] d2.utils.events INFO:  eta: 0:48:48  iter: 22119  total_loss: 3.183  loss_ce: 0.0005363  loss_mask: 0.1162  loss_dice: 0.1736  loss_ce_0: 0.1202  loss_mask_0: 0.1173  loss_dice_0: 0.1809  loss_ce_1: 0.0005578  loss_mask_1: 0.1159  loss_dice_1: 0.1751  loss_ce_2: 0.0006015  loss_mask_2: 0.1189  loss_dice_2: 0.1829  loss_ce_3: 0.0004381  loss_mask_3: 0.1139  loss_dice_3: 0.1781  loss_ce_4: 0.0003869  loss_mask_4: 0.1191  loss_dice_4: 0.1729  loss_ce_5: 0.0008432  loss_mask_5: 0.1167  loss_dice_5: 0.1805  loss_ce_6: 0.0001231  loss_mask_6: 0.1122  loss_dice_6: 0.1765  loss_ce_7: 0.0005827  loss_mask_7: 0.1147  loss_dice_7: 0.1724  loss_ce_8: 0.0008938  loss_mask_8: 0.1195  loss_dice_8: 0.1797  time: 0.6504  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:09] d2.utils.events INFO:  eta: 0:48:42  iter: 22139  total_loss: 2.961  loss_ce: 0.0002826  loss_mask: 0.1109  loss_dice: 0.1724  loss_ce_0: 0.1265  loss_mask_0: 0.1138  loss_dice_0: 0.1729  loss_ce_1: 0.0001836  loss_mask_1: 0.1129  loss_dice_1: 0.1815  loss_ce_2: 0.0003219  loss_mask_2: 0.114  loss_dice_2: 0.1833  loss_ce_3: 0.0001257  loss_mask_3: 0.1136  loss_dice_3: 0.1812  loss_ce_4: 0.0002194  loss_mask_4: 0.1113  loss_dice_4: 0.1766  loss_ce_5: 0.0003497  loss_mask_5: 0.1154  loss_dice_5: 0.1809  loss_ce_6: 7.52e-05  loss_mask_6: 0.1151  loss_dice_6: 0.1764  loss_ce_7: 0.000352  loss_mask_7: 0.115  loss_dice_7: 0.1703  loss_ce_8: 0.000411  loss_mask_8: 0.1106  loss_dice_8: 0.1749  time: 0.6500  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:14] d2.utils.events INFO:  eta: 0:48:33  iter: 22159  total_loss: 2.946  loss_ce: 0.0002708  loss_mask: 0.115  loss_dice: 0.1697  loss_ce_0: 0.1201  loss_mask_0: 0.1131  loss_dice_0: 0.1626  loss_ce_1: 0.0003036  loss_mask_1: 0.116  loss_dice_1: 0.1704  loss_ce_2: 0.0003902  loss_mask_2: 0.1122  loss_dice_2: 0.1702  loss_ce_3: 0.0002225  loss_mask_3: 0.1131  loss_dice_3: 0.1688  loss_ce_4: 0.0002364  loss_mask_4: 0.1129  loss_dice_4: 0.1634  loss_ce_5: 0.0004159  loss_mask_5: 0.1167  loss_dice_5: 0.1693  loss_ce_6: 7.641e-05  loss_mask_6: 0.1121  loss_dice_6: 0.1668  loss_ce_7: 0.0002953  loss_mask_7: 0.1142  loss_dice_7: 0.1621  loss_ce_8: 0.0004427  loss_mask_8: 0.1108  loss_dice_8: 0.164  time: 0.6496  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:18] d2.utils.events INFO:  eta: 0:48:27  iter: 22179  total_loss: 3.071  loss_ce: 0.0002421  loss_mask: 0.1107  loss_dice: 0.175  loss_ce_0: 0.126  loss_mask_0: 0.1098  loss_dice_0: 0.1868  loss_ce_1: 0.000163  loss_mask_1: 0.1128  loss_dice_1: 0.1752  loss_ce_2: 0.0002656  loss_mask_2: 0.1075  loss_dice_2: 0.1731  loss_ce_3: 0.0001263  loss_mask_3: 0.1168  loss_dice_3: 0.1807  loss_ce_4: 0.0002166  loss_mask_4: 0.1109  loss_dice_4: 0.1821  loss_ce_5: 0.0002572  loss_mask_5: 0.1134  loss_dice_5: 0.183  loss_ce_6: 7.36e-05  loss_mask_6: 0.1119  loss_dice_6: 0.1802  loss_ce_7: 0.0002722  loss_mask_7: 0.1095  loss_dice_7: 0.177  loss_ce_8: 0.0003041  loss_mask_8: 0.1149  loss_dice_8: 0.1807  time: 0.6492  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:23] d2.utils.events INFO:  eta: 0:48:23  iter: 22199  total_loss: 2.949  loss_ce: 0.0001921  loss_mask: 0.1155  loss_dice: 0.1741  loss_ce_0: 0.1304  loss_mask_0: 0.1108  loss_dice_0: 0.1711  loss_ce_1: 0.0002722  loss_mask_1: 0.1123  loss_dice_1: 0.1718  loss_ce_2: 0.0003168  loss_mask_2: 0.1105  loss_dice_2: 0.1708  loss_ce_3: 0.0001532  loss_mask_3: 0.1163  loss_dice_3: 0.1728  loss_ce_4: 0.0001747  loss_mask_4: 0.1095  loss_dice_4: 0.1618  loss_ce_5: 0.0003095  loss_mask_5: 0.1118  loss_dice_5: 0.1676  loss_ce_6: 5.313e-05  loss_mask_6: 0.1151  loss_dice_6: 0.1724  loss_ce_7: 0.0002256  loss_mask_7: 0.1102  loss_dice_7: 0.1681  loss_ce_8: 0.000305  loss_mask_8: 0.1136  loss_dice_8: 0.1702  time: 0.6489  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:27] d2.utils.events INFO:  eta: 0:48:19  iter: 22219  total_loss: 3.12  loss_ce: 0.0001754  loss_mask: 0.1147  loss_dice: 0.188  loss_ce_0: 0.1261  loss_mask_0: 0.1142  loss_dice_0: 0.1883  loss_ce_1: 0.0001928  loss_mask_1: 0.1171  loss_dice_1: 0.1919  loss_ce_2: 0.0002377  loss_mask_2: 0.1175  loss_dice_2: 0.1915  loss_ce_3: 0.0001272  loss_mask_3: 0.1137  loss_dice_3: 0.1872  loss_ce_4: 0.0001542  loss_mask_4: 0.1156  loss_dice_4: 0.1846  loss_ce_5: 0.0002196  loss_mask_5: 0.1135  loss_dice_5: 0.1828  loss_ce_6: 6.068e-05  loss_mask_6: 0.1175  loss_dice_6: 0.19  loss_ce_7: 0.0001755  loss_mask_7: 0.1125  loss_dice_7: 0.1847  loss_ce_8: 0.0002396  loss_mask_8: 0.1153  loss_dice_8: 0.192  time: 0.6485  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:32] d2.utils.events INFO:  eta: 0:48:14  iter: 22239  total_loss: 3.121  loss_ce: 0.0001437  loss_mask: 0.122  loss_dice: 0.18  loss_ce_0: 0.1254  loss_mask_0: 0.1195  loss_dice_0: 0.1838  loss_ce_1: 0.0001154  loss_mask_1: 0.1215  loss_dice_1: 0.1778  loss_ce_2: 0.0001958  loss_mask_2: 0.1138  loss_dice_2: 0.1728  loss_ce_3: 8.329e-05  loss_mask_3: 0.1215  loss_dice_3: 0.1817  loss_ce_4: 0.0001421  loss_mask_4: 0.1158  loss_dice_4: 0.1704  loss_ce_5: 0.000177  loss_mask_5: 0.1209  loss_dice_5: 0.1748  loss_ce_6: 6.331e-05  loss_mask_6: 0.1245  loss_dice_6: 0.18  loss_ce_7: 0.0001478  loss_mask_7: 0.1225  loss_dice_7: 0.1799  loss_ce_8: 0.0002015  loss_mask_8: 0.1194  loss_dice_8: 0.1794  time: 0.6481  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:36] d2.utils.events INFO:  eta: 0:48:11  iter: 22259  total_loss: 2.888  loss_ce: 0.0001346  loss_mask: 0.1103  loss_dice: 0.162  loss_ce_0: 0.1253  loss_mask_0: 0.1087  loss_dice_0: 0.1759  loss_ce_1: 0.0001171  loss_mask_1: 0.1104  loss_dice_1: 0.1659  loss_ce_2: 0.0001853  loss_mask_2: 0.1101  loss_dice_2: 0.168  loss_ce_3: 8.171e-05  loss_mask_3: 0.1111  loss_dice_3: 0.1689  loss_ce_4: 0.0001265  loss_mask_4: 0.11  loss_dice_4: 0.1641  loss_ce_5: 0.0001673  loss_mask_5: 0.1097  loss_dice_5: 0.1665  loss_ce_6: 6.061e-05  loss_mask_6: 0.1074  loss_dice_6: 0.1654  loss_ce_7: 0.000152  loss_mask_7: 0.1124  loss_dice_7: 0.1688  loss_ce_8: 0.0001931  loss_mask_8: 0.1096  loss_dice_8: 0.1652  time: 0.6477  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:41] d2.utils.events INFO:  eta: 0:48:08  iter: 22279  total_loss: 2.936  loss_ce: 0.0001468  loss_mask: 0.1106  loss_dice: 0.1702  loss_ce_0: 0.1249  loss_mask_0: 0.1158  loss_dice_0: 0.1776  loss_ce_1: 0.000129  loss_mask_1: 0.1138  loss_dice_1: 0.1753  loss_ce_2: 0.0001776  loss_mask_2: 0.1148  loss_dice_2: 0.1752  loss_ce_3: 0.0001164  loss_mask_3: 0.1147  loss_dice_3: 0.1691  loss_ce_4: 0.0001204  loss_mask_4: 0.1148  loss_dice_4: 0.1659  loss_ce_5: 0.0001588  loss_mask_5: 0.1104  loss_dice_5: 0.1633  loss_ce_6: 6.166e-05  loss_mask_6: 0.1131  loss_dice_6: 0.1704  loss_ce_7: 0.0001442  loss_mask_7: 0.1081  loss_dice_7: 0.1688  loss_ce_8: 0.0001857  loss_mask_8: 0.1134  loss_dice_8: 0.1694  time: 0.6473  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:45] d2.utils.events INFO:  eta: 0:48:05  iter: 22299  total_loss: 3.213  loss_ce: 0.0001403  loss_mask: 0.119  loss_dice: 0.1927  loss_ce_0: 0.1244  loss_mask_0: 0.1169  loss_dice_0: 0.1948  loss_ce_1: 0.0001206  loss_mask_1: 0.1197  loss_dice_1: 0.1968  loss_ce_2: 0.0001817  loss_mask_2: 0.1168  loss_dice_2: 0.1995  loss_ce_3: 0.0001117  loss_mask_3: 0.1175  loss_dice_3: 0.1862  loss_ce_4: 0.0001185  loss_mask_4: 0.1143  loss_dice_4: 0.1949  loss_ce_5: 0.0001588  loss_mask_5: 0.1186  loss_dice_5: 0.1952  loss_ce_6: 5.648e-05  loss_mask_6: 0.1142  loss_dice_6: 0.1864  loss_ce_7: 0.0001574  loss_mask_7: 0.1156  loss_dice_7: 0.1919  loss_ce_8: 0.0001796  loss_mask_8: 0.1125  loss_dice_8: 0.1934  time: 0.6470  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:50] d2.utils.events INFO:  eta: 0:48:00  iter: 22319  total_loss: 2.987  loss_ce: 0.000114  loss_mask: 0.1136  loss_dice: 0.1692  loss_ce_0: 0.1231  loss_mask_0: 0.1139  loss_dice_0: 0.1685  loss_ce_1: 0.0001084  loss_mask_1: 0.1112  loss_dice_1: 0.1766  loss_ce_2: 0.000149  loss_mask_2: 0.116  loss_dice_2: 0.1798  loss_ce_3: 9.287e-05  loss_mask_3: 0.1166  loss_dice_3: 0.1772  loss_ce_4: 0.0001049  loss_mask_4: 0.1131  loss_dice_4: 0.1712  loss_ce_5: 0.0001402  loss_mask_5: 0.1154  loss_dice_5: 0.1767  loss_ce_6: 4e-05  loss_mask_6: 0.1154  loss_dice_6: 0.1791  loss_ce_7: 0.0001198  loss_mask_7: 0.1148  loss_dice_7: 0.1756  loss_ce_8: 0.0001519  loss_mask_8: 0.1136  loss_dice_8: 0.1734  time: 0.6466  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:54] d2.utils.events INFO:  eta: 0:47:58  iter: 22339  total_loss: 2.897  loss_ce: 0.0001385  loss_mask: 0.1109  loss_dice: 0.1679  loss_ce_0: 0.1208  loss_mask_0: 0.1102  loss_dice_0: 0.1676  loss_ce_1: 0.0001179  loss_mask_1: 0.1084  loss_dice_1: 0.1705  loss_ce_2: 0.0001513  loss_mask_2: 0.1107  loss_dice_2: 0.1735  loss_ce_3: 8.442e-05  loss_mask_3: 0.1089  loss_dice_3: 0.1725  loss_ce_4: 0.0001145  loss_mask_4: 0.1141  loss_dice_4: 0.1748  loss_ce_5: 0.0001523  loss_mask_5: 0.1081  loss_dice_5: 0.1696  loss_ce_6: 6.494e-05  loss_mask_6: 0.1128  loss_dice_6: 0.1736  loss_ce_7: 0.0001168  loss_mask_7: 0.113  loss_dice_7: 0.1701  loss_ce_8: 0.0001444  loss_mask_8: 0.1101  loss_dice_8: 0.1694  time: 0.6462  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:44:59] d2.utils.events INFO:  eta: 0:47:53  iter: 22359  total_loss: 3.011  loss_ce: 0.0001447  loss_mask: 0.114  loss_dice: 0.1736  loss_ce_0: 0.1215  loss_mask_0: 0.1125  loss_dice_0: 0.1757  loss_ce_1: 0.0001143  loss_mask_1: 0.1108  loss_dice_1: 0.18  loss_ce_2: 0.0001394  loss_mask_2: 0.1143  loss_dice_2: 0.1742  loss_ce_3: 8.917e-05  loss_mask_3: 0.1156  loss_dice_3: 0.1793  loss_ce_4: 0.0001164  loss_mask_4: 0.1125  loss_dice_4: 0.1784  loss_ce_5: 0.0001475  loss_mask_5: 0.1137  loss_dice_5: 0.178  loss_ce_6: 7.548e-05  loss_mask_6: 0.1171  loss_dice_6: 0.1844  loss_ce_7: 0.0001148  loss_mask_7: 0.1116  loss_dice_7: 0.1705  loss_ce_8: 0.0001425  loss_mask_8: 0.1158  loss_dice_8: 0.1741  time: 0.6458  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:45:03] d2.utils.events INFO:  eta: 0:47:49  iter: 22379  total_loss: 3.112  loss_ce: 0.0001257  loss_mask: 0.1182  loss_dice: 0.1772  loss_ce_0: 0.1215  loss_mask_0: 0.1202  loss_dice_0: 0.1797  loss_ce_1: 0.0001047  loss_mask_1: 0.1224  loss_dice_1: 0.1812  loss_ce_2: 0.0001306  loss_mask_2: 0.1199  loss_dice_2: 0.184  loss_ce_3: 8.324e-05  loss_mask_3: 0.1181  loss_dice_3: 0.1818  loss_ce_4: 9.314e-05  loss_mask_4: 0.1228  loss_dice_4: 0.1846  loss_ce_5: 0.000121  loss_mask_5: 0.115  loss_dice_5: 0.1696  loss_ce_6: 6.744e-05  loss_mask_6: 0.1196  loss_dice_6: 0.1773  loss_ce_7: 9.855e-05  loss_mask_7: 0.1203  loss_dice_7: 0.1821  loss_ce_8: 0.0001338  loss_mask_8: 0.1146  loss_dice_8: 0.177  time: 0.6455  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:45:08] d2.utils.events INFO:  eta: 0:47:45  iter: 22399  total_loss: 2.993  loss_ce: 0.0001238  loss_mask: 0.1116  loss_dice: 0.1818  loss_ce_0: 0.1227  loss_mask_0: 0.1086  loss_dice_0: 0.1754  loss_ce_1: 0.0001096  loss_mask_1: 0.1135  loss_dice_1: 0.1764  loss_ce_2: 9.88e-05  loss_mask_2: 0.1122  loss_dice_2: 0.1814  loss_ce_3: 6.96e-05  loss_mask_3: 0.1107  loss_dice_3: 0.1708  loss_ce_4: 9.158e-05  loss_mask_4: 0.1123  loss_dice_4: 0.1798  loss_ce_5: 0.0001162  loss_mask_5: 0.1082  loss_dice_5: 0.171  loss_ce_6: 7.048e-05  loss_mask_6: 0.1114  loss_dice_6: 0.1729  loss_ce_7: 9.656e-05  loss_mask_7: 0.1117  loss_dice_7: 0.1779  loss_ce_8: 0.0001227  loss_mask_8: 0.1109  loss_dice_8: 0.1758  time: 0.6451  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:45:12] d2.utils.events INFO:  eta: 0:47:41  iter: 22419  total_loss: 2.874  loss_ce: 0.0001093  loss_mask: 0.1124  loss_dice: 0.1719  loss_ce_0: 0.1198  loss_mask_0: 0.1087  loss_dice_0: 0.1663  loss_ce_1: 6.861e-05  loss_mask_1: 0.1096  loss_dice_1: 0.1631  loss_ce_2: 0.0001043  loss_mask_2: 0.1082  loss_dice_2: 0.1665  loss_ce_3: 6.776e-05  loss_mask_3: 0.1111  loss_dice_3: 0.167  loss_ce_4: 7.913e-05  loss_mask_4: 0.1145  loss_dice_4: 0.17  loss_ce_5: 0.0001114  loss_mask_5: 0.1093  loss_dice_5: 0.1727  loss_ce_6: 5.831e-05  loss_mask_6: 0.1063  loss_dice_6: 0.1677  loss_ce_7: 9.196e-05  loss_mask_7: 0.1115  loss_dice_7: 0.1703  loss_ce_8: 0.0001213  loss_mask_8: 0.1118  loss_dice_8: 0.1723  time: 0.6447  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:45:17] d2.utils.events INFO:  eta: 0:47:36  iter: 22439  total_loss: 3.137  loss_ce: 9.634e-05  loss_mask: 0.1187  loss_dice: 0.1837  loss_ce_0: 0.1184  loss_mask_0: 0.119  loss_dice_0: 0.185  loss_ce_1: 7.577e-05  loss_mask_1: 0.1179  loss_dice_1: 0.1845  loss_ce_2: 9.399e-05  loss_mask_2: 0.1198  loss_dice_2: 0.1819  loss_ce_3: 6.727e-05  loss_mask_3: 0.1192  loss_dice_3: 0.1795  loss_ce_4: 7.6e-05  loss_mask_4: 0.1174  loss_dice_4: 0.1844  loss_ce_5: 0.0001075  loss_mask_5: 0.1198  loss_dice_5: 0.1805  loss_ce_6: 5.758e-05  loss_mask_6: 0.1162  loss_dice_6: 0.1829  loss_ce_7: 8.913e-05  loss_mask_7: 0.1185  loss_dice_7: 0.1849  loss_ce_8: 0.0001175  loss_mask_8: 0.1178  loss_dice_8: 0.1847  time: 0.6443  data_time: 0.0010  lr: 0.0001  max_mem: 8444M
[08/01 21:45:21] d2.utils.events INFO:  eta: 0:47:32  iter: 22459  total_loss: 2.934  loss_ce: 0.0001921  loss_mask: 0.1126  loss_dice: 0.171  loss_ce_0: 0.1213  loss_mask_0: 0.1114  loss_dice_0: 0.1683  loss_ce_1: 0.0001197  loss_mask_1: 0.1133  loss_dice_1: 0.169  loss_ce_2: 0.0001584  loss_mask_2: 0.1115  loss_dice_2: 0.1631  loss_ce_3: 0.000102  loss_mask_3: 0.1129  loss_dice_3: 0.1673  loss_ce_4: 0.0001474  loss_mask_4: 0.1147  loss_dice_4: 0.1692  loss_ce_5: 0.0002856  loss_mask_5: 0.1127  loss_dice_5: 0.1633  loss_ce_6: 7.741e-05  loss_mask_6: 0.1146  loss_dice_6: 0.1709  loss_ce_7: 0.0001803  loss_mask_7: 0.1116  loss_dice_7: 0.1681  loss_ce_8: 0.0001904  loss_mask_8: 0.1117  loss_dice_8: 0.1675  time: 0.6440  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:45:26] d2.utils.events INFO:  eta: 0:47:29  iter: 22479  total_loss: 3.204  loss_ce: 0.0001648  loss_mask: 0.1215  loss_dice: 0.1857  loss_ce_0: 0.1161  loss_mask_0: 0.1202  loss_dice_0: 0.1854  loss_ce_1: 0.0001363  loss_mask_1: 0.1218  loss_dice_1: 0.1894  loss_ce_2: 0.0001835  loss_mask_2: 0.121  loss_dice_2: 0.1907  loss_ce_3: 0.0001211  loss_mask_3: 0.1205  loss_dice_3: 0.1834  loss_ce_4: 0.0001384  loss_mask_4: 0.1198  loss_dice_4: 0.1852  loss_ce_5: 0.000282  loss_mask_5: 0.1229  loss_dice_5: 0.189  loss_ce_6: 6.576e-05  loss_mask_6: 0.1215  loss_dice_6: 0.1883  loss_ce_7: 0.0001714  loss_mask_7: 0.1196  loss_dice_7: 0.1896  loss_ce_8: 0.0002319  loss_mask_8: 0.12  loss_dice_8: 0.186  time: 0.6436  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:45:31] d2.utils.events INFO:  eta: 0:47:24  iter: 22499  total_loss: 3.069  loss_ce: 0.000152  loss_mask: 0.1175  loss_dice: 0.1709  loss_ce_0: 0.1155  loss_mask_0: 0.1179  loss_dice_0: 0.1796  loss_ce_1: 0.0001045  loss_mask_1: 0.1196  loss_dice_1: 0.1772  loss_ce_2: 0.0001319  loss_mask_2: 0.1168  loss_dice_2: 0.1703  loss_ce_3: 8.034e-05  loss_mask_3: 0.1156  loss_dice_3: 0.167  loss_ce_4: 0.0001255  loss_mask_4: 0.1163  loss_dice_4: 0.1696  loss_ce_5: 0.0002161  loss_mask_5: 0.1177  loss_dice_5: 0.1722  loss_ce_6: 6.702e-05  loss_mask_6: 0.1177  loss_dice_6: 0.1719  loss_ce_7: 9.072e-05  loss_mask_7: 0.1174  loss_dice_7: 0.1734  loss_ce_8: 0.0001716  loss_mask_8: 0.1147  loss_dice_8: 0.1726  time: 0.6432  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:45:35] d2.utils.events INFO:  eta: 0:47:20  iter: 22519  total_loss: 3.27  loss_ce: 0.0001401  loss_mask: 0.1148  loss_dice: 0.1922  loss_ce_0: 0.1129  loss_mask_0: 0.1167  loss_dice_0: 0.2001  loss_ce_1: 0.0001093  loss_mask_1: 0.1157  loss_dice_1: 0.2064  loss_ce_2: 0.0001555  loss_mask_2: 0.1146  loss_dice_2: 0.1963  loss_ce_3: 9.707e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1962  loss_ce_4: 0.0001274  loss_mask_4: 0.116  loss_dice_4: 0.1985  loss_ce_5: 0.0002327  loss_mask_5: 0.1166  loss_dice_5: 0.1999  loss_ce_6: 6.313e-05  loss_mask_6: 0.1141  loss_dice_6: 0.1968  loss_ce_7: 0.00015  loss_mask_7: 0.1207  loss_dice_7: 0.1949  loss_ce_8: 0.0001669  loss_mask_8: 0.1157  loss_dice_8: 0.2006  time: 0.6428  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:45:40] d2.utils.events INFO:  eta: 0:47:15  iter: 22539  total_loss: 3.081  loss_ce: 0.0001249  loss_mask: 0.1089  loss_dice: 0.1787  loss_ce_0: 0.1145  loss_mask_0: 0.1125  loss_dice_0: 0.1798  loss_ce_1: 9.971e-05  loss_mask_1: 0.1134  loss_dice_1: 0.1757  loss_ce_2: 0.0001271  loss_mask_2: 0.1123  loss_dice_2: 0.1817  loss_ce_3: 9.739e-05  loss_mask_3: 0.112  loss_dice_3: 0.1769  loss_ce_4: 0.0001178  loss_mask_4: 0.1127  loss_dice_4: 0.1838  loss_ce_5: 0.0001943  loss_mask_5: 0.1134  loss_dice_5: 0.1771  loss_ce_6: 7.707e-05  loss_mask_6: 0.1135  loss_dice_6: 0.1796  loss_ce_7: 0.0001596  loss_mask_7: 0.1126  loss_dice_7: 0.1806  loss_ce_8: 0.0001564  loss_mask_8: 0.112  loss_dice_8: 0.1711  time: 0.6425  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:45:44] d2.utils.events INFO:  eta: 0:47:08  iter: 22559  total_loss: 2.931  loss_ce: 0.0001254  loss_mask: 0.112  loss_dice: 0.1602  loss_ce_0: 0.1301  loss_mask_0: 0.1126  loss_dice_0: 0.1686  loss_ce_1: 9.162e-05  loss_mask_1: 0.1117  loss_dice_1: 0.1633  loss_ce_2: 0.0001065  loss_mask_2: 0.1138  loss_dice_2: 0.1617  loss_ce_3: 7.5e-05  loss_mask_3: 0.1124  loss_dice_3: 0.1677  loss_ce_4: 0.0001045  loss_mask_4: 0.1118  loss_dice_4: 0.1645  loss_ce_5: 0.0001126  loss_mask_5: 0.1097  loss_dice_5: 0.1684  loss_ce_6: 5.953e-05  loss_mask_6: 0.1152  loss_dice_6: 0.1659  loss_ce_7: 7.075e-05  loss_mask_7: 0.11  loss_dice_7: 0.1613  loss_ce_8: 0.0001263  loss_mask_8: 0.1132  loss_dice_8: 0.1669  time: 0.6421  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:45:49] d2.utils.events INFO:  eta: 0:47:04  iter: 22579  total_loss: 3.41  loss_ce: 0.000108  loss_mask: 0.1217  loss_dice: 0.2108  loss_ce_0: 0.1218  loss_mask_0: 0.1202  loss_dice_0: 0.2031  loss_ce_1: 8.425e-05  loss_mask_1: 0.1215  loss_dice_1: 0.2058  loss_ce_2: 0.0001231  loss_mask_2: 0.1176  loss_dice_2: 0.2  loss_ce_3: 8.681e-05  loss_mask_3: 0.12  loss_dice_3: 0.204  loss_ce_4: 0.0001064  loss_mask_4: 0.1198  loss_dice_4: 0.1954  loss_ce_5: 0.0001304  loss_mask_5: 0.1195  loss_dice_5: 0.2062  loss_ce_6: 5.858e-05  loss_mask_6: 0.1204  loss_dice_6: 0.2115  loss_ce_7: 0.0001086  loss_mask_7: 0.1192  loss_dice_7: 0.2004  loss_ce_8: 0.0001281  loss_mask_8: 0.1213  loss_dice_8: 0.2136  time: 0.6417  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:45:53] d2.utils.events INFO:  eta: 0:47:00  iter: 22599  total_loss: 2.944  loss_ce: 0.0001018  loss_mask: 0.1096  loss_dice: 0.1747  loss_ce_0: 0.125  loss_mask_0: 0.1126  loss_dice_0: 0.174  loss_ce_1: 7.606e-05  loss_mask_1: 0.1137  loss_dice_1: 0.1765  loss_ce_2: 0.0001089  loss_mask_2: 0.1104  loss_dice_2: 0.1784  loss_ce_3: 6.909e-05  loss_mask_3: 0.1109  loss_dice_3: 0.1701  loss_ce_4: 9.617e-05  loss_mask_4: 0.11  loss_dice_4: 0.168  loss_ce_5: 9.819e-05  loss_mask_5: 0.1132  loss_dice_5: 0.1762  loss_ce_6: 5.38e-05  loss_mask_6: 0.1122  loss_dice_6: 0.1775  loss_ce_7: 6.411e-05  loss_mask_7: 0.1118  loss_dice_7: 0.1748  loss_ce_8: 0.0001169  loss_mask_8: 0.1109  loss_dice_8: 0.1726  time: 0.6414  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:45:58] d2.utils.events INFO:  eta: 0:46:54  iter: 22619  total_loss: 3.044  loss_ce: 0.0001177  loss_mask: 0.1158  loss_dice: 0.1759  loss_ce_0: 0.1189  loss_mask_0: 0.1181  loss_dice_0: 0.1783  loss_ce_1: 0.0001091  loss_mask_1: 0.1163  loss_dice_1: 0.1741  loss_ce_2: 0.0001094  loss_mask_2: 0.117  loss_dice_2: 0.1753  loss_ce_3: 8.275e-05  loss_mask_3: 0.1125  loss_dice_3: 0.1732  loss_ce_4: 0.0001058  loss_mask_4: 0.1156  loss_dice_4: 0.1754  loss_ce_5: 0.000143  loss_mask_5: 0.1148  loss_dice_5: 0.1745  loss_ce_6: 5.577e-05  loss_mask_6: 0.1158  loss_dice_6: 0.1776  loss_ce_7: 0.0001298  loss_mask_7: 0.1141  loss_dice_7: 0.172  loss_ce_8: 0.0001183  loss_mask_8: 0.1169  loss_dice_8: 0.1775  time: 0.6410  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:46:02] d2.utils.events INFO:  eta: 0:46:52  iter: 22639  total_loss: 2.986  loss_ce: 0.0001106  loss_mask: 0.1146  loss_dice: 0.1756  loss_ce_0: 0.1198  loss_mask_0: 0.1132  loss_dice_0: 0.1677  loss_ce_1: 8.994e-05  loss_mask_1: 0.1158  loss_dice_1: 0.171  loss_ce_2: 0.0001143  loss_mask_2: 0.1138  loss_dice_2: 0.1746  loss_ce_3: 8.808e-05  loss_mask_3: 0.1119  loss_dice_3: 0.1725  loss_ce_4: 8.644e-05  loss_mask_4: 0.1155  loss_dice_4: 0.174  loss_ce_5: 0.0001331  loss_mask_5: 0.1118  loss_dice_5: 0.167  loss_ce_6: 5.889e-05  loss_mask_6: 0.1145  loss_dice_6: 0.1712  loss_ce_7: 0.0001121  loss_mask_7: 0.1112  loss_dice_7: 0.1725  loss_ce_8: 0.0001121  loss_mask_8: 0.1099  loss_dice_8: 0.1758  time: 0.6406  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:46:07] d2.utils.events INFO:  eta: 0:46:48  iter: 22659  total_loss: 2.927  loss_ce: 9.451e-05  loss_mask: 0.1125  loss_dice: 0.1741  loss_ce_0: 0.1248  loss_mask_0: 0.1099  loss_dice_0: 0.1692  loss_ce_1: 7.587e-05  loss_mask_1: 0.1161  loss_dice_1: 0.1747  loss_ce_2: 9.304e-05  loss_mask_2: 0.108  loss_dice_2: 0.1757  loss_ce_3: 6.926e-05  loss_mask_3: 0.1139  loss_dice_3: 0.1744  loss_ce_4: 7.173e-05  loss_mask_4: 0.1142  loss_dice_4: 0.175  loss_ce_5: 0.0001191  loss_mask_5: 0.1145  loss_dice_5: 0.1846  loss_ce_6: 5.866e-05  loss_mask_6: 0.1129  loss_dice_6: 0.1781  loss_ce_7: 0.0001147  loss_mask_7: 0.1144  loss_dice_7: 0.181  loss_ce_8: 0.0001086  loss_mask_8: 0.1099  loss_dice_8: 0.1813  time: 0.6403  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:46:11] d2.utils.events INFO:  eta: 0:46:44  iter: 22679  total_loss: 2.979  loss_ce: 9.182e-05  loss_mask: 0.114  loss_dice: 0.167  loss_ce_0: 0.1187  loss_mask_0: 0.1152  loss_dice_0: 0.1718  loss_ce_1: 6.495e-05  loss_mask_1: 0.1132  loss_dice_1: 0.1726  loss_ce_2: 8.867e-05  loss_mask_2: 0.1163  loss_dice_2: 0.1751  loss_ce_3: 6.143e-05  loss_mask_3: 0.1147  loss_dice_3: 0.166  loss_ce_4: 6.346e-05  loss_mask_4: 0.1128  loss_dice_4: 0.1742  loss_ce_5: 8.097e-05  loss_mask_5: 0.1131  loss_dice_5: 0.1685  loss_ce_6: 5.362e-05  loss_mask_6: 0.1158  loss_dice_6: 0.1756  loss_ce_7: 5.974e-05  loss_mask_7: 0.117  loss_dice_7: 0.1755  loss_ce_8: 9.976e-05  loss_mask_8: 0.1187  loss_dice_8: 0.1757  time: 0.6399  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:46:16] d2.utils.events INFO:  eta: 0:46:44  iter: 22699  total_loss: 3.176  loss_ce: 8.802e-05  loss_mask: 0.1187  loss_dice: 0.1795  loss_ce_0: 0.1286  loss_mask_0: 0.1216  loss_dice_0: 0.1845  loss_ce_1: 5.912e-05  loss_mask_1: 0.1177  loss_dice_1: 0.1853  loss_ce_2: 9.041e-05  loss_mask_2: 0.1181  loss_dice_2: 0.19  loss_ce_3: 7.615e-05  loss_mask_3: 0.1155  loss_dice_3: 0.1854  loss_ce_4: 6.141e-05  loss_mask_4: 0.1171  loss_dice_4: 0.1813  loss_ce_5: 7.588e-05  loss_mask_5: 0.1172  loss_dice_5: 0.1846  loss_ce_6: 3.758e-05  loss_mask_6: 0.1149  loss_dice_6: 0.1849  loss_ce_7: 5.246e-05  loss_mask_7: 0.1117  loss_dice_7: 0.1814  loss_ce_8: 9.332e-05  loss_mask_8: 0.1174  loss_dice_8: 0.1874  time: 0.6395  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:46:20] d2.utils.events INFO:  eta: 0:46:40  iter: 22719  total_loss: 3.1  loss_ce: 9.117e-05  loss_mask: 0.114  loss_dice: 0.1823  loss_ce_0: 0.1271  loss_mask_0: 0.1158  loss_dice_0: 0.1745  loss_ce_1: 7.058e-05  loss_mask_1: 0.1174  loss_dice_1: 0.1793  loss_ce_2: 8.286e-05  loss_mask_2: 0.1155  loss_dice_2: 0.1786  loss_ce_3: 6.673e-05  loss_mask_3: 0.1132  loss_dice_3: 0.1738  loss_ce_4: 6.672e-05  loss_mask_4: 0.1178  loss_dice_4: 0.1734  loss_ce_5: 9.07e-05  loss_mask_5: 0.1194  loss_dice_5: 0.1789  loss_ce_6: 5.971e-05  loss_mask_6: 0.1143  loss_dice_6: 0.1809  loss_ce_7: 7.568e-05  loss_mask_7: 0.1168  loss_dice_7: 0.1798  loss_ce_8: 9.432e-05  loss_mask_8: 0.1144  loss_dice_8: 0.1783  time: 0.6392  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:46:25] d2.utils.events INFO:  eta: 0:46:36  iter: 22739  total_loss: 3.159  loss_ce: 7.97e-05  loss_mask: 0.1206  loss_dice: 0.1816  loss_ce_0: 0.1231  loss_mask_0: 0.1203  loss_dice_0: 0.1823  loss_ce_1: 6.514e-05  loss_mask_1: 0.1203  loss_dice_1: 0.1788  loss_ce_2: 8.541e-05  loss_mask_2: 0.1198  loss_dice_2: 0.1771  loss_ce_3: 5.613e-05  loss_mask_3: 0.1173  loss_dice_3: 0.1728  loss_ce_4: 5.779e-05  loss_mask_4: 0.1198  loss_dice_4: 0.1771  loss_ce_5: 7.786e-05  loss_mask_5: 0.116  loss_dice_5: 0.1749  loss_ce_6: 4.983e-05  loss_mask_6: 0.1186  loss_dice_6: 0.1789  loss_ce_7: 5.76e-05  loss_mask_7: 0.12  loss_dice_7: 0.182  loss_ce_8: 9.127e-05  loss_mask_8: 0.1203  loss_dice_8: 0.1835  time: 0.6388  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:46:29] d2.utils.events INFO:  eta: 0:46:32  iter: 22759  total_loss: 2.991  loss_ce: 9.11e-05  loss_mask: 0.1089  loss_dice: 0.1764  loss_ce_0: 0.1273  loss_mask_0: 0.1103  loss_dice_0: 0.1823  loss_ce_1: 6.88e-05  loss_mask_1: 0.1121  loss_dice_1: 0.1746  loss_ce_2: 8.008e-05  loss_mask_2: 0.1146  loss_dice_2: 0.1788  loss_ce_3: 6.316e-05  loss_mask_3: 0.1084  loss_dice_3: 0.1699  loss_ce_4: 7.206e-05  loss_mask_4: 0.112  loss_dice_4: 0.1728  loss_ce_5: 9.958e-05  loss_mask_5: 0.1082  loss_dice_5: 0.1745  loss_ce_6: 6.122e-05  loss_mask_6: 0.1116  loss_dice_6: 0.1729  loss_ce_7: 9.783e-05  loss_mask_7: 0.1099  loss_dice_7: 0.177  loss_ce_8: 9.179e-05  loss_mask_8: 0.1145  loss_dice_8: 0.179  time: 0.6384  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:46:34] d2.utils.events INFO:  eta: 0:46:30  iter: 22779  total_loss: 2.981  loss_ce: 7.522e-05  loss_mask: 0.1156  loss_dice: 0.1694  loss_ce_0: 0.1267  loss_mask_0: 0.1105  loss_dice_0: 0.1725  loss_ce_1: 6.829e-05  loss_mask_1: 0.1161  loss_dice_1: 0.1745  loss_ce_2: 8.087e-05  loss_mask_2: 0.1136  loss_dice_2: 0.1686  loss_ce_3: 5.449e-05  loss_mask_3: 0.1102  loss_dice_3: 0.1624  loss_ce_4: 5.913e-05  loss_mask_4: 0.1111  loss_dice_4: 0.1725  loss_ce_5: 8.548e-05  loss_mask_5: 0.1091  loss_dice_5: 0.1723  loss_ce_6: 4.93e-05  loss_mask_6: 0.113  loss_dice_6: 0.1721  loss_ce_7: 7.622e-05  loss_mask_7: 0.1131  loss_dice_7: 0.1794  loss_ce_8: 8.924e-05  loss_mask_8: 0.1138  loss_dice_8: 0.1755  time: 0.6381  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:46:38] d2.utils.events INFO:  eta: 0:46:23  iter: 22799  total_loss: 3.003  loss_ce: 7.099e-05  loss_mask: 0.1134  loss_dice: 0.1789  loss_ce_0: 0.121  loss_mask_0: 0.1155  loss_dice_0: 0.1768  loss_ce_1: 6.342e-05  loss_mask_1: 0.1196  loss_dice_1: 0.1803  loss_ce_2: 8.463e-05  loss_mask_2: 0.1117  loss_dice_2: 0.1772  loss_ce_3: 5.956e-05  loss_mask_3: 0.1149  loss_dice_3: 0.1777  loss_ce_4: 5.391e-05  loss_mask_4: 0.1139  loss_dice_4: 0.1783  loss_ce_5: 7.321e-05  loss_mask_5: 0.1147  loss_dice_5: 0.1787  loss_ce_6: 5.737e-05  loss_mask_6: 0.1139  loss_dice_6: 0.1767  loss_ce_7: 5.549e-05  loss_mask_7: 0.1153  loss_dice_7: 0.1749  loss_ce_8: 8.422e-05  loss_mask_8: 0.1126  loss_dice_8: 0.179  time: 0.6377  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:46:43] d2.utils.events INFO:  eta: 0:46:18  iter: 22819  total_loss: 3.063  loss_ce: 7.894e-05  loss_mask: 0.1194  loss_dice: 0.1829  loss_ce_0: 0.1242  loss_mask_0: 0.1168  loss_dice_0: 0.1804  loss_ce_1: 6.696e-05  loss_mask_1: 0.1185  loss_dice_1: 0.1783  loss_ce_2: 7.276e-05  loss_mask_2: 0.1158  loss_dice_2: 0.1708  loss_ce_3: 5.457e-05  loss_mask_3: 0.1182  loss_dice_3: 0.1772  loss_ce_4: 6.605e-05  loss_mask_4: 0.1156  loss_dice_4: 0.1757  loss_ce_5: 8.796e-05  loss_mask_5: 0.1143  loss_dice_5: 0.176  loss_ce_6: 6.057e-05  loss_mask_6: 0.1171  loss_dice_6: 0.1786  loss_ce_7: 8.893e-05  loss_mask_7: 0.1152  loss_dice_7: 0.1793  loss_ce_8: 8.46e-05  loss_mask_8: 0.1152  loss_dice_8: 0.1813  time: 0.6374  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:46:47] d2.utils.events INFO:  eta: 0:46:13  iter: 22839  total_loss: 2.951  loss_ce: 6.589e-05  loss_mask: 0.1141  loss_dice: 0.1723  loss_ce_0: 0.1183  loss_mask_0: 0.1134  loss_dice_0: 0.1737  loss_ce_1: 4.952e-05  loss_mask_1: 0.1153  loss_dice_1: 0.1692  loss_ce_2: 8.302e-05  loss_mask_2: 0.1131  loss_dice_2: 0.1708  loss_ce_3: 5.274e-05  loss_mask_3: 0.1066  loss_dice_3: 0.162  loss_ce_4: 4.768e-05  loss_mask_4: 0.1176  loss_dice_4: 0.1696  loss_ce_5: 6.79e-05  loss_mask_5: 0.1112  loss_dice_5: 0.164  loss_ce_6: 4.444e-05  loss_mask_6: 0.1114  loss_dice_6: 0.1703  loss_ce_7: 5.017e-05  loss_mask_7: 0.1139  loss_dice_7: 0.1701  loss_ce_8: 8.096e-05  loss_mask_8: 0.1149  loss_dice_8: 0.1735  time: 0.6370  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:46:52] d2.utils.events INFO:  eta: 0:46:08  iter: 22859  total_loss: 3.192  loss_ce: 6.916e-05  loss_mask: 0.1159  loss_dice: 0.1957  loss_ce_0: 0.1266  loss_mask_0: 0.1172  loss_dice_0: 0.1961  loss_ce_1: 5.44e-05  loss_mask_1: 0.1146  loss_dice_1: 0.1797  loss_ce_2: 7.276e-05  loss_mask_2: 0.1182  loss_dice_2: 0.1833  loss_ce_3: 5.923e-05  loss_mask_3: 0.1163  loss_dice_3: 0.1843  loss_ce_4: 5.424e-05  loss_mask_4: 0.1155  loss_dice_4: 0.1879  loss_ce_5: 7.275e-05  loss_mask_5: 0.1166  loss_dice_5: 0.1876  loss_ce_6: 4.985e-05  loss_mask_6: 0.1137  loss_dice_6: 0.1822  loss_ce_7: 6.734e-05  loss_mask_7: 0.1116  loss_dice_7: 0.194  loss_ce_8: 7.85e-05  loss_mask_8: 0.1132  loss_dice_8: 0.1887  time: 0.6366  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:46:57] d2.utils.events INFO:  eta: 0:46:05  iter: 22879  total_loss: 3.085  loss_ce: 5.632e-05  loss_mask: 0.109  loss_dice: 0.1924  loss_ce_0: 0.1295  loss_mask_0: 0.1133  loss_dice_0: 0.1801  loss_ce_1: 5.587e-05  loss_mask_1: 0.1074  loss_dice_1: 0.1795  loss_ce_2: 5.174e-05  loss_mask_2: 0.1098  loss_dice_2: 0.1818  loss_ce_3: 5.009e-05  loss_mask_3: 0.1047  loss_dice_3: 0.1694  loss_ce_4: 4.535e-05  loss_mask_4: 0.1105  loss_dice_4: 0.1811  loss_ce_5: 4.777e-05  loss_mask_5: 0.1067  loss_dice_5: 0.1834  loss_ce_6: 2.642e-05  loss_mask_6: 0.1102  loss_dice_6: 0.1844  loss_ce_7: 4.042e-05  loss_mask_7: 0.1087  loss_dice_7: 0.1922  loss_ce_8: 6.035e-05  loss_mask_8: 0.107  loss_dice_8: 0.1893  time: 0.6363  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:47:01] d2.utils.events INFO:  eta: 0:46:01  iter: 22899  total_loss: 3.12  loss_ce: 6.714e-05  loss_mask: 0.1158  loss_dice: 0.175  loss_ce_0: 0.1235  loss_mask_0: 0.1123  loss_dice_0: 0.1741  loss_ce_1: 5.718e-05  loss_mask_1: 0.1164  loss_dice_1: 0.1776  loss_ce_2: 7.195e-05  loss_mask_2: 0.1149  loss_dice_2: 0.1739  loss_ce_3: 5.243e-05  loss_mask_3: 0.1139  loss_dice_3: 0.1735  loss_ce_4: 5.128e-05  loss_mask_4: 0.117  loss_dice_4: 0.1761  loss_ce_5: 6.949e-05  loss_mask_5: 0.1117  loss_dice_5: 0.172  loss_ce_6: 5.071e-05  loss_mask_6: 0.1182  loss_dice_6: 0.1792  loss_ce_7: 5.811e-05  loss_mask_7: 0.1126  loss_dice_7: 0.176  loss_ce_8: 7.466e-05  loss_mask_8: 0.1174  loss_dice_8: 0.1794  time: 0.6359  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:47:06] d2.utils.events INFO:  eta: 0:45:57  iter: 22919  total_loss: 3.059  loss_ce: 5.961e-05  loss_mask: 0.1159  loss_dice: 0.1798  loss_ce_0: 0.1227  loss_mask_0: 0.1186  loss_dice_0: 0.1736  loss_ce_1: 5.146e-05  loss_mask_1: 0.1175  loss_dice_1: 0.1834  loss_ce_2: 6.331e-05  loss_mask_2: 0.1165  loss_dice_2: 0.1799  loss_ce_3: 4.976e-05  loss_mask_3: 0.1163  loss_dice_3: 0.1796  loss_ce_4: 4.323e-05  loss_mask_4: 0.1161  loss_dice_4: 0.1742  loss_ce_5: 5.969e-05  loss_mask_5: 0.118  loss_dice_5: 0.1808  loss_ce_6: 3.57e-05  loss_mask_6: 0.1172  loss_dice_6: 0.1763  loss_ce_7: 4.315e-05  loss_mask_7: 0.1152  loss_dice_7: 0.1716  loss_ce_8: 7.037e-05  loss_mask_8: 0.1161  loss_dice_8: 0.1727  time: 0.6356  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:47:10] d2.utils.events INFO:  eta: 0:45:53  iter: 22939  total_loss: 2.895  loss_ce: 6.37e-05  loss_mask: 0.1128  loss_dice: 0.1617  loss_ce_0: 0.1183  loss_mask_0: 0.1096  loss_dice_0: 0.166  loss_ce_1: 4.909e-05  loss_mask_1: 0.1125  loss_dice_1: 0.1633  loss_ce_2: 7.061e-05  loss_mask_2: 0.1165  loss_dice_2: 0.1677  loss_ce_3: 5.083e-05  loss_mask_3: 0.1115  loss_dice_3: 0.1668  loss_ce_4: 4.73e-05  loss_mask_4: 0.116  loss_dice_4: 0.1655  loss_ce_5: 6.907e-05  loss_mask_5: 0.1107  loss_dice_5: 0.1656  loss_ce_6: 4.457e-05  loss_mask_6: 0.1136  loss_dice_6: 0.1675  loss_ce_7: 5.692e-05  loss_mask_7: 0.1146  loss_dice_7: 0.1634  loss_ce_8: 7.105e-05  loss_mask_8: 0.1107  loss_dice_8: 0.1679  time: 0.6352  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:47:15] d2.utils.events INFO:  eta: 0:45:50  iter: 22959  total_loss: 3.024  loss_ce: 6.629e-05  loss_mask: 0.1164  loss_dice: 0.1734  loss_ce_0: 0.1198  loss_mask_0: 0.1166  loss_dice_0: 0.1689  loss_ce_1: 4.782e-05  loss_mask_1: 0.1176  loss_dice_1: 0.175  loss_ce_2: 6.447e-05  loss_mask_2: 0.1163  loss_dice_2: 0.1716  loss_ce_3: 6.773e-05  loss_mask_3: 0.1141  loss_dice_3: 0.1687  loss_ce_4: 4.673e-05  loss_mask_4: 0.1141  loss_dice_4: 0.1691  loss_ce_5: 6.638e-05  loss_mask_5: 0.1153  loss_dice_5: 0.167  loss_ce_6: 4.846e-05  loss_mask_6: 0.1189  loss_dice_6: 0.1717  loss_ce_7: 5.062e-05  loss_mask_7: 0.1139  loss_dice_7: 0.168  loss_ce_8: 7.009e-05  loss_mask_8: 0.117  loss_dice_8: 0.172  time: 0.6349  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:47:19] d2.utils.events INFO:  eta: 0:45:44  iter: 22979  total_loss: 3.057  loss_ce: 5.57e-05  loss_mask: 0.1116  loss_dice: 0.1785  loss_ce_0: 0.1236  loss_mask_0: 0.1085  loss_dice_0: 0.178  loss_ce_1: 4.82e-05  loss_mask_1: 0.1106  loss_dice_1: 0.1679  loss_ce_2: 5.851e-05  loss_mask_2: 0.1104  loss_dice_2: 0.1756  loss_ce_3: 4.631e-05  loss_mask_3: 0.1146  loss_dice_3: 0.1708  loss_ce_4: 4.266e-05  loss_mask_4: 0.1119  loss_dice_4: 0.172  loss_ce_5: 5.799e-05  loss_mask_5: 0.1116  loss_dice_5: 0.1737  loss_ce_6: 4.504e-05  loss_mask_6: 0.1163  loss_dice_6: 0.171  loss_ce_7: 4.178e-05  loss_mask_7: 0.1098  loss_dice_7: 0.1818  loss_ce_8: 6.4e-05  loss_mask_8: 0.1161  loss_dice_8: 0.1793  time: 0.6345  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:47:24] d2.utils.events INFO:  eta: 0:45:41  iter: 22999  total_loss: 3.351  loss_ce: 5.667e-05  loss_mask: 0.118  loss_dice: 0.2075  loss_ce_0: 0.1216  loss_mask_0: 0.1188  loss_dice_0: 0.2024  loss_ce_1: 4.897e-05  loss_mask_1: 0.1213  loss_dice_1: 0.1979  loss_ce_2: 6.15e-05  loss_mask_2: 0.1162  loss_dice_2: 0.1975  loss_ce_3: 4.531e-05  loss_mask_3: 0.1184  loss_dice_3: 0.2001  loss_ce_4: 4.333e-05  loss_mask_4: 0.1193  loss_dice_4: 0.1999  loss_ce_5: 6.083e-05  loss_mask_5: 0.1198  loss_dice_5: 0.2082  loss_ce_6: 4.231e-05  loss_mask_6: 0.1227  loss_dice_6: 0.2069  loss_ce_7: 5.24e-05  loss_mask_7: 0.118  loss_dice_7: 0.21  loss_ce_8: 6.614e-05  loss_mask_8: 0.1157  loss_dice_8: 0.2045  time: 0.6341  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:47:28] d2.utils.events INFO:  eta: 0:45:37  iter: 23019  total_loss: 3.356  loss_ce: 5.052e-05  loss_mask: 0.1168  loss_dice: 0.2113  loss_ce_0: 0.1231  loss_mask_0: 0.1147  loss_dice_0: 0.202  loss_ce_1: 4.05e-05  loss_mask_1: 0.1089  loss_dice_1: 0.2081  loss_ce_2: 5.636e-05  loss_mask_2: 0.1166  loss_dice_2: 0.2055  loss_ce_3: 4.014e-05  loss_mask_3: 0.1107  loss_dice_3: 0.1976  loss_ce_4: 3.918e-05  loss_mask_4: 0.1185  loss_dice_4: 0.1974  loss_ce_5: 5.484e-05  loss_mask_5: 0.1149  loss_dice_5: 0.202  loss_ce_6: 3.191e-05  loss_mask_6: 0.1197  loss_dice_6: 0.2048  loss_ce_7: 3.909e-05  loss_mask_7: 0.1162  loss_dice_7: 0.2083  loss_ce_8: 6.113e-05  loss_mask_8: 0.1184  loss_dice_8: 0.2063  time: 0.6338  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:47:33] d2.utils.events INFO:  eta: 0:45:34  iter: 23039  total_loss: 2.912  loss_ce: 5.377e-05  loss_mask: 0.1142  loss_dice: 0.1695  loss_ce_0: 0.1246  loss_mask_0: 0.1124  loss_dice_0: 0.1659  loss_ce_1: 4.875e-05  loss_mask_1: 0.1135  loss_dice_1: 0.1757  loss_ce_2: 5.635e-05  loss_mask_2: 0.1135  loss_dice_2: 0.1757  loss_ce_3: 4.565e-05  loss_mask_3: 0.1138  loss_dice_3: 0.1718  loss_ce_4: 4.542e-05  loss_mask_4: 0.1137  loss_dice_4: 0.1629  loss_ce_5: 6.347e-05  loss_mask_5: 0.1075  loss_dice_5: 0.1627  loss_ce_6: 3.953e-05  loss_mask_6: 0.1098  loss_dice_6: 0.1685  loss_ce_7: 6.337e-05  loss_mask_7: 0.1142  loss_dice_7: 0.1725  loss_ce_8: 6.549e-05  loss_mask_8: 0.1101  loss_dice_8: 0.1772  time: 0.6334  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:47:37] d2.utils.events INFO:  eta: 0:45:27  iter: 23059  total_loss: 3.174  loss_ce: 4.856e-05  loss_mask: 0.1169  loss_dice: 0.1857  loss_ce_0: 0.1269  loss_mask_0: 0.113  loss_dice_0: 0.183  loss_ce_1: 4.409e-05  loss_mask_1: 0.1135  loss_dice_1: 0.18  loss_ce_2: 5.829e-05  loss_mask_2: 0.1176  loss_dice_2: 0.1787  loss_ce_3: 4.012e-05  loss_mask_3: 0.1157  loss_dice_3: 0.188  loss_ce_4: 3.888e-05  loss_mask_4: 0.1137  loss_dice_4: 0.1784  loss_ce_5: 5.297e-05  loss_mask_5: 0.1131  loss_dice_5: 0.1791  loss_ce_6: 3.576e-05  loss_mask_6: 0.1167  loss_dice_6: 0.1811  loss_ce_7: 3.657e-05  loss_mask_7: 0.1169  loss_dice_7: 0.1947  loss_ce_8: 6.111e-05  loss_mask_8: 0.115  loss_dice_8: 0.1917  time: 0.6331  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:47:41] d2.utils.events INFO:  eta: 0:45:17  iter: 23079  total_loss: 2.891  loss_ce: 5.065e-05  loss_mask: 0.1069  loss_dice: 0.1682  loss_ce_0: 0.1305  loss_mask_0: 0.1055  loss_dice_0: 0.1646  loss_ce_1: 4.508e-05  loss_mask_1: 0.1077  loss_dice_1: 0.1712  loss_ce_2: 4.68e-05  loss_mask_2: 0.1081  loss_dice_2: 0.1648  loss_ce_3: 4.668e-05  loss_mask_3: 0.1064  loss_dice_3: 0.1641  loss_ce_4: 3.817e-05  loss_mask_4: 0.1077  loss_dice_4: 0.1671  loss_ce_5: 4.734e-05  loss_mask_5: 0.1084  loss_dice_5: 0.1671  loss_ce_6: 3.603e-05  loss_mask_6: 0.1067  loss_dice_6: 0.1659  loss_ce_7: 3.801e-05  loss_mask_7: 0.1067  loss_dice_7: 0.1708  loss_ce_8: 5.504e-05  loss_mask_8: 0.1069  loss_dice_8: 0.1759  time: 0.6327  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:47:45] d2.utils.events INFO:  eta: 0:45:02  iter: 23099  total_loss: 2.965  loss_ce: 4.55e-05  loss_mask: 0.1094  loss_dice: 0.1716  loss_ce_0: 0.1257  loss_mask_0: 0.1094  loss_dice_0: 0.1714  loss_ce_1: 4.861e-05  loss_mask_1: 0.1131  loss_dice_1: 0.177  loss_ce_2: 5.008e-05  loss_mask_2: 0.1095  loss_dice_2: 0.1686  loss_ce_3: 3.851e-05  loss_mask_3: 0.114  loss_dice_3: 0.1798  loss_ce_4: 3.896e-05  loss_mask_4: 0.1106  loss_dice_4: 0.1649  loss_ce_5: 5.683e-05  loss_mask_5: 0.1139  loss_dice_5: 0.1745  loss_ce_6: 3.644e-05  loss_mask_6: 0.1114  loss_dice_6: 0.1731  loss_ce_7: 5.154e-05  loss_mask_7: 0.1115  loss_dice_7: 0.1705  loss_ce_8: 5.79e-05  loss_mask_8: 0.1122  loss_dice_8: 0.1675  time: 0.6323  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:47:48] d2.utils.events INFO:  eta: 0:44:49  iter: 23119  total_loss: 3.108  loss_ce: 4.932e-05  loss_mask: 0.1114  loss_dice: 0.1823  loss_ce_0: 0.1352  loss_mask_0: 0.1114  loss_dice_0: 0.1832  loss_ce_1: 3.804e-05  loss_mask_1: 0.113  loss_dice_1: 0.1884  loss_ce_2: 4.281e-05  loss_mask_2: 0.1126  loss_dice_2: 0.1848  loss_ce_3: 4.082e-05  loss_mask_3: 0.1155  loss_dice_3: 0.1831  loss_ce_4: 3.478e-05  loss_mask_4: 0.1153  loss_dice_4: 0.1869  loss_ce_5: 4.337e-05  loss_mask_5: 0.1147  loss_dice_5: 0.1846  loss_ce_6: 3.306e-05  loss_mask_6: 0.1168  loss_dice_6: 0.1874  loss_ce_7: 3.412e-05  loss_mask_7: 0.1137  loss_dice_7: 0.1873  loss_ce_8: 5.118e-05  loss_mask_8: 0.1151  loss_dice_8: 0.194  time: 0.6319  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:47:52] d2.utils.events INFO:  eta: 0:44:34  iter: 23139  total_loss: 3.178  loss_ce: 4.423e-05  loss_mask: 0.1108  loss_dice: 0.1902  loss_ce_0: 0.1296  loss_mask_0: 0.1115  loss_dice_0: 0.1896  loss_ce_1: 3.793e-05  loss_mask_1: 0.1196  loss_dice_1: 0.1889  loss_ce_2: 5.273e-05  loss_mask_2: 0.1152  loss_dice_2: 0.1885  loss_ce_3: 3.554e-05  loss_mask_3: 0.1155  loss_dice_3: 0.1868  loss_ce_4: 3.595e-05  loss_mask_4: 0.1154  loss_dice_4: 0.1851  loss_ce_5: 4.952e-05  loss_mask_5: 0.1136  loss_dice_5: 0.1946  loss_ce_6: 3.142e-05  loss_mask_6: 0.1148  loss_dice_6: 0.1886  loss_ce_7: 3.501e-05  loss_mask_7: 0.1136  loss_dice_7: 0.1862  loss_ce_8: 5.65e-05  loss_mask_8: 0.112  loss_dice_8: 0.1815  time: 0.6315  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:47:56] d2.utils.events INFO:  eta: 0:44:22  iter: 23159  total_loss: 2.989  loss_ce: 5.02e-05  loss_mask: 0.108  loss_dice: 0.175  loss_ce_0: 0.1277  loss_mask_0: 0.1118  loss_dice_0: 0.1789  loss_ce_1: 4.205e-05  loss_mask_1: 0.1121  loss_dice_1: 0.1781  loss_ce_2: 5.409e-05  loss_mask_2: 0.1096  loss_dice_2: 0.1687  loss_ce_3: 4.517e-05  loss_mask_3: 0.1085  loss_dice_3: 0.1715  loss_ce_4: 3.701e-05  loss_mask_4: 0.1082  loss_dice_4: 0.1694  loss_ce_5: 5.139e-05  loss_mask_5: 0.1122  loss_dice_5: 0.172  loss_ce_6: 3.455e-05  loss_mask_6: 0.1111  loss_dice_6: 0.171  loss_ce_7: 4.105e-05  loss_mask_7: 0.1108  loss_dice_7: 0.176  loss_ce_8: 5.5e-05  loss_mask_8: 0.1116  loss_dice_8: 0.1787  time: 0.6311  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:47:59] d2.utils.events INFO:  eta: 0:44:05  iter: 23179  total_loss: 3.068  loss_ce: 3.716e-05  loss_mask: 0.1155  loss_dice: 0.1848  loss_ce_0: 0.125  loss_mask_0: 0.115  loss_dice_0: 0.1756  loss_ce_1: 3.322e-05  loss_mask_1: 0.1174  loss_dice_1: 0.1791  loss_ce_2: 4.026e-05  loss_mask_2: 0.1154  loss_dice_2: 0.1792  loss_ce_3: 2.901e-05  loss_mask_3: 0.117  loss_dice_3: 0.1745  loss_ce_4: 2.953e-05  loss_mask_4: 0.1184  loss_dice_4: 0.1739  loss_ce_5: 3.994e-05  loss_mask_5: 0.1127  loss_dice_5: 0.1757  loss_ce_6: 2.325e-05  loss_mask_6: 0.1135  loss_dice_6: 0.1713  loss_ce_7: 3.098e-05  loss_mask_7: 0.116  loss_dice_7: 0.1789  loss_ce_8: 4.67e-05  loss_mask_8: 0.1139  loss_dice_8: 0.1858  time: 0.6307  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:03] d2.utils.events INFO:  eta: 0:43:50  iter: 23199  total_loss: 2.959  loss_ce: 4.75e-05  loss_mask: 0.1162  loss_dice: 0.1719  loss_ce_0: 0.1237  loss_mask_0: 0.1184  loss_dice_0: 0.1658  loss_ce_1: 3.34e-05  loss_mask_1: 0.1128  loss_dice_1: 0.1714  loss_ce_2: 5.274e-05  loss_mask_2: 0.1139  loss_dice_2: 0.1626  loss_ce_3: 4.25e-05  loss_mask_3: 0.112  loss_dice_3: 0.1636  loss_ce_4: 3.478e-05  loss_mask_4: 0.1127  loss_dice_4: 0.1643  loss_ce_5: 4.702e-05  loss_mask_5: 0.1152  loss_dice_5: 0.1653  loss_ce_6: 3.691e-05  loss_mask_6: 0.1193  loss_dice_6: 0.1685  loss_ce_7: 3.762e-05  loss_mask_7: 0.1141  loss_dice_7: 0.1711  loss_ce_8: 5.335e-05  loss_mask_8: 0.1158  loss_dice_8: 0.167  time: 0.6303  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:06] d2.utils.events INFO:  eta: 0:43:26  iter: 23219  total_loss: 3.07  loss_ce: 4.128e-05  loss_mask: 0.1231  loss_dice: 0.1816  loss_ce_0: 0.1163  loss_mask_0: 0.1262  loss_dice_0: 0.1752  loss_ce_1: 3.176e-05  loss_mask_1: 0.1193  loss_dice_1: 0.1742  loss_ce_2: 5.406e-05  loss_mask_2: 0.1236  loss_dice_2: 0.1745  loss_ce_3: 3.45e-05  loss_mask_3: 0.1231  loss_dice_3: 0.1789  loss_ce_4: 3.525e-05  loss_mask_4: 0.1237  loss_dice_4: 0.1784  loss_ce_5: 4.542e-05  loss_mask_5: 0.1237  loss_dice_5: 0.175  loss_ce_6: 3.131e-05  loss_mask_6: 0.1202  loss_dice_6: 0.1727  loss_ce_7: 3.473e-05  loss_mask_7: 0.124  loss_dice_7: 0.1851  loss_ce_8: 5.231e-05  loss_mask_8: 0.1226  loss_dice_8: 0.1762  time: 0.6300  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:10] d2.utils.events INFO:  eta: 0:43:07  iter: 23239  total_loss: 2.988  loss_ce: 4.269e-05  loss_mask: 0.1149  loss_dice: 0.1742  loss_ce_0: 0.1324  loss_mask_0: 0.1165  loss_dice_0: 0.1663  loss_ce_1: 3.568e-05  loss_mask_1: 0.1113  loss_dice_1: 0.1739  loss_ce_2: 4.782e-05  loss_mask_2: 0.1103  loss_dice_2: 0.1755  loss_ce_3: 3.85e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1758  loss_ce_4: 3.407e-05  loss_mask_4: 0.1119  loss_dice_4: 0.1726  loss_ce_5: 4.401e-05  loss_mask_5: 0.1106  loss_dice_5: 0.1719  loss_ce_6: 3.152e-05  loss_mask_6: 0.1133  loss_dice_6: 0.1744  loss_ce_7: 3.529e-05  loss_mask_7: 0.1094  loss_dice_7: 0.1752  loss_ce_8: 5.07e-05  loss_mask_8: 0.1097  loss_dice_8: 0.1766  time: 0.6296  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:13] d2.utils.events INFO:  eta: 0:42:49  iter: 23259  total_loss: 3.041  loss_ce: 4.922e-05  loss_mask: 0.1179  loss_dice: 0.1783  loss_ce_0: 0.1229  loss_mask_0: 0.12  loss_dice_0: 0.1758  loss_ce_1: 3.273e-05  loss_mask_1: 0.1188  loss_dice_1: 0.1795  loss_ce_2: 4.971e-05  loss_mask_2: 0.1126  loss_dice_2: 0.1782  loss_ce_3: 4.173e-05  loss_mask_3: 0.1186  loss_dice_3: 0.1805  loss_ce_4: 3.468e-05  loss_mask_4: 0.1165  loss_dice_4: 0.173  loss_ce_5: 4.313e-05  loss_mask_5: 0.1179  loss_dice_5: 0.1775  loss_ce_6: 3.21e-05  loss_mask_6: 0.1177  loss_dice_6: 0.1778  loss_ce_7: 3.75e-05  loss_mask_7: 0.1141  loss_dice_7: 0.1797  loss_ce_8: 5.118e-05  loss_mask_8: 0.1189  loss_dice_8: 0.1781  time: 0.6292  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:17] d2.utils.events INFO:  eta: 0:42:39  iter: 23279  total_loss: 2.857  loss_ce: 4.779e-05  loss_mask: 0.1075  loss_dice: 0.1649  loss_ce_0: 0.1268  loss_mask_0: 0.1054  loss_dice_0: 0.165  loss_ce_1: 3.375e-05  loss_mask_1: 0.1142  loss_dice_1: 0.1677  loss_ce_2: 4.814e-05  loss_mask_2: 0.1121  loss_dice_2: 0.1749  loss_ce_3: 4.028e-05  loss_mask_3: 0.1074  loss_dice_3: 0.1646  loss_ce_4: 3.482e-05  loss_mask_4: 0.1153  loss_dice_4: 0.1661  loss_ce_5: 4.892e-05  loss_mask_5: 0.1086  loss_dice_5: 0.1636  loss_ce_6: 2.991e-05  loss_mask_6: 0.1075  loss_dice_6: 0.16  loss_ce_7: 4.189e-05  loss_mask_7: 0.1117  loss_dice_7: 0.1673  loss_ce_8: 5.038e-05  loss_mask_8: 0.1048  loss_dice_8: 0.1618  time: 0.6288  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:21] d2.utils.events INFO:  eta: 0:42:19  iter: 23299  total_loss: 2.929  loss_ce: 3.762e-05  loss_mask: 0.1101  loss_dice: 0.1691  loss_ce_0: 0.1293  loss_mask_0: 0.1074  loss_dice_0: 0.1704  loss_ce_1: 3.055e-05  loss_mask_1: 0.1056  loss_dice_1: 0.1742  loss_ce_2: 4.364e-05  loss_mask_2: 0.1097  loss_dice_2: 0.1712  loss_ce_3: 2.787e-05  loss_mask_3: 0.1084  loss_dice_3: 0.1699  loss_ce_4: 3.348e-05  loss_mask_4: 0.1063  loss_dice_4: 0.1672  loss_ce_5: 4.326e-05  loss_mask_5: 0.1085  loss_dice_5: 0.168  loss_ce_6: 2.755e-05  loss_mask_6: 0.1072  loss_dice_6: 0.1671  loss_ce_7: 3.573e-05  loss_mask_7: 0.1101  loss_dice_7: 0.1763  loss_ce_8: 5.063e-05  loss_mask_8: 0.1062  loss_dice_8: 0.1744  time: 0.6284  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:24] d2.utils.events INFO:  eta: 0:42:04  iter: 23319  total_loss: 2.988  loss_ce: 3.84e-05  loss_mask: 0.1138  loss_dice: 0.1774  loss_ce_0: 0.1226  loss_mask_0: 0.116  loss_dice_0: 0.1805  loss_ce_1: 3.141e-05  loss_mask_1: 0.1108  loss_dice_1: 0.1728  loss_ce_2: 5.144e-05  loss_mask_2: 0.1134  loss_dice_2: 0.1705  loss_ce_3: 3.279e-05  loss_mask_3: 0.1128  loss_dice_3: 0.1731  loss_ce_4: 3.281e-05  loss_mask_4: 0.1121  loss_dice_4: 0.1669  loss_ce_5: 4.731e-05  loss_mask_5: 0.1126  loss_dice_5: 0.1745  loss_ce_6: 2.751e-05  loss_mask_6: 0.1165  loss_dice_6: 0.1708  loss_ce_7: 3.703e-05  loss_mask_7: 0.1152  loss_dice_7: 0.172  loss_ce_8: 5.073e-05  loss_mask_8: 0.1146  loss_dice_8: 0.1707  time: 0.6280  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:28] d2.utils.events INFO:  eta: 0:41:48  iter: 23339  total_loss: 3.224  loss_ce: 3.691e-05  loss_mask: 0.1176  loss_dice: 0.1859  loss_ce_0: 0.1233  loss_mask_0: 0.1192  loss_dice_0: 0.1887  loss_ce_1: 3.209e-05  loss_mask_1: 0.1182  loss_dice_1: 0.1854  loss_ce_2: 4.316e-05  loss_mask_2: 0.1203  loss_dice_2: 0.1859  loss_ce_3: 3.133e-05  loss_mask_3: 0.1187  loss_dice_3: 0.1874  loss_ce_4: 3.156e-05  loss_mask_4: 0.1162  loss_dice_4: 0.1861  loss_ce_5: 4.119e-05  loss_mask_5: 0.1175  loss_dice_5: 0.1817  loss_ce_6: 2.629e-05  loss_mask_6: 0.1197  loss_dice_6: 0.1864  loss_ce_7: 3.104e-05  loss_mask_7: 0.1173  loss_dice_7: 0.1898  loss_ce_8: 4.633e-05  loss_mask_8: 0.1179  loss_dice_8: 0.183  time: 0.6276  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:31] d2.utils.events INFO:  eta: 0:41:40  iter: 23359  total_loss: 3.113  loss_ce: 3.857e-05  loss_mask: 0.1111  loss_dice: 0.1831  loss_ce_0: 0.1148  loss_mask_0: 0.1144  loss_dice_0: 0.1787  loss_ce_1: 3.238e-05  loss_mask_1: 0.1137  loss_dice_1: 0.1809  loss_ce_2: 4.907e-05  loss_mask_2: 0.1133  loss_dice_2: 0.1825  loss_ce_3: 3.186e-05  loss_mask_3: 0.1144  loss_dice_3: 0.1843  loss_ce_4: 3.183e-05  loss_mask_4: 0.1161  loss_dice_4: 0.1871  loss_ce_5: 4.143e-05  loss_mask_5: 0.1168  loss_dice_5: 0.1835  loss_ce_6: 3.054e-05  loss_mask_6: 0.1149  loss_dice_6: 0.1852  loss_ce_7: 3.257e-05  loss_mask_7: 0.113  loss_dice_7: 0.1811  loss_ce_8: 4.749e-05  loss_mask_8: 0.1151  loss_dice_8: 0.1847  time: 0.6272  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:35] d2.utils.events INFO:  eta: 0:41:24  iter: 23379  total_loss: 3.077  loss_ce: 4.149e-05  loss_mask: 0.1136  loss_dice: 0.1818  loss_ce_0: 0.1203  loss_mask_0: 0.1094  loss_dice_0: 0.1821  loss_ce_1: 3.319e-05  loss_mask_1: 0.1146  loss_dice_1: 0.1815  loss_ce_2: 4.359e-05  loss_mask_2: 0.1156  loss_dice_2: 0.1811  loss_ce_3: 3.407e-05  loss_mask_3: 0.1191  loss_dice_3: 0.182  loss_ce_4: 3.107e-05  loss_mask_4: 0.1157  loss_dice_4: 0.1733  loss_ce_5: 4.11e-05  loss_mask_5: 0.1135  loss_dice_5: 0.1801  loss_ce_6: 2.681e-05  loss_mask_6: 0.1112  loss_dice_6: 0.1828  loss_ce_7: 3.072e-05  loss_mask_7: 0.1142  loss_dice_7: 0.1798  loss_ce_8: 4.587e-05  loss_mask_8: 0.1137  loss_dice_8: 0.1839  time: 0.6269  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:38] d2.utils.events INFO:  eta: 0:41:08  iter: 23399  total_loss: 3.024  loss_ce: 4.476e-05  loss_mask: 0.1153  loss_dice: 0.174  loss_ce_0: 0.1177  loss_mask_0: 0.1154  loss_dice_0: 0.1812  loss_ce_1: 3.624e-05  loss_mask_1: 0.1155  loss_dice_1: 0.1781  loss_ce_2: 4.922e-05  loss_mask_2: 0.1168  loss_dice_2: 0.1796  loss_ce_3: 3.637e-05  loss_mask_3: 0.1155  loss_dice_3: 0.1824  loss_ce_4: 3.252e-05  loss_mask_4: 0.1147  loss_dice_4: 0.1758  loss_ce_5: 5.186e-05  loss_mask_5: 0.1139  loss_dice_5: 0.1767  loss_ce_6: 3.173e-05  loss_mask_6: 0.1144  loss_dice_6: 0.1745  loss_ce_7: 4.532e-05  loss_mask_7: 0.1153  loss_dice_7: 0.1803  loss_ce_8: 5.175e-05  loss_mask_8: 0.1159  loss_dice_8: 0.1789  time: 0.6265  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:42] d2.utils.events INFO:  eta: 0:40:51  iter: 23419  total_loss: 3.153  loss_ce: 3.924e-05  loss_mask: 0.1186  loss_dice: 0.1908  loss_ce_0: 0.1229  loss_mask_0: 0.1162  loss_dice_0: 0.1887  loss_ce_1: 3.06e-05  loss_mask_1: 0.1195  loss_dice_1: 0.1926  loss_ce_2: 4.458e-05  loss_mask_2: 0.1157  loss_dice_2: 0.1856  loss_ce_3: 3.272e-05  loss_mask_3: 0.1195  loss_dice_3: 0.1939  loss_ce_4: 3.041e-05  loss_mask_4: 0.1189  loss_dice_4: 0.1937  loss_ce_5: 3.925e-05  loss_mask_5: 0.118  loss_dice_5: 0.1855  loss_ce_6: 2.448e-05  loss_mask_6: 0.1175  loss_dice_6: 0.1927  loss_ce_7: 3.416e-05  loss_mask_7: 0.118  loss_dice_7: 0.1927  loss_ce_8: 4.539e-05  loss_mask_8: 0.1167  loss_dice_8: 0.1925  time: 0.6261  data_time: 0.0010  lr: 0.0001  max_mem: 8444M
[08/01 21:48:46] d2.utils.events INFO:  eta: 0:40:37  iter: 23439  total_loss: 3.122  loss_ce: 3.719e-05  loss_mask: 0.1096  loss_dice: 0.1897  loss_ce_0: 0.1225  loss_mask_0: 0.1124  loss_dice_0: 0.1814  loss_ce_1: 2.886e-05  loss_mask_1: 0.1085  loss_dice_1: 0.1806  loss_ce_2: 3.332e-05  loss_mask_2: 0.1137  loss_dice_2: 0.1815  loss_ce_3: 3.131e-05  loss_mask_3: 0.1117  loss_dice_3: 0.18  loss_ce_4: 2.601e-05  loss_mask_4: 0.1135  loss_dice_4: 0.1823  loss_ce_5: 3.145e-05  loss_mask_5: 0.1106  loss_dice_5: 0.1808  loss_ce_6: 3.081e-05  loss_mask_6: 0.1124  loss_dice_6: 0.1818  loss_ce_7: 2.723e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1865  loss_ce_8: 3.682e-05  loss_mask_8: 0.1122  loss_dice_8: 0.1828  time: 0.6257  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:49] d2.utils.events INFO:  eta: 0:40:20  iter: 23459  total_loss: 3.01  loss_ce: 3.356e-05  loss_mask: 0.1153  loss_dice: 0.1681  loss_ce_0: 0.1175  loss_mask_0: 0.1054  loss_dice_0: 0.1691  loss_ce_1: 2.527e-05  loss_mask_1: 0.108  loss_dice_1: 0.1728  loss_ce_2: 3.431e-05  loss_mask_2: 0.114  loss_dice_2: 0.1765  loss_ce_3: 2.624e-05  loss_mask_3: 0.1105  loss_dice_3: 0.1655  loss_ce_4: 2.562e-05  loss_mask_4: 0.1158  loss_dice_4: 0.1678  loss_ce_5: 3.112e-05  loss_mask_5: 0.1118  loss_dice_5: 0.172  loss_ce_6: 2.347e-05  loss_mask_6: 0.1102  loss_dice_6: 0.1694  loss_ce_7: 2.583e-05  loss_mask_7: 0.112  loss_dice_7: 0.1728  loss_ce_8: 3.612e-05  loss_mask_8: 0.116  loss_dice_8: 0.1722  time: 0.6253  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:53] d2.utils.events INFO:  eta: 0:40:03  iter: 23479  total_loss: 2.787  loss_ce: 3.543e-05  loss_mask: 0.1111  loss_dice: 0.1578  loss_ce_0: 0.1255  loss_mask_0: 0.1099  loss_dice_0: 0.1601  loss_ce_1: 2.834e-05  loss_mask_1: 0.1075  loss_dice_1: 0.1573  loss_ce_2: 3.769e-05  loss_mask_2: 0.1096  loss_dice_2: 0.1597  loss_ce_3: 2.669e-05  loss_mask_3: 0.1065  loss_dice_3: 0.1576  loss_ce_4: 2.954e-05  loss_mask_4: 0.1099  loss_dice_4: 0.1594  loss_ce_5: 3.888e-05  loss_mask_5: 0.1081  loss_dice_5: 0.1641  loss_ce_6: 2.413e-05  loss_mask_6: 0.1073  loss_dice_6: 0.1613  loss_ce_7: 3.101e-05  loss_mask_7: 0.1086  loss_dice_7: 0.1594  loss_ce_8: 4.327e-05  loss_mask_8: 0.1086  loss_dice_8: 0.1596  time: 0.6249  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:48:56] d2.utils.events INFO:  eta: 0:39:40  iter: 23499  total_loss: 3.006  loss_ce: 3.47e-05  loss_mask: 0.1119  loss_dice: 0.1709  loss_ce_0: 0.1196  loss_mask_0: 0.116  loss_dice_0: 0.1771  loss_ce_1: 2.795e-05  loss_mask_1: 0.1113  loss_dice_1: 0.1768  loss_ce_2: 4.112e-05  loss_mask_2: 0.1121  loss_dice_2: 0.1742  loss_ce_3: 3.129e-05  loss_mask_3: 0.1099  loss_dice_3: 0.1699  loss_ce_4: 3.011e-05  loss_mask_4: 0.1104  loss_dice_4: 0.1719  loss_ce_5: 4.166e-05  loss_mask_5: 0.1172  loss_dice_5: 0.1757  loss_ce_6: 2.989e-05  loss_mask_6: 0.1126  loss_dice_6: 0.1732  loss_ce_7: 3.289e-05  loss_mask_7: 0.1145  loss_dice_7: 0.1759  loss_ce_8: 4.373e-05  loss_mask_8: 0.1126  loss_dice_8: 0.1752  time: 0.6246  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:49:00] d2.utils.events INFO:  eta: 0:39:25  iter: 23519  total_loss: 3.016  loss_ce: 3.73e-05  loss_mask: 0.1144  loss_dice: 0.1809  loss_ce_0: 0.1143  loss_mask_0: 0.1132  loss_dice_0: 0.1773  loss_ce_1: 3.121e-05  loss_mask_1: 0.115  loss_dice_1: 0.18  loss_ce_2: 4.83e-05  loss_mask_2: 0.1144  loss_dice_2: 0.1787  loss_ce_3: 3.173e-05  loss_mask_3: 0.1133  loss_dice_3: 0.1735  loss_ce_4: 3.313e-05  loss_mask_4: 0.1135  loss_dice_4: 0.1756  loss_ce_5: 4.132e-05  loss_mask_5: 0.1133  loss_dice_5: 0.1791  loss_ce_6: 2.852e-05  loss_mask_6: 0.1139  loss_dice_6: 0.181  loss_ce_7: 3.365e-05  loss_mask_7: 0.1102  loss_dice_7: 0.1758  loss_ce_8: 4.318e-05  loss_mask_8: 0.1144  loss_dice_8: 0.1797  time: 0.6242  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:49:03] d2.utils.events INFO:  eta: 0:39:07  iter: 23539  total_loss: 3.018  loss_ce: 3.371e-05  loss_mask: 0.1145  loss_dice: 0.1749  loss_ce_0: 0.1244  loss_mask_0: 0.1137  loss_dice_0: 0.1744  loss_ce_1: 2.675e-05  loss_mask_1: 0.1078  loss_dice_1: 0.1664  loss_ce_2: 3.126e-05  loss_mask_2: 0.1115  loss_dice_2: 0.1762  loss_ce_3: 2.848e-05  loss_mask_3: 0.1108  loss_dice_3: 0.1713  loss_ce_4: 2.471e-05  loss_mask_4: 0.1118  loss_dice_4: 0.175  loss_ce_5: 2.936e-05  loss_mask_5: 0.1158  loss_dice_5: 0.1674  loss_ce_6: 2.564e-05  loss_mask_6: 0.1099  loss_dice_6: 0.1678  loss_ce_7: 2.493e-05  loss_mask_7: 0.1156  loss_dice_7: 0.1742  loss_ce_8: 3.394e-05  loss_mask_8: 0.1117  loss_dice_8: 0.1722  time: 0.6238  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:49:07] d2.utils.events INFO:  eta: 0:38:35  iter: 23559  total_loss: 3.005  loss_ce: 3.24e-05  loss_mask: 0.1146  loss_dice: 0.1746  loss_ce_0: 0.1245  loss_mask_0: 0.1138  loss_dice_0: 0.1755  loss_ce_1: 2.591e-05  loss_mask_1: 0.1107  loss_dice_1: 0.1719  loss_ce_2: 3.818e-05  loss_mask_2: 0.1137  loss_dice_2: 0.1725  loss_ce_3: 2.733e-05  loss_mask_3: 0.1106  loss_dice_3: 0.1742  loss_ce_4: 2.644e-05  loss_mask_4: 0.1096  loss_dice_4: 0.1676  loss_ce_5: 3.738e-05  loss_mask_5: 0.1116  loss_dice_5: 0.1753  loss_ce_6: 2.318e-05  loss_mask_6: 0.1118  loss_dice_6: 0.1746  loss_ce_7: 2.757e-05  loss_mask_7: 0.1094  loss_dice_7: 0.1709  loss_ce_8: 4.077e-05  loss_mask_8: 0.114  loss_dice_8: 0.1717  time: 0.6234  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:49:10] d2.utils.events INFO:  eta: 0:38:07  iter: 23579  total_loss: 2.845  loss_ce: 3.021e-05  loss_mask: 0.1125  loss_dice: 0.1654  loss_ce_0: 0.124  loss_mask_0: 0.1107  loss_dice_0: 0.1585  loss_ce_1: 2.577e-05  loss_mask_1: 0.1137  loss_dice_1: 0.1603  loss_ce_2: 3.336e-05  loss_mask_2: 0.1115  loss_dice_2: 0.1686  loss_ce_3: 2.176e-05  loss_mask_3: 0.1109  loss_dice_3: 0.16  loss_ce_4: 2.478e-05  loss_mask_4: 0.1114  loss_dice_4: 0.1695  loss_ce_5: 3.343e-05  loss_mask_5: 0.1113  loss_dice_5: 0.1608  loss_ce_6: 1.96e-05  loss_mask_6: 0.1115  loss_dice_6: 0.1608  loss_ce_7: 2.278e-05  loss_mask_7: 0.1108  loss_dice_7: 0.1628  loss_ce_8: 3.809e-05  loss_mask_8: 0.1118  loss_dice_8: 0.1647  time: 0.6230  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:49:14] d2.utils.events INFO:  eta: 0:37:46  iter: 23599  total_loss: 2.931  loss_ce: 3.171e-05  loss_mask: 0.1054  loss_dice: 0.1683  loss_ce_0: 0.1253  loss_mask_0: 0.1104  loss_dice_0: 0.1747  loss_ce_1: 2.899e-05  loss_mask_1: 0.1173  loss_dice_1: 0.17  loss_ce_2: 4.161e-05  loss_mask_2: 0.1133  loss_dice_2: 0.1728  loss_ce_3: 2.774e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1682  loss_ce_4: 2.832e-05  loss_mask_4: 0.1141  loss_dice_4: 0.1707  loss_ce_5: 3.948e-05  loss_mask_5: 0.1125  loss_dice_5: 0.1716  loss_ce_6: 2.592e-05  loss_mask_6: 0.1114  loss_dice_6: 0.1668  loss_ce_7: 3.232e-05  loss_mask_7: 0.1118  loss_dice_7: 0.1658  loss_ce_8: 4.108e-05  loss_mask_8: 0.1139  loss_dice_8: 0.1683  time: 0.6227  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:49:18] d2.utils.events INFO:  eta: 0:37:23  iter: 23619  total_loss: 3.078  loss_ce: 3.255e-05  loss_mask: 0.1135  loss_dice: 0.1781  loss_ce_0: 0.1263  loss_mask_0: 0.1142  loss_dice_0: 0.1783  loss_ce_1: 2.626e-05  loss_mask_1: 0.1133  loss_dice_1: 0.1748  loss_ce_2: 3.533e-05  loss_mask_2: 0.1166  loss_dice_2: 0.1791  loss_ce_3: 2.939e-05  loss_mask_3: 0.1162  loss_dice_3: 0.1711  loss_ce_4: 2.772e-05  loss_mask_4: 0.1117  loss_dice_4: 0.1696  loss_ce_5: 3.691e-05  loss_mask_5: 0.1141  loss_dice_5: 0.1749  loss_ce_6: 3.017e-05  loss_mask_6: 0.1172  loss_dice_6: 0.1788  loss_ce_7: 3.245e-05  loss_mask_7: 0.1143  loss_dice_7: 0.1765  loss_ce_8: 3.967e-05  loss_mask_8: 0.1162  loss_dice_8: 0.1768  time: 0.6223  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:49:21] d2.utils.events INFO:  eta: 0:36:50  iter: 23639  total_loss: 3.039  loss_ce: 3.017e-05  loss_mask: 0.1187  loss_dice: 0.1771  loss_ce_0: 0.1283  loss_mask_0: 0.1165  loss_dice_0: 0.1679  loss_ce_1: 2.186e-05  loss_mask_1: 0.1169  loss_dice_1: 0.1682  loss_ce_2: 3.529e-05  loss_mask_2: 0.1139  loss_dice_2: 0.1652  loss_ce_3: 2.761e-05  loss_mask_3: 0.1194  loss_dice_3: 0.1714  loss_ce_4: 2.518e-05  loss_mask_4: 0.119  loss_dice_4: 0.1676  loss_ce_5: 3.314e-05  loss_mask_5: 0.1154  loss_dice_5: 0.1695  loss_ce_6: 2.224e-05  loss_mask_6: 0.1219  loss_dice_6: 0.1726  loss_ce_7: 2.565e-05  loss_mask_7: 0.1196  loss_dice_7: 0.1762  loss_ce_8: 3.71e-05  loss_mask_8: 0.1182  loss_dice_8: 0.177  time: 0.6219  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:49:25] d2.utils.events INFO:  eta: 0:36:33  iter: 23659  total_loss: 3.127  loss_ce: 3.289e-05  loss_mask: 0.1205  loss_dice: 0.1763  loss_ce_0: 0.1271  loss_mask_0: 0.1163  loss_dice_0: 0.1685  loss_ce_1: 2.558e-05  loss_mask_1: 0.1214  loss_dice_1: 0.1808  loss_ce_2: 3.577e-05  loss_mask_2: 0.1196  loss_dice_2: 0.1799  loss_ce_3: 3.019e-05  loss_mask_3: 0.1219  loss_dice_3: 0.178  loss_ce_4: 2.562e-05  loss_mask_4: 0.1196  loss_dice_4: 0.175  loss_ce_5: 3.541e-05  loss_mask_5: 0.1108  loss_dice_5: 0.1865  loss_ce_6: 2.518e-05  loss_mask_6: 0.1151  loss_dice_6: 0.179  loss_ce_7: 3.086e-05  loss_mask_7: 0.1209  loss_dice_7: 0.1754  loss_ce_8: 3.901e-05  loss_mask_8: 0.1194  loss_dice_8: 0.183  time: 0.6215  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:49:28] d2.utils.events INFO:  eta: 0:36:07  iter: 23679  total_loss: 2.921  loss_ce: 3.197e-05  loss_mask: 0.1076  loss_dice: 0.1701  loss_ce_0: 0.1253  loss_mask_0: 0.1113  loss_dice_0: 0.1699  loss_ce_1: 2.411e-05  loss_mask_1: 0.1082  loss_dice_1: 0.1682  loss_ce_2: 3.226e-05  loss_mask_2: 0.1099  loss_dice_2: 0.1709  loss_ce_3: 2.509e-05  loss_mask_3: 0.1069  loss_dice_3: 0.1665  loss_ce_4: 2.52e-05  loss_mask_4: 0.1119  loss_dice_4: 0.1702  loss_ce_5: 3.469e-05  loss_mask_5: 0.1068  loss_dice_5: 0.1646  loss_ce_6: 2.24e-05  loss_mask_6: 0.1069  loss_dice_6: 0.164  loss_ce_7: 2.904e-05  loss_mask_7: 0.1117  loss_dice_7: 0.1688  loss_ce_8: 3.871e-05  loss_mask_8: 0.1086  loss_dice_8: 0.1685  time: 0.6212  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:49:32] d2.utils.events INFO:  eta: 0:35:43  iter: 23699  total_loss: 2.853  loss_ce: 2.982e-05  loss_mask: 0.1074  loss_dice: 0.1598  loss_ce_0: 0.1256  loss_mask_0: 0.1109  loss_dice_0: 0.1591  loss_ce_1: 2.172e-05  loss_mask_1: 0.1113  loss_dice_1: 0.1564  loss_ce_2: 3.241e-05  loss_mask_2: 0.1099  loss_dice_2: 0.1627  loss_ce_3: 2.317e-05  loss_mask_3: 0.1098  loss_dice_3: 0.1546  loss_ce_4: 2.37e-05  loss_mask_4: 0.1105  loss_dice_4: 0.1621  loss_ce_5: 3.189e-05  loss_mask_5: 0.1132  loss_dice_5: 0.1564  loss_ce_6: 2.131e-05  loss_mask_6: 0.1153  loss_dice_6: 0.1572  loss_ce_7: 2.49e-05  loss_mask_7: 0.1078  loss_dice_7: 0.1612  loss_ce_8: 3.715e-05  loss_mask_8: 0.1104  loss_dice_8: 0.159  time: 0.6208  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:49:36] d2.utils.events INFO:  eta: 0:35:24  iter: 23719  total_loss: 3.318  loss_ce: 3.023e-05  loss_mask: 0.1168  loss_dice: 0.1896  loss_ce_0: 0.1205  loss_mask_0: 0.1197  loss_dice_0: 0.1901  loss_ce_1: 2.414e-05  loss_mask_1: 0.1212  loss_dice_1: 0.1979  loss_ce_2: 3.305e-05  loss_mask_2: 0.123  loss_dice_2: 0.1935  loss_ce_3: 2.298e-05  loss_mask_3: 0.1199  loss_dice_3: 0.1968  loss_ce_4: 2.338e-05  loss_mask_4: 0.1154  loss_dice_4: 0.1888  loss_ce_5: 3.223e-05  loss_mask_5: 0.116  loss_dice_5: 0.2027  loss_ce_6: 2.042e-05  loss_mask_6: 0.1256  loss_dice_6: 0.1977  loss_ce_7: 2.619e-05  loss_mask_7: 0.1218  loss_dice_7: 0.199  loss_ce_8: 3.829e-05  loss_mask_8: 0.1208  loss_dice_8: 0.1975  time: 0.6204  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:49:39] d2.utils.events INFO:  eta: 0:35:00  iter: 23739  total_loss: 3.064  loss_ce: 3.278e-05  loss_mask: 0.1192  loss_dice: 0.1847  loss_ce_0: 0.1227  loss_mask_0: 0.1175  loss_dice_0: 0.18  loss_ce_1: 2.703e-05  loss_mask_1: 0.1177  loss_dice_1: 0.1782  loss_ce_2: 3.923e-05  loss_mask_2: 0.1201  loss_dice_2: 0.177  loss_ce_3: 3.522e-05  loss_mask_3: 0.1155  loss_dice_3: 0.1799  loss_ce_4: 3.381e-05  loss_mask_4: 0.1185  loss_dice_4: 0.175  loss_ce_5: 3.792e-05  loss_mask_5: 0.1172  loss_dice_5: 0.1773  loss_ce_6: 2.312e-05  loss_mask_6: 0.1203  loss_dice_6: 0.1804  loss_ce_7: 3.081e-05  loss_mask_7: 0.1175  loss_dice_7: 0.1811  loss_ce_8: 3.858e-05  loss_mask_8: 0.1224  loss_dice_8: 0.1817  time: 0.6200  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:49:43] d2.utils.events INFO:  eta: 0:34:42  iter: 23759  total_loss: 2.987  loss_ce: 2.842e-05  loss_mask: 0.119  loss_dice: 0.1771  loss_ce_0: 0.1207  loss_mask_0: 0.1222  loss_dice_0: 0.1747  loss_ce_1: 2.079e-05  loss_mask_1: 0.1165  loss_dice_1: 0.1673  loss_ce_2: 3.382e-05  loss_mask_2: 0.1223  loss_dice_2: 0.1782  loss_ce_3: 2.553e-05  loss_mask_3: 0.1217  loss_dice_3: 0.1742  loss_ce_4: 2.395e-05  loss_mask_4: 0.1173  loss_dice_4: 0.1683  loss_ce_5: 3.093e-05  loss_mask_5: 0.1195  loss_dice_5: 0.1772  loss_ce_6: 2.185e-05  loss_mask_6: 0.1154  loss_dice_6: 0.1671  loss_ce_7: 2.551e-05  loss_mask_7: 0.1174  loss_dice_7: 0.1711  loss_ce_8: 3.472e-05  loss_mask_8: 0.116  loss_dice_8: 0.1791  time: 0.6197  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:49:46] d2.utils.events INFO:  eta: 0:34:25  iter: 23779  total_loss: 2.85  loss_ce: 2.983e-05  loss_mask: 0.1076  loss_dice: 0.161  loss_ce_0: 0.1243  loss_mask_0: 0.1063  loss_dice_0: 0.1579  loss_ce_1: 2.516e-05  loss_mask_1: 0.1087  loss_dice_1: 0.1596  loss_ce_2: 3.958e-05  loss_mask_2: 0.1079  loss_dice_2: 0.1635  loss_ce_3: 2.75e-05  loss_mask_3: 0.107  loss_dice_3: 0.1578  loss_ce_4: 3.267e-05  loss_mask_4: 0.1066  loss_dice_4: 0.1598  loss_ce_5: 3.933e-05  loss_mask_5: 0.1111  loss_dice_5: 0.1625  loss_ce_6: 2.075e-05  loss_mask_6: 0.1074  loss_dice_6: 0.1587  loss_ce_7: 3.166e-05  loss_mask_7: 0.1072  loss_dice_7: 0.1632  loss_ce_8: 4.298e-05  loss_mask_8: 0.1052  loss_dice_8: 0.1609  time: 0.6193  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:49:50] d2.utils.events INFO:  eta: 0:34:12  iter: 23799  total_loss: 2.971  loss_ce: 1.768e-05  loss_mask: 0.1183  loss_dice: 0.1806  loss_ce_0: 0.1254  loss_mask_0: 0.1141  loss_dice_0: 0.1676  loss_ce_1: 1.977e-05  loss_mask_1: 0.1177  loss_dice_1: 0.1773  loss_ce_2: 2.03e-05  loss_mask_2: 0.1139  loss_dice_2: 0.1752  loss_ce_3: 1.332e-05  loss_mask_3: 0.1142  loss_dice_3: 0.1745  loss_ce_4: 1.578e-05  loss_mask_4: 0.1129  loss_dice_4: 0.1734  loss_ce_5: 2e-05  loss_mask_5: 0.1132  loss_dice_5: 0.1785  loss_ce_6: 9.83e-06  loss_mask_6: 0.1159  loss_dice_6: 0.1723  loss_ce_7: 1.453e-05  loss_mask_7: 0.1118  loss_dice_7: 0.1786  loss_ce_8: 2.244e-05  loss_mask_8: 0.1117  loss_dice_8: 0.1847  time: 0.6189  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:49:53] d2.utils.events INFO:  eta: 0:33:57  iter: 23819  total_loss: 3.091  loss_ce: 2.715e-05  loss_mask: 0.1143  loss_dice: 0.1895  loss_ce_0: 0.1225  loss_mask_0: 0.1126  loss_dice_0: 0.1798  loss_ce_1: 2.239e-05  loss_mask_1: 0.1131  loss_dice_1: 0.1835  loss_ce_2: 3.27e-05  loss_mask_2: 0.1101  loss_dice_2: 0.1771  loss_ce_3: 2.504e-05  loss_mask_3: 0.1131  loss_dice_3: 0.178  loss_ce_4: 2.416e-05  loss_mask_4: 0.1126  loss_dice_4: 0.1802  loss_ce_5: 3.149e-05  loss_mask_5: 0.11  loss_dice_5: 0.1769  loss_ce_6: 2.459e-05  loss_mask_6: 0.1138  loss_dice_6: 0.1773  loss_ce_7: 2.387e-05  loss_mask_7: 0.1123  loss_dice_7: 0.1795  loss_ce_8: 3.584e-05  loss_mask_8: 0.1122  loss_dice_8: 0.1841  time: 0.6186  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:49:57] d2.utils.events INFO:  eta: 0:33:39  iter: 23839  total_loss: 2.947  loss_ce: 3.384e-05  loss_mask: 0.1162  loss_dice: 0.1751  loss_ce_0: 0.125  loss_mask_0: 0.1148  loss_dice_0: 0.1742  loss_ce_1: 3.973e-05  loss_mask_1: 0.1132  loss_dice_1: 0.1666  loss_ce_2: 4.314e-05  loss_mask_2: 0.1128  loss_dice_2: 0.1738  loss_ce_3: 3.545e-05  loss_mask_3: 0.1168  loss_dice_3: 0.1702  loss_ce_4: 3.531e-05  loss_mask_4: 0.1132  loss_dice_4: 0.1686  loss_ce_5: 4.284e-05  loss_mask_5: 0.1132  loss_dice_5: 0.168  loss_ce_6: 2.627e-05  loss_mask_6: 0.113  loss_dice_6: 0.1707  loss_ce_7: 3.89e-05  loss_mask_7: 0.1096  loss_dice_7: 0.1681  loss_ce_8: 4.735e-05  loss_mask_8: 0.1144  loss_dice_8: 0.1677  time: 0.6182  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:50:00] d2.utils.events INFO:  eta: 0:33:20  iter: 23859  total_loss: 3.199  loss_ce: 4.915e-05  loss_mask: 0.1159  loss_dice: 0.2002  loss_ce_0: 0.1207  loss_mask_0: 0.114  loss_dice_0: 0.1902  loss_ce_1: 7.312e-05  loss_mask_1: 0.1136  loss_dice_1: 0.1966  loss_ce_2: 5.94e-05  loss_mask_2: 0.1158  loss_dice_2: 0.1982  loss_ce_3: 7.17e-05  loss_mask_3: 0.1105  loss_dice_3: 0.1861  loss_ce_4: 4.741e-05  loss_mask_4: 0.115  loss_dice_4: 0.1953  loss_ce_5: 5.01e-05  loss_mask_5: 0.1136  loss_dice_5: 0.1844  loss_ce_6: 6.33e-05  loss_mask_6: 0.1126  loss_dice_6: 0.1918  loss_ce_7: 4.985e-05  loss_mask_7: 0.1143  loss_dice_7: 0.194  loss_ce_8: 5.696e-05  loss_mask_8: 0.1202  loss_dice_8: 0.2034  time: 0.6178  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:50:04] d2.utils.events INFO:  eta: 0:33:07  iter: 23879  total_loss: 2.93  loss_ce: 5.566e-05  loss_mask: 0.1125  loss_dice: 0.1634  loss_ce_0: 0.1267  loss_mask_0: 0.1137  loss_dice_0: 0.1733  loss_ce_1: 0.0001139  loss_mask_1: 0.1072  loss_dice_1: 0.1608  loss_ce_2: 5.478e-05  loss_mask_2: 0.1095  loss_dice_2: 0.164  loss_ce_3: 6.13e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1658  loss_ce_4: 4.754e-05  loss_mask_4: 0.1128  loss_dice_4: 0.166  loss_ce_5: 5.368e-05  loss_mask_5: 0.1151  loss_dice_5: 0.1668  loss_ce_6: 5.477e-05  loss_mask_6: 0.1127  loss_dice_6: 0.1691  loss_ce_7: 5.431e-05  loss_mask_7: 0.1105  loss_dice_7: 0.1647  loss_ce_8: 6.06e-05  loss_mask_8: 0.1122  loss_dice_8: 0.1644  time: 0.6174  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:50:07] d2.utils.events INFO:  eta: 0:32:56  iter: 23899  total_loss: 3.002  loss_ce: 3.557e-05  loss_mask: 0.1178  loss_dice: 0.1703  loss_ce_0: 0.1239  loss_mask_0: 0.1158  loss_dice_0: 0.1738  loss_ce_1: 3.323e-05  loss_mask_1: 0.1198  loss_dice_1: 0.1785  loss_ce_2: 4.717e-05  loss_mask_2: 0.1187  loss_dice_2: 0.1759  loss_ce_3: 3.422e-05  loss_mask_3: 0.1169  loss_dice_3: 0.1776  loss_ce_4: 3.814e-05  loss_mask_4: 0.1217  loss_dice_4: 0.1725  loss_ce_5: 4.425e-05  loss_mask_5: 0.1153  loss_dice_5: 0.1752  loss_ce_6: 3.055e-05  loss_mask_6: 0.1202  loss_dice_6: 0.168  loss_ce_7: 4.538e-05  loss_mask_7: 0.1162  loss_dice_7: 0.1702  loss_ce_8: 4.844e-05  loss_mask_8: 0.1197  loss_dice_8: 0.1797  time: 0.6171  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:50:11] d2.utils.events INFO:  eta: 0:32:44  iter: 23919  total_loss: 2.908  loss_ce: 3.792e-05  loss_mask: 0.1107  loss_dice: 0.1683  loss_ce_0: 0.1179  loss_mask_0: 0.1122  loss_dice_0: 0.1717  loss_ce_1: 3.491e-05  loss_mask_1: 0.1132  loss_dice_1: 0.1683  loss_ce_2: 4.801e-05  loss_mask_2: 0.113  loss_dice_2: 0.1652  loss_ce_3: 3.928e-05  loss_mask_3: 0.1113  loss_dice_3: 0.1641  loss_ce_4: 4.037e-05  loss_mask_4: 0.1102  loss_dice_4: 0.1628  loss_ce_5: 4.415e-05  loss_mask_5: 0.1146  loss_dice_5: 0.1709  loss_ce_6: 3.281e-05  loss_mask_6: 0.1149  loss_dice_6: 0.1669  loss_ce_7: 4.351e-05  loss_mask_7: 0.1136  loss_dice_7: 0.1659  loss_ce_8: 4.721e-05  loss_mask_8: 0.1097  loss_dice_8: 0.1669  time: 0.6167  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:50:15] d2.utils.events INFO:  eta: 0:32:36  iter: 23939  total_loss: 3.003  loss_ce: 8.613e-05  loss_mask: 0.1207  loss_dice: 0.1792  loss_ce_0: 0.1234  loss_mask_0: 0.1145  loss_dice_0: 0.179  loss_ce_1: 0.0001102  loss_mask_1: 0.1128  loss_dice_1: 0.171  loss_ce_2: 5.555e-05  loss_mask_2: 0.1168  loss_dice_2: 0.1724  loss_ce_3: 4.948e-05  loss_mask_3: 0.1151  loss_dice_3: 0.1763  loss_ce_4: 8.162e-05  loss_mask_4: 0.1185  loss_dice_4: 0.1808  loss_ce_5: 9.016e-05  loss_mask_5: 0.1169  loss_dice_5: 0.1704  loss_ce_6: 5.669e-05  loss_mask_6: 0.1166  loss_dice_6: 0.1782  loss_ce_7: 7.308e-05  loss_mask_7: 0.1151  loss_dice_7: 0.1715  loss_ce_8: 7.917e-05  loss_mask_8: 0.1154  loss_dice_8: 0.1733  time: 0.6163  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:50:18] d2.utils.events INFO:  eta: 0:32:27  iter: 23959  total_loss: 3.063  loss_ce: 5.302e-05  loss_mask: 0.1157  loss_dice: 0.1681  loss_ce_0: 0.1225  loss_mask_0: 0.1176  loss_dice_0: 0.1744  loss_ce_1: 9.45e-05  loss_mask_1: 0.1161  loss_dice_1: 0.1693  loss_ce_2: 4.819e-05  loss_mask_2: 0.1168  loss_dice_2: 0.1751  loss_ce_3: 5.511e-05  loss_mask_3: 0.1147  loss_dice_3: 0.1707  loss_ce_4: 4.181e-05  loss_mask_4: 0.1133  loss_dice_4: 0.1698  loss_ce_5: 4.713e-05  loss_mask_5: 0.1122  loss_dice_5: 0.1669  loss_ce_6: 4.41e-05  loss_mask_6: 0.1151  loss_dice_6: 0.1715  loss_ce_7: 4.568e-05  loss_mask_7: 0.117  loss_dice_7: 0.1743  loss_ce_8: 4.726e-05  loss_mask_8: 0.1195  loss_dice_8: 0.1776  time: 0.6160  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:50:22] d2.utils.events INFO:  eta: 0:32:20  iter: 23979  total_loss: 3.023  loss_ce: 0.0003507  loss_mask: 0.1138  loss_dice: 0.1675  loss_ce_0: 0.1219  loss_mask_0: 0.112  loss_dice_0: 0.1655  loss_ce_1: 0.0003175  loss_mask_1: 0.1151  loss_dice_1: 0.1645  loss_ce_2: 0.000227  loss_mask_2: 0.1126  loss_dice_2: 0.1698  loss_ce_3: 9.871e-05  loss_mask_3: 0.1103  loss_dice_3: 0.1648  loss_ce_4: 0.0003217  loss_mask_4: 0.1093  loss_dice_4: 0.1646  loss_ce_5: 0.0002307  loss_mask_5: 0.1101  loss_dice_5: 0.17  loss_ce_6: 0.0001219  loss_mask_6: 0.1095  loss_dice_6: 0.168  loss_ce_7: 0.0004172  loss_mask_7: 0.1139  loss_dice_7: 0.1681  loss_ce_8: 0.0002898  loss_mask_8: 0.1125  loss_dice_8: 0.1679  time: 0.6156  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:50:25] d2.utils.events INFO:  eta: 0:32:13  iter: 23999  total_loss: 3.005  loss_ce: 0.001874  loss_mask: 0.1126  loss_dice: 0.1669  loss_ce_0: 0.1188  loss_mask_0: 0.1134  loss_dice_0: 0.1598  loss_ce_1: 0.008517  loss_mask_1: 0.1125  loss_dice_1: 0.1596  loss_ce_2: 0.006476  loss_mask_2: 0.1128  loss_dice_2: 0.16  loss_ce_3: 0.003237  loss_mask_3: 0.1125  loss_dice_3: 0.1622  loss_ce_4: 0.007471  loss_mask_4: 0.1106  loss_dice_4: 0.1595  loss_ce_5: 0.004656  loss_mask_5: 0.1149  loss_dice_5: 0.1596  loss_ce_6: 0.000837  loss_mask_6: 0.1121  loss_dice_6: 0.1604  loss_ce_7: 0.003033  loss_mask_7: 0.1135  loss_dice_7: 0.166  loss_ce_8: 0.002841  loss_mask_8: 0.1138  loss_dice_8: 0.1628  time: 0.6152  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:50:29] d2.utils.events INFO:  eta: 0:32:02  iter: 24019  total_loss: 3.01  loss_ce: 0.0001496  loss_mask: 0.1088  loss_dice: 0.161  loss_ce_0: 0.1186  loss_mask_0: 0.1123  loss_dice_0: 0.1658  loss_ce_1: 0.0006627  loss_mask_1: 0.1091  loss_dice_1: 0.1677  loss_ce_2: 0.001388  loss_mask_2: 0.1098  loss_dice_2: 0.1615  loss_ce_3: 0.0004011  loss_mask_3: 0.1102  loss_dice_3: 0.1644  loss_ce_4: 0.000668  loss_mask_4: 0.1121  loss_dice_4: 0.1636  loss_ce_5: 0.001446  loss_mask_5: 0.1117  loss_dice_5: 0.1696  loss_ce_6: 0.0001537  loss_mask_6: 0.1143  loss_dice_6: 0.1621  loss_ce_7: 0.000614  loss_mask_7: 0.116  loss_dice_7: 0.1623  loss_ce_8: 0.0009846  loss_mask_8: 0.11  loss_dice_8: 0.1646  time: 0.6149  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:50:33] d2.utils.events INFO:  eta: 0:31:54  iter: 24039  total_loss: 3.117  loss_ce: 0.0001201  loss_mask: 0.112  loss_dice: 0.1676  loss_ce_0: 0.1204  loss_mask_0: 0.1081  loss_dice_0: 0.1655  loss_ce_1: 0.0004846  loss_mask_1: 0.1091  loss_dice_1: 0.1682  loss_ce_2: 0.0006297  loss_mask_2: 0.1087  loss_dice_2: 0.1702  loss_ce_3: 0.0004361  loss_mask_3: 0.1096  loss_dice_3: 0.1637  loss_ce_4: 0.000908  loss_mask_4: 0.1077  loss_dice_4: 0.1665  loss_ce_5: 0.0005874  loss_mask_5: 0.1111  loss_dice_5: 0.1643  loss_ce_6: 0.0003278  loss_mask_6: 0.114  loss_dice_6: 0.1691  loss_ce_7: 0.0004574  loss_mask_7: 0.1122  loss_dice_7: 0.1622  loss_ce_8: 0.0005711  loss_mask_8: 0.1099  loss_dice_8: 0.1679  time: 0.6145  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:50:36] d2.utils.events INFO:  eta: 0:31:48  iter: 24059  total_loss: 3.227  loss_ce: 0.0004905  loss_mask: 0.1181  loss_dice: 0.1759  loss_ce_0: 0.1171  loss_mask_0: 0.119  loss_dice_0: 0.1734  loss_ce_1: 0.001403  loss_mask_1: 0.1155  loss_dice_1: 0.1755  loss_ce_2: 0.0006911  loss_mask_2: 0.1165  loss_dice_2: 0.1785  loss_ce_3: 0.0006952  loss_mask_3: 0.1174  loss_dice_3: 0.1718  loss_ce_4: 0.0005771  loss_mask_4: 0.1157  loss_dice_4: 0.177  loss_ce_5: 0.0008264  loss_mask_5: 0.1188  loss_dice_5: 0.1757  loss_ce_6: 0.0007662  loss_mask_6: 0.1167  loss_dice_6: 0.178  loss_ce_7: 0.0005893  loss_mask_7: 0.1155  loss_dice_7: 0.1676  loss_ce_8: 0.0007417  loss_mask_8: 0.1175  loss_dice_8: 0.1749  time: 0.6142  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:50:40] d2.utils.events INFO:  eta: 0:31:44  iter: 24079  total_loss: 3.232  loss_ce: 0.001403  loss_mask: 0.1157  loss_dice: 0.1655  loss_ce_0: 0.1186  loss_mask_0: 0.1124  loss_dice_0: 0.1719  loss_ce_1: 0.0119  loss_mask_1: 0.1187  loss_dice_1: 0.1662  loss_ce_2: 0.001073  loss_mask_2: 0.1193  loss_dice_2: 0.1633  loss_ce_3: 0.003394  loss_mask_3: 0.1152  loss_dice_3: 0.1699  loss_ce_4: 0.001405  loss_mask_4: 0.1118  loss_dice_4: 0.1652  loss_ce_5: 0.002612  loss_mask_5: 0.1151  loss_dice_5: 0.171  loss_ce_6: 0.001123  loss_mask_6: 0.1193  loss_dice_6: 0.1705  loss_ce_7: 0.005117  loss_mask_7: 0.1169  loss_dice_7: 0.1629  loss_ce_8: 0.002857  loss_mask_8: 0.1201  loss_dice_8: 0.1647  time: 0.6138  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:50:43] d2.utils.events INFO:  eta: 0:31:39  iter: 24099  total_loss: 3.038  loss_ce: 0.001381  loss_mask: 0.1146  loss_dice: 0.173  loss_ce_0: 0.1187  loss_mask_0: 0.1133  loss_dice_0: 0.1701  loss_ce_1: 0.003434  loss_mask_1: 0.113  loss_dice_1: 0.1729  loss_ce_2: 0.0007897  loss_mask_2: 0.1138  loss_dice_2: 0.1778  loss_ce_3: 0.001358  loss_mask_3: 0.1139  loss_dice_3: 0.1747  loss_ce_4: 0.0009534  loss_mask_4: 0.1116  loss_dice_4: 0.1698  loss_ce_5: 0.001892  loss_mask_5: 0.1131  loss_dice_5: 0.1717  loss_ce_6: 0.0009064  loss_mask_6: 0.1147  loss_dice_6: 0.1788  loss_ce_7: 0.002029  loss_mask_7: 0.1145  loss_dice_7: 0.1724  loss_ce_8: 0.001944  loss_mask_8: 0.1146  loss_dice_8: 0.1725  time: 0.6134  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:50:47] d2.utils.events INFO:  eta: 0:31:35  iter: 24119  total_loss: 3.032  loss_ce: 0.0008681  loss_mask: 0.119  loss_dice: 0.186  loss_ce_0: 0.1229  loss_mask_0: 0.1135  loss_dice_0: 0.1734  loss_ce_1: 0.001369  loss_mask_1: 0.1158  loss_dice_1: 0.1831  loss_ce_2: 0.0007215  loss_mask_2: 0.1129  loss_dice_2: 0.1762  loss_ce_3: 0.0006769  loss_mask_3: 0.1188  loss_dice_3: 0.1831  loss_ce_4: 0.0009283  loss_mask_4: 0.1161  loss_dice_4: 0.1818  loss_ce_5: 0.000709  loss_mask_5: 0.1159  loss_dice_5: 0.1806  loss_ce_6: 0.0004287  loss_mask_6: 0.1172  loss_dice_6: 0.1835  loss_ce_7: 0.0007187  loss_mask_7: 0.1131  loss_dice_7: 0.1773  loss_ce_8: 0.001352  loss_mask_8: 0.1107  loss_dice_8: 0.1757  time: 0.6131  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:50:50] d2.utils.events INFO:  eta: 0:31:31  iter: 24139  total_loss: 3.407  loss_ce: 0.001276  loss_mask: 0.1164  loss_dice: 0.2  loss_ce_0: 0.1133  loss_mask_0: 0.116  loss_dice_0: 0.2024  loss_ce_1: 0.0009983  loss_mask_1: 0.1188  loss_dice_1: 0.2029  loss_ce_2: 0.0006196  loss_mask_2: 0.118  loss_dice_2: 0.203  loss_ce_3: 0.0004493  loss_mask_3: 0.117  loss_dice_3: 0.2048  loss_ce_4: 0.0005634  loss_mask_4: 0.1208  loss_dice_4: 0.1961  loss_ce_5: 0.0004503  loss_mask_5: 0.1147  loss_dice_5: 0.1957  loss_ce_6: 0.0001693  loss_mask_6: 0.1174  loss_dice_6: 0.2052  loss_ce_7: 0.0005474  loss_mask_7: 0.1189  loss_dice_7: 0.1972  loss_ce_8: 0.0007262  loss_mask_8: 0.1129  loss_dice_8: 0.1974  time: 0.6127  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:50:54] d2.utils.events INFO:  eta: 0:31:28  iter: 24159  total_loss: 3.172  loss_ce: 0.0005699  loss_mask: 0.1179  loss_dice: 0.1771  loss_ce_0: 0.1231  loss_mask_0: 0.1188  loss_dice_0: 0.1802  loss_ce_1: 0.001135  loss_mask_1: 0.1238  loss_dice_1: 0.1801  loss_ce_2: 0.000868  loss_mask_2: 0.1196  loss_dice_2: 0.1802  loss_ce_3: 0.0007892  loss_mask_3: 0.1187  loss_dice_3: 0.1821  loss_ce_4: 0.0008172  loss_mask_4: 0.1166  loss_dice_4: 0.1825  loss_ce_5: 0.0009244  loss_mask_5: 0.1182  loss_dice_5: 0.1798  loss_ce_6: 0.0003998  loss_mask_6: 0.117  loss_dice_6: 0.1816  loss_ce_7: 0.0007217  loss_mask_7: 0.1225  loss_dice_7: 0.1792  loss_ce_8: 0.0007991  loss_mask_8: 0.1201  loss_dice_8: 0.1774  time: 0.6123  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:50:57] d2.utils.events INFO:  eta: 0:31:25  iter: 24179  total_loss: 3.164  loss_ce: 0.0003594  loss_mask: 0.1189  loss_dice: 0.1888  loss_ce_0: 0.1234  loss_mask_0: 0.1239  loss_dice_0: 0.1877  loss_ce_1: 0.0008722  loss_mask_1: 0.1152  loss_dice_1: 0.1838  loss_ce_2: 0.0006336  loss_mask_2: 0.1175  loss_dice_2: 0.1847  loss_ce_3: 0.001027  loss_mask_3: 0.1173  loss_dice_3: 0.1837  loss_ce_4: 0.0004653  loss_mask_4: 0.1163  loss_dice_4: 0.1898  loss_ce_5: 0.0005577  loss_mask_5: 0.1229  loss_dice_5: 0.1847  loss_ce_6: 0.0004276  loss_mask_6: 0.119  loss_dice_6: 0.1869  loss_ce_7: 0.0005291  loss_mask_7: 0.1214  loss_dice_7: 0.1904  loss_ce_8: 0.0005862  loss_mask_8: 0.1218  loss_dice_8: 0.1874  time: 0.6120  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:51:01] d2.utils.events INFO:  eta: 0:31:21  iter: 24199  total_loss: 2.917  loss_ce: 0.0003576  loss_mask: 0.1097  loss_dice: 0.1663  loss_ce_0: 0.1328  loss_mask_0: 0.1114  loss_dice_0: 0.168  loss_ce_1: 0.0007741  loss_mask_1: 0.1109  loss_dice_1: 0.1645  loss_ce_2: 0.0006705  loss_mask_2: 0.1098  loss_dice_2: 0.163  loss_ce_3: 0.0007244  loss_mask_3: 0.1114  loss_dice_3: 0.1666  loss_ce_4: 0.0006273  loss_mask_4: 0.111  loss_dice_4: 0.1637  loss_ce_5: 0.0005733  loss_mask_5: 0.1087  loss_dice_5: 0.166  loss_ce_6: 0.0005816  loss_mask_6: 0.1106  loss_dice_6: 0.1654  loss_ce_7: 0.0005748  loss_mask_7: 0.1118  loss_dice_7: 0.165  loss_ce_8: 0.0007274  loss_mask_8: 0.1094  loss_dice_8: 0.1664  time: 0.6116  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:51:04] d2.utils.events INFO:  eta: 0:31:17  iter: 24219  total_loss: 3.038  loss_ce: 0.0002664  loss_mask: 0.1118  loss_dice: 0.1846  loss_ce_0: 0.1237  loss_mask_0: 0.111  loss_dice_0: 0.1831  loss_ce_1: 0.0007086  loss_mask_1: 0.1081  loss_dice_1: 0.1793  loss_ce_2: 0.0007392  loss_mask_2: 0.1135  loss_dice_2: 0.1796  loss_ce_3: 0.0004222  loss_mask_3: 0.1115  loss_dice_3: 0.1798  loss_ce_4: 0.0004236  loss_mask_4: 0.1092  loss_dice_4: 0.1783  loss_ce_5: 0.0006003  loss_mask_5: 0.1116  loss_dice_5: 0.1767  loss_ce_6: 0.000288  loss_mask_6: 0.1101  loss_dice_6: 0.1773  loss_ce_7: 0.0005144  loss_mask_7: 0.1113  loss_dice_7: 0.1832  loss_ce_8: 0.0005246  loss_mask_8: 0.1148  loss_dice_8: 0.1745  time: 0.6113  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:51:08] d2.utils.events INFO:  eta: 0:31:14  iter: 24239  total_loss: 3.081  loss_ce: 0.0002471  loss_mask: 0.116  loss_dice: 0.1782  loss_ce_0: 0.1249  loss_mask_0: 0.1164  loss_dice_0: 0.179  loss_ce_1: 0.0006782  loss_mask_1: 0.1187  loss_dice_1: 0.1865  loss_ce_2: 0.0007689  loss_mask_2: 0.1131  loss_dice_2: 0.1754  loss_ce_3: 0.000374  loss_mask_3: 0.116  loss_dice_3: 0.18  loss_ce_4: 0.0004415  loss_mask_4: 0.1137  loss_dice_4: 0.184  loss_ce_5: 0.0005918  loss_mask_5: 0.1188  loss_dice_5: 0.1931  loss_ce_6: 0.0003486  loss_mask_6: 0.1122  loss_dice_6: 0.1802  loss_ce_7: 0.0004709  loss_mask_7: 0.1149  loss_dice_7: 0.1808  loss_ce_8: 0.0004015  loss_mask_8: 0.1179  loss_dice_8: 0.1834  time: 0.6109  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:51:12] d2.utils.events INFO:  eta: 0:31:10  iter: 24259  total_loss: 3.093  loss_ce: 0.0005534  loss_mask: 0.1172  loss_dice: 0.1819  loss_ce_0: 0.1246  loss_mask_0: 0.1167  loss_dice_0: 0.1861  loss_ce_1: 0.001131  loss_mask_1: 0.1194  loss_dice_1: 0.1809  loss_ce_2: 0.0008064  loss_mask_2: 0.1152  loss_dice_2: 0.1771  loss_ce_3: 0.0009023  loss_mask_3: 0.116  loss_dice_3: 0.1757  loss_ce_4: 0.0008872  loss_mask_4: 0.1198  loss_dice_4: 0.177  loss_ce_5: 0.0009141  loss_mask_5: 0.1147  loss_dice_5: 0.1737  loss_ce_6: 0.0004806  loss_mask_6: 0.1173  loss_dice_6: 0.1753  loss_ce_7: 0.001008  loss_mask_7: 0.1165  loss_dice_7: 0.1881  loss_ce_8: 0.0009608  loss_mask_8: 0.1162  loss_dice_8: 0.183  time: 0.6106  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:51:15] d2.utils.events INFO:  eta: 0:31:07  iter: 24279  total_loss: 2.99  loss_ce: 0.0008436  loss_mask: 0.1091  loss_dice: 0.1663  loss_ce_0: 0.1236  loss_mask_0: 0.1097  loss_dice_0: 0.158  loss_ce_1: 0.00111  loss_mask_1: 0.1113  loss_dice_1: 0.1773  loss_ce_2: 0.001005  loss_mask_2: 0.1145  loss_dice_2: 0.1679  loss_ce_3: 0.001014  loss_mask_3: 0.1092  loss_dice_3: 0.1665  loss_ce_4: 0.001171  loss_mask_4: 0.109  loss_dice_4: 0.174  loss_ce_5: 0.001104  loss_mask_5: 0.109  loss_dice_5: 0.1642  loss_ce_6: 0.0008903  loss_mask_6: 0.1081  loss_dice_6: 0.1695  loss_ce_7: 0.001084  loss_mask_7: 0.1109  loss_dice_7: 0.1754  loss_ce_8: 0.0009753  loss_mask_8: 0.1111  loss_dice_8: 0.168  time: 0.6102  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:51:19] d2.utils.events INFO:  eta: 0:31:04  iter: 24299  total_loss: 3.155  loss_ce: 0.0007457  loss_mask: 0.1194  loss_dice: 0.1678  loss_ce_0: 0.1218  loss_mask_0: 0.1183  loss_dice_0: 0.175  loss_ce_1: 0.001553  loss_mask_1: 0.118  loss_dice_1: 0.1734  loss_ce_2: 0.001257  loss_mask_2: 0.1172  loss_dice_2: 0.173  loss_ce_3: 0.0007613  loss_mask_3: 0.1187  loss_dice_3: 0.1721  loss_ce_4: 0.001162  loss_mask_4: 0.1178  loss_dice_4: 0.1702  loss_ce_5: 0.001355  loss_mask_5: 0.1187  loss_dice_5: 0.1773  loss_ce_6: 0.0007035  loss_mask_6: 0.1202  loss_dice_6: 0.1683  loss_ce_7: 0.00136  loss_mask_7: 0.1168  loss_dice_7: 0.1742  loss_ce_8: 0.0009962  loss_mask_8: 0.1174  loss_dice_8: 0.1727  time: 0.6098  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:51:22] d2.utils.events INFO:  eta: 0:31:01  iter: 24319  total_loss: 3.046  loss_ce: 0.0005894  loss_mask: 0.1198  loss_dice: 0.1772  loss_ce_0: 0.1215  loss_mask_0: 0.1161  loss_dice_0: 0.1791  loss_ce_1: 0.0009227  loss_mask_1: 0.1182  loss_dice_1: 0.178  loss_ce_2: 0.0008785  loss_mask_2: 0.1169  loss_dice_2: 0.1776  loss_ce_3: 0.000665  loss_mask_3: 0.1181  loss_dice_3: 0.1742  loss_ce_4: 0.0007975  loss_mask_4: 0.1166  loss_dice_4: 0.1766  loss_ce_5: 0.0009246  loss_mask_5: 0.1172  loss_dice_5: 0.1728  loss_ce_6: 0.0005159  loss_mask_6: 0.1136  loss_dice_6: 0.1793  loss_ce_7: 0.00068  loss_mask_7: 0.1179  loss_dice_7: 0.1792  loss_ce_8: 0.0007325  loss_mask_8: 0.1173  loss_dice_8: 0.1744  time: 0.6095  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:51:26] d2.utils.events INFO:  eta: 0:30:58  iter: 24339  total_loss: 2.934  loss_ce: 0.0004071  loss_mask: 0.1095  loss_dice: 0.1712  loss_ce_0: 0.1222  loss_mask_0: 0.1116  loss_dice_0: 0.1682  loss_ce_1: 0.0007135  loss_mask_1: 0.1087  loss_dice_1: 0.1735  loss_ce_2: 0.0007358  loss_mask_2: 0.1129  loss_dice_2: 0.1714  loss_ce_3: 0.0004931  loss_mask_3: 0.1104  loss_dice_3: 0.1675  loss_ce_4: 0.0005444  loss_mask_4: 0.1121  loss_dice_4: 0.1706  loss_ce_5: 0.0007323  loss_mask_5: 0.1096  loss_dice_5: 0.1694  loss_ce_6: 0.0003901  loss_mask_6: 0.1093  loss_dice_6: 0.1743  loss_ce_7: 0.0005168  loss_mask_7: 0.1122  loss_dice_7: 0.1698  loss_ce_8: 0.0006222  loss_mask_8: 0.1109  loss_dice_8: 0.1654  time: 0.6091  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:51:30] d2.utils.events INFO:  eta: 0:30:53  iter: 24359  total_loss: 2.916  loss_ce: 0.0003778  loss_mask: 0.1129  loss_dice: 0.1626  loss_ce_0: 0.1243  loss_mask_0: 0.1139  loss_dice_0: 0.1617  loss_ce_1: 0.0005569  loss_mask_1: 0.1175  loss_dice_1: 0.168  loss_ce_2: 0.000607  loss_mask_2: 0.1142  loss_dice_2: 0.1607  loss_ce_3: 0.000445  loss_mask_3: 0.1148  loss_dice_3: 0.173  loss_ce_4: 0.0004667  loss_mask_4: 0.1122  loss_dice_4: 0.1653  loss_ce_5: 0.0005595  loss_mask_5: 0.1071  loss_dice_5: 0.162  loss_ce_6: 0.0003201  loss_mask_6: 0.1169  loss_dice_6: 0.1651  loss_ce_7: 0.0004275  loss_mask_7: 0.111  loss_dice_7: 0.1643  loss_ce_8: 0.0004706  loss_mask_8: 0.1088  loss_dice_8: 0.1648  time: 0.6088  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:51:33] d2.utils.events INFO:  eta: 0:30:50  iter: 24379  total_loss: 2.902  loss_ce: 0.00028  loss_mask: 0.1143  loss_dice: 0.1638  loss_ce_0: 0.123  loss_mask_0: 0.1162  loss_dice_0: 0.17  loss_ce_1: 0.000467  loss_mask_1: 0.1131  loss_dice_1: 0.1714  loss_ce_2: 0.000515  loss_mask_2: 0.1146  loss_dice_2: 0.1669  loss_ce_3: 0.0003404  loss_mask_3: 0.1154  loss_dice_3: 0.1652  loss_ce_4: 0.0003624  loss_mask_4: 0.1116  loss_dice_4: 0.1663  loss_ce_5: 0.0004838  loss_mask_5: 0.1163  loss_dice_5: 0.1689  loss_ce_6: 0.0002918  loss_mask_6: 0.1152  loss_dice_6: 0.1638  loss_ce_7: 0.000357  loss_mask_7: 0.1158  loss_dice_7: 0.1653  loss_ce_8: 0.0004247  loss_mask_8: 0.1127  loss_dice_8: 0.1684  time: 0.6084  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:51:37] d2.utils.events INFO:  eta: 0:30:46  iter: 24399  total_loss: 3.067  loss_ce: 0.0003945  loss_mask: 0.111  loss_dice: 0.18  loss_ce_0: 0.1255  loss_mask_0: 0.1099  loss_dice_0: 0.1727  loss_ce_1: 0.0005236  loss_mask_1: 0.1114  loss_dice_1: 0.1747  loss_ce_2: 0.0005115  loss_mask_2: 0.1109  loss_dice_2: 0.1749  loss_ce_3: 0.0004591  loss_mask_3: 0.1125  loss_dice_3: 0.1775  loss_ce_4: 0.0003752  loss_mask_4: 0.1121  loss_dice_4: 0.1729  loss_ce_5: 0.0004474  loss_mask_5: 0.1125  loss_dice_5: 0.1739  loss_ce_6: 0.0002725  loss_mask_6: 0.1113  loss_dice_6: 0.178  loss_ce_7: 0.0003826  loss_mask_7: 0.1125  loss_dice_7: 0.1778  loss_ce_8: 0.0005335  loss_mask_8: 0.1121  loss_dice_8: 0.1751  time: 0.6081  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:51:40] d2.utils.events INFO:  eta: 0:30:42  iter: 24419  total_loss: 2.937  loss_ce: 0.0003932  loss_mask: 0.1133  loss_dice: 0.1602  loss_ce_0: 0.1233  loss_mask_0: 0.1122  loss_dice_0: 0.1595  loss_ce_1: 0.0006026  loss_mask_1: 0.1172  loss_dice_1: 0.1655  loss_ce_2: 0.0005912  loss_mask_2: 0.1169  loss_dice_2: 0.1634  loss_ce_3: 0.0004225  loss_mask_3: 0.1136  loss_dice_3: 0.1588  loss_ce_4: 0.0002794  loss_mask_4: 0.1124  loss_dice_4: 0.1612  loss_ce_5: 0.0005091  loss_mask_5: 0.1109  loss_dice_5: 0.1595  loss_ce_6: 0.0002423  loss_mask_6: 0.1183  loss_dice_6: 0.161  loss_ce_7: 0.0003744  loss_mask_7: 0.1137  loss_dice_7: 0.1658  loss_ce_8: 0.000644  loss_mask_8: 0.1184  loss_dice_8: 0.1636  time: 0.6077  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:51:44] d2.utils.events INFO:  eta: 0:30:39  iter: 24439  total_loss: 3.171  loss_ce: 0.0002987  loss_mask: 0.1197  loss_dice: 0.1808  loss_ce_0: 0.1227  loss_mask_0: 0.1202  loss_dice_0: 0.1835  loss_ce_1: 0.0005393  loss_mask_1: 0.1187  loss_dice_1: 0.1787  loss_ce_2: 0.0005523  loss_mask_2: 0.121  loss_dice_2: 0.1812  loss_ce_3: 0.0002862  loss_mask_3: 0.1187  loss_dice_3: 0.1778  loss_ce_4: 0.0002854  loss_mask_4: 0.1213  loss_dice_4: 0.1784  loss_ce_5: 0.0004815  loss_mask_5: 0.1236  loss_dice_5: 0.1803  loss_ce_6: 0.0002317  loss_mask_6: 0.1187  loss_dice_6: 0.1786  loss_ce_7: 0.0003216  loss_mask_7: 0.1166  loss_dice_7: 0.1805  loss_ce_8: 0.0005478  loss_mask_8: 0.1211  loss_dice_8: 0.1823  time: 0.6074  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:51:47] d2.utils.events INFO:  eta: 0:30:35  iter: 24459  total_loss: 3.201  loss_ce: 0.0002865  loss_mask: 0.1239  loss_dice: 0.1794  loss_ce_0: 0.1218  loss_mask_0: 0.1246  loss_dice_0: 0.1738  loss_ce_1: 0.0004588  loss_mask_1: 0.1254  loss_dice_1: 0.1883  loss_ce_2: 0.000507  loss_mask_2: 0.1266  loss_dice_2: 0.1798  loss_ce_3: 0.0003609  loss_mask_3: 0.1246  loss_dice_3: 0.1831  loss_ce_4: 0.0003158  loss_mask_4: 0.1251  loss_dice_4: 0.1849  loss_ce_5: 0.0004819  loss_mask_5: 0.1252  loss_dice_5: 0.1844  loss_ce_6: 0.0002384  loss_mask_6: 0.1223  loss_dice_6: 0.1828  loss_ce_7: 0.0002872  loss_mask_7: 0.1253  loss_dice_7: 0.1722  loss_ce_8: 0.0005067  loss_mask_8: 0.1263  loss_dice_8: 0.1793  time: 0.6070  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:51:51] d2.utils.events INFO:  eta: 0:30:31  iter: 24479  total_loss: 3.026  loss_ce: 0.0002473  loss_mask: 0.1104  loss_dice: 0.1702  loss_ce_0: 0.1294  loss_mask_0: 0.1131  loss_dice_0: 0.1866  loss_ce_1: 0.0003993  loss_mask_1: 0.111  loss_dice_1: 0.1779  loss_ce_2: 0.0004477  loss_mask_2: 0.112  loss_dice_2: 0.1743  loss_ce_3: 0.0002485  loss_mask_3: 0.1112  loss_dice_3: 0.1686  loss_ce_4: 0.0002242  loss_mask_4: 0.1124  loss_dice_4: 0.1762  loss_ce_5: 0.0004158  loss_mask_5: 0.1134  loss_dice_5: 0.1793  loss_ce_6: 0.000194  loss_mask_6: 0.1147  loss_dice_6: 0.1749  loss_ce_7: 0.0002511  loss_mask_7: 0.1125  loss_dice_7: 0.1696  loss_ce_8: 0.0004407  loss_mask_8: 0.1117  loss_dice_8: 0.178  time: 0.6067  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:51:54] d2.utils.events INFO:  eta: 0:30:27  iter: 24499  total_loss: 2.876  loss_ce: 0.0002009  loss_mask: 0.1115  loss_dice: 0.1651  loss_ce_0: 0.1242  loss_mask_0: 0.1107  loss_dice_0: 0.1644  loss_ce_1: 0.0003335  loss_mask_1: 0.1111  loss_dice_1: 0.163  loss_ce_2: 0.0003948  loss_mask_2: 0.1148  loss_dice_2: 0.1659  loss_ce_3: 0.0003112  loss_mask_3: 0.1146  loss_dice_3: 0.1646  loss_ce_4: 0.0002206  loss_mask_4: 0.1094  loss_dice_4: 0.1597  loss_ce_5: 0.0002544  loss_mask_5: 0.1142  loss_dice_5: 0.163  loss_ce_6: 0.0001823  loss_mask_6: 0.1134  loss_dice_6: 0.1638  loss_ce_7: 0.0002468  loss_mask_7: 0.1098  loss_dice_7: 0.1595  loss_ce_8: 0.0002518  loss_mask_8: 0.1129  loss_dice_8: 0.1633  time: 0.6063  data_time: 0.0010  lr: 0.0001  max_mem: 8444M
[08/01 21:51:58] d2.utils.events INFO:  eta: 0:30:23  iter: 24519  total_loss: 2.943  loss_ce: 0.0002224  loss_mask: 0.1123  loss_dice: 0.1676  loss_ce_0: 0.1233  loss_mask_0: 0.1101  loss_dice_0: 0.1672  loss_ce_1: 0.0003417  loss_mask_1: 0.1094  loss_dice_1: 0.1673  loss_ce_2: 0.0003596  loss_mask_2: 0.1077  loss_dice_2: 0.1618  loss_ce_3: 0.0002815  loss_mask_3: 0.11  loss_dice_3: 0.1613  loss_ce_4: 0.0002471  loss_mask_4: 0.1112  loss_dice_4: 0.1624  loss_ce_5: 0.0003398  loss_mask_5: 0.1131  loss_dice_5: 0.1625  loss_ce_6: 0.000199  loss_mask_6: 0.1114  loss_dice_6: 0.1685  loss_ce_7: 0.0002338  loss_mask_7: 0.1097  loss_dice_7: 0.1617  loss_ce_8: 0.000384  loss_mask_8: 0.1119  loss_dice_8: 0.1656  time: 0.6060  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:02] d2.utils.events INFO:  eta: 0:30:20  iter: 24539  total_loss: 3.041  loss_ce: 0.0002005  loss_mask: 0.1129  loss_dice: 0.1778  loss_ce_0: 0.1243  loss_mask_0: 0.1099  loss_dice_0: 0.1775  loss_ce_1: 0.0002856  loss_mask_1: 0.1091  loss_dice_1: 0.1821  loss_ce_2: 0.0003016  loss_mask_2: 0.1123  loss_dice_2: 0.1757  loss_ce_3: 0.0002334  loss_mask_3: 0.1116  loss_dice_3: 0.1797  loss_ce_4: 0.0001781  loss_mask_4: 0.1128  loss_dice_4: 0.1769  loss_ce_5: 0.0002316  loss_mask_5: 0.1117  loss_dice_5: 0.1797  loss_ce_6: 0.0001468  loss_mask_6: 0.1127  loss_dice_6: 0.1831  loss_ce_7: 0.0001832  loss_mask_7: 0.1176  loss_dice_7: 0.1791  loss_ce_8: 0.0002392  loss_mask_8: 0.1125  loss_dice_8: 0.1782  time: 0.6056  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:05] d2.utils.events INFO:  eta: 0:30:16  iter: 24559  total_loss: 2.886  loss_ce: 0.0001792  loss_mask: 0.1121  loss_dice: 0.1687  loss_ce_0: 0.1281  loss_mask_0: 0.1099  loss_dice_0: 0.1643  loss_ce_1: 0.0002677  loss_mask_1: 0.1118  loss_dice_1: 0.1609  loss_ce_2: 0.0002861  loss_mask_2: 0.1107  loss_dice_2: 0.1628  loss_ce_3: 0.0001391  loss_mask_3: 0.1112  loss_dice_3: 0.1626  loss_ce_4: 0.0001534  loss_mask_4: 0.1112  loss_dice_4: 0.1673  loss_ce_5: 0.0002171  loss_mask_5: 0.1099  loss_dice_5: 0.1664  loss_ce_6: 0.000124  loss_mask_6: 0.1084  loss_dice_6: 0.1654  loss_ce_7: 0.0001781  loss_mask_7: 0.108  loss_dice_7: 0.1622  loss_ce_8: 0.0002365  loss_mask_8: 0.1101  loss_dice_8: 0.1619  time: 0.6053  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:09] d2.utils.events INFO:  eta: 0:30:13  iter: 24579  total_loss: 3.047  loss_ce: 0.0001764  loss_mask: 0.1095  loss_dice: 0.1682  loss_ce_0: 0.1139  loss_mask_0: 0.1114  loss_dice_0: 0.171  loss_ce_1: 0.0002562  loss_mask_1: 0.1119  loss_dice_1: 0.1749  loss_ce_2: 0.0002811  loss_mask_2: 0.1111  loss_dice_2: 0.1769  loss_ce_3: 0.0001989  loss_mask_3: 0.1112  loss_dice_3: 0.1733  loss_ce_4: 0.0001578  loss_mask_4: 0.1108  loss_dice_4: 0.1747  loss_ce_5: 0.0001892  loss_mask_5: 0.1086  loss_dice_5: 0.1749  loss_ce_6: 0.0001327  loss_mask_6: 0.1075  loss_dice_6: 0.1768  loss_ce_7: 0.0001821  loss_mask_7: 0.1094  loss_dice_7: 0.1719  loss_ce_8: 0.0002086  loss_mask_8: 0.1104  loss_dice_8: 0.1701  time: 0.6049  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:12] d2.utils.events INFO:  eta: 0:30:09  iter: 24599  total_loss: 3.078  loss_ce: 0.0001346  loss_mask: 0.1174  loss_dice: 0.1786  loss_ce_0: 0.1295  loss_mask_0: 0.1197  loss_dice_0: 0.176  loss_ce_1: 0.0002361  loss_mask_1: 0.1186  loss_dice_1: 0.1772  loss_ce_2: 0.0002603  loss_mask_2: 0.1163  loss_dice_2: 0.1754  loss_ce_3: 0.0001641  loss_mask_3: 0.1174  loss_dice_3: 0.1696  loss_ce_4: 0.0001564  loss_mask_4: 0.1183  loss_dice_4: 0.1738  loss_ce_5: 0.000247  loss_mask_5: 0.1192  loss_dice_5: 0.1692  loss_ce_6: 0.0001044  loss_mask_6: 0.1158  loss_dice_6: 0.1721  loss_ce_7: 0.0001535  loss_mask_7: 0.1185  loss_dice_7: 0.1754  loss_ce_8: 0.000304  loss_mask_8: 0.1179  loss_dice_8: 0.1754  time: 0.6046  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:16] d2.utils.events INFO:  eta: 0:30:06  iter: 24619  total_loss: 3.015  loss_ce: 0.0001537  loss_mask: 0.1172  loss_dice: 0.177  loss_ce_0: 0.125  loss_mask_0: 0.1148  loss_dice_0: 0.1759  loss_ce_1: 0.0002187  loss_mask_1: 0.1141  loss_dice_1: 0.1683  loss_ce_2: 0.0002607  loss_mask_2: 0.1159  loss_dice_2: 0.172  loss_ce_3: 0.0001517  loss_mask_3: 0.1192  loss_dice_3: 0.1667  loss_ce_4: 0.0001649  loss_mask_4: 0.1187  loss_dice_4: 0.1657  loss_ce_5: 0.0001931  loss_mask_5: 0.1193  loss_dice_5: 0.1698  loss_ce_6: 0.0001121  loss_mask_6: 0.1188  loss_dice_6: 0.1715  loss_ce_7: 0.0001597  loss_mask_7: 0.1149  loss_dice_7: 0.1667  loss_ce_8: 0.0002102  loss_mask_8: 0.1175  loss_dice_8: 0.1668  time: 0.6042  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:19] d2.utils.events INFO:  eta: 0:30:02  iter: 24639  total_loss: 2.955  loss_ce: 0.0001503  loss_mask: 0.1161  loss_dice: 0.1659  loss_ce_0: 0.1255  loss_mask_0: 0.118  loss_dice_0: 0.1722  loss_ce_1: 0.0001827  loss_mask_1: 0.1194  loss_dice_1: 0.1635  loss_ce_2: 0.0002398  loss_mask_2: 0.116  loss_dice_2: 0.1674  loss_ce_3: 0.0001345  loss_mask_3: 0.1181  loss_dice_3: 0.1598  loss_ce_4: 0.0001467  loss_mask_4: 0.1132  loss_dice_4: 0.162  loss_ce_5: 0.0001485  loss_mask_5: 0.1129  loss_dice_5: 0.1624  loss_ce_6: 0.0001014  loss_mask_6: 0.1187  loss_dice_6: 0.1675  loss_ce_7: 0.0001588  loss_mask_7: 0.1166  loss_dice_7: 0.1675  loss_ce_8: 0.0001712  loss_mask_8: 0.1172  loss_dice_8: 0.1647  time: 0.6039  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:23] d2.utils.events INFO:  eta: 0:29:58  iter: 24659  total_loss: 3.1  loss_ce: 0.0001576  loss_mask: 0.1084  loss_dice: 0.1757  loss_ce_0: 0.1248  loss_mask_0: 0.111  loss_dice_0: 0.1857  loss_ce_1: 0.000201  loss_mask_1: 0.1121  loss_dice_1: 0.186  loss_ce_2: 0.0002405  loss_mask_2: 0.1121  loss_dice_2: 0.1779  loss_ce_3: 0.00015  loss_mask_3: 0.1101  loss_dice_3: 0.1753  loss_ce_4: 0.000172  loss_mask_4: 0.1079  loss_dice_4: 0.1841  loss_ce_5: 0.0001808  loss_mask_5: 0.1101  loss_dice_5: 0.1852  loss_ce_6: 0.0001203  loss_mask_6: 0.1116  loss_dice_6: 0.1855  loss_ce_7: 0.0001541  loss_mask_7: 0.1126  loss_dice_7: 0.1847  loss_ce_8: 0.0002079  loss_mask_8: 0.1124  loss_dice_8: 0.1808  time: 0.6035  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:27] d2.utils.events INFO:  eta: 0:29:53  iter: 24679  total_loss: 3.047  loss_ce: 0.0001097  loss_mask: 0.1171  loss_dice: 0.1728  loss_ce_0: 0.1223  loss_mask_0: 0.1198  loss_dice_0: 0.1734  loss_ce_1: 0.0001622  loss_mask_1: 0.1183  loss_dice_1: 0.1753  loss_ce_2: 0.000172  loss_mask_2: 0.1195  loss_dice_2: 0.1734  loss_ce_3: 9.627e-05  loss_mask_3: 0.1234  loss_dice_3: 0.1732  loss_ce_4: 0.0001237  loss_mask_4: 0.1176  loss_dice_4: 0.1741  loss_ce_5: 0.0001305  loss_mask_5: 0.1185  loss_dice_5: 0.1716  loss_ce_6: 8.217e-05  loss_mask_6: 0.1223  loss_dice_6: 0.1749  loss_ce_7: 0.0001444  loss_mask_7: 0.1164  loss_dice_7: 0.1738  loss_ce_8: 0.0001471  loss_mask_8: 0.1228  loss_dice_8: 0.1782  time: 0.6032  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:30] d2.utils.events INFO:  eta: 0:29:50  iter: 24699  total_loss: 2.979  loss_ce: 0.0001217  loss_mask: 0.1098  loss_dice: 0.1742  loss_ce_0: 0.1181  loss_mask_0: 0.1094  loss_dice_0: 0.1857  loss_ce_1: 0.000206  loss_mask_1: 0.1078  loss_dice_1: 0.1685  loss_ce_2: 0.0002466  loss_mask_2: 0.1091  loss_dice_2: 0.1715  loss_ce_3: 0.0001198  loss_mask_3: 0.1085  loss_dice_3: 0.1747  loss_ce_4: 0.0001534  loss_mask_4: 0.1112  loss_dice_4: 0.1751  loss_ce_5: 0.0001905  loss_mask_5: 0.1095  loss_dice_5: 0.1706  loss_ce_6: 8.75e-05  loss_mask_6: 0.1135  loss_dice_6: 0.1749  loss_ce_7: 0.0001549  loss_mask_7: 0.1073  loss_dice_7: 0.1739  loss_ce_8: 0.0002221  loss_mask_8: 0.1118  loss_dice_8: 0.1755  time: 0.6028  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:34] d2.utils.events INFO:  eta: 0:29:47  iter: 24719  total_loss: 2.951  loss_ce: 0.0001151  loss_mask: 0.1132  loss_dice: 0.1691  loss_ce_0: 0.1292  loss_mask_0: 0.1107  loss_dice_0: 0.174  loss_ce_1: 0.0001695  loss_mask_1: 0.1107  loss_dice_1: 0.1653  loss_ce_2: 0.0001744  loss_mask_2: 0.1081  loss_dice_2: 0.1651  loss_ce_3: 8.788e-05  loss_mask_3: 0.1083  loss_dice_3: 0.1626  loss_ce_4: 0.0001327  loss_mask_4: 0.1075  loss_dice_4: 0.1697  loss_ce_5: 0.0001491  loss_mask_5: 0.1104  loss_dice_5: 0.1657  loss_ce_6: 8.177e-05  loss_mask_6: 0.1079  loss_dice_6: 0.1658  loss_ce_7: 0.0001237  loss_mask_7: 0.1079  loss_dice_7: 0.165  loss_ce_8: 0.0001759  loss_mask_8: 0.1119  loss_dice_8: 0.1746  time: 0.6025  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:52:37] d2.utils.events INFO:  eta: 0:29:45  iter: 24739  total_loss: 2.958  loss_ce: 0.0001084  loss_mask: 0.1165  loss_dice: 0.1688  loss_ce_0: 0.124  loss_mask_0: 0.1135  loss_dice_0: 0.1711  loss_ce_1: 0.0001629  loss_mask_1: 0.1116  loss_dice_1: 0.1719  loss_ce_2: 0.0001908  loss_mask_2: 0.1126  loss_dice_2: 0.1707  loss_ce_3: 8.46e-05  loss_mask_3: 0.1161  loss_dice_3: 0.1717  loss_ce_4: 0.0001076  loss_mask_4: 0.1097  loss_dice_4: 0.1645  loss_ce_5: 0.0001202  loss_mask_5: 0.1131  loss_dice_5: 0.1619  loss_ce_6: 7.669e-05  loss_mask_6: 0.1125  loss_dice_6: 0.165  loss_ce_7: 0.0001187  loss_mask_7: 0.1151  loss_dice_7: 0.1684  loss_ce_8: 0.0001269  loss_mask_8: 0.1133  loss_dice_8: 0.1737  time: 0.6022  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:41] d2.utils.events INFO:  eta: 0:29:39  iter: 24759  total_loss: 3.018  loss_ce: 0.00011  loss_mask: 0.1139  loss_dice: 0.1727  loss_ce_0: 0.126  loss_mask_0: 0.1128  loss_dice_0: 0.1649  loss_ce_1: 0.0001809  loss_mask_1: 0.1133  loss_dice_1: 0.1716  loss_ce_2: 0.0002091  loss_mask_2: 0.1155  loss_dice_2: 0.168  loss_ce_3: 9.275e-05  loss_mask_3: 0.1147  loss_dice_3: 0.1678  loss_ce_4: 0.0001355  loss_mask_4: 0.1169  loss_dice_4: 0.1697  loss_ce_5: 0.000189  loss_mask_5: 0.1136  loss_dice_5: 0.167  loss_ce_6: 7.477e-05  loss_mask_6: 0.1168  loss_dice_6: 0.1722  loss_ce_7: 0.0001279  loss_mask_7: 0.1151  loss_dice_7: 0.1699  loss_ce_8: 0.000234  loss_mask_8: 0.1169  loss_dice_8: 0.1703  time: 0.6018  data_time: 0.0012  lr: 0.0001  max_mem: 8444M
[08/01 21:52:44] d2.utils.events INFO:  eta: 0:29:35  iter: 24779  total_loss: 3.012  loss_ce: 9.967e-05  loss_mask: 0.1151  loss_dice: 0.1778  loss_ce_0: 0.1267  loss_mask_0: 0.11  loss_dice_0: 0.1717  loss_ce_1: 0.0001487  loss_mask_1: 0.1115  loss_dice_1: 0.1719  loss_ce_2: 0.0001657  loss_mask_2: 0.1169  loss_dice_2: 0.1706  loss_ce_3: 9.052e-05  loss_mask_3: 0.1143  loss_dice_3: 0.1711  loss_ce_4: 0.0001168  loss_mask_4: 0.1146  loss_dice_4: 0.1711  loss_ce_5: 0.0001308  loss_mask_5: 0.1086  loss_dice_5: 0.1663  loss_ce_6: 7.765e-05  loss_mask_6: 0.1163  loss_dice_6: 0.1778  loss_ce_7: 0.0001132  loss_mask_7: 0.1148  loss_dice_7: 0.1715  loss_ce_8: 0.0001466  loss_mask_8: 0.1142  loss_dice_8: 0.1769  time: 0.6015  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:48] d2.utils.events INFO:  eta: 0:29:30  iter: 24799  total_loss: 2.797  loss_ce: 9.249e-05  loss_mask: 0.1122  loss_dice: 0.1597  loss_ce_0: 0.1278  loss_mask_0: 0.1103  loss_dice_0: 0.1617  loss_ce_1: 0.0001526  loss_mask_1: 0.1125  loss_dice_1: 0.1612  loss_ce_2: 0.000162  loss_mask_2: 0.1148  loss_dice_2: 0.1671  loss_ce_3: 8.531e-05  loss_mask_3: 0.1088  loss_dice_3: 0.1567  loss_ce_4: 0.0001083  loss_mask_4: 0.1123  loss_dice_4: 0.1622  loss_ce_5: 0.0001376  loss_mask_5: 0.1118  loss_dice_5: 0.1624  loss_ce_6: 7.28e-05  loss_mask_6: 0.1142  loss_dice_6: 0.1658  loss_ce_7: 0.0001164  loss_mask_7: 0.1134  loss_dice_7: 0.161  loss_ce_8: 0.0001479  loss_mask_8: 0.1077  loss_dice_8: 0.1647  time: 0.6011  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:52] d2.utils.events INFO:  eta: 0:29:29  iter: 24819  total_loss: 2.938  loss_ce: 9.547e-05  loss_mask: 0.113  loss_dice: 0.1803  loss_ce_0: 0.1262  loss_mask_0: 0.1137  loss_dice_0: 0.1644  loss_ce_1: 0.0001372  loss_mask_1: 0.1114  loss_dice_1: 0.1738  loss_ce_2: 0.0001571  loss_mask_2: 0.1156  loss_dice_2: 0.1804  loss_ce_3: 6.71e-05  loss_mask_3: 0.1129  loss_dice_3: 0.1683  loss_ce_4: 0.0001114  loss_mask_4: 0.1173  loss_dice_4: 0.1718  loss_ce_5: 0.0001054  loss_mask_5: 0.1142  loss_dice_5: 0.1707  loss_ce_6: 6.201e-05  loss_mask_6: 0.113  loss_dice_6: 0.1637  loss_ce_7: 0.0001144  loss_mask_7: 0.1119  loss_dice_7: 0.1736  loss_ce_8: 0.0001132  loss_mask_8: 0.1091  loss_dice_8: 0.1735  time: 0.6008  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:52:57] d2.utils.events INFO:  eta: 0:29:30  iter: 24839  total_loss: 2.973  loss_ce: 9.899e-05  loss_mask: 0.1157  loss_dice: 0.17  loss_ce_0: 0.1265  loss_mask_0: 0.1158  loss_dice_0: 0.1744  loss_ce_1: 0.0001285  loss_mask_1: 0.1165  loss_dice_1: 0.17  loss_ce_2: 0.0001592  loss_mask_2: 0.1151  loss_dice_2: 0.1696  loss_ce_3: 8.578e-05  loss_mask_3: 0.1118  loss_dice_3: 0.1606  loss_ce_4: 0.0001092  loss_mask_4: 0.1119  loss_dice_4: 0.1621  loss_ce_5: 0.0001013  loss_mask_5: 0.1143  loss_dice_5: 0.1711  loss_ce_6: 6.687e-05  loss_mask_6: 0.1137  loss_dice_6: 0.1671  loss_ce_7: 0.0001061  loss_mask_7: 0.1131  loss_dice_7: 0.1674  loss_ce_8: 0.0001099  loss_mask_8: 0.1131  loss_dice_8: 0.1661  time: 0.6005  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:53:01] d2.utils.events INFO:  eta: 0:29:30  iter: 24859  total_loss: 2.726  loss_ce: 8.311e-05  loss_mask: 0.104  loss_dice: 0.1485  loss_ce_0: 0.1259  loss_mask_0: 0.1049  loss_dice_0: 0.1585  loss_ce_1: 0.0001257  loss_mask_1: 0.1064  loss_dice_1: 0.1533  loss_ce_2: 0.0001524  loss_mask_2: 0.1067  loss_dice_2: 0.1542  loss_ce_3: 9.844e-05  loss_mask_3: 0.1076  loss_dice_3: 0.1508  loss_ce_4: 9.944e-05  loss_mask_4: 0.1049  loss_dice_4: 0.1567  loss_ce_5: 9.855e-05  loss_mask_5: 0.1059  loss_dice_5: 0.1545  loss_ce_6: 7.286e-05  loss_mask_6: 0.1035  loss_dice_6: 0.1552  loss_ce_7: 0.0001067  loss_mask_7: 0.1041  loss_dice_7: 0.153  loss_ce_8: 0.0001056  loss_mask_8: 0.1108  loss_dice_8: 0.157  time: 0.6002  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:53:06] d2.utils.events INFO:  eta: 0:29:33  iter: 24879  total_loss: 2.848  loss_ce: 8.175e-05  loss_mask: 0.114  loss_dice: 0.1669  loss_ce_0: 0.1242  loss_mask_0: 0.1137  loss_dice_0: 0.1613  loss_ce_1: 0.0001407  loss_mask_1: 0.1113  loss_dice_1: 0.1622  loss_ce_2: 0.0001775  loss_mask_2: 0.1127  loss_dice_2: 0.1633  loss_ce_3: 7.98e-05  loss_mask_3: 0.1146  loss_dice_3: 0.1631  loss_ce_4: 0.0001086  loss_mask_4: 0.113  loss_dice_4: 0.1636  loss_ce_5: 0.0001723  loss_mask_5: 0.1127  loss_dice_5: 0.1634  loss_ce_6: 6.493e-05  loss_mask_6: 0.1108  loss_dice_6: 0.1648  loss_ce_7: 0.0001111  loss_mask_7: 0.1162  loss_dice_7: 0.1589  loss_ce_8: 0.0001546  loss_mask_8: 0.115  loss_dice_8: 0.1633  time: 0.5999  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:53:10] d2.utils.events INFO:  eta: 0:29:33  iter: 24899  total_loss: 2.869  loss_ce: 7.584e-05  loss_mask: 0.1107  loss_dice: 0.1633  loss_ce_0: 0.1235  loss_mask_0: 0.1142  loss_dice_0: 0.1623  loss_ce_1: 0.0001255  loss_mask_1: 0.1132  loss_dice_1: 0.1622  loss_ce_2: 0.0001373  loss_mask_2: 0.1128  loss_dice_2: 0.1641  loss_ce_3: 5.842e-05  loss_mask_3: 0.1099  loss_dice_3: 0.1554  loss_ce_4: 9.692e-05  loss_mask_4: 0.1129  loss_dice_4: 0.162  loss_ce_5: 0.0001098  loss_mask_5: 0.113  loss_dice_5: 0.1663  loss_ce_6: 5.132e-05  loss_mask_6: 0.1124  loss_dice_6: 0.1665  loss_ce_7: 9.175e-05  loss_mask_7: 0.1093  loss_dice_7: 0.1609  loss_ce_8: 0.0001183  loss_mask_8: 0.1151  loss_dice_8: 0.1625  time: 0.5996  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:53:15] d2.utils.events INFO:  eta: 0:29:35  iter: 24919  total_loss: 2.958  loss_ce: 8.453e-05  loss_mask: 0.111  loss_dice: 0.1705  loss_ce_0: 0.1222  loss_mask_0: 0.1088  loss_dice_0: 0.1744  loss_ce_1: 0.0001206  loss_mask_1: 0.1111  loss_dice_1: 0.1706  loss_ce_2: 0.0001608  loss_mask_2: 0.1068  loss_dice_2: 0.1709  loss_ce_3: 0.0001117  loss_mask_3: 0.1091  loss_dice_3: 0.1701  loss_ce_4: 0.0001036  loss_mask_4: 0.1123  loss_dice_4: 0.1675  loss_ce_5: 0.0001406  loss_mask_5: 0.1176  loss_dice_5: 0.1694  loss_ce_6: 6.388e-05  loss_mask_6: 0.1111  loss_dice_6: 0.1668  loss_ce_7: 9.052e-05  loss_mask_7: 0.1118  loss_dice_7: 0.1686  loss_ce_8: 0.0001476  loss_mask_8: 0.1127  loss_dice_8: 0.1706  time: 0.5993  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:53:20] d2.utils.events INFO:  eta: 0:29:36  iter: 24939  total_loss: 2.949  loss_ce: 7.704e-05  loss_mask: 0.1135  loss_dice: 0.1731  loss_ce_0: 0.1266  loss_mask_0: 0.1122  loss_dice_0: 0.1676  loss_ce_1: 9.791e-05  loss_mask_1: 0.1096  loss_dice_1: 0.1689  loss_ce_2: 0.0001142  loss_mask_2: 0.1085  loss_dice_2: 0.1681  loss_ce_3: 5.633e-05  loss_mask_3: 0.1096  loss_dice_3: 0.1675  loss_ce_4: 5.415e-05  loss_mask_4: 0.1124  loss_dice_4: 0.1712  loss_ce_5: 8.061e-05  loss_mask_5: 0.1109  loss_dice_5: 0.1637  loss_ce_6: 5.206e-05  loss_mask_6: 0.1098  loss_dice_6: 0.1664  loss_ce_7: 6.271e-05  loss_mask_7: 0.1096  loss_dice_7: 0.1634  loss_ce_8: 9.883e-05  loss_mask_8: 0.1138  loss_dice_8: 0.1717  time: 0.5990  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:53:24] d2.utils.events INFO:  eta: 0:29:39  iter: 24959  total_loss: 2.942  loss_ce: 6.806e-05  loss_mask: 0.1129  loss_dice: 0.1733  loss_ce_0: 0.1228  loss_mask_0: 0.114  loss_dice_0: 0.1738  loss_ce_1: 0.0001172  loss_mask_1: 0.1144  loss_dice_1: 0.1735  loss_ce_2: 0.0001632  loss_mask_2: 0.1152  loss_dice_2: 0.1722  loss_ce_3: 6.003e-05  loss_mask_3: 0.1151  loss_dice_3: 0.1708  loss_ce_4: 9.694e-05  loss_mask_4: 0.1128  loss_dice_4: 0.1688  loss_ce_5: 0.0001652  loss_mask_5: 0.1179  loss_dice_5: 0.1704  loss_ce_6: 4.669e-05  loss_mask_6: 0.1117  loss_dice_6: 0.1667  loss_ce_7: 8.073e-05  loss_mask_7: 0.1135  loss_dice_7: 0.175  loss_ce_8: 0.0001608  loss_mask_8: 0.1123  loss_dice_8: 0.17  time: 0.5987  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:53:29] d2.utils.events INFO:  eta: 0:29:41  iter: 24979  total_loss: 3.042  loss_ce: 6.185e-05  loss_mask: 0.1151  loss_dice: 0.1818  loss_ce_0: 0.124  loss_mask_0: 0.112  loss_dice_0: 0.1723  loss_ce_1: 0.0001064  loss_mask_1: 0.1124  loss_dice_1: 0.1756  loss_ce_2: 0.0001166  loss_mask_2: 0.114  loss_dice_2: 0.1801  loss_ce_3: 4.643e-05  loss_mask_3: 0.1128  loss_dice_3: 0.1789  loss_ce_4: 6.569e-05  loss_mask_4: 0.1115  loss_dice_4: 0.1707  loss_ce_5: 8.086e-05  loss_mask_5: 0.1115  loss_dice_5: 0.1736  loss_ce_6: 5.183e-05  loss_mask_6: 0.115  loss_dice_6: 0.1777  loss_ce_7: 6.531e-05  loss_mask_7: 0.1118  loss_dice_7: 0.1758  loss_ce_8: 8.923e-05  loss_mask_8: 0.1131  loss_dice_8: 0.1727  time: 0.5984  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 21:53:33] fvcore.common.checkpoint INFO: Saving checkpoint to ./R101_overlap/model_0024999.pth
[08/01 21:53:33] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(256, 256), max_size=256, sample_style='choice')]
[08/01 21:53:33] d2.data.common INFO: Serializing 535 elements to byte tensors and concatenating them all ...
[08/01 21:53:33] d2.data.common INFO: Serialized dataset takes 0.22 MiB
[08/01 21:53:34] d2.evaluation.evaluator INFO: Start inference on 535 batches
[08/01 21:53:45] d2.evaluation.evaluator INFO: Inference done 11/535. Dataloading: 0.0006 s/iter. Inference: 0.1575 s/iter. Eval: 0.9004 s/iter. Total: 1.0585 s/iter. ETA=0:09:14
[08/01 21:53:51] d2.evaluation.evaluator INFO: Inference done 16/535. Dataloading: 0.0006 s/iter. Inference: 0.1586 s/iter. Eval: 0.8981 s/iter. Total: 1.0574 s/iter. ETA=0:09:08
[08/01 21:53:56] d2.evaluation.evaluator INFO: Inference done 21/535. Dataloading: 0.0007 s/iter. Inference: 0.1578 s/iter. Eval: 0.9014 s/iter. Total: 1.0600 s/iter. ETA=0:09:04
[08/01 21:54:02] d2.evaluation.evaluator INFO: Inference done 26/535. Dataloading: 0.0007 s/iter. Inference: 0.1589 s/iter. Eval: 0.9057 s/iter. Total: 1.0653 s/iter. ETA=0:09:02
[08/01 21:54:07] d2.evaluation.evaluator INFO: Inference done 31/535. Dataloading: 0.0007 s/iter. Inference: 0.1589 s/iter. Eval: 0.9080 s/iter. Total: 1.0676 s/iter. ETA=0:08:58
[08/01 21:54:12] d2.evaluation.evaluator INFO: Inference done 36/535. Dataloading: 0.0007 s/iter. Inference: 0.1576 s/iter. Eval: 0.9059 s/iter. Total: 1.0643 s/iter. ETA=0:08:51
[08/01 21:54:17] d2.evaluation.evaluator INFO: Inference done 41/535. Dataloading: 0.0007 s/iter. Inference: 0.1601 s/iter. Eval: 0.9032 s/iter. Total: 1.0641 s/iter. ETA=0:08:45
[08/01 21:54:23] d2.evaluation.evaluator INFO: Inference done 46/535. Dataloading: 0.0007 s/iter. Inference: 0.1608 s/iter. Eval: 0.9021 s/iter. Total: 1.0637 s/iter. ETA=0:08:40
[08/01 21:54:28] d2.evaluation.evaluator INFO: Inference done 51/535. Dataloading: 0.0007 s/iter. Inference: 0.1609 s/iter. Eval: 0.9010 s/iter. Total: 1.0626 s/iter. ETA=0:08:34
[08/01 21:54:33] d2.evaluation.evaluator INFO: Inference done 56/535. Dataloading: 0.0007 s/iter. Inference: 0.1613 s/iter. Eval: 0.8996 s/iter. Total: 1.0617 s/iter. ETA=0:08:28
[08/01 21:54:39] d2.evaluation.evaluator INFO: Inference done 61/535. Dataloading: 0.0007 s/iter. Inference: 0.1612 s/iter. Eval: 0.8983 s/iter. Total: 1.0602 s/iter. ETA=0:08:22
[08/01 21:54:44] d2.evaluation.evaluator INFO: Inference done 66/535. Dataloading: 0.0007 s/iter. Inference: 0.1616 s/iter. Eval: 0.8972 s/iter. Total: 1.0596 s/iter. ETA=0:08:16
[08/01 21:54:49] d2.evaluation.evaluator INFO: Inference done 71/535. Dataloading: 0.0007 s/iter. Inference: 0.1614 s/iter. Eval: 0.8965 s/iter. Total: 1.0587 s/iter. ETA=0:08:11
[08/01 21:54:54] d2.evaluation.evaluator INFO: Inference done 76/535. Dataloading: 0.0007 s/iter. Inference: 0.1613 s/iter. Eval: 0.8958 s/iter. Total: 1.0578 s/iter. ETA=0:08:05
[08/01 21:55:00] d2.evaluation.evaluator INFO: Inference done 81/535. Dataloading: 0.0007 s/iter. Inference: 0.1613 s/iter. Eval: 0.8970 s/iter. Total: 1.0591 s/iter. ETA=0:08:00
[08/01 21:55:05] d2.evaluation.evaluator INFO: Inference done 86/535. Dataloading: 0.0007 s/iter. Inference: 0.1619 s/iter. Eval: 0.8967 s/iter. Total: 1.0594 s/iter. ETA=0:07:55
[08/01 21:55:10] d2.evaluation.evaluator INFO: Inference done 91/535. Dataloading: 0.0007 s/iter. Inference: 0.1611 s/iter. Eval: 0.8963 s/iter. Total: 1.0582 s/iter. ETA=0:07:49
[08/01 21:55:15] d2.evaluation.evaluator INFO: Inference done 96/535. Dataloading: 0.0007 s/iter. Inference: 0.1611 s/iter. Eval: 0.8960 s/iter. Total: 1.0579 s/iter. ETA=0:07:44
[08/01 21:55:21] d2.evaluation.evaluator INFO: Inference done 101/535. Dataloading: 0.0007 s/iter. Inference: 0.1610 s/iter. Eval: 0.8958 s/iter. Total: 1.0576 s/iter. ETA=0:07:38
[08/01 21:55:26] d2.evaluation.evaluator INFO: Inference done 106/535. Dataloading: 0.0007 s/iter. Inference: 0.1607 s/iter. Eval: 0.8957 s/iter. Total: 1.0572 s/iter. ETA=0:07:33
[08/01 21:55:31] d2.evaluation.evaluator INFO: Inference done 111/535. Dataloading: 0.0007 s/iter. Inference: 0.1603 s/iter. Eval: 0.8956 s/iter. Total: 1.0566 s/iter. ETA=0:07:28
[08/01 21:55:36] d2.evaluation.evaluator INFO: Inference done 116/535. Dataloading: 0.0007 s/iter. Inference: 0.1606 s/iter. Eval: 0.8953 s/iter. Total: 1.0566 s/iter. ETA=0:07:22
[08/01 21:55:42] d2.evaluation.evaluator INFO: Inference done 121/535. Dataloading: 0.0007 s/iter. Inference: 0.1606 s/iter. Eval: 0.8950 s/iter. Total: 1.0564 s/iter. ETA=0:07:17
[08/01 21:55:47] d2.evaluation.evaluator INFO: Inference done 126/535. Dataloading: 0.0007 s/iter. Inference: 0.1608 s/iter. Eval: 0.8948 s/iter. Total: 1.0564 s/iter. ETA=0:07:12
[08/01 21:55:52] d2.evaluation.evaluator INFO: Inference done 131/535. Dataloading: 0.0007 s/iter. Inference: 0.1605 s/iter. Eval: 0.8946 s/iter. Total: 1.0559 s/iter. ETA=0:07:06
[08/01 21:55:57] d2.evaluation.evaluator INFO: Inference done 136/535. Dataloading: 0.0007 s/iter. Inference: 0.1604 s/iter. Eval: 0.8944 s/iter. Total: 1.0556 s/iter. ETA=0:07:01
[08/01 21:56:03] d2.evaluation.evaluator INFO: Inference done 141/535. Dataloading: 0.0007 s/iter. Inference: 0.1603 s/iter. Eval: 0.8941 s/iter. Total: 1.0552 s/iter. ETA=0:06:55
[08/01 21:56:08] d2.evaluation.evaluator INFO: Inference done 146/535. Dataloading: 0.0007 s/iter. Inference: 0.1604 s/iter. Eval: 0.8938 s/iter. Total: 1.0550 s/iter. ETA=0:06:50
[08/01 21:56:13] d2.evaluation.evaluator INFO: Inference done 151/535. Dataloading: 0.0007 s/iter. Inference: 0.1606 s/iter. Eval: 0.8936 s/iter. Total: 1.0549 s/iter. ETA=0:06:45
[08/01 21:56:18] d2.evaluation.evaluator INFO: Inference done 156/535. Dataloading: 0.0007 s/iter. Inference: 0.1607 s/iter. Eval: 0.8935 s/iter. Total: 1.0550 s/iter. ETA=0:06:39
[08/01 21:56:24] d2.evaluation.evaluator INFO: Inference done 161/535. Dataloading: 0.0007 s/iter. Inference: 0.1609 s/iter. Eval: 0.8933 s/iter. Total: 1.0550 s/iter. ETA=0:06:34
[08/01 21:56:29] d2.evaluation.evaluator INFO: Inference done 166/535. Dataloading: 0.0007 s/iter. Inference: 0.1607 s/iter. Eval: 0.8933 s/iter. Total: 1.0548 s/iter. ETA=0:06:29
[08/01 21:56:34] d2.evaluation.evaluator INFO: Inference done 171/535. Dataloading: 0.0007 s/iter. Inference: 0.1605 s/iter. Eval: 0.8933 s/iter. Total: 1.0546 s/iter. ETA=0:06:23
[08/01 21:56:39] d2.evaluation.evaluator INFO: Inference done 176/535. Dataloading: 0.0007 s/iter. Inference: 0.1602 s/iter. Eval: 0.8932 s/iter. Total: 1.0541 s/iter. ETA=0:06:18
[08/01 21:56:45] d2.evaluation.evaluator INFO: Inference done 181/535. Dataloading: 0.0007 s/iter. Inference: 0.1603 s/iter. Eval: 0.8932 s/iter. Total: 1.0543 s/iter. ETA=0:06:13
[08/01 21:56:50] d2.evaluation.evaluator INFO: Inference done 186/535. Dataloading: 0.0007 s/iter. Inference: 0.1601 s/iter. Eval: 0.8931 s/iter. Total: 1.0540 s/iter. ETA=0:06:07
[08/01 21:56:55] d2.evaluation.evaluator INFO: Inference done 191/535. Dataloading: 0.0007 s/iter. Inference: 0.1600 s/iter. Eval: 0.8930 s/iter. Total: 1.0538 s/iter. ETA=0:06:02
[08/01 21:57:00] d2.evaluation.evaluator INFO: Inference done 196/535. Dataloading: 0.0007 s/iter. Inference: 0.1602 s/iter. Eval: 0.8929 s/iter. Total: 1.0539 s/iter. ETA=0:05:57
[08/01 21:57:06] d2.evaluation.evaluator INFO: Inference done 201/535. Dataloading: 0.0007 s/iter. Inference: 0.1603 s/iter. Eval: 0.8929 s/iter. Total: 1.0539 s/iter. ETA=0:05:51
[08/01 21:57:11] d2.evaluation.evaluator INFO: Inference done 206/535. Dataloading: 0.0007 s/iter. Inference: 0.1602 s/iter. Eval: 0.8928 s/iter. Total: 1.0538 s/iter. ETA=0:05:46
[08/01 21:57:16] d2.evaluation.evaluator INFO: Inference done 211/535. Dataloading: 0.0007 s/iter. Inference: 0.1602 s/iter. Eval: 0.8927 s/iter. Total: 1.0537 s/iter. ETA=0:05:41
[08/01 21:57:22] d2.evaluation.evaluator INFO: Inference done 216/535. Dataloading: 0.0007 s/iter. Inference: 0.1604 s/iter. Eval: 0.8928 s/iter. Total: 1.0539 s/iter. ETA=0:05:36
[08/01 21:57:27] d2.evaluation.evaluator INFO: Inference done 221/535. Dataloading: 0.0007 s/iter. Inference: 0.1603 s/iter. Eval: 0.8927 s/iter. Total: 1.0538 s/iter. ETA=0:05:30
[08/01 21:57:32] d2.evaluation.evaluator INFO: Inference done 226/535. Dataloading: 0.0007 s/iter. Inference: 0.1604 s/iter. Eval: 0.8926 s/iter. Total: 1.0538 s/iter. ETA=0:05:25
[08/01 21:57:37] d2.evaluation.evaluator INFO: Inference done 231/535. Dataloading: 0.0007 s/iter. Inference: 0.1604 s/iter. Eval: 0.8928 s/iter. Total: 1.0539 s/iter. ETA=0:05:20
[08/01 21:57:43] d2.evaluation.evaluator INFO: Inference done 236/535. Dataloading: 0.0007 s/iter. Inference: 0.1602 s/iter. Eval: 0.8928 s/iter. Total: 1.0537 s/iter. ETA=0:05:15
[08/01 21:57:48] d2.evaluation.evaluator INFO: Inference done 241/535. Dataloading: 0.0007 s/iter. Inference: 0.1600 s/iter. Eval: 0.8928 s/iter. Total: 1.0536 s/iter. ETA=0:05:09
[08/01 21:57:53] d2.evaluation.evaluator INFO: Inference done 246/535. Dataloading: 0.0007 s/iter. Inference: 0.1597 s/iter. Eval: 0.8928 s/iter. Total: 1.0533 s/iter. ETA=0:05:04
[08/01 21:57:58] d2.evaluation.evaluator INFO: Inference done 251/535. Dataloading: 0.0007 s/iter. Inference: 0.1600 s/iter. Eval: 0.8927 s/iter. Total: 1.0535 s/iter. ETA=0:04:59
[08/01 21:58:03] d2.evaluation.evaluator INFO: Inference done 256/535. Dataloading: 0.0007 s/iter. Inference: 0.1597 s/iter. Eval: 0.8926 s/iter. Total: 1.0531 s/iter. ETA=0:04:53
[08/01 21:58:09] d2.evaluation.evaluator INFO: Inference done 261/535. Dataloading: 0.0007 s/iter. Inference: 0.1596 s/iter. Eval: 0.8925 s/iter. Total: 1.0529 s/iter. ETA=0:04:48
[08/01 21:58:14] d2.evaluation.evaluator INFO: Inference done 266/535. Dataloading: 0.0007 s/iter. Inference: 0.1596 s/iter. Eval: 0.8925 s/iter. Total: 1.0529 s/iter. ETA=0:04:43
[08/01 21:58:19] d2.evaluation.evaluator INFO: Inference done 271/535. Dataloading: 0.0007 s/iter. Inference: 0.1596 s/iter. Eval: 0.8925 s/iter. Total: 1.0528 s/iter. ETA=0:04:37
[08/01 21:58:24] d2.evaluation.evaluator INFO: Inference done 276/535. Dataloading: 0.0007 s/iter. Inference: 0.1594 s/iter. Eval: 0.8924 s/iter. Total: 1.0526 s/iter. ETA=0:04:32
[08/01 21:58:30] d2.evaluation.evaluator INFO: Inference done 281/535. Dataloading: 0.0007 s/iter. Inference: 0.1593 s/iter. Eval: 0.8922 s/iter. Total: 1.0523 s/iter. ETA=0:04:27
[08/01 21:58:35] d2.evaluation.evaluator INFO: Inference done 286/535. Dataloading: 0.0007 s/iter. Inference: 0.1593 s/iter. Eval: 0.8922 s/iter. Total: 1.0522 s/iter. ETA=0:04:21
[08/01 21:58:40] d2.evaluation.evaluator INFO: Inference done 291/535. Dataloading: 0.0007 s/iter. Inference: 0.1591 s/iter. Eval: 0.8921 s/iter. Total: 1.0519 s/iter. ETA=0:04:16
[08/01 21:58:45] d2.evaluation.evaluator INFO: Inference done 296/535. Dataloading: 0.0007 s/iter. Inference: 0.1589 s/iter. Eval: 0.8920 s/iter. Total: 1.0516 s/iter. ETA=0:04:11
[08/01 21:58:50] d2.evaluation.evaluator INFO: Inference done 301/535. Dataloading: 0.0007 s/iter. Inference: 0.1588 s/iter. Eval: 0.8919 s/iter. Total: 1.0515 s/iter. ETA=0:04:06
[08/01 21:58:56] d2.evaluation.evaluator INFO: Inference done 306/535. Dataloading: 0.0007 s/iter. Inference: 0.1591 s/iter. Eval: 0.8920 s/iter. Total: 1.0519 s/iter. ETA=0:04:00
[08/01 21:59:01] d2.evaluation.evaluator INFO: Inference done 311/535. Dataloading: 0.0007 s/iter. Inference: 0.1589 s/iter. Eval: 0.8919 s/iter. Total: 1.0515 s/iter. ETA=0:03:55
[08/01 21:59:06] d2.evaluation.evaluator INFO: Inference done 316/535. Dataloading: 0.0007 s/iter. Inference: 0.1588 s/iter. Eval: 0.8918 s/iter. Total: 1.0514 s/iter. ETA=0:03:50
[08/01 21:59:11] d2.evaluation.evaluator INFO: Inference done 321/535. Dataloading: 0.0007 s/iter. Inference: 0.1586 s/iter. Eval: 0.8917 s/iter. Total: 1.0511 s/iter. ETA=0:03:44
[08/01 21:59:16] d2.evaluation.evaluator INFO: Inference done 326/535. Dataloading: 0.0007 s/iter. Inference: 0.1585 s/iter. Eval: 0.8917 s/iter. Total: 1.0510 s/iter. ETA=0:03:39
[08/01 21:59:22] d2.evaluation.evaluator INFO: Inference done 331/535. Dataloading: 0.0007 s/iter. Inference: 0.1585 s/iter. Eval: 0.8917 s/iter. Total: 1.0510 s/iter. ETA=0:03:34
[08/01 21:59:27] d2.evaluation.evaluator INFO: Inference done 336/535. Dataloading: 0.0007 s/iter. Inference: 0.1584 s/iter. Eval: 0.8918 s/iter. Total: 1.0509 s/iter. ETA=0:03:29
[08/01 21:59:32] d2.evaluation.evaluator INFO: Inference done 341/535. Dataloading: 0.0007 s/iter. Inference: 0.1583 s/iter. Eval: 0.8917 s/iter. Total: 1.0508 s/iter. ETA=0:03:23
[08/01 21:59:37] d2.evaluation.evaluator INFO: Inference done 346/535. Dataloading: 0.0007 s/iter. Inference: 0.1582 s/iter. Eval: 0.8916 s/iter. Total: 1.0506 s/iter. ETA=0:03:18
[08/01 21:59:43] d2.evaluation.evaluator INFO: Inference done 351/535. Dataloading: 0.0007 s/iter. Inference: 0.1580 s/iter. Eval: 0.8916 s/iter. Total: 1.0504 s/iter. ETA=0:03:13
[08/01 21:59:48] d2.evaluation.evaluator INFO: Inference done 356/535. Dataloading: 0.0007 s/iter. Inference: 0.1580 s/iter. Eval: 0.8915 s/iter. Total: 1.0503 s/iter. ETA=0:03:08
[08/01 21:59:53] d2.evaluation.evaluator INFO: Inference done 361/535. Dataloading: 0.0007 s/iter. Inference: 0.1580 s/iter. Eval: 0.8916 s/iter. Total: 1.0504 s/iter. ETA=0:03:02
[08/01 21:59:58] d2.evaluation.evaluator INFO: Inference done 366/535. Dataloading: 0.0007 s/iter. Inference: 0.1579 s/iter. Eval: 0.8915 s/iter. Total: 1.0502 s/iter. ETA=0:02:57
[08/01 22:00:03] d2.evaluation.evaluator INFO: Inference done 371/535. Dataloading: 0.0007 s/iter. Inference: 0.1578 s/iter. Eval: 0.8915 s/iter. Total: 1.0501 s/iter. ETA=0:02:52
[08/01 22:00:09] d2.evaluation.evaluator INFO: Inference done 376/535. Dataloading: 0.0007 s/iter. Inference: 0.1576 s/iter. Eval: 0.8915 s/iter. Total: 1.0499 s/iter. ETA=0:02:46
[08/01 22:00:14] d2.evaluation.evaluator INFO: Inference done 381/535. Dataloading: 0.0007 s/iter. Inference: 0.1576 s/iter. Eval: 0.8916 s/iter. Total: 1.0500 s/iter. ETA=0:02:41
[08/01 22:00:19] d2.evaluation.evaluator INFO: Inference done 386/535. Dataloading: 0.0007 s/iter. Inference: 0.1576 s/iter. Eval: 0.8916 s/iter. Total: 1.0499 s/iter. ETA=0:02:36
[08/01 22:00:24] d2.evaluation.evaluator INFO: Inference done 391/535. Dataloading: 0.0007 s/iter. Inference: 0.1574 s/iter. Eval: 0.8915 s/iter. Total: 1.0497 s/iter. ETA=0:02:31
[08/01 22:00:30] d2.evaluation.evaluator INFO: Inference done 396/535. Dataloading: 0.0007 s/iter. Inference: 0.1574 s/iter. Eval: 0.8915 s/iter. Total: 1.0497 s/iter. ETA=0:02:25
[08/01 22:00:35] d2.evaluation.evaluator INFO: Inference done 401/535. Dataloading: 0.0007 s/iter. Inference: 0.1573 s/iter. Eval: 0.8915 s/iter. Total: 1.0496 s/iter. ETA=0:02:20
[08/01 22:00:40] d2.evaluation.evaluator INFO: Inference done 406/535. Dataloading: 0.0007 s/iter. Inference: 0.1571 s/iter. Eval: 0.8915 s/iter. Total: 1.0494 s/iter. ETA=0:02:15
[08/01 22:00:45] d2.evaluation.evaluator INFO: Inference done 411/535. Dataloading: 0.0007 s/iter. Inference: 0.1570 s/iter. Eval: 0.8916 s/iter. Total: 1.0493 s/iter. ETA=0:02:10
[08/01 22:00:50] d2.evaluation.evaluator INFO: Inference done 416/535. Dataloading: 0.0007 s/iter. Inference: 0.1569 s/iter. Eval: 0.8916 s/iter. Total: 1.0493 s/iter. ETA=0:02:04
[08/01 22:00:56] d2.evaluation.evaluator INFO: Inference done 421/535. Dataloading: 0.0007 s/iter. Inference: 0.1568 s/iter. Eval: 0.8915 s/iter. Total: 1.0491 s/iter. ETA=0:01:59
[08/01 22:01:01] d2.evaluation.evaluator INFO: Inference done 426/535. Dataloading: 0.0007 s/iter. Inference: 0.1568 s/iter. Eval: 0.8915 s/iter. Total: 1.0490 s/iter. ETA=0:01:54
[08/01 22:01:06] d2.evaluation.evaluator INFO: Inference done 431/535. Dataloading: 0.0007 s/iter. Inference: 0.1568 s/iter. Eval: 0.8914 s/iter. Total: 1.0489 s/iter. ETA=0:01:49
[08/01 22:01:11] d2.evaluation.evaluator INFO: Inference done 436/535. Dataloading: 0.0007 s/iter. Inference: 0.1568 s/iter. Eval: 0.8913 s/iter. Total: 1.0489 s/iter. ETA=0:01:43
[08/01 22:01:16] d2.evaluation.evaluator INFO: Inference done 441/535. Dataloading: 0.0007 s/iter. Inference: 0.1567 s/iter. Eval: 0.8913 s/iter. Total: 1.0488 s/iter. ETA=0:01:38
[08/01 22:01:22] d2.evaluation.evaluator INFO: Inference done 446/535. Dataloading: 0.0007 s/iter. Inference: 0.1568 s/iter. Eval: 0.8913 s/iter. Total: 1.0488 s/iter. ETA=0:01:33
[08/01 22:01:27] d2.evaluation.evaluator INFO: Inference done 451/535. Dataloading: 0.0007 s/iter. Inference: 0.1567 s/iter. Eval: 0.8913 s/iter. Total: 1.0488 s/iter. ETA=0:01:28
[08/01 22:01:32] d2.evaluation.evaluator INFO: Inference done 456/535. Dataloading: 0.0007 s/iter. Inference: 0.1566 s/iter. Eval: 0.8913 s/iter. Total: 1.0486 s/iter. ETA=0:01:22
[08/01 22:01:37] d2.evaluation.evaluator INFO: Inference done 461/535. Dataloading: 0.0007 s/iter. Inference: 0.1565 s/iter. Eval: 0.8913 s/iter. Total: 1.0485 s/iter. ETA=0:01:17
[08/01 22:01:43] d2.evaluation.evaluator INFO: Inference done 466/535. Dataloading: 0.0007 s/iter. Inference: 0.1565 s/iter. Eval: 0.8913 s/iter. Total: 1.0486 s/iter. ETA=0:01:12
[08/01 22:01:48] d2.evaluation.evaluator INFO: Inference done 471/535. Dataloading: 0.0007 s/iter. Inference: 0.1565 s/iter. Eval: 0.8912 s/iter. Total: 1.0485 s/iter. ETA=0:01:07
[08/01 22:01:53] d2.evaluation.evaluator INFO: Inference done 476/535. Dataloading: 0.0007 s/iter. Inference: 0.1565 s/iter. Eval: 0.8913 s/iter. Total: 1.0485 s/iter. ETA=0:01:01
[08/01 22:01:58] d2.evaluation.evaluator INFO: Inference done 481/535. Dataloading: 0.0007 s/iter. Inference: 0.1565 s/iter. Eval: 0.8912 s/iter. Total: 1.0485 s/iter. ETA=0:00:56
[08/01 22:02:03] d2.evaluation.evaluator INFO: Inference done 486/535. Dataloading: 0.0007 s/iter. Inference: 0.1565 s/iter. Eval: 0.8912 s/iter. Total: 1.0485 s/iter. ETA=0:00:51
[08/01 22:02:09] d2.evaluation.evaluator INFO: Inference done 491/535. Dataloading: 0.0007 s/iter. Inference: 0.1564 s/iter. Eval: 0.8912 s/iter. Total: 1.0484 s/iter. ETA=0:00:46
[08/01 22:02:14] d2.evaluation.evaluator INFO: Inference done 496/535. Dataloading: 0.0007 s/iter. Inference: 0.1563 s/iter. Eval: 0.8912 s/iter. Total: 1.0483 s/iter. ETA=0:00:40
[08/01 22:02:19] d2.evaluation.evaluator INFO: Inference done 501/535. Dataloading: 0.0007 s/iter. Inference: 0.1563 s/iter. Eval: 0.8911 s/iter. Total: 1.0482 s/iter. ETA=0:00:35
[08/01 22:02:24] d2.evaluation.evaluator INFO: Inference done 506/535. Dataloading: 0.0007 s/iter. Inference: 0.1563 s/iter. Eval: 0.8911 s/iter. Total: 1.0482 s/iter. ETA=0:00:30
[08/01 22:02:30] d2.evaluation.evaluator INFO: Inference done 511/535. Dataloading: 0.0007 s/iter. Inference: 0.1564 s/iter. Eval: 0.8910 s/iter. Total: 1.0482 s/iter. ETA=0:00:25
[08/01 22:02:35] d2.evaluation.evaluator INFO: Inference done 516/535. Dataloading: 0.0007 s/iter. Inference: 0.1563 s/iter. Eval: 0.8910 s/iter. Total: 1.0481 s/iter. ETA=0:00:19
[08/01 22:02:40] d2.evaluation.evaluator INFO: Inference done 521/535. Dataloading: 0.0007 s/iter. Inference: 0.1563 s/iter. Eval: 0.8910 s/iter. Total: 1.0481 s/iter. ETA=0:00:14
[08/01 22:02:45] d2.evaluation.evaluator INFO: Inference done 526/535. Dataloading: 0.0007 s/iter. Inference: 0.1565 s/iter. Eval: 0.8910 s/iter. Total: 1.0483 s/iter. ETA=0:00:09
[08/01 22:02:51] d2.evaluation.evaluator INFO: Inference done 531/535. Dataloading: 0.0007 s/iter. Inference: 0.1565 s/iter. Eval: 0.8911 s/iter. Total: 1.0483 s/iter. ETA=0:00:04
[08/01 22:02:55] d2.evaluation.evaluator INFO: Total inference time: 0:09:15.664352 (1.048423 s / iter per device, on 1 devices)
[08/01 22:02:55] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:01:22 (0.156439 s / iter per device, on 1 devices)
[08/01 22:02:55] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[08/01 22:02:55] d2.evaluation.coco_evaluation INFO: Saving results to ./R101_overlap/inference/coco_instances_results.json
[08/01 22:02:56] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[08/01 22:02:58] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 |  nan  | 0.000 |
[08/01 22:02:58] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 22:02:58] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| normal     | 0.000 | defect     | 0.000 |
[08/01 22:03:04] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl   |
|:------:|:------:|:------:|:------:|:-----:|:------:|
| 98.713 | 99.713 | 99.221 | 93.548 |  nan  | 98.713 |
[08/01 22:03:04] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 22:03:04] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| normal     | 99.260 | defect     | 98.165 |
[08/01 22:03:04] d2.engine.defaults INFO: Evaluation results for front2class_2017_val_overlap_panoptic in csv format:
[08/01 22:03:04] d2.evaluation.testing INFO: copypaste: Task: bbox
[08/01 22:03:04] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 22:03:04] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,nan,0.0000
[08/01 22:03:04] d2.evaluation.testing INFO: copypaste: Task: segm
[08/01 22:03:04] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 22:03:04] d2.evaluation.testing INFO: copypaste: 98.7126,99.7131,99.2212,93.5485,nan,98.7126
[08/01 22:03:04] d2.utils.events INFO:  eta: 0:29:47  iter: 24999  total_loss: 2.9  loss_ce: 6.591e-05  loss_mask: 0.1077  loss_dice: 0.1625  loss_ce_0: 0.1265  loss_mask_0: 0.1101  loss_dice_0: 0.1682  loss_ce_1: 0.0001063  loss_mask_1: 0.1108  loss_dice_1: 0.167  loss_ce_2: 0.000119  loss_mask_2: 0.1112  loss_dice_2: 0.1711  loss_ce_3: 5.389e-05  loss_mask_3: 0.1086  loss_dice_3: 0.1641  loss_ce_4: 8.326e-05  loss_mask_4: 0.1108  loss_dice_4: 0.1592  loss_ce_5: 9.01e-05  loss_mask_5: 0.1137  loss_dice_5: 0.1703  loss_ce_6: 5.137e-05  loss_mask_6: 0.1135  loss_dice_6: 0.1649  loss_ce_7: 7.405e-05  loss_mask_7: 0.1112  loss_dice_7: 0.1701  loss_ce_8: 8.933e-05  loss_mask_8: 0.1121  loss_dice_8: 0.1655  time: 0.5981  data_time: 0.0011  lr: 0.0001  max_mem: 8444M
[08/01 22:03:04] fvcore.common.checkpoint INFO: Saving checkpoint to ./R101_overlap/model_best.pth
[08/01 22:03:04] d2.engine.hooks INFO: Saved best model as latest eval score for total_loss is2.42329, better than last best score 2.85451 @ iteration 19999.
[08/01 22:03:09] d2.utils.events INFO:  eta: 0:29:52  iter: 25019  total_loss: 2.801  loss_ce: 6.939e-05  loss_mask: 0.1123  loss_dice: 0.1544  loss_ce_0: 0.1206  loss_mask_0: 0.1131  loss_dice_0: 0.1588  loss_ce_1: 9.312e-05  loss_mask_1: 0.1151  loss_dice_1: 0.1623  loss_ce_2: 0.0001112  loss_mask_2: 0.1115  loss_dice_2: 0.1591  loss_ce_3: 6.67e-05  loss_mask_3: 0.1106  loss_dice_3: 0.1556  loss_ce_4: 6.563e-05  loss_mask_4: 0.1123  loss_dice_4: 0.157  loss_ce_5: 8.164e-05  loss_mask_5: 0.1117  loss_dice_5: 0.16  loss_ce_6: 4.861e-05  loss_mask_6: 0.11  loss_dice_6: 0.1522  loss_ce_7: 7.645e-05  loss_mask_7: 0.1088  loss_dice_7: 0.1514  loss_ce_8: 8.566e-05  loss_mask_8: 0.1081  loss_dice_8: 0.1511  time: 0.5978  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:03:13] d2.utils.events INFO:  eta: 0:30:00  iter: 25039  total_loss: 2.995  loss_ce: 6.798e-05  loss_mask: 0.1098  loss_dice: 0.1653  loss_ce_0: 0.1255  loss_mask_0: 0.1156  loss_dice_0: 0.1769  loss_ce_1: 9.412e-05  loss_mask_1: 0.1129  loss_dice_1: 0.1725  loss_ce_2: 0.0001017  loss_mask_2: 0.1102  loss_dice_2: 0.1695  loss_ce_3: 4.952e-05  loss_mask_3: 0.1137  loss_dice_3: 0.1759  loss_ce_4: 4.99e-05  loss_mask_4: 0.1136  loss_dice_4: 0.1693  loss_ce_5: 7.471e-05  loss_mask_5: 0.1157  loss_dice_5: 0.1645  loss_ce_6: 4.773e-05  loss_mask_6: 0.1146  loss_dice_6: 0.1746  loss_ce_7: 5.676e-05  loss_mask_7: 0.1119  loss_dice_7: 0.1691  loss_ce_8: 8.472e-05  loss_mask_8: 0.1144  loss_dice_8: 0.1709  time: 0.5975  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:03:18] d2.utils.events INFO:  eta: 0:30:12  iter: 25059  total_loss: 2.804  loss_ce: 6.556e-05  loss_mask: 0.1074  loss_dice: 0.1626  loss_ce_0: 0.1204  loss_mask_0: 0.1089  loss_dice_0: 0.1587  loss_ce_1: 9.947e-05  loss_mask_1: 0.1075  loss_dice_1: 0.1586  loss_ce_2: 0.000104  loss_mask_2: 0.1085  loss_dice_2: 0.1679  loss_ce_3: 5.147e-05  loss_mask_3: 0.1059  loss_dice_3: 0.1578  loss_ce_4: 5.03e-05  loss_mask_4: 0.1056  loss_dice_4: 0.1554  loss_ce_5: 8.304e-05  loss_mask_5: 0.1071  loss_dice_5: 0.1607  loss_ce_6: 4.88e-05  loss_mask_6: 0.1077  loss_dice_6: 0.1596  loss_ce_7: 6.598e-05  loss_mask_7: 0.1083  loss_dice_7: 0.1656  loss_ce_8: 8.52e-05  loss_mask_8: 0.1117  loss_dice_8: 0.1637  time: 0.5972  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:03:22] d2.utils.events INFO:  eta: 0:30:17  iter: 25079  total_loss: 2.952  loss_ce: 6.134e-05  loss_mask: 0.1136  loss_dice: 0.1722  loss_ce_0: 0.1201  loss_mask_0: 0.117  loss_dice_0: 0.1764  loss_ce_1: 0.0001036  loss_mask_1: 0.1151  loss_dice_1: 0.1794  loss_ce_2: 0.0001234  loss_mask_2: 0.1145  loss_dice_2: 0.1734  loss_ce_3: 5.293e-05  loss_mask_3: 0.1178  loss_dice_3: 0.1736  loss_ce_4: 8.484e-05  loss_mask_4: 0.1113  loss_dice_4: 0.1702  loss_ce_5: 0.0001158  loss_mask_5: 0.1128  loss_dice_5: 0.1758  loss_ce_6: 4.742e-05  loss_mask_6: 0.1126  loss_dice_6: 0.1728  loss_ce_7: 7.231e-05  loss_mask_7: 0.113  loss_dice_7: 0.1791  loss_ce_8: 0.0001402  loss_mask_8: 0.1127  loss_dice_8: 0.1759  time: 0.5969  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:03:27] d2.utils.events INFO:  eta: 0:30:23  iter: 25099  total_loss: 2.916  loss_ce: 6.402e-05  loss_mask: 0.1154  loss_dice: 0.16  loss_ce_0: 0.1202  loss_mask_0: 0.1141  loss_dice_0: 0.1671  loss_ce_1: 8.768e-05  loss_mask_1: 0.114  loss_dice_1: 0.1622  loss_ce_2: 0.0001006  loss_mask_2: 0.1123  loss_dice_2: 0.165  loss_ce_3: 4.681e-05  loss_mask_3: 0.1117  loss_dice_3: 0.163  loss_ce_4: 4.905e-05  loss_mask_4: 0.1092  loss_dice_4: 0.1581  loss_ce_5: 7.305e-05  loss_mask_5: 0.1144  loss_dice_5: 0.1677  loss_ce_6: 4.664e-05  loss_mask_6: 0.1126  loss_dice_6: 0.167  loss_ce_7: 6.106e-05  loss_mask_7: 0.112  loss_dice_7: 0.166  loss_ce_8: 8.338e-05  loss_mask_8: 0.1112  loss_dice_8: 0.1667  time: 0.5966  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:03:31] d2.utils.events INFO:  eta: 0:30:35  iter: 25119  total_loss: 2.838  loss_ce: 6.714e-05  loss_mask: 0.1101  loss_dice: 0.1571  loss_ce_0: 0.12  loss_mask_0: 0.1099  loss_dice_0: 0.1616  loss_ce_1: 9.8e-05  loss_mask_1: 0.1119  loss_dice_1: 0.1577  loss_ce_2: 0.0001428  loss_mask_2: 0.1096  loss_dice_2: 0.1621  loss_ce_3: 5.814e-05  loss_mask_3: 0.1052  loss_dice_3: 0.1571  loss_ce_4: 8.166e-05  loss_mask_4: 0.1098  loss_dice_4: 0.1644  loss_ce_5: 8.414e-05  loss_mask_5: 0.1067  loss_dice_5: 0.1567  loss_ce_6: 5.241e-05  loss_mask_6: 0.1112  loss_dice_6: 0.1615  loss_ce_7: 7.8e-05  loss_mask_7: 0.109  loss_dice_7: 0.1561  loss_ce_8: 8.746e-05  loss_mask_8: 0.1087  loss_dice_8: 0.1534  time: 0.5963  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:03:36] d2.utils.events INFO:  eta: 0:30:49  iter: 25139  total_loss: 2.89  loss_ce: 5.929e-05  loss_mask: 0.1114  loss_dice: 0.1661  loss_ce_0: 0.1202  loss_mask_0: 0.1091  loss_dice_0: 0.1671  loss_ce_1: 9.132e-05  loss_mask_1: 0.1124  loss_dice_1: 0.1709  loss_ce_2: 0.000102  loss_mask_2: 0.1102  loss_dice_2: 0.1618  loss_ce_3: 4.498e-05  loss_mask_3: 0.1132  loss_dice_3: 0.1659  loss_ce_4: 4.68e-05  loss_mask_4: 0.1107  loss_dice_4: 0.1604  loss_ce_5: 7.757e-05  loss_mask_5: 0.1104  loss_dice_5: 0.1661  loss_ce_6: 4.054e-05  loss_mask_6: 0.1162  loss_dice_6: 0.1669  loss_ce_7: 6.28e-05  loss_mask_7: 0.1102  loss_dice_7: 0.1644  loss_ce_8: 8.217e-05  loss_mask_8: 0.1094  loss_dice_8: 0.1633  time: 0.5960  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:03:40] d2.utils.events INFO:  eta: 0:30:58  iter: 25159  total_loss: 3.005  loss_ce: 6.443e-05  loss_mask: 0.1174  loss_dice: 0.1769  loss_ce_0: 0.1199  loss_mask_0: 0.1135  loss_dice_0: 0.1681  loss_ce_1: 0.0001055  loss_mask_1: 0.1148  loss_dice_1: 0.1736  loss_ce_2: 0.0001206  loss_mask_2: 0.113  loss_dice_2: 0.1731  loss_ce_3: 6.717e-05  loss_mask_3: 0.1122  loss_dice_3: 0.1762  loss_ce_4: 8.264e-05  loss_mask_4: 0.1126  loss_dice_4: 0.1715  loss_ce_5: 0.0001101  loss_mask_5: 0.1118  loss_dice_5: 0.1744  loss_ce_6: 4.761e-05  loss_mask_6: 0.1148  loss_dice_6: 0.1777  loss_ce_7: 7.925e-05  loss_mask_7: 0.1128  loss_dice_7: 0.1707  loss_ce_8: 0.0001326  loss_mask_8: 0.1092  loss_dice_8: 0.1668  time: 0.5957  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:03:45] d2.utils.events INFO:  eta: 0:31:07  iter: 25179  total_loss: 2.929  loss_ce: 6.325e-05  loss_mask: 0.108  loss_dice: 0.1704  loss_ce_0: 0.1198  loss_mask_0: 0.1117  loss_dice_0: 0.168  loss_ce_1: 9.978e-05  loss_mask_1: 0.1133  loss_dice_1: 0.1695  loss_ce_2: 0.000141  loss_mask_2: 0.1126  loss_dice_2: 0.17  loss_ce_3: 5.399e-05  loss_mask_3: 0.1112  loss_dice_3: 0.173  loss_ce_4: 8.516e-05  loss_mask_4: 0.1114  loss_dice_4: 0.1688  loss_ce_5: 0.0001332  loss_mask_5: 0.1109  loss_dice_5: 0.1723  loss_ce_6: 4.755e-05  loss_mask_6: 0.1139  loss_dice_6: 0.1707  loss_ce_7: 7.503e-05  loss_mask_7: 0.1094  loss_dice_7: 0.1671  loss_ce_8: 0.0001373  loss_mask_8: 0.1121  loss_dice_8: 0.1667  time: 0.5955  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:03:49] d2.utils.events INFO:  eta: 0:31:13  iter: 25199  total_loss: 3.029  loss_ce: 6.581e-05  loss_mask: 0.1171  loss_dice: 0.1745  loss_ce_0: 0.1304  loss_mask_0: 0.1155  loss_dice_0: 0.1739  loss_ce_1: 9.846e-05  loss_mask_1: 0.1164  loss_dice_1: 0.175  loss_ce_2: 0.0001192  loss_mask_2: 0.1181  loss_dice_2: 0.1667  loss_ce_3: 5.589e-05  loss_mask_3: 0.1162  loss_dice_3: 0.1668  loss_ce_4: 7.954e-05  loss_mask_4: 0.1191  loss_dice_4: 0.1736  loss_ce_5: 8.703e-05  loss_mask_5: 0.1167  loss_dice_5: 0.1723  loss_ce_6: 4.982e-05  loss_mask_6: 0.1151  loss_dice_6: 0.1672  loss_ce_7: 7.655e-05  loss_mask_7: 0.1155  loss_dice_7: 0.1721  loss_ce_8: 8.687e-05  loss_mask_8: 0.1163  loss_dice_8: 0.167  time: 0.5952  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:03:54] d2.utils.events INFO:  eta: 0:31:34  iter: 25219  total_loss: 2.987  loss_ce: 6.404e-05  loss_mask: 0.1128  loss_dice: 0.1731  loss_ce_0: 0.1204  loss_mask_0: 0.1056  loss_dice_0: 0.1701  loss_ce_1: 9.472e-05  loss_mask_1: 0.1072  loss_dice_1: 0.1716  loss_ce_2: 0.0001098  loss_mask_2: 0.1102  loss_dice_2: 0.1708  loss_ce_3: 4.766e-05  loss_mask_3: 0.1108  loss_dice_3: 0.1745  loss_ce_4: 6.352e-05  loss_mask_4: 0.1117  loss_dice_4: 0.1743  loss_ce_5: 7.673e-05  loss_mask_5: 0.1097  loss_dice_5: 0.1747  loss_ce_6: 4.697e-05  loss_mask_6: 0.1122  loss_dice_6: 0.1794  loss_ce_7: 6.729e-05  loss_mask_7: 0.1091  loss_dice_7: 0.1704  loss_ce_8: 8.367e-05  loss_mask_8: 0.1102  loss_dice_8: 0.1745  time: 0.5949  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:03:58] d2.utils.events INFO:  eta: 0:31:40  iter: 25239  total_loss: 2.895  loss_ce: 6.926e-05  loss_mask: 0.1103  loss_dice: 0.1662  loss_ce_0: 0.1295  loss_mask_0: 0.1123  loss_dice_0: 0.1697  loss_ce_1: 0.0001062  loss_mask_1: 0.1098  loss_dice_1: 0.1671  loss_ce_2: 0.0001301  loss_mask_2: 0.1103  loss_dice_2: 0.1672  loss_ce_3: 6.426e-05  loss_mask_3: 0.1132  loss_dice_3: 0.1746  loss_ce_4: 8.098e-05  loss_mask_4: 0.1091  loss_dice_4: 0.1704  loss_ce_5: 0.0001107  loss_mask_5: 0.1123  loss_dice_5: 0.1697  loss_ce_6: 5.235e-05  loss_mask_6: 0.1118  loss_dice_6: 0.1669  loss_ce_7: 8.875e-05  loss_mask_7: 0.1101  loss_dice_7: 0.1662  loss_ce_8: 0.0001311  loss_mask_8: 0.1099  loss_dice_8: 0.1712  time: 0.5946  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:04:03] d2.utils.events INFO:  eta: 0:31:59  iter: 25259  total_loss: 3.08  loss_ce: 6.367e-05  loss_mask: 0.1098  loss_dice: 0.1835  loss_ce_0: 0.1212  loss_mask_0: 0.1139  loss_dice_0: 0.1796  loss_ce_1: 9.906e-05  loss_mask_1: 0.1152  loss_dice_1: 0.1839  loss_ce_2: 0.0001285  loss_mask_2: 0.1143  loss_dice_2: 0.1787  loss_ce_3: 5.647e-05  loss_mask_3: 0.1127  loss_dice_3: 0.1831  loss_ce_4: 8.01e-05  loss_mask_4: 0.1127  loss_dice_4: 0.1818  loss_ce_5: 8.344e-05  loss_mask_5: 0.1105  loss_dice_5: 0.1816  loss_ce_6: 4.888e-05  loss_mask_6: 0.1133  loss_dice_6: 0.1832  loss_ce_7: 7.655e-05  loss_mask_7: 0.1152  loss_dice_7: 0.1775  loss_ce_8: 8.676e-05  loss_mask_8: 0.1151  loss_dice_8: 0.1832  time: 0.5943  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:04:07] d2.utils.events INFO:  eta: 0:32:24  iter: 25279  total_loss: 2.9  loss_ce: 6.095e-05  loss_mask: 0.1116  loss_dice: 0.1631  loss_ce_0: 0.1245  loss_mask_0: 0.1136  loss_dice_0: 0.1622  loss_ce_1: 0.0001004  loss_mask_1: 0.1159  loss_dice_1: 0.1672  loss_ce_2: 0.0001204  loss_mask_2: 0.1106  loss_dice_2: 0.1603  loss_ce_3: 5.908e-05  loss_mask_3: 0.1104  loss_dice_3: 0.1631  loss_ce_4: 7.795e-05  loss_mask_4: 0.1098  loss_dice_4: 0.1612  loss_ce_5: 8.026e-05  loss_mask_5: 0.109  loss_dice_5: 0.164  loss_ce_6: 5.02e-05  loss_mask_6: 0.1082  loss_dice_6: 0.1592  loss_ce_7: 8.162e-05  loss_mask_7: 0.1124  loss_dice_7: 0.1614  loss_ce_8: 8.746e-05  loss_mask_8: 0.1122  loss_dice_8: 0.1592  time: 0.5940  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:04:12] d2.utils.events INFO:  eta: 0:32:45  iter: 25299  total_loss: 3.022  loss_ce: 5.994e-05  loss_mask: 0.1115  loss_dice: 0.1784  loss_ce_0: 0.1221  loss_mask_0: 0.1118  loss_dice_0: 0.1731  loss_ce_1: 0.0001048  loss_mask_1: 0.1125  loss_dice_1: 0.1776  loss_ce_2: 0.0001239  loss_mask_2: 0.1098  loss_dice_2: 0.1712  loss_ce_3: 5.662e-05  loss_mask_3: 0.1147  loss_dice_3: 0.1788  loss_ce_4: 8.078e-05  loss_mask_4: 0.1144  loss_dice_4: 0.178  loss_ce_5: 0.0001061  loss_mask_5: 0.1126  loss_dice_5: 0.1765  loss_ce_6: 4.861e-05  loss_mask_6: 0.1116  loss_dice_6: 0.1743  loss_ce_7: 8.251e-05  loss_mask_7: 0.1131  loss_dice_7: 0.1719  loss_ce_8: 0.0001309  loss_mask_8: 0.1126  loss_dice_8: 0.1765  time: 0.5937  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:04:17] d2.utils.events INFO:  eta: 0:32:56  iter: 25319  total_loss: 2.918  loss_ce: 6.142e-05  loss_mask: 0.1102  loss_dice: 0.1648  loss_ce_0: 0.1247  loss_mask_0: 0.1072  loss_dice_0: 0.1636  loss_ce_1: 9.223e-05  loss_mask_1: 0.1105  loss_dice_1: 0.1688  loss_ce_2: 0.0001137  loss_mask_2: 0.1148  loss_dice_2: 0.1711  loss_ce_3: 5.148e-05  loss_mask_3: 0.1105  loss_dice_3: 0.1655  loss_ce_4: 7.749e-05  loss_mask_4: 0.1151  loss_dice_4: 0.1678  loss_ce_5: 7.998e-05  loss_mask_5: 0.1119  loss_dice_5: 0.1673  loss_ce_6: 4.672e-05  loss_mask_6: 0.112  loss_dice_6: 0.1699  loss_ce_7: 7.173e-05  loss_mask_7: 0.1081  loss_dice_7: 0.1621  loss_ce_8: 8.204e-05  loss_mask_8: 0.1075  loss_dice_8: 0.1611  time: 0.5934  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:04:21] d2.utils.events INFO:  eta: 0:33:03  iter: 25339  total_loss: 2.815  loss_ce: 6.938e-05  loss_mask: 0.1063  loss_dice: 0.1632  loss_ce_0: 0.1233  loss_mask_0: 0.1097  loss_dice_0: 0.1675  loss_ce_1: 9.304e-05  loss_mask_1: 0.1133  loss_dice_1: 0.1663  loss_ce_2: 0.0001251  loss_mask_2: 0.1083  loss_dice_2: 0.1629  loss_ce_3: 7.151e-05  loss_mask_3: 0.1055  loss_dice_3: 0.1589  loss_ce_4: 8.262e-05  loss_mask_4: 0.1112  loss_dice_4: 0.1659  loss_ce_5: 7.954e-05  loss_mask_5: 0.1096  loss_dice_5: 0.1636  loss_ce_6: 5.018e-05  loss_mask_6: 0.1078  loss_dice_6: 0.1644  loss_ce_7: 7.347e-05  loss_mask_7: 0.1052  loss_dice_7: 0.1552  loss_ce_8: 8.365e-05  loss_mask_8: 0.1107  loss_dice_8: 0.161  time: 0.5931  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:04:26] d2.utils.events INFO:  eta: 0:33:15  iter: 25359  total_loss: 2.873  loss_ce: 6.775e-05  loss_mask: 0.1113  loss_dice: 0.1658  loss_ce_0: 0.1252  loss_mask_0: 0.1115  loss_dice_0: 0.1633  loss_ce_1: 0.0001063  loss_mask_1: 0.1125  loss_dice_1: 0.1619  loss_ce_2: 0.0001454  loss_mask_2: 0.1111  loss_dice_2: 0.1669  loss_ce_3: 8.451e-05  loss_mask_3: 0.1093  loss_dice_3: 0.1601  loss_ce_4: 8.589e-05  loss_mask_4: 0.1107  loss_dice_4: 0.1579  loss_ce_5: 0.0001492  loss_mask_5: 0.1077  loss_dice_5: 0.1593  loss_ce_6: 5.106e-05  loss_mask_6: 0.1085  loss_dice_6: 0.1578  loss_ce_7: 8.917e-05  loss_mask_7: 0.1082  loss_dice_7: 0.1588  loss_ce_8: 0.0001334  loss_mask_8: 0.1117  loss_dice_8: 0.1632  time: 0.5928  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:04:30] d2.utils.events INFO:  eta: 0:33:26  iter: 25379  total_loss: 2.848  loss_ce: 5.887e-05  loss_mask: 0.1078  loss_dice: 0.1639  loss_ce_0: 0.1241  loss_mask_0: 0.1132  loss_dice_0: 0.1645  loss_ce_1: 0.0001035  loss_mask_1: 0.1088  loss_dice_1: 0.1629  loss_ce_2: 0.0001337  loss_mask_2: 0.1075  loss_dice_2: 0.1638  loss_ce_3: 4.837e-05  loss_mask_3: 0.106  loss_dice_3: 0.1612  loss_ce_4: 7.813e-05  loss_mask_4: 0.1096  loss_dice_4: 0.1604  loss_ce_5: 0.0001109  loss_mask_5: 0.106  loss_dice_5: 0.1607  loss_ce_6: 4.344e-05  loss_mask_6: 0.11  loss_dice_6: 0.1635  loss_ce_7: 7.275e-05  loss_mask_7: 0.1073  loss_dice_7: 0.1634  loss_ce_8: 0.0001315  loss_mask_8: 0.1095  loss_dice_8: 0.1642  time: 0.5925  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:04:35] d2.utils.events INFO:  eta: 0:33:35  iter: 25399  total_loss: 3.004  loss_ce: 6.272e-05  loss_mask: 0.1163  loss_dice: 0.1717  loss_ce_0: 0.1241  loss_mask_0: 0.1159  loss_dice_0: 0.1719  loss_ce_1: 9.629e-05  loss_mask_1: 0.1114  loss_dice_1: 0.1693  loss_ce_2: 0.0001263  loss_mask_2: 0.1149  loss_dice_2: 0.1734  loss_ce_3: 5.873e-05  loss_mask_3: 0.1157  loss_dice_3: 0.1745  loss_ce_4: 7.914e-05  loss_mask_4: 0.1156  loss_dice_4: 0.1745  loss_ce_5: 9.348e-05  loss_mask_5: 0.1165  loss_dice_5: 0.1735  loss_ce_6: 4.031e-05  loss_mask_6: 0.1156  loss_dice_6: 0.1731  loss_ce_7: 7.495e-05  loss_mask_7: 0.1177  loss_dice_7: 0.1757  loss_ce_8: 0.0001049  loss_mask_8: 0.1194  loss_dice_8: 0.1804  time: 0.5923  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:04:39] d2.utils.events INFO:  eta: 0:33:40  iter: 25419  total_loss: 2.885  loss_ce: 6.041e-05  loss_mask: 0.1076  loss_dice: 0.1554  loss_ce_0: 0.124  loss_mask_0: 0.1109  loss_dice_0: 0.161  loss_ce_1: 0.0001026  loss_mask_1: 0.1118  loss_dice_1: 0.1655  loss_ce_2: 0.0001156  loss_mask_2: 0.1125  loss_dice_2: 0.1572  loss_ce_3: 4.816e-05  loss_mask_3: 0.1106  loss_dice_3: 0.1571  loss_ce_4: 7.47e-05  loss_mask_4: 0.1092  loss_dice_4: 0.1594  loss_ce_5: 7.841e-05  loss_mask_5: 0.1078  loss_dice_5: 0.1606  loss_ce_6: 4.437e-05  loss_mask_6: 0.1088  loss_dice_6: 0.1619  loss_ce_7: 7.623e-05  loss_mask_7: 0.1086  loss_dice_7: 0.1601  loss_ce_8: 9.457e-05  loss_mask_8: 0.1143  loss_dice_8: 0.1599  time: 0.5920  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:04:44] d2.utils.events INFO:  eta: 0:33:45  iter: 25439  total_loss: 2.797  loss_ce: 5.762e-05  loss_mask: 0.1065  loss_dice: 0.155  loss_ce_0: 0.1241  loss_mask_0: 0.1056  loss_dice_0: 0.16  loss_ce_1: 0.0001046  loss_mask_1: 0.1062  loss_dice_1: 0.1545  loss_ce_2: 0.0001362  loss_mask_2: 0.1054  loss_dice_2: 0.1561  loss_ce_3: 7.298e-05  loss_mask_3: 0.107  loss_dice_3: 0.1558  loss_ce_4: 8.156e-05  loss_mask_4: 0.1063  loss_dice_4: 0.1568  loss_ce_5: 0.0001096  loss_mask_5: 0.1052  loss_dice_5: 0.1496  loss_ce_6: 4.789e-05  loss_mask_6: 0.1076  loss_dice_6: 0.1533  loss_ce_7: 7.774e-05  loss_mask_7: 0.1071  loss_dice_7: 0.1632  loss_ce_8: 0.000129  loss_mask_8: 0.1069  loss_dice_8: 0.1557  time: 0.5917  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:04:48] d2.utils.events INFO:  eta: 0:33:52  iter: 25459  total_loss: 2.932  loss_ce: 6.451e-05  loss_mask: 0.1112  loss_dice: 0.161  loss_ce_0: 0.1243  loss_mask_0: 0.1053  loss_dice_0: 0.165  loss_ce_1: 0.0001023  loss_mask_1: 0.1096  loss_dice_1: 0.1644  loss_ce_2: 0.0001217  loss_mask_2: 0.1109  loss_dice_2: 0.1623  loss_ce_3: 4.552e-05  loss_mask_3: 0.1148  loss_dice_3: 0.1662  loss_ce_4: 7.414e-05  loss_mask_4: 0.1096  loss_dice_4: 0.1649  loss_ce_5: 0.000103  loss_mask_5: 0.1106  loss_dice_5: 0.1654  loss_ce_6: 4.569e-05  loss_mask_6: 0.1072  loss_dice_6: 0.1602  loss_ce_7: 6.869e-05  loss_mask_7: 0.1113  loss_dice_7: 0.1677  loss_ce_8: 0.0001266  loss_mask_8: 0.1111  loss_dice_8: 0.1631  time: 0.5914  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:04:53] d2.utils.events INFO:  eta: 0:33:57  iter: 25479  total_loss: 3.027  loss_ce: 6.29e-05  loss_mask: 0.1123  loss_dice: 0.1677  loss_ce_0: 0.1122  loss_mask_0: 0.1079  loss_dice_0: 0.17  loss_ce_1: 0.000101  loss_mask_1: 0.1097  loss_dice_1: 0.1698  loss_ce_2: 0.0001383  loss_mask_2: 0.111  loss_dice_2: 0.1722  loss_ce_3: 7.65e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1629  loss_ce_4: 7.782e-05  loss_mask_4: 0.1105  loss_dice_4: 0.169  loss_ce_5: 0.000105  loss_mask_5: 0.1116  loss_dice_5: 0.1682  loss_ce_6: 4.692e-05  loss_mask_6: 0.1135  loss_dice_6: 0.1677  loss_ce_7: 8.195e-05  loss_mask_7: 0.114  loss_dice_7: 0.1792  loss_ce_8: 0.0001307  loss_mask_8: 0.1118  loss_dice_8: 0.1739  time: 0.5911  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:04:58] d2.utils.events INFO:  eta: 0:34:05  iter: 25499  total_loss: 2.838  loss_ce: 7.017e-05  loss_mask: 0.1093  loss_dice: 0.1626  loss_ce_0: 0.1246  loss_mask_0: 0.1055  loss_dice_0: 0.1592  loss_ce_1: 0.0001026  loss_mask_1: 0.1051  loss_dice_1: 0.1616  loss_ce_2: 0.0001232  loss_mask_2: 0.1078  loss_dice_2: 0.1572  loss_ce_3: 6.816e-05  loss_mask_3: 0.1132  loss_dice_3: 0.1634  loss_ce_4: 8.29e-05  loss_mask_4: 0.1087  loss_dice_4: 0.1657  loss_ce_5: 0.0001043  loss_mask_5: 0.1097  loss_dice_5: 0.1595  loss_ce_6: 5.161e-05  loss_mask_6: 0.1133  loss_dice_6: 0.1604  loss_ce_7: 8.701e-05  loss_mask_7: 0.1088  loss_dice_7: 0.1577  loss_ce_8: 0.0001276  loss_mask_8: 0.1073  loss_dice_8: 0.159  time: 0.5908  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:05:02] d2.utils.events INFO:  eta: 0:34:11  iter: 25519  total_loss: 2.84  loss_ce: 7.698e-05  loss_mask: 0.1085  loss_dice: 0.1707  loss_ce_0: 0.1242  loss_mask_0: 0.1073  loss_dice_0: 0.17  loss_ce_1: 9.898e-05  loss_mask_1: 0.1087  loss_dice_1: 0.1714  loss_ce_2: 0.0001339  loss_mask_2: 0.1083  loss_dice_2: 0.1724  loss_ce_3: 5.718e-05  loss_mask_3: 0.1066  loss_dice_3: 0.1644  loss_ce_4: 7.913e-05  loss_mask_4: 0.1057  loss_dice_4: 0.1656  loss_ce_5: 8.864e-05  loss_mask_5: 0.1123  loss_dice_5: 0.1668  loss_ce_6: 4.734e-05  loss_mask_6: 0.1088  loss_dice_6: 0.1666  loss_ce_7: 9.259e-05  loss_mask_7: 0.1085  loss_dice_7: 0.1673  loss_ce_8: 0.0001004  loss_mask_8: 0.1083  loss_dice_8: 0.1631  time: 0.5905  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:05:07] d2.utils.events INFO:  eta: 0:34:18  iter: 25539  total_loss: 2.881  loss_ce: 8.655e-05  loss_mask: 0.1115  loss_dice: 0.1665  loss_ce_0: 0.1242  loss_mask_0: 0.1133  loss_dice_0: 0.1746  loss_ce_1: 0.0001051  loss_mask_1: 0.11  loss_dice_1: 0.1691  loss_ce_2: 0.00014  loss_mask_2: 0.1061  loss_dice_2: 0.1657  loss_ce_3: 9.674e-05  loss_mask_3: 0.1093  loss_dice_3: 0.1678  loss_ce_4: 8.333e-05  loss_mask_4: 0.1103  loss_dice_4: 0.1654  loss_ce_5: 0.0001395  loss_mask_5: 0.104  loss_dice_5: 0.1633  loss_ce_6: 6.08e-05  loss_mask_6: 0.107  loss_dice_6: 0.165  loss_ce_7: 9.566e-05  loss_mask_7: 0.111  loss_dice_7: 0.1746  loss_ce_8: 0.0001226  loss_mask_8: 0.1108  loss_dice_8: 0.1701  time: 0.5903  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:05:11] d2.utils.events INFO:  eta: 0:34:21  iter: 25559  total_loss: 2.88  loss_ce: 6.33e-05  loss_mask: 0.1104  loss_dice: 0.1741  loss_ce_0: 0.1256  loss_mask_0: 0.1119  loss_dice_0: 0.18  loss_ce_1: 8.585e-05  loss_mask_1: 0.1107  loss_dice_1: 0.1691  loss_ce_2: 0.0001059  loss_mask_2: 0.1094  loss_dice_2: 0.1729  loss_ce_3: 4.606e-05  loss_mask_3: 0.1125  loss_dice_3: 0.173  loss_ce_4: 7.197e-05  loss_mask_4: 0.1077  loss_dice_4: 0.1627  loss_ce_5: 7.533e-05  loss_mask_5: 0.1114  loss_dice_5: 0.1743  loss_ce_6: 4.437e-05  loss_mask_6: 0.1062  loss_dice_6: 0.1641  loss_ce_7: 8.036e-05  loss_mask_7: 0.1102  loss_dice_7: 0.1694  loss_ce_8: 7.905e-05  loss_mask_8: 0.1116  loss_dice_8: 0.1738  time: 0.5900  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:05:16] d2.utils.events INFO:  eta: 0:34:24  iter: 25579  total_loss: 2.779  loss_ce: 7.433e-05  loss_mask: 0.106  loss_dice: 0.1582  loss_ce_0: 0.1231  loss_mask_0: 0.1065  loss_dice_0: 0.159  loss_ce_1: 9.873e-05  loss_mask_1: 0.1089  loss_dice_1: 0.1579  loss_ce_2: 0.000131  loss_mask_2: 0.1078  loss_dice_2: 0.1617  loss_ce_3: 6.941e-05  loss_mask_3: 0.112  loss_dice_3: 0.1599  loss_ce_4: 7.963e-05  loss_mask_4: 0.1098  loss_dice_4: 0.155  loss_ce_5: 9.935e-05  loss_mask_5: 0.1109  loss_dice_5: 0.1561  loss_ce_6: 5.009e-05  loss_mask_6: 0.1071  loss_dice_6: 0.1609  loss_ce_7: 9.124e-05  loss_mask_7: 0.1094  loss_dice_7: 0.1587  loss_ce_8: 0.0001157  loss_mask_8: 0.1109  loss_dice_8: 0.1617  time: 0.5897  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:05:20] d2.utils.events INFO:  eta: 0:34:29  iter: 25599  total_loss: 2.923  loss_ce: 6.258e-05  loss_mask: 0.1111  loss_dice: 0.1647  loss_ce_0: 0.1244  loss_mask_0: 0.1113  loss_dice_0: 0.1685  loss_ce_1: 9.242e-05  loss_mask_1: 0.1101  loss_dice_1: 0.164  loss_ce_2: 0.0001189  loss_mask_2: 0.1097  loss_dice_2: 0.1701  loss_ce_3: 5.649e-05  loss_mask_3: 0.1136  loss_dice_3: 0.1718  loss_ce_4: 7.391e-05  loss_mask_4: 0.1108  loss_dice_4: 0.1665  loss_ce_5: 8.518e-05  loss_mask_5: 0.1115  loss_dice_5: 0.1657  loss_ce_6: 4.479e-05  loss_mask_6: 0.1119  loss_dice_6: 0.1681  loss_ce_7: 8.837e-05  loss_mask_7: 0.1132  loss_dice_7: 0.1691  loss_ce_8: 8.491e-05  loss_mask_8: 0.1118  loss_dice_8: 0.1687  time: 0.5894  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:05:25] d2.utils.events INFO:  eta: 0:34:32  iter: 25619  total_loss: 2.859  loss_ce: 6.134e-05  loss_mask: 0.1104  loss_dice: 0.166  loss_ce_0: 0.1256  loss_mask_0: 0.1145  loss_dice_0: 0.1657  loss_ce_1: 8.229e-05  loss_mask_1: 0.1052  loss_dice_1: 0.1574  loss_ce_2: 9.624e-05  loss_mask_2: 0.1113  loss_dice_2: 0.1658  loss_ce_3: 4.197e-05  loss_mask_3: 0.1085  loss_dice_3: 0.1621  loss_ce_4: 5.62e-05  loss_mask_4: 0.1074  loss_dice_4: 0.1601  loss_ce_5: 6.933e-05  loss_mask_5: 0.1137  loss_dice_5: 0.1659  loss_ce_6: 4.16e-05  loss_mask_6: 0.1105  loss_dice_6: 0.1651  loss_ce_7: 7.391e-05  loss_mask_7: 0.1114  loss_dice_7: 0.1634  loss_ce_8: 7.808e-05  loss_mask_8: 0.1121  loss_dice_8: 0.163  time: 0.5891  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:05:29] d2.utils.events INFO:  eta: 0:34:38  iter: 25639  total_loss: 2.91  loss_ce: 6.128e-05  loss_mask: 0.1087  loss_dice: 0.1686  loss_ce_0: 0.1344  loss_mask_0: 0.115  loss_dice_0: 0.1718  loss_ce_1: 9.347e-05  loss_mask_1: 0.112  loss_dice_1: 0.1743  loss_ce_2: 0.0001061  loss_mask_2: 0.1128  loss_dice_2: 0.1725  loss_ce_3: 5.143e-05  loss_mask_3: 0.1103  loss_dice_3: 0.1656  loss_ce_4: 7.407e-05  loss_mask_4: 0.11  loss_dice_4: 0.1629  loss_ce_5: 9.574e-05  loss_mask_5: 0.1103  loss_dice_5: 0.1616  loss_ce_6: 4.188e-05  loss_mask_6: 0.1107  loss_dice_6: 0.1642  loss_ce_7: 7.942e-05  loss_mask_7: 0.1104  loss_dice_7: 0.1664  loss_ce_8: 0.0001212  loss_mask_8: 0.1104  loss_dice_8: 0.1663  time: 0.5888  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:05:34] d2.utils.events INFO:  eta: 0:34:41  iter: 25659  total_loss: 2.904  loss_ce: 6.428e-05  loss_mask: 0.1093  loss_dice: 0.1646  loss_ce_0: 0.1259  loss_mask_0: 0.1103  loss_dice_0: 0.1677  loss_ce_1: 9.701e-05  loss_mask_1: 0.1104  loss_dice_1: 0.1673  loss_ce_2: 0.00011  loss_mask_2: 0.1072  loss_dice_2: 0.1675  loss_ce_3: 5.633e-05  loss_mask_3: 0.1099  loss_dice_3: 0.1668  loss_ce_4: 7.322e-05  loss_mask_4: 0.1101  loss_dice_4: 0.1642  loss_ce_5: 9.96e-05  loss_mask_5: 0.112  loss_dice_5: 0.1691  loss_ce_6: 4.449e-05  loss_mask_6: 0.112  loss_dice_6: 0.1677  loss_ce_7: 8.454e-05  loss_mask_7: 0.1095  loss_dice_7: 0.1654  loss_ce_8: 0.000127  loss_mask_8: 0.1079  loss_dice_8: 0.1671  time: 0.5886  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:05:39] d2.utils.events INFO:  eta: 0:34:41  iter: 25679  total_loss: 2.815  loss_ce: 5.141e-05  loss_mask: 0.1058  loss_dice: 0.1705  loss_ce_0: 0.1257  loss_mask_0: 0.1052  loss_dice_0: 0.1605  loss_ce_1: 5.433e-05  loss_mask_1: 0.1104  loss_dice_1: 0.1714  loss_ce_2: 6.344e-05  loss_mask_2: 0.1061  loss_dice_2: 0.1608  loss_ce_3: 3.66e-05  loss_mask_3: 0.1093  loss_dice_3: 0.1696  loss_ce_4: 3.737e-05  loss_mask_4: 0.1072  loss_dice_4: 0.1669  loss_ce_5: 5.093e-05  loss_mask_5: 0.1087  loss_dice_5: 0.1656  loss_ce_6: 3.723e-05  loss_mask_6: 0.1073  loss_dice_6: 0.1677  loss_ce_7: 6.286e-05  loss_mask_7: 0.1098  loss_dice_7: 0.1599  loss_ce_8: 6.613e-05  loss_mask_8: 0.107  loss_dice_8: 0.1686  time: 0.5883  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:05:43] d2.utils.events INFO:  eta: 0:34:51  iter: 25699  total_loss: 2.781  loss_ce: 6.755e-05  loss_mask: 0.1097  loss_dice: 0.1599  loss_ce_0: 0.1248  loss_mask_0: 0.1098  loss_dice_0: 0.1622  loss_ce_1: 0.0001003  loss_mask_1: 0.109  loss_dice_1: 0.1629  loss_ce_2: 0.0001334  loss_mask_2: 0.1139  loss_dice_2: 0.1567  loss_ce_3: 5.589e-05  loss_mask_3: 0.1112  loss_dice_3: 0.1617  loss_ce_4: 7.357e-05  loss_mask_4: 0.1092  loss_dice_4: 0.1588  loss_ce_5: 0.000105  loss_mask_5: 0.1082  loss_dice_5: 0.1577  loss_ce_6: 4.666e-05  loss_mask_6: 0.1148  loss_dice_6: 0.166  loss_ce_7: 8.905e-05  loss_mask_7: 0.1088  loss_dice_7: 0.161  loss_ce_8: 9.705e-05  loss_mask_8: 0.1104  loss_dice_8: 0.1637  time: 0.5880  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:05:48] d2.utils.events INFO:  eta: 0:34:58  iter: 25719  total_loss: 2.783  loss_ce: 6.185e-05  loss_mask: 0.1079  loss_dice: 0.1576  loss_ce_0: 0.1246  loss_mask_0: 0.1087  loss_dice_0: 0.1601  loss_ce_1: 9.405e-05  loss_mask_1: 0.1098  loss_dice_1: 0.1635  loss_ce_2: 0.0001161  loss_mask_2: 0.1078  loss_dice_2: 0.1602  loss_ce_3: 5.147e-05  loss_mask_3: 0.1058  loss_dice_3: 0.1539  loss_ce_4: 7.132e-05  loss_mask_4: 0.1107  loss_dice_4: 0.1631  loss_ce_5: 8.394e-05  loss_mask_5: 0.1104  loss_dice_5: 0.1581  loss_ce_6: 4.313e-05  loss_mask_6: 0.1113  loss_dice_6: 0.1652  loss_ce_7: 8.538e-05  loss_mask_7: 0.11  loss_dice_7: 0.1638  loss_ce_8: 9.728e-05  loss_mask_8: 0.112  loss_dice_8: 0.1591  time: 0.5877  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:05:52] d2.utils.events INFO:  eta: 0:35:01  iter: 25739  total_loss: 2.779  loss_ce: 5.802e-05  loss_mask: 0.1082  loss_dice: 0.1613  loss_ce_0: 0.1249  loss_mask_0: 0.1087  loss_dice_0: 0.1643  loss_ce_1: 8.487e-05  loss_mask_1: 0.1097  loss_dice_1: 0.1622  loss_ce_2: 0.0001013  loss_mask_2: 0.1095  loss_dice_2: 0.1621  loss_ce_3: 5.108e-05  loss_mask_3: 0.1104  loss_dice_3: 0.1592  loss_ce_4: 6.93e-05  loss_mask_4: 0.1094  loss_dice_4: 0.1608  loss_ce_5: 7.346e-05  loss_mask_5: 0.1079  loss_dice_5: 0.1591  loss_ce_6: 4.319e-05  loss_mask_6: 0.1102  loss_dice_6: 0.1614  loss_ce_7: 7.779e-05  loss_mask_7: 0.111  loss_dice_7: 0.16  loss_ce_8: 7.906e-05  loss_mask_8: 0.1095  loss_dice_8: 0.1583  time: 0.5874  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:05:57] d2.utils.events INFO:  eta: 0:35:02  iter: 25759  total_loss: 2.704  loss_ce: 5.929e-05  loss_mask: 0.1099  loss_dice: 0.1567  loss_ce_0: 0.1244  loss_mask_0: 0.1031  loss_dice_0: 0.1529  loss_ce_1: 8.646e-05  loss_mask_1: 0.1078  loss_dice_1: 0.1514  loss_ce_2: 0.0001261  loss_mask_2: 0.1066  loss_dice_2: 0.1539  loss_ce_3: 4.283e-05  loss_mask_3: 0.1108  loss_dice_3: 0.1567  loss_ce_4: 6.934e-05  loss_mask_4: 0.1067  loss_dice_4: 0.1509  loss_ce_5: 7.362e-05  loss_mask_5: 0.1046  loss_dice_5: 0.153  loss_ce_6: 4.191e-05  loss_mask_6: 0.111  loss_dice_6: 0.1547  loss_ce_7: 8.311e-05  loss_mask_7: 0.1064  loss_dice_7: 0.1544  loss_ce_8: 7.926e-05  loss_mask_8: 0.1046  loss_dice_8: 0.1532  time: 0.5871  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:06:01] d2.utils.events INFO:  eta: 0:35:05  iter: 25779  total_loss: 3.052  loss_ce: 5.94e-05  loss_mask: 0.1153  loss_dice: 0.1728  loss_ce_0: 0.1182  loss_mask_0: 0.1146  loss_dice_0: 0.1726  loss_ce_1: 8.705e-05  loss_mask_1: 0.1172  loss_dice_1: 0.1772  loss_ce_2: 0.0001132  loss_mask_2: 0.1187  loss_dice_2: 0.1746  loss_ce_3: 4.873e-05  loss_mask_3: 0.1133  loss_dice_3: 0.1732  loss_ce_4: 6.552e-05  loss_mask_4: 0.1172  loss_dice_4: 0.1739  loss_ce_5: 7.211e-05  loss_mask_5: 0.1128  loss_dice_5: 0.1692  loss_ce_6: 4.121e-05  loss_mask_6: 0.1181  loss_dice_6: 0.1753  loss_ce_7: 8.467e-05  loss_mask_7: 0.1191  loss_dice_7: 0.1756  loss_ce_8: 7.857e-05  loss_mask_8: 0.1139  loss_dice_8: 0.173  time: 0.5869  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:06:06] d2.utils.events INFO:  eta: 0:35:04  iter: 25799  total_loss: 2.863  loss_ce: 6.064e-05  loss_mask: 0.1123  loss_dice: 0.1644  loss_ce_0: 0.124  loss_mask_0: 0.1086  loss_dice_0: 0.1653  loss_ce_1: 7.856e-05  loss_mask_1: 0.1116  loss_dice_1: 0.1627  loss_ce_2: 0.0001044  loss_mask_2: 0.1122  loss_dice_2: 0.1627  loss_ce_3: 5.838e-05  loss_mask_3: 0.1103  loss_dice_3: 0.1672  loss_ce_4: 6.812e-05  loss_mask_4: 0.11  loss_dice_4: 0.1623  loss_ce_5: 7.259e-05  loss_mask_5: 0.1127  loss_dice_5: 0.1632  loss_ce_6: 4.751e-05  loss_mask_6: 0.1115  loss_dice_6: 0.1655  loss_ce_7: 7.624e-05  loss_mask_7: 0.1103  loss_dice_7: 0.1623  loss_ce_8: 7.627e-05  loss_mask_8: 0.1085  loss_dice_8: 0.1592  time: 0.5866  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:06:10] d2.utils.events INFO:  eta: 0:34:59  iter: 25819  total_loss: 2.926  loss_ce: 5.953e-05  loss_mask: 0.1139  loss_dice: 0.1566  loss_ce_0: 0.1235  loss_mask_0: 0.1168  loss_dice_0: 0.1646  loss_ce_1: 8.52e-05  loss_mask_1: 0.1155  loss_dice_1: 0.1626  loss_ce_2: 0.0001139  loss_mask_2: 0.1165  loss_dice_2: 0.1599  loss_ce_3: 4.198e-05  loss_mask_3: 0.1152  loss_dice_3: 0.1623  loss_ce_4: 6.919e-05  loss_mask_4: 0.1171  loss_dice_4: 0.1594  loss_ce_5: 7.804e-05  loss_mask_5: 0.1168  loss_dice_5: 0.1603  loss_ce_6: 4.07e-05  loss_mask_6: 0.1164  loss_dice_6: 0.1653  loss_ce_7: 7.989e-05  loss_mask_7: 0.1173  loss_dice_7: 0.1593  loss_ce_8: 7.766e-05  loss_mask_8: 0.1187  loss_dice_8: 0.1615  time: 0.5863  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:06:15] d2.utils.events INFO:  eta: 0:34:55  iter: 25839  total_loss: 2.795  loss_ce: 5.9e-05  loss_mask: 0.1109  loss_dice: 0.1621  loss_ce_0: 0.1233  loss_mask_0: 0.1121  loss_dice_0: 0.1605  loss_ce_1: 8.645e-05  loss_mask_1: 0.1073  loss_dice_1: 0.1604  loss_ce_2: 0.0001015  loss_mask_2: 0.1065  loss_dice_2: 0.1644  loss_ce_3: 4.423e-05  loss_mask_3: 0.1076  loss_dice_3: 0.1573  loss_ce_4: 6.91e-05  loss_mask_4: 0.1084  loss_dice_4: 0.158  loss_ce_5: 7.204e-05  loss_mask_5: 0.1054  loss_dice_5: 0.1562  loss_ce_6: 4.117e-05  loss_mask_6: 0.1086  loss_dice_6: 0.1607  loss_ce_7: 7.788e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1602  loss_ce_8: 7.731e-05  loss_mask_8: 0.1114  loss_dice_8: 0.1641  time: 0.5860  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:06:19] d2.utils.events INFO:  eta: 0:34:50  iter: 25859  total_loss: 2.916  loss_ce: 5.89e-05  loss_mask: 0.109  loss_dice: 0.1679  loss_ce_0: 0.1259  loss_mask_0: 0.1099  loss_dice_0: 0.162  loss_ce_1: 9.558e-05  loss_mask_1: 0.1074  loss_dice_1: 0.1648  loss_ce_2: 0.0001182  loss_mask_2: 0.1065  loss_dice_2: 0.1712  loss_ce_3: 4.266e-05  loss_mask_3: 0.1078  loss_dice_3: 0.1642  loss_ce_4: 7.216e-05  loss_mask_4: 0.1055  loss_dice_4: 0.1637  loss_ce_5: 9.781e-05  loss_mask_5: 0.1114  loss_dice_5: 0.1673  loss_ce_6: 4.115e-05  loss_mask_6: 0.1101  loss_dice_6: 0.1697  loss_ce_7: 7.95e-05  loss_mask_7: 0.1114  loss_dice_7: 0.1744  loss_ce_8: 0.0001131  loss_mask_8: 0.1103  loss_dice_8: 0.1742  time: 0.5857  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:06:24] d2.utils.events INFO:  eta: 0:34:46  iter: 25879  total_loss: 2.985  loss_ce: 5.506e-05  loss_mask: 0.114  loss_dice: 0.1657  loss_ce_0: 0.1232  loss_mask_0: 0.1126  loss_dice_0: 0.1734  loss_ce_1: 9.545e-05  loss_mask_1: 0.1061  loss_dice_1: 0.1658  loss_ce_2: 0.0001149  loss_mask_2: 0.1135  loss_dice_2: 0.1709  loss_ce_3: 4.463e-05  loss_mask_3: 0.1145  loss_dice_3: 0.1726  loss_ce_4: 6.781e-05  loss_mask_4: 0.1161  loss_dice_4: 0.167  loss_ce_5: 9.105e-05  loss_mask_5: 0.11  loss_dice_5: 0.1647  loss_ce_6: 3.969e-05  loss_mask_6: 0.1169  loss_dice_6: 0.1684  loss_ce_7: 7.73e-05  loss_mask_7: 0.111  loss_dice_7: 0.1667  loss_ce_8: 0.0001146  loss_mask_8: 0.1124  loss_dice_8: 0.1691  time: 0.5855  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:06:28] d2.utils.events INFO:  eta: 0:34:42  iter: 25899  total_loss: 2.855  loss_ce: 6.226e-05  loss_mask: 0.1055  loss_dice: 0.1681  loss_ce_0: 0.1248  loss_mask_0: 0.1086  loss_dice_0: 0.1673  loss_ce_1: 8.074e-05  loss_mask_1: 0.1072  loss_dice_1: 0.1644  loss_ce_2: 0.0001207  loss_mask_2: 0.106  loss_dice_2: 0.1583  loss_ce_3: 5.815e-05  loss_mask_3: 0.1072  loss_dice_3: 0.1638  loss_ce_4: 6.907e-05  loss_mask_4: 0.1057  loss_dice_4: 0.1643  loss_ce_5: 7.165e-05  loss_mask_5: 0.1082  loss_dice_5: 0.162  loss_ce_6: 4.483e-05  loss_mask_6: 0.1063  loss_dice_6: 0.1608  loss_ce_7: 7.892e-05  loss_mask_7: 0.1087  loss_dice_7: 0.1573  loss_ce_8: 7.762e-05  loss_mask_8: 0.1072  loss_dice_8: 0.1638  time: 0.5852  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:06:33] d2.utils.events INFO:  eta: 0:34:37  iter: 25919  total_loss: 2.717  loss_ce: 6.225e-05  loss_mask: 0.1046  loss_dice: 0.1589  loss_ce_0: 0.1257  loss_mask_0: 0.1062  loss_dice_0: 0.1497  loss_ce_1: 9.06e-05  loss_mask_1: 0.1079  loss_dice_1: 0.149  loss_ce_2: 0.000119  loss_mask_2: 0.1052  loss_dice_2: 0.1568  loss_ce_3: 5.335e-05  loss_mask_3: 0.1048  loss_dice_3: 0.1515  loss_ce_4: 7.071e-05  loss_mask_4: 0.1065  loss_dice_4: 0.1551  loss_ce_5: 9.114e-05  loss_mask_5: 0.1032  loss_dice_5: 0.1486  loss_ce_6: 4.602e-05  loss_mask_6: 0.1067  loss_dice_6: 0.1541  loss_ce_7: 8.04e-05  loss_mask_7: 0.1035  loss_dice_7: 0.1558  loss_ce_8: 0.0001115  loss_mask_8: 0.106  loss_dice_8: 0.1533  time: 0.5849  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:06:37] d2.utils.events INFO:  eta: 0:34:32  iter: 25939  total_loss: 2.881  loss_ce: 5.876e-05  loss_mask: 0.1078  loss_dice: 0.166  loss_ce_0: 0.1238  loss_mask_0: 0.1104  loss_dice_0: 0.1629  loss_ce_1: 8.899e-05  loss_mask_1: 0.114  loss_dice_1: 0.1686  loss_ce_2: 0.0001023  loss_mask_2: 0.1121  loss_dice_2: 0.1659  loss_ce_3: 4.543e-05  loss_mask_3: 0.1113  loss_dice_3: 0.1631  loss_ce_4: 6.91e-05  loss_mask_4: 0.1088  loss_dice_4: 0.1575  loss_ce_5: 8.144e-05  loss_mask_5: 0.1141  loss_dice_5: 0.169  loss_ce_6: 4.067e-05  loss_mask_6: 0.1127  loss_dice_6: 0.164  loss_ce_7: 7.901e-05  loss_mask_7: 0.111  loss_dice_7: 0.161  loss_ce_8: 9.619e-05  loss_mask_8: 0.1113  loss_dice_8: 0.1643  time: 0.5846  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:06:42] d2.utils.events INFO:  eta: 0:34:23  iter: 25959  total_loss: 2.898  loss_ce: 5.916e-05  loss_mask: 0.1102  loss_dice: 0.1659  loss_ce_0: 0.1256  loss_mask_0: 0.1089  loss_dice_0: 0.1644  loss_ce_1: 8.551e-05  loss_mask_1: 0.1115  loss_dice_1: 0.1639  loss_ce_2: 8.941e-05  loss_mask_2: 0.1109  loss_dice_2: 0.1652  loss_ce_3: 4.323e-05  loss_mask_3: 0.1118  loss_dice_3: 0.1639  loss_ce_4: 5.488e-05  loss_mask_4: 0.1124  loss_dice_4: 0.1613  loss_ce_5: 7.459e-05  loss_mask_5: 0.109  loss_dice_5: 0.1573  loss_ce_6: 4.007e-05  loss_mask_6: 0.1089  loss_dice_6: 0.1588  loss_ce_7: 7.454e-05  loss_mask_7: 0.1124  loss_dice_7: 0.1719  loss_ce_8: 8.796e-05  loss_mask_8: 0.1164  loss_dice_8: 0.1641  time: 0.5844  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:06:46] d2.utils.events INFO:  eta: 0:34:19  iter: 25979  total_loss: 2.849  loss_ce: 5.72e-05  loss_mask: 0.1089  loss_dice: 0.1689  loss_ce_0: 0.1243  loss_mask_0: 0.1101  loss_dice_0: 0.1703  loss_ce_1: 8.035e-05  loss_mask_1: 0.1069  loss_dice_1: 0.1635  loss_ce_2: 0.0001087  loss_mask_2: 0.1123  loss_dice_2: 0.165  loss_ce_3: 4.746e-05  loss_mask_3: 0.1122  loss_dice_3: 0.1695  loss_ce_4: 6.659e-05  loss_mask_4: 0.1069  loss_dice_4: 0.1615  loss_ce_5: 7.114e-05  loss_mask_5: 0.1092  loss_dice_5: 0.159  loss_ce_6: 4.153e-05  loss_mask_6: 0.1086  loss_dice_6: 0.1608  loss_ce_7: 7.741e-05  loss_mask_7: 0.1107  loss_dice_7: 0.1719  loss_ce_8: 7.4e-05  loss_mask_8: 0.1074  loss_dice_8: 0.1655  time: 0.5841  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:06:51] d2.utils.events INFO:  eta: 0:34:14  iter: 25999  total_loss: 2.951  loss_ce: 5.705e-05  loss_mask: 0.1156  loss_dice: 0.1658  loss_ce_0: 0.1246  loss_mask_0: 0.1174  loss_dice_0: 0.1671  loss_ce_1: 8.969e-05  loss_mask_1: 0.1134  loss_dice_1: 0.1691  loss_ce_2: 9.918e-05  loss_mask_2: 0.1152  loss_dice_2: 0.168  loss_ce_3: 4.469e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1637  loss_ce_4: 6.786e-05  loss_mask_4: 0.1165  loss_dice_4: 0.1633  loss_ce_5: 9.069e-05  loss_mask_5: 0.1135  loss_dice_5: 0.1647  loss_ce_6: 3.913e-05  loss_mask_6: 0.1161  loss_dice_6: 0.1701  loss_ce_7: 7.804e-05  loss_mask_7: 0.1137  loss_dice_7: 0.1668  loss_ce_8: 0.0001113  loss_mask_8: 0.1142  loss_dice_8: 0.1651  time: 0.5838  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:06:55] d2.utils.events INFO:  eta: 0:34:10  iter: 26019  total_loss: 2.931  loss_ce: 5.77e-05  loss_mask: 0.1078  loss_dice: 0.1713  loss_ce_0: 0.1324  loss_mask_0: 0.1141  loss_dice_0: 0.1708  loss_ce_1: 7.683e-05  loss_mask_1: 0.1101  loss_dice_1: 0.1782  loss_ce_2: 9.146e-05  loss_mask_2: 0.1107  loss_dice_2: 0.1757  loss_ce_3: 4.616e-05  loss_mask_3: 0.1053  loss_dice_3: 0.1722  loss_ce_4: 5.444e-05  loss_mask_4: 0.1104  loss_dice_4: 0.1668  loss_ce_5: 6.584e-05  loss_mask_5: 0.1097  loss_dice_5: 0.1705  loss_ce_6: 4.122e-05  loss_mask_6: 0.1066  loss_dice_6: 0.1698  loss_ce_7: 6.861e-05  loss_mask_7: 0.108  loss_dice_7: 0.1657  loss_ce_8: 7.179e-05  loss_mask_8: 0.1107  loss_dice_8: 0.1718  time: 0.5835  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:07:00] d2.utils.events INFO:  eta: 0:34:05  iter: 26039  total_loss: 2.913  loss_ce: 5.524e-05  loss_mask: 0.1112  loss_dice: 0.1652  loss_ce_0: 0.1188  loss_mask_0: 0.1147  loss_dice_0: 0.1678  loss_ce_1: 8.382e-05  loss_mask_1: 0.1177  loss_dice_1: 0.1688  loss_ce_2: 0.0001203  loss_mask_2: 0.1165  loss_dice_2: 0.1675  loss_ce_3: 4.514e-05  loss_mask_3: 0.1131  loss_dice_3: 0.1638  loss_ce_4: 6.747e-05  loss_mask_4: 0.112  loss_dice_4: 0.1629  loss_ce_5: 7.02e-05  loss_mask_5: 0.1127  loss_dice_5: 0.1591  loss_ce_6: 3.842e-05  loss_mask_6: 0.1129  loss_dice_6: 0.1635  loss_ce_7: 7.7e-05  loss_mask_7: 0.1107  loss_dice_7: 0.1663  loss_ce_8: 7.634e-05  loss_mask_8: 0.1126  loss_dice_8: 0.1683  time: 0.5833  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:07:04] d2.utils.events INFO:  eta: 0:34:01  iter: 26059  total_loss: 2.966  loss_ce: 5.778e-05  loss_mask: 0.1088  loss_dice: 0.167  loss_ce_0: 0.1242  loss_mask_0: 0.1095  loss_dice_0: 0.1634  loss_ce_1: 9.515e-05  loss_mask_1: 0.1092  loss_dice_1: 0.1695  loss_ce_2: 9.951e-05  loss_mask_2: 0.109  loss_dice_2: 0.1651  loss_ce_3: 4.425e-05  loss_mask_3: 0.1119  loss_dice_3: 0.1678  loss_ce_4: 6.601e-05  loss_mask_4: 0.1099  loss_dice_4: 0.1737  loss_ce_5: 6.938e-05  loss_mask_5: 0.1127  loss_dice_5: 0.1722  loss_ce_6: 4.355e-05  loss_mask_6: 0.1163  loss_dice_6: 0.1751  loss_ce_7: 7.626e-05  loss_mask_7: 0.1156  loss_dice_7: 0.1701  loss_ce_8: 7.294e-05  loss_mask_8: 0.1077  loss_dice_8: 0.1708  time: 0.5830  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:07:09] d2.utils.events INFO:  eta: 0:33:59  iter: 26079  total_loss: 2.803  loss_ce: 5.729e-05  loss_mask: 0.1037  loss_dice: 0.1608  loss_ce_0: 0.1249  loss_mask_0: 0.108  loss_dice_0: 0.1613  loss_ce_1: 0.0001038  loss_mask_1: 0.1034  loss_dice_1: 0.1609  loss_ce_2: 0.0001228  loss_mask_2: 0.107  loss_dice_2: 0.169  loss_ce_3: 4.025e-05  loss_mask_3: 0.1058  loss_dice_3: 0.16  loss_ce_4: 6.773e-05  loss_mask_4: 0.1045  loss_dice_4: 0.1601  loss_ce_5: 9.346e-05  loss_mask_5: 0.1065  loss_dice_5: 0.159  loss_ce_6: 3.968e-05  loss_mask_6: 0.1095  loss_dice_6: 0.159  loss_ce_7: 7.99e-05  loss_mask_7: 0.1028  loss_dice_7: 0.1599  loss_ce_8: 0.0001096  loss_mask_8: 0.1072  loss_dice_8: 0.1645  time: 0.5827  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:07:14] d2.utils.events INFO:  eta: 0:33:53  iter: 26099  total_loss: 2.95  loss_ce: 5.745e-05  loss_mask: 0.1107  loss_dice: 0.1673  loss_ce_0: 0.124  loss_mask_0: 0.1091  loss_dice_0: 0.1669  loss_ce_1: 7.165e-05  loss_mask_1: 0.1091  loss_dice_1: 0.1695  loss_ce_2: 8.096e-05  loss_mask_2: 0.1104  loss_dice_2: 0.1681  loss_ce_3: 3.484e-05  loss_mask_3: 0.1082  loss_dice_3: 0.1696  loss_ce_4: 3.678e-05  loss_mask_4: 0.1104  loss_dice_4: 0.1697  loss_ce_5: 5.637e-05  loss_mask_5: 0.1081  loss_dice_5: 0.1701  loss_ce_6: 3.878e-05  loss_mask_6: 0.1093  loss_dice_6: 0.1687  loss_ce_7: 6.113e-05  loss_mask_7: 0.1079  loss_dice_7: 0.1653  loss_ce_8: 6.652e-05  loss_mask_8: 0.109  loss_dice_8: 0.1732  time: 0.5824  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:07:18] d2.utils.events INFO:  eta: 0:33:51  iter: 26119  total_loss: 2.743  loss_ce: 5.712e-05  loss_mask: 0.1087  loss_dice: 0.1565  loss_ce_0: 0.1248  loss_mask_0: 0.1044  loss_dice_0: 0.1598  loss_ce_1: 9.078e-05  loss_mask_1: 0.1055  loss_dice_1: 0.1595  loss_ce_2: 9.69e-05  loss_mask_2: 0.1065  loss_dice_2: 0.1589  loss_ce_3: 4.653e-05  loss_mask_3: 0.1091  loss_dice_3: 0.1617  loss_ce_4: 6.426e-05  loss_mask_4: 0.1052  loss_dice_4: 0.1557  loss_ce_5: 6.92e-05  loss_mask_5: 0.1072  loss_dice_5: 0.1578  loss_ce_6: 4.01e-05  loss_mask_6: 0.1034  loss_dice_6: 0.1578  loss_ce_7: 7.624e-05  loss_mask_7: 0.1044  loss_dice_7: 0.1605  loss_ce_8: 7.465e-05  loss_mask_8: 0.1033  loss_dice_8: 0.1615  time: 0.5822  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:07:23] d2.utils.events INFO:  eta: 0:33:47  iter: 26139  total_loss: 2.953  loss_ce: 5.689e-05  loss_mask: 0.1109  loss_dice: 0.1683  loss_ce_0: 0.1235  loss_mask_0: 0.1101  loss_dice_0: 0.1713  loss_ce_1: 7.44e-05  loss_mask_1: 0.11  loss_dice_1: 0.1753  loss_ce_2: 8.922e-05  loss_mask_2: 0.1158  loss_dice_2: 0.1737  loss_ce_3: 3.615e-05  loss_mask_3: 0.11  loss_dice_3: 0.1648  loss_ce_4: 5.306e-05  loss_mask_4: 0.1145  loss_dice_4: 0.1713  loss_ce_5: 6.377e-05  loss_mask_5: 0.114  loss_dice_5: 0.1674  loss_ce_6: 3.817e-05  loss_mask_6: 0.1147  loss_dice_6: 0.1703  loss_ce_7: 6.773e-05  loss_mask_7: 0.1107  loss_dice_7: 0.1716  loss_ce_8: 7.083e-05  loss_mask_8: 0.1102  loss_dice_8: 0.1683  time: 0.5819  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:07:27] d2.utils.events INFO:  eta: 0:33:42  iter: 26159  total_loss: 2.882  loss_ce: 5.284e-05  loss_mask: 0.1134  loss_dice: 0.161  loss_ce_0: 0.1232  loss_mask_0: 0.1187  loss_dice_0: 0.168  loss_ce_1: 7.585e-05  loss_mask_1: 0.1137  loss_dice_1: 0.171  loss_ce_2: 7.973e-05  loss_mask_2: 0.1135  loss_dice_2: 0.1621  loss_ce_3: 4.025e-05  loss_mask_3: 0.1105  loss_dice_3: 0.1582  loss_ce_4: 5.945e-05  loss_mask_4: 0.1075  loss_dice_4: 0.1642  loss_ce_5: 5.768e-05  loss_mask_5: 0.106  loss_dice_5: 0.1668  loss_ce_6: 3.642e-05  loss_mask_6: 0.1101  loss_dice_6: 0.1648  loss_ce_7: 7.321e-05  loss_mask_7: 0.1081  loss_dice_7: 0.1645  loss_ce_8: 6.554e-05  loss_mask_8: 0.1062  loss_dice_8: 0.162  time: 0.5816  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:07:32] d2.utils.events INFO:  eta: 0:33:37  iter: 26179  total_loss: 2.882  loss_ce: 5.948e-05  loss_mask: 0.1069  loss_dice: 0.1664  loss_ce_0: 0.1247  loss_mask_0: 0.1095  loss_dice_0: 0.1659  loss_ce_1: 0.00011  loss_mask_1: 0.1093  loss_dice_1: 0.1633  loss_ce_2: 0.0001237  loss_mask_2: 0.1076  loss_dice_2: 0.1631  loss_ce_3: 5.688e-05  loss_mask_3: 0.1115  loss_dice_3: 0.1607  loss_ce_4: 6.989e-05  loss_mask_4: 0.1061  loss_dice_4: 0.1618  loss_ce_5: 0.0001079  loss_mask_5: 0.1078  loss_dice_5: 0.1599  loss_ce_6: 4.513e-05  loss_mask_6: 0.1114  loss_dice_6: 0.1694  loss_ce_7: 8.105e-05  loss_mask_7: 0.1111  loss_dice_7: 0.1638  loss_ce_8: 0.0001107  loss_mask_8: 0.1094  loss_dice_8: 0.1623  time: 0.5813  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:07:36] d2.utils.events INFO:  eta: 0:33:33  iter: 26199  total_loss: 2.954  loss_ce: 5.409e-05  loss_mask: 0.1155  loss_dice: 0.1727  loss_ce_0: 0.1232  loss_mask_0: 0.1149  loss_dice_0: 0.1707  loss_ce_1: 9.754e-05  loss_mask_1: 0.1124  loss_dice_1: 0.1702  loss_ce_2: 0.0001046  loss_mask_2: 0.1126  loss_dice_2: 0.1695  loss_ce_3: 3.748e-05  loss_mask_3: 0.1103  loss_dice_3: 0.1681  loss_ce_4: 6.576e-05  loss_mask_4: 0.111  loss_dice_4: 0.1684  loss_ce_5: 7.84e-05  loss_mask_5: 0.1108  loss_dice_5: 0.1648  loss_ce_6: 3.881e-05  loss_mask_6: 0.1116  loss_dice_6: 0.1672  loss_ce_7: 7.477e-05  loss_mask_7: 0.1127  loss_dice_7: 0.1758  loss_ce_8: 9.218e-05  loss_mask_8: 0.1103  loss_dice_8: 0.1657  time: 0.5811  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:07:41] d2.utils.events INFO:  eta: 0:33:28  iter: 26219  total_loss: 2.812  loss_ce: 5.553e-05  loss_mask: 0.1125  loss_dice: 0.17  loss_ce_0: 0.123  loss_mask_0: 0.1083  loss_dice_0: 0.167  loss_ce_1: 7.376e-05  loss_mask_1: 0.105  loss_dice_1: 0.1594  loss_ce_2: 8.033e-05  loss_mask_2: 0.1117  loss_dice_2: 0.168  loss_ce_3: 3.988e-05  loss_mask_3: 0.108  loss_dice_3: 0.1629  loss_ce_4: 3.994e-05  loss_mask_4: 0.1079  loss_dice_4: 0.1646  loss_ce_5: 5.798e-05  loss_mask_5: 0.1068  loss_dice_5: 0.1632  loss_ce_6: 3.679e-05  loss_mask_6: 0.1105  loss_dice_6: 0.162  loss_ce_7: 6.628e-05  loss_mask_7: 0.1075  loss_dice_7: 0.1638  loss_ce_8: 6.747e-05  loss_mask_8: 0.113  loss_dice_8: 0.1601  time: 0.5808  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:07:45] d2.utils.events INFO:  eta: 0:33:23  iter: 26239  total_loss: 2.805  loss_ce: 5.693e-05  loss_mask: 0.1066  loss_dice: 0.1602  loss_ce_0: 0.1281  loss_mask_0: 0.1053  loss_dice_0: 0.1596  loss_ce_1: 9.676e-05  loss_mask_1: 0.1069  loss_dice_1: 0.1589  loss_ce_2: 9.735e-05  loss_mask_2: 0.1111  loss_dice_2: 0.1628  loss_ce_3: 4.39e-05  loss_mask_3: 0.1112  loss_dice_3: 0.1588  loss_ce_4: 6.452e-05  loss_mask_4: 0.1067  loss_dice_4: 0.1551  loss_ce_5: 6.819e-05  loss_mask_5: 0.1045  loss_dice_5: 0.1602  loss_ce_6: 3.856e-05  loss_mask_6: 0.1035  loss_dice_6: 0.1623  loss_ce_7: 7.648e-05  loss_mask_7: 0.1058  loss_dice_7: 0.1617  loss_ce_8: 7.176e-05  loss_mask_8: 0.1081  loss_dice_8: 0.1643  time: 0.5805  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:07:50] d2.utils.events INFO:  eta: 0:33:19  iter: 26259  total_loss: 2.876  loss_ce: 5.502e-05  loss_mask: 0.1135  loss_dice: 0.1649  loss_ce_0: 0.1183  loss_mask_0: 0.1096  loss_dice_0: 0.1661  loss_ce_1: 0.0001065  loss_mask_1: 0.1121  loss_dice_1: 0.165  loss_ce_2: 0.0001201  loss_mask_2: 0.1164  loss_dice_2: 0.1664  loss_ce_3: 3.832e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1645  loss_ce_4: 6.649e-05  loss_mask_4: 0.1104  loss_dice_4: 0.168  loss_ce_5: 0.0001062  loss_mask_5: 0.1139  loss_dice_5: 0.1665  loss_ce_6: 3.501e-05  loss_mask_6: 0.1134  loss_dice_6: 0.1662  loss_ce_7: 7.956e-05  loss_mask_7: 0.1136  loss_dice_7: 0.1662  loss_ce_8: 0.0001113  loss_mask_8: 0.1091  loss_dice_8: 0.1655  time: 0.5803  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:07:54] d2.utils.events INFO:  eta: 0:33:14  iter: 26279  total_loss: 2.897  loss_ce: 5.486e-05  loss_mask: 0.1141  loss_dice: 0.1651  loss_ce_0: 0.1131  loss_mask_0: 0.1132  loss_dice_0: 0.1647  loss_ce_1: 0.0001026  loss_mask_1: 0.1143  loss_dice_1: 0.1704  loss_ce_2: 0.0001181  loss_mask_2: 0.1106  loss_dice_2: 0.1654  loss_ce_3: 4.692e-05  loss_mask_3: 0.1135  loss_dice_3: 0.1659  loss_ce_4: 6.368e-05  loss_mask_4: 0.1152  loss_dice_4: 0.1664  loss_ce_5: 6.817e-05  loss_mask_5: 0.1143  loss_dice_5: 0.1684  loss_ce_6: 3.892e-05  loss_mask_6: 0.1108  loss_dice_6: 0.162  loss_ce_7: 7.515e-05  loss_mask_7: 0.11  loss_dice_7: 0.1653  loss_ce_8: 7.474e-05  loss_mask_8: 0.1146  loss_dice_8: 0.1695  time: 0.5800  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:07:59] d2.utils.events INFO:  eta: 0:33:10  iter: 26299  total_loss: 2.763  loss_ce: 5.159e-05  loss_mask: 0.1026  loss_dice: 0.1599  loss_ce_0: 0.1218  loss_mask_0: 0.1043  loss_dice_0: 0.1645  loss_ce_1: 8.257e-05  loss_mask_1: 0.1052  loss_dice_1: 0.161  loss_ce_2: 8.773e-05  loss_mask_2: 0.1052  loss_dice_2: 0.1576  loss_ce_3: 3.574e-05  loss_mask_3: 0.1033  loss_dice_3: 0.1592  loss_ce_4: 5.397e-05  loss_mask_4: 0.1056  loss_dice_4: 0.1614  loss_ce_5: 6.065e-05  loss_mask_5: 0.1047  loss_dice_5: 0.1603  loss_ce_6: 3.796e-05  loss_mask_6: 0.1047  loss_dice_6: 0.1624  loss_ce_7: 6.841e-05  loss_mask_7: 0.1044  loss_dice_7: 0.1634  loss_ce_8: 6.825e-05  loss_mask_8: 0.1067  loss_dice_8: 0.1615  time: 0.5797  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:08:04] d2.utils.events INFO:  eta: 0:33:05  iter: 26319  total_loss: 2.976  loss_ce: 5.365e-05  loss_mask: 0.11  loss_dice: 0.1698  loss_ce_0: 0.1212  loss_mask_0: 0.1127  loss_dice_0: 0.1789  loss_ce_1: 9.693e-05  loss_mask_1: 0.1124  loss_dice_1: 0.1676  loss_ce_2: 0.0001172  loss_mask_2: 0.1095  loss_dice_2: 0.1712  loss_ce_3: 3.727e-05  loss_mask_3: 0.1117  loss_dice_3: 0.1778  loss_ce_4: 6.663e-05  loss_mask_4: 0.1094  loss_dice_4: 0.1691  loss_ce_5: 9.265e-05  loss_mask_5: 0.1124  loss_dice_5: 0.173  loss_ce_6: 3.853e-05  loss_mask_6: 0.1103  loss_dice_6: 0.1742  loss_ce_7: 7.675e-05  loss_mask_7: 0.1121  loss_dice_7: 0.1722  loss_ce_8: 9.028e-05  loss_mask_8: 0.112  loss_dice_8: 0.1703  time: 0.5795  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:08:08] d2.utils.events INFO:  eta: 0:33:01  iter: 26339  total_loss: 2.975  loss_ce: 5.637e-05  loss_mask: 0.1114  loss_dice: 0.1725  loss_ce_0: 0.1248  loss_mask_0: 0.1086  loss_dice_0: 0.1639  loss_ce_1: 8.899e-05  loss_mask_1: 0.1094  loss_dice_1: 0.1721  loss_ce_2: 0.0001036  loss_mask_2: 0.1081  loss_dice_2: 0.167  loss_ce_3: 4.812e-05  loss_mask_3: 0.1092  loss_dice_3: 0.1726  loss_ce_4: 6.533e-05  loss_mask_4: 0.1115  loss_dice_4: 0.1703  loss_ce_5: 7.644e-05  loss_mask_5: 0.1124  loss_dice_5: 0.1744  loss_ce_6: 4.047e-05  loss_mask_6: 0.1101  loss_dice_6: 0.1721  loss_ce_7: 7.385e-05  loss_mask_7: 0.1132  loss_dice_7: 0.1729  loss_ce_8: 8.424e-05  loss_mask_8: 0.1107  loss_dice_8: 0.1675  time: 0.5792  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:08:13] d2.utils.events INFO:  eta: 0:32:57  iter: 26359  total_loss: 2.971  loss_ce: 5.597e-05  loss_mask: 0.1138  loss_dice: 0.1669  loss_ce_0: 0.1211  loss_mask_0: 0.1101  loss_dice_0: 0.1707  loss_ce_1: 0.000102  loss_mask_1: 0.1141  loss_dice_1: 0.1649  loss_ce_2: 0.0001176  loss_mask_2: 0.1105  loss_dice_2: 0.1695  loss_ce_3: 4.625e-05  loss_mask_3: 0.1112  loss_dice_3: 0.1713  loss_ce_4: 6.435e-05  loss_mask_4: 0.1089  loss_dice_4: 0.1705  loss_ce_5: 8.907e-05  loss_mask_5: 0.1175  loss_dice_5: 0.1727  loss_ce_6: 3.907e-05  loss_mask_6: 0.1126  loss_dice_6: 0.1691  loss_ce_7: 7.588e-05  loss_mask_7: 0.1117  loss_dice_7: 0.1703  loss_ce_8: 0.0001024  loss_mask_8: 0.1127  loss_dice_8: 0.1722  time: 0.5789  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:08:17] d2.utils.events INFO:  eta: 0:32:53  iter: 26379  total_loss: 2.798  loss_ce: 5.525e-05  loss_mask: 0.1064  loss_dice: 0.1633  loss_ce_0: 0.1164  loss_mask_0: 0.1051  loss_dice_0: 0.1648  loss_ce_1: 9.485e-05  loss_mask_1: 0.1082  loss_dice_1: 0.1644  loss_ce_2: 0.000114  loss_mask_2: 0.1072  loss_dice_2: 0.1613  loss_ce_3: 7.268e-05  loss_mask_3: 0.1095  loss_dice_3: 0.1631  loss_ce_4: 6.304e-05  loss_mask_4: 0.1069  loss_dice_4: 0.1633  loss_ce_5: 6.698e-05  loss_mask_5: 0.1058  loss_dice_5: 0.162  loss_ce_6: 4.711e-05  loss_mask_6: 0.107  loss_dice_6: 0.1644  loss_ce_7: 7.759e-05  loss_mask_7: 0.1036  loss_dice_7: 0.1609  loss_ce_8: 7.126e-05  loss_mask_8: 0.1055  loss_dice_8: 0.1623  time: 0.5787  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:08:22] d2.utils.events INFO:  eta: 0:32:49  iter: 26399  total_loss: 2.985  loss_ce: 5.231e-05  loss_mask: 0.1144  loss_dice: 0.176  loss_ce_0: 0.1212  loss_mask_0: 0.1164  loss_dice_0: 0.1824  loss_ce_1: 8.736e-05  loss_mask_1: 0.1177  loss_dice_1: 0.1711  loss_ce_2: 0.0001039  loss_mask_2: 0.116  loss_dice_2: 0.1735  loss_ce_3: 3.399e-05  loss_mask_3: 0.1168  loss_dice_3: 0.1696  loss_ce_4: 6.201e-05  loss_mask_4: 0.1165  loss_dice_4: 0.173  loss_ce_5: 6.688e-05  loss_mask_5: 0.1159  loss_dice_5: 0.1773  loss_ce_6: 3.469e-05  loss_mask_6: 0.1133  loss_dice_6: 0.1778  loss_ce_7: 7.236e-05  loss_mask_7: 0.114  loss_dice_7: 0.177  loss_ce_8: 6.889e-05  loss_mask_8: 0.1133  loss_dice_8: 0.1774  time: 0.5784  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:08:26] d2.utils.events INFO:  eta: 0:32:45  iter: 26419  total_loss: 2.938  loss_ce: 4.971e-05  loss_mask: 0.1161  loss_dice: 0.1668  loss_ce_0: 0.1209  loss_mask_0: 0.1128  loss_dice_0: 0.1715  loss_ce_1: 7.974e-05  loss_mask_1: 0.1107  loss_dice_1: 0.1724  loss_ce_2: 8.289e-05  loss_mask_2: 0.1127  loss_dice_2: 0.1694  loss_ce_3: 3.729e-05  loss_mask_3: 0.1117  loss_dice_3: 0.1669  loss_ce_4: 4.874e-05  loss_mask_4: 0.1124  loss_dice_4: 0.1661  loss_ce_5: 5.941e-05  loss_mask_5: 0.1101  loss_dice_5: 0.1661  loss_ce_6: 3.714e-05  loss_mask_6: 0.1134  loss_dice_6: 0.1725  loss_ce_7: 6.628e-05  loss_mask_7: 0.1125  loss_dice_7: 0.1675  loss_ce_8: 7.057e-05  loss_mask_8: 0.1121  loss_dice_8: 0.1684  time: 0.5781  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:08:31] d2.utils.events INFO:  eta: 0:32:39  iter: 26439  total_loss: 2.766  loss_ce: 5.289e-05  loss_mask: 0.1028  loss_dice: 0.1583  loss_ce_0: 0.1279  loss_mask_0: 0.1043  loss_dice_0: 0.164  loss_ce_1: 9.674e-05  loss_mask_1: 0.1053  loss_dice_1: 0.1641  loss_ce_2: 9.471e-05  loss_mask_2: 0.107  loss_dice_2: 0.1627  loss_ce_3: 4.658e-05  loss_mask_3: 0.1057  loss_dice_3: 0.1585  loss_ce_4: 6.268e-05  loss_mask_4: 0.1044  loss_dice_4: 0.155  loss_ce_5: 8.837e-05  loss_mask_5: 0.1018  loss_dice_5: 0.1592  loss_ce_6: 3.935e-05  loss_mask_6: 0.1048  loss_dice_6: 0.1615  loss_ce_7: 7.558e-05  loss_mask_7: 0.1053  loss_dice_7: 0.1599  loss_ce_8: 0.0001063  loss_mask_8: 0.1047  loss_dice_8: 0.1669  time: 0.5779  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:08:35] d2.utils.events INFO:  eta: 0:32:35  iter: 26459  total_loss: 2.962  loss_ce: 5.891e-05  loss_mask: 0.1173  loss_dice: 0.1658  loss_ce_0: 0.122  loss_mask_0: 0.1157  loss_dice_0: 0.1666  loss_ce_1: 0.0001023  loss_mask_1: 0.1173  loss_dice_1: 0.1688  loss_ce_2: 0.0001176  loss_mask_2: 0.1113  loss_dice_2: 0.1694  loss_ce_3: 5.477e-05  loss_mask_3: 0.1236  loss_dice_3: 0.1727  loss_ce_4: 6.781e-05  loss_mask_4: 0.1163  loss_dice_4: 0.1686  loss_ce_5: 0.0001185  loss_mask_5: 0.1152  loss_dice_5: 0.1719  loss_ce_6: 4.086e-05  loss_mask_6: 0.1152  loss_dice_6: 0.1707  loss_ce_7: 7.623e-05  loss_mask_7: 0.1157  loss_dice_7: 0.1663  loss_ce_8: 0.0001044  loss_mask_8: 0.1137  loss_dice_8: 0.1663  time: 0.5776  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:08:40] d2.utils.events INFO:  eta: 0:32:29  iter: 26479  total_loss: 2.735  loss_ce: 5.841e-05  loss_mask: 0.1082  loss_dice: 0.1521  loss_ce_0: 0.1286  loss_mask_0: 0.1055  loss_dice_0: 0.1576  loss_ce_1: 9.424e-05  loss_mask_1: 0.1088  loss_dice_1: 0.1554  loss_ce_2: 9.046e-05  loss_mask_2: 0.106  loss_dice_2: 0.1514  loss_ce_3: 4.654e-05  loss_mask_3: 0.1041  loss_dice_3: 0.1515  loss_ce_4: 6.075e-05  loss_mask_4: 0.1058  loss_dice_4: 0.1569  loss_ce_5: 7.392e-05  loss_mask_5: 0.1046  loss_dice_5: 0.1499  loss_ce_6: 4.025e-05  loss_mask_6: 0.1048  loss_dice_6: 0.1517  loss_ce_7: 6.913e-05  loss_mask_7: 0.1081  loss_dice_7: 0.1572  loss_ce_8: 8.308e-05  loss_mask_8: 0.1053  loss_dice_8: 0.1565  time: 0.5773  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:08:44] d2.utils.events INFO:  eta: 0:32:24  iter: 26499  total_loss: 2.743  loss_ce: 6.692e-05  loss_mask: 0.1083  loss_dice: 0.158  loss_ce_0: 0.123  loss_mask_0: 0.1024  loss_dice_0: 0.156  loss_ce_1: 9.148e-05  loss_mask_1: 0.1052  loss_dice_1: 0.1599  loss_ce_2: 0.0001118  loss_mask_2: 0.1069  loss_dice_2: 0.1629  loss_ce_3: 7.578e-05  loss_mask_3: 0.1038  loss_dice_3: 0.1585  loss_ce_4: 6.55e-05  loss_mask_4: 0.1035  loss_dice_4: 0.1583  loss_ce_5: 8.633e-05  loss_mask_5: 0.102  loss_dice_5: 0.1583  loss_ce_6: 4.884e-05  loss_mask_6: 0.1034  loss_dice_6: 0.157  loss_ce_7: 7.564e-05  loss_mask_7: 0.1065  loss_dice_7: 0.1595  loss_ce_8: 9.945e-05  loss_mask_8: 0.1069  loss_dice_8: 0.1579  time: 0.5771  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:08:48] d2.utils.events INFO:  eta: 0:32:13  iter: 26519  total_loss: 2.804  loss_ce: 5.156e-05  loss_mask: 0.1074  loss_dice: 0.1556  loss_ce_0: 0.1231  loss_mask_0: 0.1071  loss_dice_0: 0.1602  loss_ce_1: 8.787e-05  loss_mask_1: 0.1086  loss_dice_1: 0.1645  loss_ce_2: 8.969e-05  loss_mask_2: 0.1136  loss_dice_2: 0.1594  loss_ce_3: 4.618e-05  loss_mask_3: 0.1096  loss_dice_3: 0.156  loss_ce_4: 5.695e-05  loss_mask_4: 0.1122  loss_dice_4: 0.1602  loss_ce_5: 6.423e-05  loss_mask_5: 0.1077  loss_dice_5: 0.1603  loss_ce_6: 3.941e-05  loss_mask_6: 0.107  loss_dice_6: 0.1577  loss_ce_7: 7.257e-05  loss_mask_7: 0.106  loss_dice_7: 0.1557  loss_ce_8: 6.772e-05  loss_mask_8: 0.1085  loss_dice_8: 0.1568  time: 0.5768  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:08:52] d2.utils.events INFO:  eta: 0:32:04  iter: 26539  total_loss: 2.747  loss_ce: 5.22e-05  loss_mask: 0.1031  loss_dice: 0.1549  loss_ce_0: 0.1231  loss_mask_0: 0.1058  loss_dice_0: 0.1683  loss_ce_1: 6.616e-05  loss_mask_1: 0.1075  loss_dice_1: 0.1654  loss_ce_2: 7.361e-05  loss_mask_2: 0.1042  loss_dice_2: 0.1601  loss_ce_3: 3.097e-05  loss_mask_3: 0.104  loss_dice_3: 0.1568  loss_ce_4: 3.516e-05  loss_mask_4: 0.1075  loss_dice_4: 0.159  loss_ce_5: 5.76e-05  loss_mask_5: 0.104  loss_dice_5: 0.1522  loss_ce_6: 3.506e-05  loss_mask_6: 0.1036  loss_dice_6: 0.1542  loss_ce_7: 6.074e-05  loss_mask_7: 0.1053  loss_dice_7: 0.1559  loss_ce_8: 6.399e-05  loss_mask_8: 0.1056  loss_dice_8: 0.1627  time: 0.5765  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:08:55] d2.utils.events INFO:  eta: 0:31:54  iter: 26559  total_loss: 2.795  loss_ce: 5.208e-05  loss_mask: 0.1086  loss_dice: 0.1625  loss_ce_0: 0.1227  loss_mask_0: 0.1105  loss_dice_0: 0.164  loss_ce_1: 6.648e-05  loss_mask_1: 0.1072  loss_dice_1: 0.1626  loss_ce_2: 7.322e-05  loss_mask_2: 0.1062  loss_dice_2: 0.1602  loss_ce_3: 3.733e-05  loss_mask_3: 0.1081  loss_dice_3: 0.1654  loss_ce_4: 3.543e-05  loss_mask_4: 0.1056  loss_dice_4: 0.1592  loss_ce_5: 5.211e-05  loss_mask_5: 0.1076  loss_dice_5: 0.1588  loss_ce_6: 3.745e-05  loss_mask_6: 0.1053  loss_dice_6: 0.1612  loss_ce_7: 5.998e-05  loss_mask_7: 0.107  loss_dice_7: 0.1601  loss_ce_8: 6.426e-05  loss_mask_8: 0.106  loss_dice_8: 0.1648  time: 0.5762  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:08:59] d2.utils.events INFO:  eta: 0:31:36  iter: 26579  total_loss: 2.784  loss_ce: 5.633e-05  loss_mask: 0.1117  loss_dice: 0.161  loss_ce_0: 0.1238  loss_mask_0: 0.1051  loss_dice_0: 0.1599  loss_ce_1: 8.037e-05  loss_mask_1: 0.1097  loss_dice_1: 0.1621  loss_ce_2: 9.948e-05  loss_mask_2: 0.107  loss_dice_2: 0.1576  loss_ce_3: 6.25e-05  loss_mask_3: 0.107  loss_dice_3: 0.1609  loss_ce_4: 5.921e-05  loss_mask_4: 0.107  loss_dice_4: 0.1597  loss_ce_5: 6.357e-05  loss_mask_5: 0.1103  loss_dice_5: 0.1622  loss_ce_6: 4.459e-05  loss_mask_6: 0.1092  loss_dice_6: 0.1643  loss_ce_7: 6.859e-05  loss_mask_7: 0.1119  loss_dice_7: 0.161  loss_ce_8: 6.826e-05  loss_mask_8: 0.1057  loss_dice_8: 0.1602  time: 0.5759  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:09:02] d2.utils.events INFO:  eta: 0:31:23  iter: 26599  total_loss: 2.821  loss_ce: 5.346e-05  loss_mask: 0.1102  loss_dice: 0.1621  loss_ce_0: 0.1225  loss_mask_0: 0.109  loss_dice_0: 0.1572  loss_ce_1: 9.097e-05  loss_mask_1: 0.1103  loss_dice_1: 0.159  loss_ce_2: 0.0001103  loss_mask_2: 0.1069  loss_dice_2: 0.1579  loss_ce_3: 6.639e-05  loss_mask_3: 0.1132  loss_dice_3: 0.1683  loss_ce_4: 6.221e-05  loss_mask_4: 0.1068  loss_dice_4: 0.1597  loss_ce_5: 7.283e-05  loss_mask_5: 0.1089  loss_dice_5: 0.1581  loss_ce_6: 4.287e-05  loss_mask_6: 0.1114  loss_dice_6: 0.1604  loss_ce_7: 6.972e-05  loss_mask_7: 0.1149  loss_dice_7: 0.1647  loss_ce_8: 8.068e-05  loss_mask_8: 0.1134  loss_dice_8: 0.1583  time: 0.5756  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:09:06] d2.utils.events INFO:  eta: 0:31:12  iter: 26619  total_loss: 2.778  loss_ce: 5.024e-05  loss_mask: 0.1089  loss_dice: 0.1635  loss_ce_0: 0.1227  loss_mask_0: 0.108  loss_dice_0: 0.1597  loss_ce_1: 9.611e-05  loss_mask_1: 0.1042  loss_dice_1: 0.1599  loss_ce_2: 9.299e-05  loss_mask_2: 0.1075  loss_dice_2: 0.1636  loss_ce_3: 4.4e-05  loss_mask_3: 0.1089  loss_dice_3: 0.1589  loss_ce_4: 6.1e-05  loss_mask_4: 0.1091  loss_dice_4: 0.1623  loss_ce_5: 7.356e-05  loss_mask_5: 0.1073  loss_dice_5: 0.1589  loss_ce_6: 3.793e-05  loss_mask_6: 0.1066  loss_dice_6: 0.1583  loss_ce_7: 7.093e-05  loss_mask_7: 0.1116  loss_dice_7: 0.1629  loss_ce_8: 8.896e-05  loss_mask_8: 0.1098  loss_dice_8: 0.1626  time: 0.5753  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:09:10] d2.utils.events INFO:  eta: 0:30:56  iter: 26639  total_loss: 2.821  loss_ce: 5.14e-05  loss_mask: 0.107  loss_dice: 0.1646  loss_ce_0: 0.123  loss_mask_0: 0.1105  loss_dice_0: 0.1653  loss_ce_1: 8.842e-05  loss_mask_1: 0.1086  loss_dice_1: 0.1608  loss_ce_2: 0.0001063  loss_mask_2: 0.1089  loss_dice_2: 0.1608  loss_ce_3: 5.777e-05  loss_mask_3: 0.111  loss_dice_3: 0.1634  loss_ce_4: 6.186e-05  loss_mask_4: 0.1068  loss_dice_4: 0.1646  loss_ce_5: 7.379e-05  loss_mask_5: 0.1109  loss_dice_5: 0.1591  loss_ce_6: 4.101e-05  loss_mask_6: 0.1069  loss_dice_6: 0.1621  loss_ce_7: 6.997e-05  loss_mask_7: 0.1093  loss_dice_7: 0.1645  loss_ce_8: 8.107e-05  loss_mask_8: 0.1066  loss_dice_8: 0.1716  time: 0.5750  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:09:13] d2.utils.events INFO:  eta: 0:30:42  iter: 26659  total_loss: 2.845  loss_ce: 5.517e-05  loss_mask: 0.1112  loss_dice: 0.1665  loss_ce_0: 0.1236  loss_mask_0: 0.1041  loss_dice_0: 0.1662  loss_ce_1: 0.0001001  loss_mask_1: 0.1082  loss_dice_1: 0.1596  loss_ce_2: 0.000108  loss_mask_2: 0.1086  loss_dice_2: 0.1662  loss_ce_3: 5.296e-05  loss_mask_3: 0.1088  loss_dice_3: 0.1615  loss_ce_4: 5.999e-05  loss_mask_4: 0.1072  loss_dice_4: 0.1623  loss_ce_5: 7.386e-05  loss_mask_5: 0.109  loss_dice_5: 0.1625  loss_ce_6: 4.274e-05  loss_mask_6: 0.1069  loss_dice_6: 0.1627  loss_ce_7: 7.508e-05  loss_mask_7: 0.1071  loss_dice_7: 0.163  loss_ce_8: 8.143e-05  loss_mask_8: 0.1067  loss_dice_8: 0.1633  time: 0.5747  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:09:17] d2.utils.events INFO:  eta: 0:30:30  iter: 26679  total_loss: 2.757  loss_ce: 5.139e-05  loss_mask: 0.1044  loss_dice: 0.1643  loss_ce_0: 0.1236  loss_mask_0: 0.1077  loss_dice_0: 0.162  loss_ce_1: 7.69e-05  loss_mask_1: 0.1023  loss_dice_1: 0.1608  loss_ce_2: 8.948e-05  loss_mask_2: 0.1066  loss_dice_2: 0.1653  loss_ce_3: 4.889e-05  loss_mask_3: 0.1115  loss_dice_3: 0.166  loss_ce_4: 5.842e-05  loss_mask_4: 0.1062  loss_dice_4: 0.1595  loss_ce_5: 6.251e-05  loss_mask_5: 0.1079  loss_dice_5: 0.1636  loss_ce_6: 3.757e-05  loss_mask_6: 0.103  loss_dice_6: 0.1591  loss_ce_7: 6.608e-05  loss_mask_7: 0.1051  loss_dice_7: 0.1615  loss_ce_8: 6.676e-05  loss_mask_8: 0.1042  loss_dice_8: 0.1619  time: 0.5744  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:09:20] d2.utils.events INFO:  eta: 0:30:17  iter: 26699  total_loss: 2.797  loss_ce: 4.746e-05  loss_mask: 0.111  loss_dice: 0.1554  loss_ce_0: 0.1239  loss_mask_0: 0.114  loss_dice_0: 0.1605  loss_ce_1: 9.109e-05  loss_mask_1: 0.1138  loss_dice_1: 0.1563  loss_ce_2: 8.68e-05  loss_mask_2: 0.1133  loss_dice_2: 0.1619  loss_ce_3: 3.526e-05  loss_mask_3: 0.1131  loss_dice_3: 0.1605  loss_ce_4: 5.887e-05  loss_mask_4: 0.1115  loss_dice_4: 0.153  loss_ce_5: 8.068e-05  loss_mask_5: 0.112  loss_dice_5: 0.1536  loss_ce_6: 3.237e-05  loss_mask_6: 0.1121  loss_dice_6: 0.1525  loss_ce_7: 6.921e-05  loss_mask_7: 0.1142  loss_dice_7: 0.1562  loss_ce_8: 9.757e-05  loss_mask_8: 0.1111  loss_dice_8: 0.1494  time: 0.5741  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:09:24] d2.utils.events INFO:  eta: 0:30:04  iter: 26719  total_loss: 2.845  loss_ce: 5.165e-05  loss_mask: 0.1085  loss_dice: 0.1608  loss_ce_0: 0.1228  loss_mask_0: 0.1103  loss_dice_0: 0.1617  loss_ce_1: 8.215e-05  loss_mask_1: 0.1082  loss_dice_1: 0.1654  loss_ce_2: 0.0001063  loss_mask_2: 0.1075  loss_dice_2: 0.1578  loss_ce_3: 4.564e-05  loss_mask_3: 0.1094  loss_dice_3: 0.1606  loss_ce_4: 5.75e-05  loss_mask_4: 0.1056  loss_dice_4: 0.1572  loss_ce_5: 6.19e-05  loss_mask_5: 0.1085  loss_dice_5: 0.1615  loss_ce_6: 3.99e-05  loss_mask_6: 0.1105  loss_dice_6: 0.1627  loss_ce_7: 6.932e-05  loss_mask_7: 0.1133  loss_dice_7: 0.1656  loss_ce_8: 6.559e-05  loss_mask_8: 0.1137  loss_dice_8: 0.1689  time: 0.5738  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:09:28] d2.utils.events INFO:  eta: 0:29:49  iter: 26739  total_loss: 2.678  loss_ce: 5.059e-05  loss_mask: 0.1031  loss_dice: 0.1539  loss_ce_0: 0.1236  loss_mask_0: 0.1019  loss_dice_0: 0.1557  loss_ce_1: 7.997e-05  loss_mask_1: 0.09831  loss_dice_1: 0.1562  loss_ce_2: 7.972e-05  loss_mask_2: 0.1054  loss_dice_2: 0.1566  loss_ce_3: 3.509e-05  loss_mask_3: 0.1036  loss_dice_3: 0.1579  loss_ce_4: 4.908e-05  loss_mask_4: 0.1038  loss_dice_4: 0.1571  loss_ce_5: 5.897e-05  loss_mask_5: 0.1054  loss_dice_5: 0.156  loss_ce_6: 3.559e-05  loss_mask_6: 0.1042  loss_dice_6: 0.1565  loss_ce_7: 7.057e-05  loss_mask_7: 0.1037  loss_dice_7: 0.1546  loss_ce_8: 6.449e-05  loss_mask_8: 0.1035  loss_dice_8: 0.1564  time: 0.5735  data_time: 0.0010  lr: 1e-05  max_mem: 8444M
[08/01 22:09:31] d2.utils.events INFO:  eta: 0:29:42  iter: 26759  total_loss: 2.788  loss_ce: 5.894e-05  loss_mask: 0.1067  loss_dice: 0.1606  loss_ce_0: 0.1232  loss_mask_0: 0.1089  loss_dice_0: 0.1676  loss_ce_1: 7.16e-05  loss_mask_1: 0.108  loss_dice_1: 0.1619  loss_ce_2: 7.855e-05  loss_mask_2: 0.1091  loss_dice_2: 0.1703  loss_ce_3: 5.377e-05  loss_mask_3: 0.1102  loss_dice_3: 0.1669  loss_ce_4: 5.614e-05  loss_mask_4: 0.1078  loss_dice_4: 0.1583  loss_ce_5: 5.836e-05  loss_mask_5: 0.1091  loss_dice_5: 0.1628  loss_ce_6: 4.185e-05  loss_mask_6: 0.1088  loss_dice_6: 0.1622  loss_ce_7: 6.546e-05  loss_mask_7: 0.1081  loss_dice_7: 0.1607  loss_ce_8: 6.711e-05  loss_mask_8: 0.1097  loss_dice_8: 0.1704  time: 0.5732  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:09:35] d2.utils.events INFO:  eta: 0:29:33  iter: 26779  total_loss: 2.81  loss_ce: 6.513e-05  loss_mask: 0.1086  loss_dice: 0.1612  loss_ce_0: 0.1229  loss_mask_0: 0.1069  loss_dice_0: 0.1596  loss_ce_1: 9.478e-05  loss_mask_1: 0.1066  loss_dice_1: 0.1631  loss_ce_2: 0.0001109  loss_mask_2: 0.1069  loss_dice_2: 0.1599  loss_ce_3: 7.454e-05  loss_mask_3: 0.1081  loss_dice_3: 0.1635  loss_ce_4: 7.297e-05  loss_mask_4: 0.1058  loss_dice_4: 0.1614  loss_ce_5: 7.009e-05  loss_mask_5: 0.1094  loss_dice_5: 0.1599  loss_ce_6: 4.933e-05  loss_mask_6: 0.1076  loss_dice_6: 0.163  loss_ce_7: 8.208e-05  loss_mask_7: 0.1063  loss_dice_7: 0.1625  loss_ce_8: 7.362e-05  loss_mask_8: 0.1086  loss_dice_8: 0.1623  time: 0.5729  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:09:38] d2.utils.events INFO:  eta: 0:29:22  iter: 26799  total_loss: 2.802  loss_ce: 5.166e-05  loss_mask: 0.1123  loss_dice: 0.1685  loss_ce_0: 0.1229  loss_mask_0: 0.111  loss_dice_0: 0.1683  loss_ce_1: 6.336e-05  loss_mask_1: 0.1108  loss_dice_1: 0.1626  loss_ce_2: 7.052e-05  loss_mask_2: 0.1105  loss_dice_2: 0.1619  loss_ce_3: 3.37e-05  loss_mask_3: 0.1114  loss_dice_3: 0.163  loss_ce_4: 4.043e-05  loss_mask_4: 0.1102  loss_dice_4: 0.1641  loss_ce_5: 5.203e-05  loss_mask_5: 0.1109  loss_dice_5: 0.1579  loss_ce_6: 3.349e-05  loss_mask_6: 0.1134  loss_dice_6: 0.1612  loss_ce_7: 6.17e-05  loss_mask_7: 0.112  loss_dice_7: 0.1623  loss_ce_8: 5.918e-05  loss_mask_8: 0.1128  loss_dice_8: 0.1622  time: 0.5726  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:09:42] d2.utils.events INFO:  eta: 0:29:12  iter: 26819  total_loss: 3.097  loss_ce: 5.52e-05  loss_mask: 0.1201  loss_dice: 0.1816  loss_ce_0: 0.1224  loss_mask_0: 0.1189  loss_dice_0: 0.1818  loss_ce_1: 9.111e-05  loss_mask_1: 0.1195  loss_dice_1: 0.1795  loss_ce_2: 9.025e-05  loss_mask_2: 0.1093  loss_dice_2: 0.1743  loss_ce_3: 5.355e-05  loss_mask_3: 0.1137  loss_dice_3: 0.181  loss_ce_4: 6.748e-05  loss_mask_4: 0.1154  loss_dice_4: 0.1734  loss_ce_5: 6.849e-05  loss_mask_5: 0.1177  loss_dice_5: 0.1796  loss_ce_6: 4.441e-05  loss_mask_6: 0.1156  loss_dice_6: 0.1757  loss_ce_7: 7.562e-05  loss_mask_7: 0.1162  loss_dice_7: 0.1819  loss_ce_8: 7.307e-05  loss_mask_8: 0.1181  loss_dice_8: 0.1821  time: 0.5723  data_time: 0.0014  lr: 1e-05  max_mem: 8444M
[08/01 22:09:46] d2.utils.events INFO:  eta: 0:29:00  iter: 26839  total_loss: 2.947  loss_ce: 5.795e-05  loss_mask: 0.1128  loss_dice: 0.1596  loss_ce_0: 0.1222  loss_mask_0: 0.1157  loss_dice_0: 0.1686  loss_ce_1: 8.698e-05  loss_mask_1: 0.1082  loss_dice_1: 0.1623  loss_ce_2: 8.768e-05  loss_mask_2: 0.1135  loss_dice_2: 0.1661  loss_ce_3: 4.717e-05  loss_mask_3: 0.1106  loss_dice_3: 0.1621  loss_ce_4: 6.704e-05  loss_mask_4: 0.113  loss_dice_4: 0.1661  loss_ce_5: 7.558e-05  loss_mask_5: 0.1109  loss_dice_5: 0.1628  loss_ce_6: 4.548e-05  loss_mask_6: 0.1131  loss_dice_6: 0.1623  loss_ce_7: 7.269e-05  loss_mask_7: 0.1127  loss_dice_7: 0.1651  loss_ce_8: 8.195e-05  loss_mask_8: 0.1104  loss_dice_8: 0.1616  time: 0.5720  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:09:49] d2.utils.events INFO:  eta: 0:28:47  iter: 26859  total_loss: 3.036  loss_ce: 5.427e-05  loss_mask: 0.12  loss_dice: 0.1833  loss_ce_0: 0.1197  loss_mask_0: 0.1132  loss_dice_0: 0.187  loss_ce_1: 9.102e-05  loss_mask_1: 0.1127  loss_dice_1: 0.1791  loss_ce_2: 0.0001029  loss_mask_2: 0.1173  loss_dice_2: 0.1812  loss_ce_3: 4.443e-05  loss_mask_3: 0.1151  loss_dice_3: 0.1795  loss_ce_4: 7.008e-05  loss_mask_4: 0.1125  loss_dice_4: 0.1805  loss_ce_5: 6.886e-05  loss_mask_5: 0.1163  loss_dice_5: 0.1782  loss_ce_6: 4.129e-05  loss_mask_6: 0.1126  loss_dice_6: 0.1752  loss_ce_7: 7.391e-05  loss_mask_7: 0.1166  loss_dice_7: 0.1823  loss_ce_8: 7.386e-05  loss_mask_8: 0.1146  loss_dice_8: 0.1753  time: 0.5717  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:09:53] d2.utils.events INFO:  eta: 0:28:36  iter: 26879  total_loss: 2.993  loss_ce: 6.428e-05  loss_mask: 0.1119  loss_dice: 0.1695  loss_ce_0: 0.1223  loss_mask_0: 0.1149  loss_dice_0: 0.1714  loss_ce_1: 9.054e-05  loss_mask_1: 0.1147  loss_dice_1: 0.1689  loss_ce_2: 9.81e-05  loss_mask_2: 0.1133  loss_dice_2: 0.1743  loss_ce_3: 5.869e-05  loss_mask_3: 0.1145  loss_dice_3: 0.1705  loss_ce_4: 7.082e-05  loss_mask_4: 0.1149  loss_dice_4: 0.1694  loss_ce_5: 8.536e-05  loss_mask_5: 0.1172  loss_dice_5: 0.1726  loss_ce_6: 4.83e-05  loss_mask_6: 0.1112  loss_dice_6: 0.1713  loss_ce_7: 7.835e-05  loss_mask_7: 0.1142  loss_dice_7: 0.1723  loss_ce_8: 9.997e-05  loss_mask_8: 0.1138  loss_dice_8: 0.1721  time: 0.5714  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:09:56] d2.utils.events INFO:  eta: 0:28:24  iter: 26899  total_loss: 2.825  loss_ce: 4.855e-05  loss_mask: 0.1087  loss_dice: 0.1595  loss_ce_0: 0.1261  loss_mask_0: 0.1079  loss_dice_0: 0.1588  loss_ce_1: 8.712e-05  loss_mask_1: 0.1097  loss_dice_1: 0.1657  loss_ce_2: 8.452e-05  loss_mask_2: 0.1125  loss_dice_2: 0.1661  loss_ce_3: 3.945e-05  loss_mask_3: 0.1105  loss_dice_3: 0.1627  loss_ce_4: 6.302e-05  loss_mask_4: 0.111  loss_dice_4: 0.1591  loss_ce_5: 6.747e-05  loss_mask_5: 0.1135  loss_dice_5: 0.1644  loss_ce_6: 3.711e-05  loss_mask_6: 0.1092  loss_dice_6: 0.1605  loss_ce_7: 6.67e-05  loss_mask_7: 0.1103  loss_dice_7: 0.1599  loss_ce_8: 7.332e-05  loss_mask_8: 0.1127  loss_dice_8: 0.1674  time: 0.5711  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:00] d2.utils.events INFO:  eta: 0:28:05  iter: 26919  total_loss: 2.932  loss_ce: 4.914e-05  loss_mask: 0.1145  loss_dice: 0.1684  loss_ce_0: 0.1225  loss_mask_0: 0.1122  loss_dice_0: 0.1709  loss_ce_1: 7.532e-05  loss_mask_1: 0.1145  loss_dice_1: 0.1695  loss_ce_2: 7.673e-05  loss_mask_2: 0.1112  loss_dice_2: 0.164  loss_ce_3: 4.079e-05  loss_mask_3: 0.1115  loss_dice_3: 0.1654  loss_ce_4: 5.494e-05  loss_mask_4: 0.1124  loss_dice_4: 0.1691  loss_ce_5: 5.861e-05  loss_mask_5: 0.1117  loss_dice_5: 0.1707  loss_ce_6: 3.682e-05  loss_mask_6: 0.1128  loss_dice_6: 0.1664  loss_ce_7: 6.694e-05  loss_mask_7: 0.1152  loss_dice_7: 0.1729  loss_ce_8: 6.49e-05  loss_mask_8: 0.1128  loss_dice_8: 0.1694  time: 0.5708  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:03] d2.utils.events INFO:  eta: 0:27:51  iter: 26939  total_loss: 2.807  loss_ce: 5.071e-05  loss_mask: 0.1089  loss_dice: 0.1618  loss_ce_0: 0.1221  loss_mask_0: 0.1075  loss_dice_0: 0.1628  loss_ce_1: 9.522e-05  loss_mask_1: 0.1093  loss_dice_1: 0.1662  loss_ce_2: 9.038e-05  loss_mask_2: 0.1105  loss_dice_2: 0.1631  loss_ce_3: 4.442e-05  loss_mask_3: 0.1059  loss_dice_3: 0.1584  loss_ce_4: 6.614e-05  loss_mask_4: 0.1065  loss_dice_4: 0.1585  loss_ce_5: 7.758e-05  loss_mask_5: 0.1075  loss_dice_5: 0.1602  loss_ce_6: 3.87e-05  loss_mask_6: 0.1097  loss_dice_6: 0.1625  loss_ce_7: 7.797e-05  loss_mask_7: 0.1081  loss_dice_7: 0.161  loss_ce_8: 8.933e-05  loss_mask_8: 0.106  loss_dice_8: 0.157  time: 0.5705  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:10:07] d2.utils.events INFO:  eta: 0:27:39  iter: 26959  total_loss: 2.715  loss_ce: 5.374e-05  loss_mask: 0.105  loss_dice: 0.1523  loss_ce_0: 0.126  loss_mask_0: 0.1021  loss_dice_0: 0.1581  loss_ce_1: 8.794e-05  loss_mask_1: 0.1041  loss_dice_1: 0.1551  loss_ce_2: 8.732e-05  loss_mask_2: 0.104  loss_dice_2: 0.1537  loss_ce_3: 4.406e-05  loss_mask_3: 0.1034  loss_dice_3: 0.1494  loss_ce_4: 6.414e-05  loss_mask_4: 0.1056  loss_dice_4: 0.1565  loss_ce_5: 8.278e-05  loss_mask_5: 0.1059  loss_dice_5: 0.1557  loss_ce_6: 4.123e-05  loss_mask_6: 0.103  loss_dice_6: 0.1505  loss_ce_7: 7.337e-05  loss_mask_7: 0.1043  loss_dice_7: 0.1606  loss_ce_8: 9.887e-05  loss_mask_8: 0.1035  loss_dice_8: 0.1562  time: 0.5703  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:11] d2.utils.events INFO:  eta: 0:27:20  iter: 26979  total_loss: 2.848  loss_ce: 5.256e-05  loss_mask: 0.1091  loss_dice: 0.1626  loss_ce_0: 0.1228  loss_mask_0: 0.1091  loss_dice_0: 0.1646  loss_ce_1: 8.773e-05  loss_mask_1: 0.1096  loss_dice_1: 0.1593  loss_ce_2: 9.675e-05  loss_mask_2: 0.1119  loss_dice_2: 0.161  loss_ce_3: 4.85e-05  loss_mask_3: 0.1088  loss_dice_3: 0.1595  loss_ce_4: 6.381e-05  loss_mask_4: 0.1103  loss_dice_4: 0.1571  loss_ce_5: 8.201e-05  loss_mask_5: 0.1105  loss_dice_5: 0.1593  loss_ce_6: 4.02e-05  loss_mask_6: 0.1124  loss_dice_6: 0.1626  loss_ce_7: 7.314e-05  loss_mask_7: 0.1116  loss_dice_7: 0.162  loss_ce_8: 9.553e-05  loss_mask_8: 0.1133  loss_dice_8: 0.1608  time: 0.5700  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:10:14] d2.utils.events INFO:  eta: 0:27:08  iter: 26999  total_loss: 2.93  loss_ce: 5.621e-05  loss_mask: 0.1136  loss_dice: 0.1668  loss_ce_0: 0.1225  loss_mask_0: 0.1142  loss_dice_0: 0.1704  loss_ce_1: 8.181e-05  loss_mask_1: 0.116  loss_dice_1: 0.1729  loss_ce_2: 0.0001061  loss_mask_2: 0.1174  loss_dice_2: 0.1764  loss_ce_3: 4.785e-05  loss_mask_3: 0.1132  loss_dice_3: 0.166  loss_ce_4: 6.712e-05  loss_mask_4: 0.1125  loss_dice_4: 0.1648  loss_ce_5: 6.791e-05  loss_mask_5: 0.1127  loss_dice_5: 0.1694  loss_ce_6: 3.761e-05  loss_mask_6: 0.1124  loss_dice_6: 0.1703  loss_ce_7: 7.677e-05  loss_mask_7: 0.1131  loss_dice_7: 0.1673  loss_ce_8: 7.037e-05  loss_mask_8: 0.11  loss_dice_8: 0.1713  time: 0.5697  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:18] d2.utils.events INFO:  eta: 0:26:48  iter: 27019  total_loss: 2.86  loss_ce: 4.789e-05  loss_mask: 0.1069  loss_dice: 0.1579  loss_ce_0: 0.1262  loss_mask_0: 0.1149  loss_dice_0: 0.1622  loss_ce_1: 9.129e-05  loss_mask_1: 0.107  loss_dice_1: 0.1607  loss_ce_2: 0.0001078  loss_mask_2: 0.1071  loss_dice_2: 0.1565  loss_ce_3: 5.202e-05  loss_mask_3: 0.1071  loss_dice_3: 0.1538  loss_ce_4: 6.734e-05  loss_mask_4: 0.1094  loss_dice_4: 0.1578  loss_ce_5: 8.042e-05  loss_mask_5: 0.1037  loss_dice_5: 0.159  loss_ce_6: 4.15e-05  loss_mask_6: 0.1096  loss_dice_6: 0.1597  loss_ce_7: 7.366e-05  loss_mask_7: 0.1048  loss_dice_7: 0.1588  loss_ce_8: 9.166e-05  loss_mask_8: 0.109  loss_dice_8: 0.1646  time: 0.5694  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:21] d2.utils.events INFO:  eta: 0:26:31  iter: 27039  total_loss: 2.989  loss_ce: 5.294e-05  loss_mask: 0.117  loss_dice: 0.1703  loss_ce_0: 0.1231  loss_mask_0: 0.1169  loss_dice_0: 0.1754  loss_ce_1: 8.829e-05  loss_mask_1: 0.1167  loss_dice_1: 0.1764  loss_ce_2: 8.41e-05  loss_mask_2: 0.1163  loss_dice_2: 0.1689  loss_ce_3: 5.071e-05  loss_mask_3: 0.1181  loss_dice_3: 0.1728  loss_ce_4: 6.442e-05  loss_mask_4: 0.1183  loss_dice_4: 0.173  loss_ce_5: 6.513e-05  loss_mask_5: 0.1179  loss_dice_5: 0.1702  loss_ce_6: 4.275e-05  loss_mask_6: 0.1166  loss_dice_6: 0.1722  loss_ce_7: 7.155e-05  loss_mask_7: 0.1129  loss_dice_7: 0.1656  loss_ce_8: 7.166e-05  loss_mask_8: 0.116  loss_dice_8: 0.1665  time: 0.5691  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:25] d2.utils.events INFO:  eta: 0:26:13  iter: 27059  total_loss: 2.889  loss_ce: 4.966e-05  loss_mask: 0.1056  loss_dice: 0.1615  loss_ce_0: 0.127  loss_mask_0: 0.11  loss_dice_0: 0.165  loss_ce_1: 8.301e-05  loss_mask_1: 0.1136  loss_dice_1: 0.1675  loss_ce_2: 8.505e-05  loss_mask_2: 0.112  loss_dice_2: 0.1671  loss_ce_3: 4.248e-05  loss_mask_3: 0.1116  loss_dice_3: 0.1664  loss_ce_4: 6.865e-05  loss_mask_4: 0.1089  loss_dice_4: 0.1639  loss_ce_5: 7.892e-05  loss_mask_5: 0.1107  loss_dice_5: 0.166  loss_ce_6: 3.628e-05  loss_mask_6: 0.1081  loss_dice_6: 0.1618  loss_ce_7: 7.069e-05  loss_mask_7: 0.1126  loss_dice_7: 0.17  loss_ce_8: 9.085e-05  loss_mask_8: 0.1094  loss_dice_8: 0.1636  time: 0.5688  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:28] d2.utils.events INFO:  eta: 0:25:55  iter: 27079  total_loss: 2.856  loss_ce: 4.661e-05  loss_mask: 0.1108  loss_dice: 0.1621  loss_ce_0: 0.1233  loss_mask_0: 0.1088  loss_dice_0: 0.1633  loss_ce_1: 5.936e-05  loss_mask_1: 0.1123  loss_dice_1: 0.1707  loss_ce_2: 6.521e-05  loss_mask_2: 0.114  loss_dice_2: 0.1632  loss_ce_3: 2.452e-05  loss_mask_3: 0.1133  loss_dice_3: 0.1652  loss_ce_4: 3.106e-05  loss_mask_4: 0.1091  loss_dice_4: 0.1651  loss_ce_5: 4.566e-05  loss_mask_5: 0.1063  loss_dice_5: 0.1537  loss_ce_6: 3.06e-05  loss_mask_6: 0.1133  loss_dice_6: 0.1579  loss_ce_7: 4.899e-05  loss_mask_7: 0.1101  loss_dice_7: 0.1626  loss_ce_8: 5.583e-05  loss_mask_8: 0.113  loss_dice_8: 0.1602  time: 0.5685  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:10:32] d2.utils.events INFO:  eta: 0:25:37  iter: 27099  total_loss: 2.905  loss_ce: 4.787e-05  loss_mask: 0.1159  loss_dice: 0.1676  loss_ce_0: 0.1147  loss_mask_0: 0.1202  loss_dice_0: 0.1676  loss_ce_1: 8.997e-05  loss_mask_1: 0.1154  loss_dice_1: 0.1674  loss_ce_2: 0.0001135  loss_mask_2: 0.1131  loss_dice_2: 0.1672  loss_ce_3: 3.689e-05  loss_mask_3: 0.112  loss_dice_3: 0.1636  loss_ce_4: 6.348e-05  loss_mask_4: 0.1166  loss_dice_4: 0.1676  loss_ce_5: 7.261e-05  loss_mask_5: 0.1157  loss_dice_5: 0.1653  loss_ce_6: 3.442e-05  loss_mask_6: 0.1131  loss_dice_6: 0.1658  loss_ce_7: 7.607e-05  loss_mask_7: 0.1172  loss_dice_7: 0.1648  loss_ce_8: 8.058e-05  loss_mask_8: 0.111  loss_dice_8: 0.167  time: 0.5682  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:36] d2.utils.events INFO:  eta: 0:25:21  iter: 27119  total_loss: 2.947  loss_ce: 5.145e-05  loss_mask: 0.112  loss_dice: 0.1668  loss_ce_0: 0.1223  loss_mask_0: 0.1128  loss_dice_0: 0.1678  loss_ce_1: 8.916e-05  loss_mask_1: 0.1106  loss_dice_1: 0.1629  loss_ce_2: 0.0001053  loss_mask_2: 0.1101  loss_dice_2: 0.164  loss_ce_3: 4.465e-05  loss_mask_3: 0.1119  loss_dice_3: 0.1718  loss_ce_4: 6.238e-05  loss_mask_4: 0.1159  loss_dice_4: 0.17  loss_ce_5: 7.815e-05  loss_mask_5: 0.1135  loss_dice_5: 0.166  loss_ce_6: 3.918e-05  loss_mask_6: 0.1102  loss_dice_6: 0.1669  loss_ce_7: 7.528e-05  loss_mask_7: 0.1132  loss_dice_7: 0.1656  loss_ce_8: 9.354e-05  loss_mask_8: 0.1123  loss_dice_8: 0.1695  time: 0.5679  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:39] d2.utils.events INFO:  eta: 0:25:01  iter: 27139  total_loss: 2.9  loss_ce: 4.793e-05  loss_mask: 0.1056  loss_dice: 0.1644  loss_ce_0: 0.1224  loss_mask_0: 0.1072  loss_dice_0: 0.1603  loss_ce_1: 8.005e-05  loss_mask_1: 0.1092  loss_dice_1: 0.1622  loss_ce_2: 7.978e-05  loss_mask_2: 0.1115  loss_dice_2: 0.1649  loss_ce_3: 4.013e-05  loss_mask_3: 0.112  loss_dice_3: 0.1643  loss_ce_4: 5.529e-05  loss_mask_4: 0.1113  loss_dice_4: 0.1616  loss_ce_5: 6.471e-05  loss_mask_5: 0.1069  loss_dice_5: 0.1637  loss_ce_6: 3.606e-05  loss_mask_6: 0.1062  loss_dice_6: 0.157  loss_ce_7: 6.016e-05  loss_mask_7: 0.1086  loss_dice_7: 0.1604  loss_ce_8: 6.894e-05  loss_mask_8: 0.108  loss_dice_8: 0.1586  time: 0.5677  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:43] d2.utils.events INFO:  eta: 0:24:47  iter: 27159  total_loss: 2.958  loss_ce: 5.893e-05  loss_mask: 0.1174  loss_dice: 0.1612  loss_ce_0: 0.1221  loss_mask_0: 0.1101  loss_dice_0: 0.1654  loss_ce_1: 9.27e-05  loss_mask_1: 0.1159  loss_dice_1: 0.171  loss_ce_2: 0.0001092  loss_mask_2: 0.1123  loss_dice_2: 0.164  loss_ce_3: 6.249e-05  loss_mask_3: 0.1124  loss_dice_3: 0.1645  loss_ce_4: 6.608e-05  loss_mask_4: 0.111  loss_dice_4: 0.1635  loss_ce_5: 7.129e-05  loss_mask_5: 0.1103  loss_dice_5: 0.1641  loss_ce_6: 4.899e-05  loss_mask_6: 0.1138  loss_dice_6: 0.1645  loss_ce_7: 7.661e-05  loss_mask_7: 0.1098  loss_dice_7: 0.159  loss_ce_8: 7.822e-05  loss_mask_8: 0.1134  loss_dice_8: 0.164  time: 0.5674  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:46] d2.utils.events INFO:  eta: 0:24:30  iter: 27179  total_loss: 2.906  loss_ce: 4.978e-05  loss_mask: 0.1071  loss_dice: 0.1635  loss_ce_0: 0.127  loss_mask_0: 0.1109  loss_dice_0: 0.1726  loss_ce_1: 8.041e-05  loss_mask_1: 0.1072  loss_dice_1: 0.1659  loss_ce_2: 8.12e-05  loss_mask_2: 0.1099  loss_dice_2: 0.1676  loss_ce_3: 5.135e-05  loss_mask_3: 0.1083  loss_dice_3: 0.1657  loss_ce_4: 5.976e-05  loss_mask_4: 0.1124  loss_dice_4: 0.172  loss_ce_5: 6.464e-05  loss_mask_5: 0.1106  loss_dice_5: 0.1692  loss_ce_6: 3.967e-05  loss_mask_6: 0.1075  loss_dice_6: 0.1661  loss_ce_7: 6.608e-05  loss_mask_7: 0.1065  loss_dice_7: 0.1674  loss_ce_8: 6.951e-05  loss_mask_8: 0.1089  loss_dice_8: 0.165  time: 0.5671  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:50] d2.utils.events INFO:  eta: 0:24:16  iter: 27199  total_loss: 2.824  loss_ce: 5.26e-05  loss_mask: 0.1147  loss_dice: 0.1658  loss_ce_0: 0.1214  loss_mask_0: 0.1109  loss_dice_0: 0.1594  loss_ce_1: 6.926e-05  loss_mask_1: 0.111  loss_dice_1: 0.1618  loss_ce_2: 7.589e-05  loss_mask_2: 0.1118  loss_dice_2: 0.1628  loss_ce_3: 3.587e-05  loss_mask_3: 0.1099  loss_dice_3: 0.159  loss_ce_4: 4.867e-05  loss_mask_4: 0.1118  loss_dice_4: 0.1624  loss_ce_5: 5.454e-05  loss_mask_5: 0.1123  loss_dice_5: 0.1626  loss_ce_6: 3.427e-05  loss_mask_6: 0.1095  loss_dice_6: 0.1594  loss_ce_7: 5.927e-05  loss_mask_7: 0.1133  loss_dice_7: 0.1659  loss_ce_8: 6.041e-05  loss_mask_8: 0.1092  loss_dice_8: 0.1593  time: 0.5668  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:54] d2.utils.events INFO:  eta: 0:24:03  iter: 27219  total_loss: 2.927  loss_ce: 5.022e-05  loss_mask: 0.1136  loss_dice: 0.1655  loss_ce_0: 0.128  loss_mask_0: 0.1155  loss_dice_0: 0.1711  loss_ce_1: 8.072e-05  loss_mask_1: 0.1153  loss_dice_1: 0.1699  loss_ce_2: 7.862e-05  loss_mask_2: 0.1165  loss_dice_2: 0.1705  loss_ce_3: 4.246e-05  loss_mask_3: 0.1127  loss_dice_3: 0.1666  loss_ce_4: 5.665e-05  loss_mask_4: 0.1129  loss_dice_4: 0.1662  loss_ce_5: 7.657e-05  loss_mask_5: 0.1141  loss_dice_5: 0.1676  loss_ce_6: 3.946e-05  loss_mask_6: 0.1161  loss_dice_6: 0.1675  loss_ce_7: 6.668e-05  loss_mask_7: 0.111  loss_dice_7: 0.1608  loss_ce_8: 9.153e-05  loss_mask_8: 0.1157  loss_dice_8: 0.1735  time: 0.5665  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:10:57] d2.utils.events INFO:  eta: 0:23:52  iter: 27239  total_loss: 2.87  loss_ce: 4.859e-05  loss_mask: 0.1116  loss_dice: 0.1604  loss_ce_0: 0.1244  loss_mask_0: 0.109  loss_dice_0: 0.1646  loss_ce_1: 8.414e-05  loss_mask_1: 0.1112  loss_dice_1: 0.1629  loss_ce_2: 8.666e-05  loss_mask_2: 0.1143  loss_dice_2: 0.1699  loss_ce_3: 4.481e-05  loss_mask_3: 0.1103  loss_dice_3: 0.1618  loss_ce_4: 6.636e-05  loss_mask_4: 0.1112  loss_dice_4: 0.1624  loss_ce_5: 7.301e-05  loss_mask_5: 0.11  loss_dice_5: 0.1688  loss_ce_6: 3.921e-05  loss_mask_6: 0.1093  loss_dice_6: 0.165  loss_ce_7: 7.27e-05  loss_mask_7: 0.1107  loss_dice_7: 0.1623  loss_ce_8: 8.008e-05  loss_mask_8: 0.1086  loss_dice_8: 0.1629  time: 0.5662  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:01] d2.utils.events INFO:  eta: 0:23:39  iter: 27259  total_loss: 2.885  loss_ce: 6.349e-05  loss_mask: 0.1112  loss_dice: 0.1642  loss_ce_0: 0.1217  loss_mask_0: 0.1106  loss_dice_0: 0.1606  loss_ce_1: 8.392e-05  loss_mask_1: 0.1115  loss_dice_1: 0.1642  loss_ce_2: 0.0001001  loss_mask_2: 0.1125  loss_dice_2: 0.1646  loss_ce_3: 6.313e-05  loss_mask_3: 0.1139  loss_dice_3: 0.1648  loss_ce_4: 6.824e-05  loss_mask_4: 0.1097  loss_dice_4: 0.1625  loss_ce_5: 6.54e-05  loss_mask_5: 0.1099  loss_dice_5: 0.1618  loss_ce_6: 5.166e-05  loss_mask_6: 0.1116  loss_dice_6: 0.1613  loss_ce_7: 7.648e-05  loss_mask_7: 0.1144  loss_dice_7: 0.1654  loss_ce_8: 7.196e-05  loss_mask_8: 0.1136  loss_dice_8: 0.1639  time: 0.5659  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:11:04] d2.utils.events INFO:  eta: 0:23:30  iter: 27279  total_loss: 2.78  loss_ce: 5.229e-05  loss_mask: 0.1037  loss_dice: 0.162  loss_ce_0: 0.1256  loss_mask_0: 0.1049  loss_dice_0: 0.1554  loss_ce_1: 8.322e-05  loss_mask_1: 0.1029  loss_dice_1: 0.1595  loss_ce_2: 9.943e-05  loss_mask_2: 0.1055  loss_dice_2: 0.1649  loss_ce_3: 5.766e-05  loss_mask_3: 0.1063  loss_dice_3: 0.1614  loss_ce_4: 6.552e-05  loss_mask_4: 0.1068  loss_dice_4: 0.16  loss_ce_5: 7.294e-05  loss_mask_5: 0.1082  loss_dice_5: 0.1664  loss_ce_6: 4.528e-05  loss_mask_6: 0.1045  loss_dice_6: 0.1576  loss_ce_7: 7.707e-05  loss_mask_7: 0.1046  loss_dice_7: 0.1577  loss_ce_8: 7.6e-05  loss_mask_8: 0.1079  loss_dice_8: 0.165  time: 0.5657  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:08] d2.utils.events INFO:  eta: 0:23:17  iter: 27299  total_loss: 2.872  loss_ce: 6.066e-05  loss_mask: 0.115  loss_dice: 0.1624  loss_ce_0: 0.1234  loss_mask_0: 0.1127  loss_dice_0: 0.1607  loss_ce_1: 8.076e-05  loss_mask_1: 0.1111  loss_dice_1: 0.1636  loss_ce_2: 9.167e-05  loss_mask_2: 0.1125  loss_dice_2: 0.1649  loss_ce_3: 6.427e-05  loss_mask_3: 0.1122  loss_dice_3: 0.1572  loss_ce_4: 6.671e-05  loss_mask_4: 0.1098  loss_dice_4: 0.1561  loss_ce_5: 7.284e-05  loss_mask_5: 0.115  loss_dice_5: 0.1634  loss_ce_6: 5.114e-05  loss_mask_6: 0.1156  loss_dice_6: 0.1706  loss_ce_7: 7.427e-05  loss_mask_7: 0.1098  loss_dice_7: 0.1582  loss_ce_8: 7.619e-05  loss_mask_8: 0.1131  loss_dice_8: 0.1581  time: 0.5654  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:11] d2.utils.events INFO:  eta: 0:23:08  iter: 27319  total_loss: 2.966  loss_ce: 5.497e-05  loss_mask: 0.1129  loss_dice: 0.1642  loss_ce_0: 0.1229  loss_mask_0: 0.1108  loss_dice_0: 0.1628  loss_ce_1: 8.849e-05  loss_mask_1: 0.1175  loss_dice_1: 0.1676  loss_ce_2: 0.0001011  loss_mask_2: 0.1135  loss_dice_2: 0.162  loss_ce_3: 5.571e-05  loss_mask_3: 0.1155  loss_dice_3: 0.166  loss_ce_4: 6.749e-05  loss_mask_4: 0.1134  loss_dice_4: 0.16  loss_ce_5: 7.182e-05  loss_mask_5: 0.1101  loss_dice_5: 0.1667  loss_ce_6: 4.522e-05  loss_mask_6: 0.1131  loss_dice_6: 0.1604  loss_ce_7: 7.333e-05  loss_mask_7: 0.1138  loss_dice_7: 0.1659  loss_ce_8: 7.734e-05  loss_mask_8: 0.112  loss_dice_8: 0.1628  time: 0.5651  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:15] d2.utils.events INFO:  eta: 0:23:00  iter: 27339  total_loss: 2.827  loss_ce: 6.532e-05  loss_mask: 0.1077  loss_dice: 0.1586  loss_ce_0: 0.1231  loss_mask_0: 0.1094  loss_dice_0: 0.1619  loss_ce_1: 0.00011  loss_mask_1: 0.1105  loss_dice_1: 0.1678  loss_ce_2: 9.553e-05  loss_mask_2: 0.11  loss_dice_2: 0.164  loss_ce_3: 5.83e-05  loss_mask_3: 0.1089  loss_dice_3: 0.1597  loss_ce_4: 6.751e-05  loss_mask_4: 0.1075  loss_dice_4: 0.1603  loss_ce_5: 7.356e-05  loss_mask_5: 0.1094  loss_dice_5: 0.1644  loss_ce_6: 4.654e-05  loss_mask_6: 0.1086  loss_dice_6: 0.1655  loss_ce_7: 7.397e-05  loss_mask_7: 0.1073  loss_dice_7: 0.161  loss_ce_8: 7.841e-05  loss_mask_8: 0.1108  loss_dice_8: 0.1654  time: 0.5648  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:19] d2.utils.events INFO:  eta: 0:22:52  iter: 27359  total_loss: 2.886  loss_ce: 5.603e-05  loss_mask: 0.1065  loss_dice: 0.1576  loss_ce_0: 0.123  loss_mask_0: 0.1082  loss_dice_0: 0.1614  loss_ce_1: 9.707e-05  loss_mask_1: 0.1104  loss_dice_1: 0.1664  loss_ce_2: 0.0001014  loss_mask_2: 0.1124  loss_dice_2: 0.1676  loss_ce_3: 6.2e-05  loss_mask_3: 0.1066  loss_dice_3: 0.16  loss_ce_4: 6.23e-05  loss_mask_4: 0.1132  loss_dice_4: 0.1654  loss_ce_5: 6.279e-05  loss_mask_5: 0.1091  loss_dice_5: 0.1567  loss_ce_6: 4.893e-05  loss_mask_6: 0.1097  loss_dice_6: 0.1624  loss_ce_7: 7.251e-05  loss_mask_7: 0.1103  loss_dice_7: 0.1651  loss_ce_8: 6.845e-05  loss_mask_8: 0.1137  loss_dice_8: 0.1654  time: 0.5645  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:22] d2.utils.events INFO:  eta: 0:22:41  iter: 27379  total_loss: 2.848  loss_ce: 6.371e-05  loss_mask: 0.1106  loss_dice: 0.1692  loss_ce_0: 0.1232  loss_mask_0: 0.1104  loss_dice_0: 0.1631  loss_ce_1: 9.587e-05  loss_mask_1: 0.1101  loss_dice_1: 0.1654  loss_ce_2: 9.759e-05  loss_mask_2: 0.109  loss_dice_2: 0.1665  loss_ce_3: 6.675e-05  loss_mask_3: 0.1054  loss_dice_3: 0.1668  loss_ce_4: 6.651e-05  loss_mask_4: 0.1054  loss_dice_4: 0.162  loss_ce_5: 6.854e-05  loss_mask_5: 0.1074  loss_dice_5: 0.1641  loss_ce_6: 4.635e-05  loss_mask_6: 0.1069  loss_dice_6: 0.162  loss_ce_7: 7.723e-05  loss_mask_7: 0.107  loss_dice_7: 0.1631  loss_ce_8: 7.387e-05  loss_mask_8: 0.1085  loss_dice_8: 0.1701  time: 0.5642  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:26] d2.utils.events INFO:  eta: 0:22:31  iter: 27399  total_loss: 3.038  loss_ce: 4.655e-05  loss_mask: 0.1125  loss_dice: 0.1797  loss_ce_0: 0.1234  loss_mask_0: 0.1085  loss_dice_0: 0.1779  loss_ce_1: 8.61e-05  loss_mask_1: 0.1146  loss_dice_1: 0.1777  loss_ce_2: 8.574e-05  loss_mask_2: 0.1107  loss_dice_2: 0.1841  loss_ce_3: 4.307e-05  loss_mask_3: 0.1048  loss_dice_3: 0.1722  loss_ce_4: 5.998e-05  loss_mask_4: 0.1096  loss_dice_4: 0.1846  loss_ce_5: 6.255e-05  loss_mask_5: 0.1102  loss_dice_5: 0.185  loss_ce_6: 4.032e-05  loss_mask_6: 0.1144  loss_dice_6: 0.1838  loss_ce_7: 7.26e-05  loss_mask_7: 0.1071  loss_dice_7: 0.1811  loss_ce_8: 6.717e-05  loss_mask_8: 0.1063  loss_dice_8: 0.1749  time: 0.5640  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:29] d2.utils.events INFO:  eta: 0:22:24  iter: 27419  total_loss: 2.816  loss_ce: 4.748e-05  loss_mask: 0.1111  loss_dice: 0.1616  loss_ce_0: 0.123  loss_mask_0: 0.1072  loss_dice_0: 0.1665  loss_ce_1: 9.687e-05  loss_mask_1: 0.1076  loss_dice_1: 0.1586  loss_ce_2: 9.229e-05  loss_mask_2: 0.1092  loss_dice_2: 0.1578  loss_ce_3: 4.251e-05  loss_mask_3: 0.1064  loss_dice_3: 0.1573  loss_ce_4: 6.128e-05  loss_mask_4: 0.1084  loss_dice_4: 0.1617  loss_ce_5: 6.352e-05  loss_mask_5: 0.1049  loss_dice_5: 0.1565  loss_ce_6: 3.911e-05  loss_mask_6: 0.1065  loss_dice_6: 0.1553  loss_ce_7: 6.942e-05  loss_mask_7: 0.1083  loss_dice_7: 0.1612  loss_ce_8: 6.83e-05  loss_mask_8: 0.1083  loss_dice_8: 0.1582  time: 0.5637  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:33] d2.utils.events INFO:  eta: 0:22:16  iter: 27439  total_loss: 2.878  loss_ce: 6.204e-05  loss_mask: 0.1137  loss_dice: 0.1609  loss_ce_0: 0.1229  loss_mask_0: 0.1118  loss_dice_0: 0.1615  loss_ce_1: 0.0001129  loss_mask_1: 0.1158  loss_dice_1: 0.1653  loss_ce_2: 8.967e-05  loss_mask_2: 0.1121  loss_dice_2: 0.1601  loss_ce_3: 6.481e-05  loss_mask_3: 0.1116  loss_dice_3: 0.1616  loss_ce_4: 6.738e-05  loss_mask_4: 0.1103  loss_dice_4: 0.158  loss_ce_5: 8.07e-05  loss_mask_5: 0.1132  loss_dice_5: 0.1652  loss_ce_6: 4.715e-05  loss_mask_6: 0.114  loss_dice_6: 0.165  loss_ce_7: 7.293e-05  loss_mask_7: 0.1137  loss_dice_7: 0.1644  loss_ce_8: 8.391e-05  loss_mask_8: 0.1095  loss_dice_8: 0.1614  time: 0.5634  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:37] d2.utils.events INFO:  eta: 0:22:08  iter: 27459  total_loss: 2.68  loss_ce: 4.813e-05  loss_mask: 0.1095  loss_dice: 0.1514  loss_ce_0: 0.123  loss_mask_0: 0.1105  loss_dice_0: 0.1526  loss_ce_1: 9.703e-05  loss_mask_1: 0.1033  loss_dice_1: 0.1517  loss_ce_2: 8.554e-05  loss_mask_2: 0.1061  loss_dice_2: 0.1511  loss_ce_3: 4.209e-05  loss_mask_3: 0.11  loss_dice_3: 0.1544  loss_ce_4: 5.484e-05  loss_mask_4: 0.1084  loss_dice_4: 0.1524  loss_ce_5: 6.051e-05  loss_mask_5: 0.1062  loss_dice_5: 0.1533  loss_ce_6: 3.775e-05  loss_mask_6: 0.1074  loss_dice_6: 0.151  loss_ce_7: 6.693e-05  loss_mask_7: 0.1084  loss_dice_7: 0.1534  loss_ce_8: 6.629e-05  loss_mask_8: 0.1053  loss_dice_8: 0.1488  time: 0.5631  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:40] d2.utils.events INFO:  eta: 0:22:02  iter: 27479  total_loss: 2.888  loss_ce: 5.344e-05  loss_mask: 0.1126  loss_dice: 0.1687  loss_ce_0: 0.1238  loss_mask_0: 0.1152  loss_dice_0: 0.1669  loss_ce_1: 0.000109  loss_mask_1: 0.1106  loss_dice_1: 0.1677  loss_ce_2: 8.722e-05  loss_mask_2: 0.1074  loss_dice_2: 0.1647  loss_ce_3: 4.092e-05  loss_mask_3: 0.1101  loss_dice_3: 0.1698  loss_ce_4: 6.388e-05  loss_mask_4: 0.1108  loss_dice_4: 0.1687  loss_ce_5: 7.846e-05  loss_mask_5: 0.1144  loss_dice_5: 0.1681  loss_ce_6: 3.788e-05  loss_mask_6: 0.1114  loss_dice_6: 0.16  loss_ce_7: 7.217e-05  loss_mask_7: 0.1115  loss_dice_7: 0.1672  loss_ce_8: 8.938e-05  loss_mask_8: 0.1129  loss_dice_8: 0.1703  time: 0.5628  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:44] d2.utils.events INFO:  eta: 0:21:55  iter: 27499  total_loss: 2.913  loss_ce: 4.286e-05  loss_mask: 0.1118  loss_dice: 0.1659  loss_ce_0: 0.1241  loss_mask_0: 0.1118  loss_dice_0: 0.1729  loss_ce_1: 8.938e-05  loss_mask_1: 0.1119  loss_dice_1: 0.1734  loss_ce_2: 5.949e-05  loss_mask_2: 0.1077  loss_dice_2: 0.1671  loss_ce_3: 2.568e-05  loss_mask_3: 0.1081  loss_dice_3: 0.1661  loss_ce_4: 2.874e-05  loss_mask_4: 0.1136  loss_dice_4: 0.169  loss_ce_5: 4.506e-05  loss_mask_5: 0.1105  loss_dice_5: 0.1706  loss_ce_6: 2.79e-05  loss_mask_6: 0.1151  loss_dice_6: 0.1682  loss_ce_7: 5.198e-05  loss_mask_7: 0.112  loss_dice_7: 0.1661  loss_ce_8: 5.509e-05  loss_mask_8: 0.1081  loss_dice_8: 0.1645  time: 0.5626  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:47] d2.utils.events INFO:  eta: 0:21:53  iter: 27519  total_loss: 2.773  loss_ce: 4.771e-05  loss_mask: 0.1067  loss_dice: 0.1685  loss_ce_0: 0.1194  loss_mask_0: 0.1054  loss_dice_0: 0.1595  loss_ce_1: 9.66e-05  loss_mask_1: 0.1043  loss_dice_1: 0.1658  loss_ce_2: 0.0001026  loss_mask_2: 0.1042  loss_dice_2: 0.1586  loss_ce_3: 5.268e-05  loss_mask_3: 0.1081  loss_dice_3: 0.1644  loss_ce_4: 6.028e-05  loss_mask_4: 0.1058  loss_dice_4: 0.1613  loss_ce_5: 6.077e-05  loss_mask_5: 0.1041  loss_dice_5: 0.1631  loss_ce_6: 4.492e-05  loss_mask_6: 0.1026  loss_dice_6: 0.1588  loss_ce_7: 7.146e-05  loss_mask_7: 0.1037  loss_dice_7: 0.1592  loss_ce_8: 6.481e-05  loss_mask_8: 0.1052  loss_dice_8: 0.1643  time: 0.5623  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:51] d2.utils.events INFO:  eta: 0:21:49  iter: 27539  total_loss: 2.755  loss_ce: 4.863e-05  loss_mask: 0.1041  loss_dice: 0.1559  loss_ce_0: 0.1227  loss_mask_0: 0.1048  loss_dice_0: 0.1597  loss_ce_1: 8.48e-05  loss_mask_1: 0.112  loss_dice_1: 0.1636  loss_ce_2: 8.759e-05  loss_mask_2: 0.1059  loss_dice_2: 0.1591  loss_ce_3: 4.15e-05  loss_mask_3: 0.1077  loss_dice_3: 0.1586  loss_ce_4: 6.058e-05  loss_mask_4: 0.1077  loss_dice_4: 0.1616  loss_ce_5: 6.113e-05  loss_mask_5: 0.1077  loss_dice_5: 0.1577  loss_ce_6: 4.128e-05  loss_mask_6: 0.1074  loss_dice_6: 0.1557  loss_ce_7: 6.589e-05  loss_mask_7: 0.1102  loss_dice_7: 0.168  loss_ce_8: 6.682e-05  loss_mask_8: 0.1132  loss_dice_8: 0.1595  time: 0.5620  data_time: 0.0013  lr: 1e-05  max_mem: 8444M
[08/01 22:11:55] d2.utils.events INFO:  eta: 0:21:46  iter: 27559  total_loss: 2.896  loss_ce: 4.307e-05  loss_mask: 0.1053  loss_dice: 0.1647  loss_ce_0: 0.1229  loss_mask_0: 0.1058  loss_dice_0: 0.1611  loss_ce_1: 8.065e-05  loss_mask_1: 0.1061  loss_dice_1: 0.1679  loss_ce_2: 8.129e-05  loss_mask_2: 0.1053  loss_dice_2: 0.1649  loss_ce_3: 3.643e-05  loss_mask_3: 0.1058  loss_dice_3: 0.1659  loss_ce_4: 5.791e-05  loss_mask_4: 0.1088  loss_dice_4: 0.1644  loss_ce_5: 6.812e-05  loss_mask_5: 0.1074  loss_dice_5: 0.174  loss_ce_6: 3.671e-05  loss_mask_6: 0.1046  loss_dice_6: 0.1572  loss_ce_7: 6.65e-05  loss_mask_7: 0.1124  loss_dice_7: 0.1696  loss_ce_8: 7.422e-05  loss_mask_8: 0.107  loss_dice_8: 0.1645  time: 0.5617  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:11:58] d2.utils.events INFO:  eta: 0:21:41  iter: 27579  total_loss: 2.788  loss_ce: 4.407e-05  loss_mask: 0.1079  loss_dice: 0.1617  loss_ce_0: 0.1233  loss_mask_0: 0.1088  loss_dice_0: 0.1632  loss_ce_1: 8.511e-05  loss_mask_1: 0.1072  loss_dice_1: 0.1622  loss_ce_2: 8.451e-05  loss_mask_2: 0.1079  loss_dice_2: 0.1623  loss_ce_3: 3.666e-05  loss_mask_3: 0.109  loss_dice_3: 0.1608  loss_ce_4: 5.916e-05  loss_mask_4: 0.1094  loss_dice_4: 0.1607  loss_ce_5: 5.987e-05  loss_mask_5: 0.1061  loss_dice_5: 0.1568  loss_ce_6: 3.753e-05  loss_mask_6: 0.109  loss_dice_6: 0.162  loss_ce_7: 6.544e-05  loss_mask_7: 0.1092  loss_dice_7: 0.1573  loss_ce_8: 6.531e-05  loss_mask_8: 0.1087  loss_dice_8: 0.1621  time: 0.5614  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:02] d2.utils.events INFO:  eta: 0:21:37  iter: 27599  total_loss: 2.792  loss_ce: 5.772e-05  loss_mask: 0.1076  loss_dice: 0.1571  loss_ce_0: 0.1236  loss_mask_0: 0.1075  loss_dice_0: 0.1591  loss_ce_1: 7.659e-05  loss_mask_1: 0.1068  loss_dice_1: 0.164  loss_ce_2: 7.236e-05  loss_mask_2: 0.1079  loss_dice_2: 0.159  loss_ce_3: 6.097e-05  loss_mask_3: 0.1091  loss_dice_3: 0.1592  loss_ce_4: 5.866e-05  loss_mask_4: 0.1073  loss_dice_4: 0.1594  loss_ce_5: 5.238e-05  loss_mask_5: 0.1084  loss_dice_5: 0.1594  loss_ce_6: 4.806e-05  loss_mask_6: 0.1057  loss_dice_6: 0.1586  loss_ce_7: 6.705e-05  loss_mask_7: 0.1049  loss_dice_7: 0.153  loss_ce_8: 6.1e-05  loss_mask_8: 0.1091  loss_dice_8: 0.1622  time: 0.5612  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:05] d2.utils.events INFO:  eta: 0:21:35  iter: 27619  total_loss: 2.845  loss_ce: 4.698e-05  loss_mask: 0.1079  loss_dice: 0.159  loss_ce_0: 0.1237  loss_mask_0: 0.1038  loss_dice_0: 0.1629  loss_ce_1: 0.0001056  loss_mask_1: 0.1104  loss_dice_1: 0.1667  loss_ce_2: 8.631e-05  loss_mask_2: 0.1115  loss_dice_2: 0.1624  loss_ce_3: 4.5e-05  loss_mask_3: 0.1085  loss_dice_3: 0.1651  loss_ce_4: 5.977e-05  loss_mask_4: 0.1047  loss_dice_4: 0.1573  loss_ce_5: 7.257e-05  loss_mask_5: 0.1065  loss_dice_5: 0.1584  loss_ce_6: 4.267e-05  loss_mask_6: 0.1086  loss_dice_6: 0.1643  loss_ce_7: 6.513e-05  loss_mask_7: 0.1081  loss_dice_7: 0.1591  loss_ce_8: 7.188e-05  loss_mask_8: 0.1075  loss_dice_8: 0.1613  time: 0.5609  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:09] d2.utils.events INFO:  eta: 0:21:33  iter: 27639  total_loss: 2.9  loss_ce: 5.174e-05  loss_mask: 0.1086  loss_dice: 0.1698  loss_ce_0: 0.1221  loss_mask_0: 0.1138  loss_dice_0: 0.1728  loss_ce_1: 0.0001006  loss_mask_1: 0.1134  loss_dice_1: 0.177  loss_ce_2: 8.981e-05  loss_mask_2: 0.1123  loss_dice_2: 0.1714  loss_ce_3: 5.046e-05  loss_mask_3: 0.1092  loss_dice_3: 0.1651  loss_ce_4: 5.973e-05  loss_mask_4: 0.1126  loss_dice_4: 0.1744  loss_ce_5: 5.956e-05  loss_mask_5: 0.1091  loss_dice_5: 0.1692  loss_ce_6: 4.529e-05  loss_mask_6: 0.109  loss_dice_6: 0.1675  loss_ce_7: 7.071e-05  loss_mask_7: 0.1101  loss_dice_7: 0.1673  loss_ce_8: 6.562e-05  loss_mask_8: 0.1094  loss_dice_8: 0.1733  time: 0.5606  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:13] d2.utils.events INFO:  eta: 0:21:29  iter: 27659  total_loss: 2.907  loss_ce: 4.739e-05  loss_mask: 0.1088  loss_dice: 0.1699  loss_ce_0: 0.1222  loss_mask_0: 0.1132  loss_dice_0: 0.1627  loss_ce_1: 8.705e-05  loss_mask_1: 0.1118  loss_dice_1: 0.1724  loss_ce_2: 8.62e-05  loss_mask_2: 0.1088  loss_dice_2: 0.1669  loss_ce_3: 3.85e-05  loss_mask_3: 0.11  loss_dice_3: 0.167  loss_ce_4: 5.964e-05  loss_mask_4: 0.112  loss_dice_4: 0.1708  loss_ce_5: 5.927e-05  loss_mask_5: 0.1117  loss_dice_5: 0.1707  loss_ce_6: 3.824e-05  loss_mask_6: 0.1102  loss_dice_6: 0.1654  loss_ce_7: 6.8e-05  loss_mask_7: 0.1089  loss_dice_7: 0.167  loss_ce_8: 6.451e-05  loss_mask_8: 0.1124  loss_dice_8: 0.1679  time: 0.5603  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:16] d2.utils.events INFO:  eta: 0:21:25  iter: 27679  total_loss: 2.825  loss_ce: 5.237e-05  loss_mask: 0.1089  loss_dice: 0.1608  loss_ce_0: 0.1234  loss_mask_0: 0.1131  loss_dice_0: 0.1687  loss_ce_1: 7.855e-05  loss_mask_1: 0.1061  loss_dice_1: 0.1606  loss_ce_2: 8.128e-05  loss_mask_2: 0.1092  loss_dice_2: 0.1621  loss_ce_3: 5.881e-05  loss_mask_3: 0.1086  loss_dice_3: 0.1546  loss_ce_4: 5.949e-05  loss_mask_4: 0.1116  loss_dice_4: 0.1539  loss_ce_5: 6.688e-05  loss_mask_5: 0.1126  loss_dice_5: 0.1597  loss_ce_6: 4.588e-05  loss_mask_6: 0.109  loss_dice_6: 0.1575  loss_ce_7: 6.418e-05  loss_mask_7: 0.1081  loss_dice_7: 0.158  loss_ce_8: 7.084e-05  loss_mask_8: 0.1102  loss_dice_8: 0.1623  time: 0.5601  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:20] d2.utils.events INFO:  eta: 0:21:21  iter: 27699  total_loss: 2.901  loss_ce: 5.87e-05  loss_mask: 0.1114  loss_dice: 0.1772  loss_ce_0: 0.1203  loss_mask_0: 0.1067  loss_dice_0: 0.1644  loss_ce_1: 9.976e-05  loss_mask_1: 0.1054  loss_dice_1: 0.1722  loss_ce_2: 9.656e-05  loss_mask_2: 0.1084  loss_dice_2: 0.1664  loss_ce_3: 6.305e-05  loss_mask_3: 0.1097  loss_dice_3: 0.1714  loss_ce_4: 6.543e-05  loss_mask_4: 0.1054  loss_dice_4: 0.1645  loss_ce_5: 8.398e-05  loss_mask_5: 0.1074  loss_dice_5: 0.1671  loss_ce_6: 4.611e-05  loss_mask_6: 0.1126  loss_dice_6: 0.1717  loss_ce_7: 7.375e-05  loss_mask_7: 0.1092  loss_dice_7: 0.173  loss_ce_8: 8.125e-05  loss_mask_8: 0.1094  loss_dice_8: 0.1682  time: 0.5598  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:12:23] d2.utils.events INFO:  eta: 0:21:17  iter: 27719  total_loss: 2.714  loss_ce: 4.21e-05  loss_mask: 0.107  loss_dice: 0.1619  loss_ce_0: 0.1243  loss_mask_0: 0.1078  loss_dice_0: 0.1639  loss_ce_1: 7.7e-05  loss_mask_1: 0.1051  loss_dice_1: 0.1611  loss_ce_2: 5.447e-05  loss_mask_2: 0.1025  loss_dice_2: 0.157  loss_ce_3: 3.439e-05  loss_mask_3: 0.1053  loss_dice_3: 0.1581  loss_ce_4: 3.303e-05  loss_mask_4: 0.1084  loss_dice_4: 0.1592  loss_ce_5: 4.356e-05  loss_mask_5: 0.1049  loss_dice_5: 0.1578  loss_ce_6: 3.632e-05  loss_mask_6: 0.1052  loss_dice_6: 0.1574  loss_ce_7: 4.905e-05  loss_mask_7: 0.1072  loss_dice_7: 0.1625  loss_ce_8: 5.108e-05  loss_mask_8: 0.1063  loss_dice_8: 0.1608  time: 0.5595  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:27] d2.utils.events INFO:  eta: 0:21:14  iter: 27739  total_loss: 2.774  loss_ce: 4.556e-05  loss_mask: 0.1111  loss_dice: 0.1581  loss_ce_0: 0.1238  loss_mask_0: 0.1142  loss_dice_0: 0.1626  loss_ce_1: 7.307e-05  loss_mask_1: 0.1141  loss_dice_1: 0.1612  loss_ce_2: 6.853e-05  loss_mask_2: 0.1086  loss_dice_2: 0.1581  loss_ce_3: 4.017e-05  loss_mask_3: 0.109  loss_dice_3: 0.1612  loss_ce_4: 4.973e-05  loss_mask_4: 0.1122  loss_dice_4: 0.1632  loss_ce_5: 5.168e-05  loss_mask_5: 0.1113  loss_dice_5: 0.1581  loss_ce_6: 3.894e-05  loss_mask_6: 0.1116  loss_dice_6: 0.1608  loss_ce_7: 6.043e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1601  loss_ce_8: 5.725e-05  loss_mask_8: 0.1108  loss_dice_8: 0.1591  time: 0.5592  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:30] d2.utils.events INFO:  eta: 0:21:10  iter: 27759  total_loss: 2.982  loss_ce: 4.631e-05  loss_mask: 0.1117  loss_dice: 0.1664  loss_ce_0: 0.1235  loss_mask_0: 0.112  loss_dice_0: 0.1685  loss_ce_1: 7.923e-05  loss_mask_1: 0.1098  loss_dice_1: 0.1649  loss_ce_2: 6.792e-05  loss_mask_2: 0.1126  loss_dice_2: 0.1693  loss_ce_3: 3.084e-05  loss_mask_3: 0.1148  loss_dice_3: 0.162  loss_ce_4: 4.691e-05  loss_mask_4: 0.1121  loss_dice_4: 0.161  loss_ce_5: 5.844e-05  loss_mask_5: 0.1145  loss_dice_5: 0.1671  loss_ce_6: 3.181e-05  loss_mask_6: 0.1149  loss_dice_6: 0.1696  loss_ce_7: 6.328e-05  loss_mask_7: 0.1072  loss_dice_7: 0.1659  loss_ce_8: 6.514e-05  loss_mask_8: 0.115  loss_dice_8: 0.1639  time: 0.5590  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:34] d2.utils.events INFO:  eta: 0:21:06  iter: 27779  total_loss: 2.811  loss_ce: 4.812e-05  loss_mask: 0.1102  loss_dice: 0.163  loss_ce_0: 0.1223  loss_mask_0: 0.108  loss_dice_0: 0.1602  loss_ce_1: 9.424e-05  loss_mask_1: 0.1094  loss_dice_1: 0.1637  loss_ce_2: 8.534e-05  loss_mask_2: 0.1079  loss_dice_2: 0.1613  loss_ce_3: 4.533e-05  loss_mask_3: 0.1045  loss_dice_3: 0.1564  loss_ce_4: 5.844e-05  loss_mask_4: 0.1079  loss_dice_4: 0.1643  loss_ce_5: 7.32e-05  loss_mask_5: 0.1065  loss_dice_5: 0.1574  loss_ce_6: 3.98e-05  loss_mask_6: 0.1091  loss_dice_6: 0.1609  loss_ce_7: 6.518e-05  loss_mask_7: 0.1081  loss_dice_7: 0.1656  loss_ce_8: 7.762e-05  loss_mask_8: 0.1108  loss_dice_8: 0.1602  time: 0.5587  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:37] d2.utils.events INFO:  eta: 0:21:03  iter: 27799  total_loss: 2.792  loss_ce: 4.098e-05  loss_mask: 0.1043  loss_dice: 0.1596  loss_ce_0: 0.1237  loss_mask_0: 0.1083  loss_dice_0: 0.1631  loss_ce_1: 7.311e-05  loss_mask_1: 0.1112  loss_dice_1: 0.1614  loss_ce_2: 5.463e-05  loss_mask_2: 0.1085  loss_dice_2: 0.1582  loss_ce_3: 2.029e-05  loss_mask_3: 0.1084  loss_dice_3: 0.1665  loss_ce_4: 2.723e-05  loss_mask_4: 0.1085  loss_dice_4: 0.1678  loss_ce_5: 4.163e-05  loss_mask_5: 0.1051  loss_dice_5: 0.153  loss_ce_6: 2.374e-05  loss_mask_6: 0.1061  loss_dice_6: 0.1576  loss_ce_7: 4.946e-05  loss_mask_7: 0.1047  loss_dice_7: 0.1586  loss_ce_8: 5.09e-05  loss_mask_8: 0.1087  loss_dice_8: 0.1626  time: 0.5584  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:41] d2.utils.events INFO:  eta: 0:20:59  iter: 27819  total_loss: 2.761  loss_ce: 4.682e-05  loss_mask: 0.1048  loss_dice: 0.1495  loss_ce_0: 0.1259  loss_mask_0: 0.1077  loss_dice_0: 0.1633  loss_ce_1: 0.0001036  loss_mask_1: 0.1081  loss_dice_1: 0.1554  loss_ce_2: 7.862e-05  loss_mask_2: 0.1077  loss_dice_2: 0.1607  loss_ce_3: 4.401e-05  loss_mask_3: 0.1093  loss_dice_3: 0.1557  loss_ce_4: 5.914e-05  loss_mask_4: 0.1069  loss_dice_4: 0.158  loss_ce_5: 7.306e-05  loss_mask_5: 0.1076  loss_dice_5: 0.1579  loss_ce_6: 4.073e-05  loss_mask_6: 0.1044  loss_dice_6: 0.1572  loss_ce_7: 6.492e-05  loss_mask_7: 0.1071  loss_dice_7: 0.1607  loss_ce_8: 7.981e-05  loss_mask_8: 0.106  loss_dice_8: 0.155  time: 0.5581  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:45] d2.utils.events INFO:  eta: 0:20:55  iter: 27839  total_loss: 2.803  loss_ce: 4.651e-05  loss_mask: 0.1115  loss_dice: 0.1592  loss_ce_0: 0.1224  loss_mask_0: 0.111  loss_dice_0: 0.1628  loss_ce_1: 8.525e-05  loss_mask_1: 0.108  loss_dice_1: 0.1618  loss_ce_2: 8.754e-05  loss_mask_2: 0.1112  loss_dice_2: 0.1595  loss_ce_3: 4.094e-05  loss_mask_3: 0.1102  loss_dice_3: 0.1597  loss_ce_4: 5.612e-05  loss_mask_4: 0.1109  loss_dice_4: 0.1587  loss_ce_5: 5.74e-05  loss_mask_5: 0.1102  loss_dice_5: 0.1592  loss_ce_6: 3.966e-05  loss_mask_6: 0.1106  loss_dice_6: 0.1621  loss_ce_7: 6.109e-05  loss_mask_7: 0.1106  loss_dice_7: 0.159  loss_ce_8: 6.432e-05  loss_mask_8: 0.1108  loss_dice_8: 0.1635  time: 0.5579  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:48] d2.utils.events INFO:  eta: 0:20:52  iter: 27859  total_loss: 2.91  loss_ce: 3.963e-05  loss_mask: 0.1123  loss_dice: 0.1712  loss_ce_0: 0.1239  loss_mask_0: 0.1107  loss_dice_0: 0.1678  loss_ce_1: 7.546e-05  loss_mask_1: 0.1104  loss_dice_1: 0.1686  loss_ce_2: 5.383e-05  loss_mask_2: 0.1109  loss_dice_2: 0.1647  loss_ce_3: 2.834e-05  loss_mask_3: 0.108  loss_dice_3: 0.1616  loss_ce_4: 3.152e-05  loss_mask_4: 0.1087  loss_dice_4: 0.1617  loss_ce_5: 4.12e-05  loss_mask_5: 0.1119  loss_dice_5: 0.1641  loss_ce_6: 3.037e-05  loss_mask_6: 0.1095  loss_dice_6: 0.1646  loss_ce_7: 4.838e-05  loss_mask_7: 0.1101  loss_dice_7: 0.1645  loss_ce_8: 4.979e-05  loss_mask_8: 0.1102  loss_dice_8: 0.1648  time: 0.5576  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:52] d2.utils.events INFO:  eta: 0:20:49  iter: 27879  total_loss: 2.77  loss_ce: 5.722e-05  loss_mask: 0.107  loss_dice: 0.1599  loss_ce_0: 0.1225  loss_mask_0: 0.1044  loss_dice_0: 0.1612  loss_ce_1: 8.345e-05  loss_mask_1: 0.1038  loss_dice_1: 0.1544  loss_ce_2: 8.17e-05  loss_mask_2: 0.1056  loss_dice_2: 0.1581  loss_ce_3: 5.667e-05  loss_mask_3: 0.1069  loss_dice_3: 0.1592  loss_ce_4: 6.189e-05  loss_mask_4: 0.105  loss_dice_4: 0.1571  loss_ce_5: 7.333e-05  loss_mask_5: 0.1071  loss_dice_5: 0.158  loss_ce_6: 4.445e-05  loss_mask_6: 0.1029  loss_dice_6: 0.1524  loss_ce_7: 6.44e-05  loss_mask_7: 0.107  loss_dice_7: 0.1528  loss_ce_8: 7.277e-05  loss_mask_8: 0.1051  loss_dice_8: 0.1583  time: 0.5573  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:55] d2.utils.events INFO:  eta: 0:20:46  iter: 27899  total_loss: 2.982  loss_ce: 4.143e-05  loss_mask: 0.1129  loss_dice: 0.1683  loss_ce_0: 0.1236  loss_mask_0: 0.1123  loss_dice_0: 0.1645  loss_ce_1: 0.0001002  loss_mask_1: 0.112  loss_dice_1: 0.1671  loss_ce_2: 7.532e-05  loss_mask_2: 0.1174  loss_dice_2: 0.1703  loss_ce_3: 3.586e-05  loss_mask_3: 0.1167  loss_dice_3: 0.1729  loss_ce_4: 5.545e-05  loss_mask_4: 0.1104  loss_dice_4: 0.1677  loss_ce_5: 7.066e-05  loss_mask_5: 0.1139  loss_dice_5: 0.1686  loss_ce_6: 3.327e-05  loss_mask_6: 0.1171  loss_dice_6: 0.174  loss_ce_7: 5.943e-05  loss_mask_7: 0.1139  loss_dice_7: 0.1642  loss_ce_8: 8.356e-05  loss_mask_8: 0.1159  loss_dice_8: 0.1716  time: 0.5570  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:12:59] d2.utils.events INFO:  eta: 0:20:41  iter: 27919  total_loss: 2.818  loss_ce: 4.41e-05  loss_mask: 0.1112  loss_dice: 0.1603  loss_ce_0: 0.1234  loss_mask_0: 0.1121  loss_dice_0: 0.1684  loss_ce_1: 0.0001041  loss_mask_1: 0.1122  loss_dice_1: 0.1598  loss_ce_2: 7.712e-05  loss_mask_2: 0.1124  loss_dice_2: 0.1605  loss_ce_3: 4.167e-05  loss_mask_3: 0.1099  loss_dice_3: 0.1638  loss_ce_4: 5.715e-05  loss_mask_4: 0.1083  loss_dice_4: 0.1595  loss_ce_5: 7.19e-05  loss_mask_5: 0.1107  loss_dice_5: 0.1559  loss_ce_6: 3.632e-05  loss_mask_6: 0.1095  loss_dice_6: 0.1639  loss_ce_7: 6.759e-05  loss_mask_7: 0.1088  loss_dice_7: 0.1582  loss_ce_8: 7.287e-05  loss_mask_8: 0.1072  loss_dice_8: 0.1635  time: 0.5568  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:02] d2.utils.events INFO:  eta: 0:20:38  iter: 27939  total_loss: 2.834  loss_ce: 4.821e-05  loss_mask: 0.1052  loss_dice: 0.1557  loss_ce_0: 0.1232  loss_mask_0: 0.1075  loss_dice_0: 0.1629  loss_ce_1: 7.843e-05  loss_mask_1: 0.1067  loss_dice_1: 0.1672  loss_ce_2: 7.436e-05  loss_mask_2: 0.1115  loss_dice_2: 0.1632  loss_ce_3: 4.064e-05  loss_mask_3: 0.1079  loss_dice_3: 0.163  loss_ce_4: 5.575e-05  loss_mask_4: 0.1058  loss_dice_4: 0.1555  loss_ce_5: 5.507e-05  loss_mask_5: 0.1049  loss_dice_5: 0.1622  loss_ce_6: 3.796e-05  loss_mask_6: 0.1036  loss_dice_6: 0.1583  loss_ce_7: 6.01e-05  loss_mask_7: 0.1071  loss_dice_7: 0.1614  loss_ce_8: 6.058e-05  loss_mask_8: 0.1043  loss_dice_8: 0.1624  time: 0.5565  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:06] d2.utils.events INFO:  eta: 0:20:34  iter: 27959  total_loss: 2.888  loss_ce: 4.594e-05  loss_mask: 0.1105  loss_dice: 0.17  loss_ce_0: 0.123  loss_mask_0: 0.1075  loss_dice_0: 0.1662  loss_ce_1: 7.182e-05  loss_mask_1: 0.1112  loss_dice_1: 0.1692  loss_ce_2: 7.905e-05  loss_mask_2: 0.1107  loss_dice_2: 0.1663  loss_ce_3: 4.439e-05  loss_mask_3: 0.1096  loss_dice_3: 0.1618  loss_ce_4: 5.418e-05  loss_mask_4: 0.1102  loss_dice_4: 0.1676  loss_ce_5: 6.337e-05  loss_mask_5: 0.113  loss_dice_5: 0.166  loss_ce_6: 3.914e-05  loss_mask_6: 0.1114  loss_dice_6: 0.16  loss_ce_7: 6.502e-05  loss_mask_7: 0.1089  loss_dice_7: 0.1677  loss_ce_8: 6.558e-05  loss_mask_8: 0.1095  loss_dice_8: 0.1669  time: 0.5562  data_time: 0.0013  lr: 1e-05  max_mem: 8444M
[08/01 22:13:10] d2.utils.events INFO:  eta: 0:20:30  iter: 27979  total_loss: 2.762  loss_ce: 4.101e-05  loss_mask: 0.108  loss_dice: 0.1583  loss_ce_0: 0.1269  loss_mask_0: 0.107  loss_dice_0: 0.1535  loss_ce_1: 8.224e-05  loss_mask_1: 0.107  loss_dice_1: 0.154  loss_ce_2: 7.398e-05  loss_mask_2: 0.1086  loss_dice_2: 0.1603  loss_ce_3: 3.779e-05  loss_mask_3: 0.109  loss_dice_3: 0.1539  loss_ce_4: 5.546e-05  loss_mask_4: 0.1046  loss_dice_4: 0.1523  loss_ce_5: 6.985e-05  loss_mask_5: 0.1086  loss_dice_5: 0.1588  loss_ce_6: 3.5e-05  loss_mask_6: 0.1056  loss_dice_6: 0.1509  loss_ce_7: 5.866e-05  loss_mask_7: 0.1093  loss_dice_7: 0.1591  loss_ce_8: 7.354e-05  loss_mask_8: 0.1079  loss_dice_8: 0.1549  time: 0.5560  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:13] d2.utils.events INFO:  eta: 0:20:26  iter: 27999  total_loss: 2.832  loss_ce: 4.47e-05  loss_mask: 0.1098  loss_dice: 0.1635  loss_ce_0: 0.1214  loss_mask_0: 0.1083  loss_dice_0: 0.1661  loss_ce_1: 8.198e-05  loss_mask_1: 0.1108  loss_dice_1: 0.1647  loss_ce_2: 8.852e-05  loss_mask_2: 0.1127  loss_dice_2: 0.172  loss_ce_3: 4.621e-05  loss_mask_3: 0.1085  loss_dice_3: 0.1664  loss_ce_4: 6.313e-05  loss_mask_4: 0.1072  loss_dice_4: 0.1628  loss_ce_5: 7.724e-05  loss_mask_5: 0.1108  loss_dice_5: 0.1634  loss_ce_6: 3.784e-05  loss_mask_6: 0.1067  loss_dice_6: 0.1618  loss_ce_7: 6.83e-05  loss_mask_7: 0.112  loss_dice_7: 0.1694  loss_ce_8: 7.096e-05  loss_mask_8: 0.108  loss_dice_8: 0.1631  time: 0.5557  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:13:17] d2.utils.events INFO:  eta: 0:20:22  iter: 28019  total_loss: 2.741  loss_ce: 4.215e-05  loss_mask: 0.1093  loss_dice: 0.16  loss_ce_0: 0.1299  loss_mask_0: 0.1091  loss_dice_0: 0.1596  loss_ce_1: 7.503e-05  loss_mask_1: 0.1083  loss_dice_1: 0.1628  loss_ce_2: 7.146e-05  loss_mask_2: 0.1067  loss_dice_2: 0.1528  loss_ce_3: 3.381e-05  loss_mask_3: 0.1055  loss_dice_3: 0.154  loss_ce_4: 5.03e-05  loss_mask_4: 0.1076  loss_dice_4: 0.1519  loss_ce_5: 5.383e-05  loss_mask_5: 0.1107  loss_dice_5: 0.1576  loss_ce_6: 3.268e-05  loss_mask_6: 0.109  loss_dice_6: 0.1559  loss_ce_7: 5.676e-05  loss_mask_7: 0.11  loss_dice_7: 0.1499  loss_ce_8: 5.891e-05  loss_mask_8: 0.1051  loss_dice_8: 0.1575  time: 0.5554  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:20] d2.utils.events INFO:  eta: 0:20:19  iter: 28039  total_loss: 2.885  loss_ce: 4.392e-05  loss_mask: 0.1076  loss_dice: 0.1646  loss_ce_0: 0.1243  loss_mask_0: 0.1055  loss_dice_0: 0.1702  loss_ce_1: 8.523e-05  loss_mask_1: 0.1047  loss_dice_1: 0.1696  loss_ce_2: 7.408e-05  loss_mask_2: 0.1084  loss_dice_2: 0.1712  loss_ce_3: 4.54e-05  loss_mask_3: 0.1077  loss_dice_3: 0.1716  loss_ce_4: 5.488e-05  loss_mask_4: 0.1081  loss_dice_4: 0.1696  loss_ce_5: 6.947e-05  loss_mask_5: 0.1093  loss_dice_5: 0.1671  loss_ce_6: 3.795e-05  loss_mask_6: 0.1086  loss_dice_6: 0.172  loss_ce_7: 6.026e-05  loss_mask_7: 0.1087  loss_dice_7: 0.1731  loss_ce_8: 7.39e-05  loss_mask_8: 0.1074  loss_dice_8: 0.1687  time: 0.5552  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:24] d2.utils.events INFO:  eta: 0:20:15  iter: 28059  total_loss: 2.781  loss_ce: 4.557e-05  loss_mask: 0.108  loss_dice: 0.1554  loss_ce_0: 0.1232  loss_mask_0: 0.1093  loss_dice_0: 0.1548  loss_ce_1: 9.403e-05  loss_mask_1: 0.1099  loss_dice_1: 0.1567  loss_ce_2: 8.142e-05  loss_mask_2: 0.1096  loss_dice_2: 0.1599  loss_ce_3: 4.013e-05  loss_mask_3: 0.1091  loss_dice_3: 0.1587  loss_ce_4: 5.568e-05  loss_mask_4: 0.1085  loss_dice_4: 0.1562  loss_ce_5: 6.969e-05  loss_mask_5: 0.1065  loss_dice_5: 0.1578  loss_ce_6: 3.744e-05  loss_mask_6: 0.1064  loss_dice_6: 0.1576  loss_ce_7: 6.582e-05  loss_mask_7: 0.1101  loss_dice_7: 0.1622  loss_ce_8: 7.361e-05  loss_mask_8: 0.1092  loss_dice_8: 0.1595  time: 0.5549  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:27] d2.utils.events INFO:  eta: 0:20:11  iter: 28079  total_loss: 2.929  loss_ce: 3.868e-05  loss_mask: 0.1057  loss_dice: 0.1658  loss_ce_0: 0.1256  loss_mask_0: 0.1081  loss_dice_0: 0.1714  loss_ce_1: 6.4e-05  loss_mask_1: 0.1118  loss_dice_1: 0.171  loss_ce_2: 5.142e-05  loss_mask_2: 0.1078  loss_dice_2: 0.1653  loss_ce_3: 2.725e-05  loss_mask_3: 0.1075  loss_dice_3: 0.1645  loss_ce_4: 2.745e-05  loss_mask_4: 0.1109  loss_dice_4: 0.1629  loss_ce_5: 3.787e-05  loss_mask_5: 0.1087  loss_dice_5: 0.1678  loss_ce_6: 2.641e-05  loss_mask_6: 0.1083  loss_dice_6: 0.1647  loss_ce_7: 5.009e-05  loss_mask_7: 0.1095  loss_dice_7: 0.1682  loss_ce_8: 4.69e-05  loss_mask_8: 0.1068  loss_dice_8: 0.1679  time: 0.5546  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:31] d2.utils.events INFO:  eta: 0:20:08  iter: 28099  total_loss: 2.838  loss_ce: 3.978e-05  loss_mask: 0.1097  loss_dice: 0.1708  loss_ce_0: 0.1253  loss_mask_0: 0.1114  loss_dice_0: 0.1649  loss_ce_1: 6.889e-05  loss_mask_1: 0.1107  loss_dice_1: 0.1662  loss_ce_2: 7.136e-05  loss_mask_2: 0.107  loss_dice_2: 0.1612  loss_ce_3: 3.481e-05  loss_mask_3: 0.1079  loss_dice_3: 0.1603  loss_ce_4: 4.866e-05  loss_mask_4: 0.1081  loss_dice_4: 0.1588  loss_ce_5: 6.042e-05  loss_mask_5: 0.1078  loss_dice_5: 0.1619  loss_ce_6: 3.055e-05  loss_mask_6: 0.1095  loss_dice_6: 0.1663  loss_ce_7: 5.581e-05  loss_mask_7: 0.109  loss_dice_7: 0.16  loss_ce_8: 6.288e-05  loss_mask_8: 0.1103  loss_dice_8: 0.1693  time: 0.5544  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:35] d2.utils.events INFO:  eta: 0:20:04  iter: 28119  total_loss: 2.915  loss_ce: 4.769e-05  loss_mask: 0.1095  loss_dice: 0.1681  loss_ce_0: 0.1231  loss_mask_0: 0.1088  loss_dice_0: 0.1732  loss_ce_1: 6.445e-05  loss_mask_1: 0.1101  loss_dice_1: 0.1712  loss_ce_2: 7.548e-05  loss_mask_2: 0.1089  loss_dice_2: 0.1707  loss_ce_3: 4.161e-05  loss_mask_3: 0.1115  loss_dice_3: 0.174  loss_ce_4: 5.5e-05  loss_mask_4: 0.109  loss_dice_4: 0.1685  loss_ce_5: 5.433e-05  loss_mask_5: 0.1074  loss_dice_5: 0.1739  loss_ce_6: 3.712e-05  loss_mask_6: 0.1085  loss_dice_6: 0.1653  loss_ce_7: 5.902e-05  loss_mask_7: 0.11  loss_dice_7: 0.1733  loss_ce_8: 5.927e-05  loss_mask_8: 0.1072  loss_dice_8: 0.1694  time: 0.5541  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:38] d2.utils.events INFO:  eta: 0:19:59  iter: 28139  total_loss: 2.893  loss_ce: 4.127e-05  loss_mask: 0.1136  loss_dice: 0.1652  loss_ce_0: 0.1175  loss_mask_0: 0.1121  loss_dice_0: 0.1643  loss_ce_1: 8.016e-05  loss_mask_1: 0.1138  loss_dice_1: 0.1653  loss_ce_2: 9.086e-05  loss_mask_2: 0.1133  loss_dice_2: 0.1651  loss_ce_3: 4.662e-05  loss_mask_3: 0.1104  loss_dice_3: 0.1615  loss_ce_4: 5.23e-05  loss_mask_4: 0.1118  loss_dice_4: 0.1656  loss_ce_5: 5.393e-05  loss_mask_5: 0.1124  loss_dice_5: 0.1643  loss_ce_6: 3.658e-05  loss_mask_6: 0.1084  loss_dice_6: 0.1632  loss_ce_7: 5.605e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1636  loss_ce_8: 5.939e-05  loss_mask_8: 0.1085  loss_dice_8: 0.1672  time: 0.5538  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:42] d2.utils.events INFO:  eta: 0:19:53  iter: 28159  total_loss: 3.019  loss_ce: 3.624e-05  loss_mask: 0.1135  loss_dice: 0.173  loss_ce_0: 0.1242  loss_mask_0: 0.115  loss_dice_0: 0.1782  loss_ce_1: 7.008e-05  loss_mask_1: 0.1161  loss_dice_1: 0.1705  loss_ce_2: 6.153e-05  loss_mask_2: 0.1159  loss_dice_2: 0.1749  loss_ce_3: 2.631e-05  loss_mask_3: 0.119  loss_dice_3: 0.1722  loss_ce_4: 3.915e-05  loss_mask_4: 0.1166  loss_dice_4: 0.1718  loss_ce_5: 4.525e-05  loss_mask_5: 0.1192  loss_dice_5: 0.1753  loss_ce_6: 2.615e-05  loss_mask_6: 0.118  loss_dice_6: 0.1725  loss_ce_7: 4.869e-05  loss_mask_7: 0.1187  loss_dice_7: 0.1739  loss_ce_8: 5.117e-05  loss_mask_8: 0.1118  loss_dice_8: 0.1726  time: 0.5535  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:13:45] d2.utils.events INFO:  eta: 0:19:47  iter: 28179  total_loss: 2.771  loss_ce: 3.97e-05  loss_mask: 0.1063  loss_dice: 0.159  loss_ce_0: 0.1229  loss_mask_0: 0.1056  loss_dice_0: 0.1618  loss_ce_1: 8.208e-05  loss_mask_1: 0.109  loss_dice_1: 0.1625  loss_ce_2: 7.661e-05  loss_mask_2: 0.1073  loss_dice_2: 0.1601  loss_ce_3: 4.209e-05  loss_mask_3: 0.1075  loss_dice_3: 0.1598  loss_ce_4: 5.272e-05  loss_mask_4: 0.1117  loss_dice_4: 0.1613  loss_ce_5: 6.826e-05  loss_mask_5: 0.1085  loss_dice_5: 0.1561  loss_ce_6: 3.441e-05  loss_mask_6: 0.1091  loss_dice_6: 0.1598  loss_ce_7: 5.816e-05  loss_mask_7: 0.1093  loss_dice_7: 0.1556  loss_ce_8: 7.356e-05  loss_mask_8: 0.1107  loss_dice_8: 0.1594  time: 0.5533  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:48] d2.utils.events INFO:  eta: 0:19:40  iter: 28199  total_loss: 2.883  loss_ce: 3.888e-05  loss_mask: 0.1145  loss_dice: 0.1703  loss_ce_0: 0.1237  loss_mask_0: 0.1148  loss_dice_0: 0.1726  loss_ce_1: 6.711e-05  loss_mask_1: 0.1118  loss_dice_1: 0.1676  loss_ce_2: 6.924e-05  loss_mask_2: 0.1107  loss_dice_2: 0.1603  loss_ce_3: 3.285e-05  loss_mask_3: 0.112  loss_dice_3: 0.1626  loss_ce_4: 5.093e-05  loss_mask_4: 0.112  loss_dice_4: 0.1676  loss_ce_5: 5.368e-05  loss_mask_5: 0.1119  loss_dice_5: 0.1745  loss_ce_6: 3.081e-05  loss_mask_6: 0.1107  loss_dice_6: 0.1728  loss_ce_7: 5.282e-05  loss_mask_7: 0.1071  loss_dice_7: 0.1642  loss_ce_8: 5.856e-05  loss_mask_8: 0.1157  loss_dice_8: 0.1717  time: 0.5530  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:52] d2.utils.events INFO:  eta: 0:19:34  iter: 28219  total_loss: 2.855  loss_ce: 4.407e-05  loss_mask: 0.1128  loss_dice: 0.1644  loss_ce_0: 0.1234  loss_mask_0: 0.1101  loss_dice_0: 0.1637  loss_ce_1: 9.536e-05  loss_mask_1: 0.1097  loss_dice_1: 0.1641  loss_ce_2: 8.096e-05  loss_mask_2: 0.1098  loss_dice_2: 0.1557  loss_ce_3: 3.602e-05  loss_mask_3: 0.112  loss_dice_3: 0.1646  loss_ce_4: 5.256e-05  loss_mask_4: 0.1104  loss_dice_4: 0.1608  loss_ce_5: 6.043e-05  loss_mask_5: 0.1144  loss_dice_5: 0.1706  loss_ce_6: 3.296e-05  loss_mask_6: 0.1119  loss_dice_6: 0.1656  loss_ce_7: 5.741e-05  loss_mask_7: 0.1135  loss_dice_7: 0.1645  loss_ce_8: 7.159e-05  loss_mask_8: 0.1131  loss_dice_8: 0.165  time: 0.5527  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:55] d2.utils.events INFO:  eta: 0:19:30  iter: 28239  total_loss: 2.819  loss_ce: 4.294e-05  loss_mask: 0.1063  loss_dice: 0.169  loss_ce_0: 0.1231  loss_mask_0: 0.1068  loss_dice_0: 0.1635  loss_ce_1: 7.671e-05  loss_mask_1: 0.1059  loss_dice_1: 0.1674  loss_ce_2: 8.126e-05  loss_mask_2: 0.1075  loss_dice_2: 0.1642  loss_ce_3: 3.918e-05  loss_mask_3: 0.1076  loss_dice_3: 0.1637  loss_ce_4: 5.407e-05  loss_mask_4: 0.1057  loss_dice_4: 0.1629  loss_ce_5: 6.683e-05  loss_mask_5: 0.1067  loss_dice_5: 0.1626  loss_ce_6: 3.807e-05  loss_mask_6: 0.1074  loss_dice_6: 0.1588  loss_ce_7: 5.858e-05  loss_mask_7: 0.1084  loss_dice_7: 0.1659  loss_ce_8: 6.865e-05  loss_mask_8: 0.1043  loss_dice_8: 0.1614  time: 0.5524  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:13:58] d2.utils.events INFO:  eta: 0:19:25  iter: 28259  total_loss: 2.808  loss_ce: 3.951e-05  loss_mask: 0.1068  loss_dice: 0.1599  loss_ce_0: 0.1225  loss_mask_0: 0.1066  loss_dice_0: 0.1597  loss_ce_1: 7.597e-05  loss_mask_1: 0.1069  loss_dice_1: 0.1629  loss_ce_2: 8.251e-05  loss_mask_2: 0.1087  loss_dice_2: 0.1685  loss_ce_3: 3.24e-05  loss_mask_3: 0.1064  loss_dice_3: 0.1612  loss_ce_4: 5.107e-05  loss_mask_4: 0.1067  loss_dice_4: 0.1609  loss_ce_5: 5.947e-05  loss_mask_5: 0.1058  loss_dice_5: 0.1622  loss_ce_6: 3.181e-05  loss_mask_6: 0.1075  loss_dice_6: 0.1591  loss_ce_7: 5.832e-05  loss_mask_7: 0.1112  loss_dice_7: 0.1641  loss_ce_8: 6.18e-05  loss_mask_8: 0.1091  loss_dice_8: 0.1665  time: 0.5522  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:02] d2.utils.events INFO:  eta: 0:19:19  iter: 28279  total_loss: 2.914  loss_ce: 3.724e-05  loss_mask: 0.117  loss_dice: 0.1681  loss_ce_0: 0.1238  loss_mask_0: 0.116  loss_dice_0: 0.1726  loss_ce_1: 6.574e-05  loss_mask_1: 0.1152  loss_dice_1: 0.1688  loss_ce_2: 5.87e-05  loss_mask_2: 0.1133  loss_dice_2: 0.1695  loss_ce_3: 2.594e-05  loss_mask_3: 0.1159  loss_dice_3: 0.1679  loss_ce_4: 3.59e-05  loss_mask_4: 0.1115  loss_dice_4: 0.1624  loss_ce_5: 4.4e-05  loss_mask_5: 0.1149  loss_dice_5: 0.1663  loss_ce_6: 2.711e-05  loss_mask_6: 0.1116  loss_dice_6: 0.1676  loss_ce_7: 4.67e-05  loss_mask_7: 0.1166  loss_dice_7: 0.163  loss_ce_8: 5.023e-05  loss_mask_8: 0.115  loss_dice_8: 0.1665  time: 0.5519  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:14:05] d2.utils.events INFO:  eta: 0:19:15  iter: 28299  total_loss: 2.859  loss_ce: 3.812e-05  loss_mask: 0.1088  loss_dice: 0.1647  loss_ce_0: 0.1237  loss_mask_0: 0.1096  loss_dice_0: 0.1599  loss_ce_1: 7.564e-05  loss_mask_1: 0.1162  loss_dice_1: 0.1666  loss_ce_2: 7.429e-05  loss_mask_2: 0.1113  loss_dice_2: 0.1692  loss_ce_3: 3.29e-05  loss_mask_3: 0.109  loss_dice_3: 0.163  loss_ce_4: 5.232e-05  loss_mask_4: 0.1115  loss_dice_4: 0.1647  loss_ce_5: 7.397e-05  loss_mask_5: 0.1081  loss_dice_5: 0.1614  loss_ce_6: 3.067e-05  loss_mask_6: 0.1081  loss_dice_6: 0.1639  loss_ce_7: 5.941e-05  loss_mask_7: 0.1101  loss_dice_7: 0.1662  loss_ce_8: 7.08e-05  loss_mask_8: 0.1085  loss_dice_8: 0.1626  time: 0.5516  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:09] d2.utils.events INFO:  eta: 0:19:11  iter: 28319  total_loss: 2.858  loss_ce: 3.919e-05  loss_mask: 0.113  loss_dice: 0.1748  loss_ce_0: 0.1224  loss_mask_0: 0.1103  loss_dice_0: 0.1671  loss_ce_1: 7.107e-05  loss_mask_1: 0.1098  loss_dice_1: 0.1722  loss_ce_2: 8.03e-05  loss_mask_2: 0.1085  loss_dice_2: 0.1617  loss_ce_3: 3.916e-05  loss_mask_3: 0.1094  loss_dice_3: 0.1669  loss_ce_4: 5.419e-05  loss_mask_4: 0.1123  loss_dice_4: 0.1672  loss_ce_5: 5.952e-05  loss_mask_5: 0.1085  loss_dice_5: 0.1632  loss_ce_6: 3.258e-05  loss_mask_6: 0.1077  loss_dice_6: 0.1631  loss_ce_7: 6.014e-05  loss_mask_7: 0.1079  loss_dice_7: 0.1651  loss_ce_8: 6.22e-05  loss_mask_8: 0.1084  loss_dice_8: 0.1703  time: 0.5514  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:14:12] d2.utils.events INFO:  eta: 0:19:05  iter: 28339  total_loss: 3.011  loss_ce: 4.227e-05  loss_mask: 0.1124  loss_dice: 0.1677  loss_ce_0: 0.123  loss_mask_0: 0.1097  loss_dice_0: 0.1662  loss_ce_1: 9.867e-05  loss_mask_1: 0.1142  loss_dice_1: 0.1639  loss_ce_2: 7.463e-05  loss_mask_2: 0.1155  loss_dice_2: 0.1679  loss_ce_3: 4.704e-05  loss_mask_3: 0.1137  loss_dice_3: 0.1667  loss_ce_4: 5.104e-05  loss_mask_4: 0.1171  loss_dice_4: 0.1728  loss_ce_5: 6.463e-05  loss_mask_5: 0.1129  loss_dice_5: 0.1642  loss_ce_6: 3.712e-05  loss_mask_6: 0.1113  loss_dice_6: 0.1652  loss_ce_7: 5.854e-05  loss_mask_7: 0.1133  loss_dice_7: 0.1686  loss_ce_8: 7.351e-05  loss_mask_8: 0.1122  loss_dice_8: 0.1619  time: 0.5511  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:15] d2.utils.events INFO:  eta: 0:19:01  iter: 28359  total_loss: 2.807  loss_ce: 4.6e-05  loss_mask: 0.1033  loss_dice: 0.1616  loss_ce_0: 0.1246  loss_mask_0: 0.1062  loss_dice_0: 0.1686  loss_ce_1: 6.777e-05  loss_mask_1: 0.108  loss_dice_1: 0.1617  loss_ce_2: 6.573e-05  loss_mask_2: 0.1055  loss_dice_2: 0.1599  loss_ce_3: 3.727e-05  loss_mask_3: 0.105  loss_dice_3: 0.1576  loss_ce_4: 5.1e-05  loss_mask_4: 0.1058  loss_dice_4: 0.1612  loss_ce_5: 5.198e-05  loss_mask_5: 0.1042  loss_dice_5: 0.1609  loss_ce_6: 3.799e-05  loss_mask_6: 0.1078  loss_dice_6: 0.1601  loss_ce_7: 5.028e-05  loss_mask_7: 0.1069  loss_dice_7: 0.165  loss_ce_8: 5.553e-05  loss_mask_8: 0.1076  loss_dice_8: 0.159  time: 0.5508  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:19] d2.utils.events INFO:  eta: 0:18:57  iter: 28379  total_loss: 2.929  loss_ce: 3.755e-05  loss_mask: 0.1083  loss_dice: 0.164  loss_ce_0: 0.1245  loss_mask_0: 0.1115  loss_dice_0: 0.1614  loss_ce_1: 7.203e-05  loss_mask_1: 0.109  loss_dice_1: 0.1592  loss_ce_2: 6.779e-05  loss_mask_2: 0.1102  loss_dice_2: 0.1586  loss_ce_3: 3.084e-05  loss_mask_3: 0.1093  loss_dice_3: 0.1585  loss_ce_4: 4.828e-05  loss_mask_4: 0.1088  loss_dice_4: 0.1617  loss_ce_5: 5.102e-05  loss_mask_5: 0.1135  loss_dice_5: 0.1645  loss_ce_6: 2.894e-05  loss_mask_6: 0.1081  loss_dice_6: 0.1611  loss_ce_7: 5.526e-05  loss_mask_7: 0.1116  loss_dice_7: 0.1639  loss_ce_8: 5.585e-05  loss_mask_8: 0.1119  loss_dice_8: 0.1601  time: 0.5505  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:22] d2.utils.events INFO:  eta: 0:18:52  iter: 28399  total_loss: 3.014  loss_ce: 5.257e-05  loss_mask: 0.1136  loss_dice: 0.1707  loss_ce_0: 0.1219  loss_mask_0: 0.114  loss_dice_0: 0.1722  loss_ce_1: 8.186e-05  loss_mask_1: 0.1126  loss_dice_1: 0.1716  loss_ce_2: 8.259e-05  loss_mask_2: 0.1097  loss_dice_2: 0.1708  loss_ce_3: 5.465e-05  loss_mask_3: 0.1162  loss_dice_3: 0.1718  loss_ce_4: 5.355e-05  loss_mask_4: 0.1152  loss_dice_4: 0.1741  loss_ce_5: 6.414e-05  loss_mask_5: 0.1092  loss_dice_5: 0.1691  loss_ce_6: 4.085e-05  loss_mask_6: 0.1145  loss_dice_6: 0.1688  loss_ce_7: 6.043e-05  loss_mask_7: 0.1145  loss_dice_7: 0.1667  loss_ce_8: 6.566e-05  loss_mask_8: 0.1118  loss_dice_8: 0.1708  time: 0.5503  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:25] d2.utils.events INFO:  eta: 0:18:48  iter: 28419  total_loss: 2.783  loss_ce: 5.319e-05  loss_mask: 0.1116  loss_dice: 0.1634  loss_ce_0: 0.1216  loss_mask_0: 0.1083  loss_dice_0: 0.1605  loss_ce_1: 7.607e-05  loss_mask_1: 0.1074  loss_dice_1: 0.1601  loss_ce_2: 7.884e-05  loss_mask_2: 0.1082  loss_dice_2: 0.1594  loss_ce_3: 5.862e-05  loss_mask_3: 0.1063  loss_dice_3: 0.1612  loss_ce_4: 5.325e-05  loss_mask_4: 0.1112  loss_dice_4: 0.1611  loss_ce_5: 5.748e-05  loss_mask_5: 0.114  loss_dice_5: 0.164  loss_ce_6: 4.267e-05  loss_mask_6: 0.1114  loss_dice_6: 0.1615  loss_ce_7: 5.622e-05  loss_mask_7: 0.1093  loss_dice_7: 0.1624  loss_ce_8: 5.904e-05  loss_mask_8: 0.1089  loss_dice_8: 0.1614  time: 0.5500  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:29] d2.utils.events INFO:  eta: 0:18:43  iter: 28439  total_loss: 2.847  loss_ce: 4.328e-05  loss_mask: 0.1145  loss_dice: 0.1609  loss_ce_0: 0.1232  loss_mask_0: 0.114  loss_dice_0: 0.1625  loss_ce_1: 9.491e-05  loss_mask_1: 0.1087  loss_dice_1: 0.1637  loss_ce_2: 7.265e-05  loss_mask_2: 0.1143  loss_dice_2: 0.1704  loss_ce_3: 3.265e-05  loss_mask_3: 0.1131  loss_dice_3: 0.1596  loss_ce_4: 5.303e-05  loss_mask_4: 0.1119  loss_dice_4: 0.1628  loss_ce_5: 6.482e-05  loss_mask_5: 0.1119  loss_dice_5: 0.1599  loss_ce_6: 3.122e-05  loss_mask_6: 0.1132  loss_dice_6: 0.1617  loss_ce_7: 6.253e-05  loss_mask_7: 0.1152  loss_dice_7: 0.1628  loss_ce_8: 8.444e-05  loss_mask_8: 0.1146  loss_dice_8: 0.1655  time: 0.5497  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:32] d2.utils.events INFO:  eta: 0:18:39  iter: 28459  total_loss: 2.818  loss_ce: 4.062e-05  loss_mask: 0.1096  loss_dice: 0.1627  loss_ce_0: 0.1235  loss_mask_0: 0.1086  loss_dice_0: 0.1667  loss_ce_1: 7.592e-05  loss_mask_1: 0.1106  loss_dice_1: 0.1628  loss_ce_2: 7.674e-05  loss_mask_2: 0.1046  loss_dice_2: 0.161  loss_ce_3: 4.392e-05  loss_mask_3: 0.1073  loss_dice_3: 0.1631  loss_ce_4: 4.803e-05  loss_mask_4: 0.1058  loss_dice_4: 0.1604  loss_ce_5: 5.097e-05  loss_mask_5: 0.1076  loss_dice_5: 0.1633  loss_ce_6: 3.466e-05  loss_mask_6: 0.1097  loss_dice_6: 0.1624  loss_ce_7: 5.403e-05  loss_mask_7: 0.1058  loss_dice_7: 0.1573  loss_ce_8: 5.481e-05  loss_mask_8: 0.1108  loss_dice_8: 0.1606  time: 0.5495  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:14:35] d2.utils.events INFO:  eta: 0:18:35  iter: 28479  total_loss: 2.787  loss_ce: 3.716e-05  loss_mask: 0.1077  loss_dice: 0.1614  loss_ce_0: 0.1214  loss_mask_0: 0.1028  loss_dice_0: 0.1587  loss_ce_1: 6.991e-05  loss_mask_1: 0.1078  loss_dice_1: 0.1584  loss_ce_2: 8.058e-05  loss_mask_2: 0.107  loss_dice_2: 0.1584  loss_ce_3: 4.765e-05  loss_mask_3: 0.1094  loss_dice_3: 0.159  loss_ce_4: 4.897e-05  loss_mask_4: 0.1072  loss_dice_4: 0.1572  loss_ce_5: 5.008e-05  loss_mask_5: 0.1072  loss_dice_5: 0.1599  loss_ce_6: 3.618e-05  loss_mask_6: 0.1095  loss_dice_6: 0.1663  loss_ce_7: 5.644e-05  loss_mask_7: 0.1049  loss_dice_7: 0.1603  loss_ce_8: 5.47e-05  loss_mask_8: 0.1057  loss_dice_8: 0.16  time: 0.5492  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:39] d2.utils.events INFO:  eta: 0:18:31  iter: 28499  total_loss: 2.845  loss_ce: 4.223e-05  loss_mask: 0.1063  loss_dice: 0.1671  loss_ce_0: 0.1213  loss_mask_0: 0.1093  loss_dice_0: 0.1663  loss_ce_1: 6.819e-05  loss_mask_1: 0.1096  loss_dice_1: 0.1618  loss_ce_2: 7.507e-05  loss_mask_2: 0.1076  loss_dice_2: 0.1629  loss_ce_3: 3.972e-05  loss_mask_3: 0.1076  loss_dice_3: 0.1632  loss_ce_4: 4.797e-05  loss_mask_4: 0.1095  loss_dice_4: 0.171  loss_ce_5: 4.997e-05  loss_mask_5: 0.1098  loss_dice_5: 0.1679  loss_ce_6: 3.533e-05  loss_mask_6: 0.1081  loss_dice_6: 0.1633  loss_ce_7: 5.192e-05  loss_mask_7: 0.1078  loss_dice_7: 0.1655  loss_ce_8: 5.381e-05  loss_mask_8: 0.1113  loss_dice_8: 0.1651  time: 0.5489  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:42] d2.utils.events INFO:  eta: 0:18:27  iter: 28519  total_loss: 2.874  loss_ce: 3.675e-05  loss_mask: 0.1096  loss_dice: 0.1694  loss_ce_0: 0.123  loss_mask_0: 0.108  loss_dice_0: 0.1646  loss_ce_1: 6.043e-05  loss_mask_1: 0.108  loss_dice_1: 0.1697  loss_ce_2: 6.955e-05  loss_mask_2: 0.109  loss_dice_2: 0.1733  loss_ce_3: 3.575e-05  loss_mask_3: 0.1063  loss_dice_3: 0.1646  loss_ce_4: 4.472e-05  loss_mask_4: 0.1127  loss_dice_4: 0.1715  loss_ce_5: 4.845e-05  loss_mask_5: 0.1082  loss_dice_5: 0.1696  loss_ce_6: 3.203e-05  loss_mask_6: 0.1096  loss_dice_6: 0.1656  loss_ce_7: 4.895e-05  loss_mask_7: 0.1067  loss_dice_7: 0.1616  loss_ce_8: 5.201e-05  loss_mask_8: 0.1066  loss_dice_8: 0.1658  time: 0.5487  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:46] d2.utils.events INFO:  eta: 0:18:23  iter: 28539  total_loss: 2.882  loss_ce: 3.457e-05  loss_mask: 0.1157  loss_dice: 0.1605  loss_ce_0: 0.1245  loss_mask_0: 0.1128  loss_dice_0: 0.1574  loss_ce_1: 6.867e-05  loss_mask_1: 0.1096  loss_dice_1: 0.16  loss_ce_2: 5.551e-05  loss_mask_2: 0.1165  loss_dice_2: 0.1608  loss_ce_3: 2.734e-05  loss_mask_3: 0.1166  loss_dice_3: 0.1629  loss_ce_4: 3.471e-05  loss_mask_4: 0.1087  loss_dice_4: 0.1587  loss_ce_5: 4.143e-05  loss_mask_5: 0.1118  loss_dice_5: 0.1621  loss_ce_6: 2.663e-05  loss_mask_6: 0.1149  loss_dice_6: 0.1659  loss_ce_7: 4.431e-05  loss_mask_7: 0.1178  loss_dice_7: 0.1603  loss_ce_8: 4.682e-05  loss_mask_8: 0.1151  loss_dice_8: 0.1593  time: 0.5484  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:49] d2.utils.events INFO:  eta: 0:18:19  iter: 28559  total_loss: 2.814  loss_ce: 4.16e-05  loss_mask: 0.1087  loss_dice: 0.1604  loss_ce_0: 0.1216  loss_mask_0: 0.1069  loss_dice_0: 0.1568  loss_ce_1: 7.341e-05  loss_mask_1: 0.1091  loss_dice_1: 0.1587  loss_ce_2: 7.521e-05  loss_mask_2: 0.1074  loss_dice_2: 0.1551  loss_ce_3: 4.873e-05  loss_mask_3: 0.1068  loss_dice_3: 0.1572  loss_ce_4: 5.146e-05  loss_mask_4: 0.1101  loss_dice_4: 0.1612  loss_ce_5: 6.245e-05  loss_mask_5: 0.1102  loss_dice_5: 0.1633  loss_ce_6: 3.752e-05  loss_mask_6: 0.107  loss_dice_6: 0.1593  loss_ce_7: 5.836e-05  loss_mask_7: 0.1087  loss_dice_7: 0.1606  loss_ce_8: 6.516e-05  loss_mask_8: 0.1077  loss_dice_8: 0.1598  time: 0.5481  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:52] d2.utils.events INFO:  eta: 0:18:15  iter: 28579  total_loss: 2.769  loss_ce: 3.538e-05  loss_mask: 0.1111  loss_dice: 0.1572  loss_ce_0: 0.1244  loss_mask_0: 0.1097  loss_dice_0: 0.1542  loss_ce_1: 6.687e-05  loss_mask_1: 0.1087  loss_dice_1: 0.1581  loss_ce_2: 6.486e-05  loss_mask_2: 0.1045  loss_dice_2: 0.1498  loss_ce_3: 2.915e-05  loss_mask_3: 0.1092  loss_dice_3: 0.156  loss_ce_4: 4.477e-05  loss_mask_4: 0.1078  loss_dice_4: 0.1541  loss_ce_5: 4.95e-05  loss_mask_5: 0.1063  loss_dice_5: 0.1527  loss_ce_6: 2.903e-05  loss_mask_6: 0.1072  loss_dice_6: 0.1572  loss_ce_7: 4.928e-05  loss_mask_7: 0.11  loss_dice_7: 0.1578  loss_ce_8: 5.386e-05  loss_mask_8: 0.1066  loss_dice_8: 0.1506  time: 0.5479  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:56] d2.utils.events INFO:  eta: 0:18:10  iter: 28599  total_loss: 2.843  loss_ce: 4.108e-05  loss_mask: 0.1098  loss_dice: 0.1628  loss_ce_0: 0.1217  loss_mask_0: 0.1094  loss_dice_0: 0.1647  loss_ce_1: 7.074e-05  loss_mask_1: 0.1075  loss_dice_1: 0.1687  loss_ce_2: 7.828e-05  loss_mask_2: 0.1142  loss_dice_2: 0.1647  loss_ce_3: 4.391e-05  loss_mask_3: 0.1085  loss_dice_3: 0.1585  loss_ce_4: 4.789e-05  loss_mask_4: 0.1106  loss_dice_4: 0.1578  loss_ce_5: 4.989e-05  loss_mask_5: 0.1101  loss_dice_5: 0.1596  loss_ce_6: 3.544e-05  loss_mask_6: 0.1102  loss_dice_6: 0.1666  loss_ce_7: 5.202e-05  loss_mask_7: 0.1078  loss_dice_7: 0.1649  loss_ce_8: 5.302e-05  loss_mask_8: 0.1124  loss_dice_8: 0.1682  time: 0.5476  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:14:59] d2.utils.events INFO:  eta: 0:18:06  iter: 28619  total_loss: 2.824  loss_ce: 3.795e-05  loss_mask: 0.1067  loss_dice: 0.1638  loss_ce_0: 0.1245  loss_mask_0: 0.1094  loss_dice_0: 0.1704  loss_ce_1: 6.364e-05  loss_mask_1: 0.1079  loss_dice_1: 0.1647  loss_ce_2: 6.396e-05  loss_mask_2: 0.1096  loss_dice_2: 0.1573  loss_ce_3: 3.316e-05  loss_mask_3: 0.1096  loss_dice_3: 0.1625  loss_ce_4: 4.22e-05  loss_mask_4: 0.1109  loss_dice_4: 0.1617  loss_ce_5: 5.439e-05  loss_mask_5: 0.1132  loss_dice_5: 0.1652  loss_ce_6: 2.951e-05  loss_mask_6: 0.1063  loss_dice_6: 0.1592  loss_ce_7: 4.783e-05  loss_mask_7: 0.1096  loss_dice_7: 0.1621  loss_ce_8: 5.706e-05  loss_mask_8: 0.1089  loss_dice_8: 0.1574  time: 0.5473  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:02] d2.utils.events INFO:  eta: 0:18:03  iter: 28639  total_loss: 2.759  loss_ce: 3.533e-05  loss_mask: 0.1077  loss_dice: 0.16  loss_ce_0: 0.1244  loss_mask_0: 0.1055  loss_dice_0: 0.1608  loss_ce_1: 5.249e-05  loss_mask_1: 0.1048  loss_dice_1: 0.1546  loss_ce_2: 5.52e-05  loss_mask_2: 0.11  loss_dice_2: 0.1582  loss_ce_3: 2.892e-05  loss_mask_3: 0.1064  loss_dice_3: 0.1561  loss_ce_4: 3.545e-05  loss_mask_4: 0.1045  loss_dice_4: 0.1537  loss_ce_5: 4.113e-05  loss_mask_5: 0.1072  loss_dice_5: 0.1588  loss_ce_6: 2.784e-05  loss_mask_6: 0.1097  loss_dice_6: 0.158  loss_ce_7: 4.341e-05  loss_mask_7: 0.1049  loss_dice_7: 0.157  loss_ce_8: 4.596e-05  loss_mask_8: 0.1066  loss_dice_8: 0.1589  time: 0.5471  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:15:06] d2.utils.events INFO:  eta: 0:17:59  iter: 28659  total_loss: 2.875  loss_ce: 3.89e-05  loss_mask: 0.1134  loss_dice: 0.1678  loss_ce_0: 0.1228  loss_mask_0: 0.1109  loss_dice_0: 0.164  loss_ce_1: 6.605e-05  loss_mask_1: 0.1135  loss_dice_1: 0.1637  loss_ce_2: 6.884e-05  loss_mask_2: 0.1112  loss_dice_2: 0.1652  loss_ce_3: 3.649e-05  loss_mask_3: 0.1113  loss_dice_3: 0.1647  loss_ce_4: 4.823e-05  loss_mask_4: 0.1112  loss_dice_4: 0.1602  loss_ce_5: 6.143e-05  loss_mask_5: 0.1127  loss_dice_5: 0.1656  loss_ce_6: 3.593e-05  loss_mask_6: 0.1108  loss_dice_6: 0.1605  loss_ce_7: 4.972e-05  loss_mask_7: 0.1105  loss_dice_7: 0.1604  loss_ce_8: 5.954e-05  loss_mask_8: 0.1072  loss_dice_8: 0.1602  time: 0.5468  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:15:09] d2.utils.events INFO:  eta: 0:17:55  iter: 28679  total_loss: 2.909  loss_ce: 3.474e-05  loss_mask: 0.112  loss_dice: 0.1657  loss_ce_0: 0.125  loss_mask_0: 0.1107  loss_dice_0: 0.1664  loss_ce_1: 8.128e-05  loss_mask_1: 0.1099  loss_dice_1: 0.1678  loss_ce_2: 6.21e-05  loss_mask_2: 0.1066  loss_dice_2: 0.1671  loss_ce_3: 3.045e-05  loss_mask_3: 0.109  loss_dice_3: 0.1632  loss_ce_4: 4.543e-05  loss_mask_4: 0.1102  loss_dice_4: 0.1642  loss_ce_5: 4.833e-05  loss_mask_5: 0.1104  loss_dice_5: 0.1662  loss_ce_6: 2.916e-05  loss_mask_6: 0.1107  loss_dice_6: 0.1609  loss_ce_7: 4.991e-05  loss_mask_7: 0.1091  loss_dice_7: 0.1638  loss_ce_8: 5.178e-05  loss_mask_8: 0.1136  loss_dice_8: 0.1685  time: 0.5465  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:12] d2.utils.events INFO:  eta: 0:17:51  iter: 28699  total_loss: 2.909  loss_ce: 3.472e-05  loss_mask: 0.1091  loss_dice: 0.1632  loss_ce_0: 0.1248  loss_mask_0: 0.1114  loss_dice_0: 0.168  loss_ce_1: 5.334e-05  loss_mask_1: 0.1115  loss_dice_1: 0.1684  loss_ce_2: 4.584e-05  loss_mask_2: 0.1106  loss_dice_2: 0.17  loss_ce_3: 2.136e-05  loss_mask_3: 0.1102  loss_dice_3: 0.1673  loss_ce_4: 2.282e-05  loss_mask_4: 0.1114  loss_dice_4: 0.1645  loss_ce_5: 3.271e-05  loss_mask_5: 0.1105  loss_dice_5: 0.1666  loss_ce_6: 2.24e-05  loss_mask_6: 0.1105  loss_dice_6: 0.1603  loss_ce_7: 4.049e-05  loss_mask_7: 0.1141  loss_dice_7: 0.1782  loss_ce_8: 3.956e-05  loss_mask_8: 0.1071  loss_dice_8: 0.1612  time: 0.5463  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:16] d2.utils.events INFO:  eta: 0:17:47  iter: 28719  total_loss: 2.9  loss_ce: 3.527e-05  loss_mask: 0.1082  loss_dice: 0.165  loss_ce_0: 0.121  loss_mask_0: 0.109  loss_dice_0: 0.1674  loss_ce_1: 6.874e-05  loss_mask_1: 0.1068  loss_dice_1: 0.1663  loss_ce_2: 7.637e-05  loss_mask_2: 0.1113  loss_dice_2: 0.166  loss_ce_3: 2.802e-05  loss_mask_3: 0.1119  loss_dice_3: 0.171  loss_ce_4: 4.958e-05  loss_mask_4: 0.1061  loss_dice_4: 0.1606  loss_ce_5: 7.416e-05  loss_mask_5: 0.1113  loss_dice_5: 0.1694  loss_ce_6: 2.818e-05  loss_mask_6: 0.1083  loss_dice_6: 0.1654  loss_ce_7: 5.617e-05  loss_mask_7: 0.1112  loss_dice_7: 0.1741  loss_ce_8: 6.629e-05  loss_mask_8: 0.109  loss_dice_8: 0.1743  time: 0.5460  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:19] d2.utils.events INFO:  eta: 0:17:43  iter: 28739  total_loss: 2.883  loss_ce: 3.591e-05  loss_mask: 0.1051  loss_dice: 0.1582  loss_ce_0: 0.1227  loss_mask_0: 0.1095  loss_dice_0: 0.1643  loss_ce_1: 7.549e-05  loss_mask_1: 0.1079  loss_dice_1: 0.1713  loss_ce_2: 6.744e-05  loss_mask_2: 0.1104  loss_dice_2: 0.1714  loss_ce_3: 3.001e-05  loss_mask_3: 0.1097  loss_dice_3: 0.1665  loss_ce_4: 4.481e-05  loss_mask_4: 0.1069  loss_dice_4: 0.1616  loss_ce_5: 5.342e-05  loss_mask_5: 0.1057  loss_dice_5: 0.1639  loss_ce_6: 2.854e-05  loss_mask_6: 0.1043  loss_dice_6: 0.1657  loss_ce_7: 5.378e-05  loss_mask_7: 0.1062  loss_dice_7: 0.1597  loss_ce_8: 5.863e-05  loss_mask_8: 0.109  loss_dice_8: 0.1694  time: 0.5457  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:22] d2.utils.events INFO:  eta: 0:17:39  iter: 28759  total_loss: 2.867  loss_ce: 4.808e-05  loss_mask: 0.1121  loss_dice: 0.1648  loss_ce_0: 0.1247  loss_mask_0: 0.1102  loss_dice_0: 0.1649  loss_ce_1: 6.421e-05  loss_mask_1: 0.1102  loss_dice_1: 0.1621  loss_ce_2: 6.146e-05  loss_mask_2: 0.1135  loss_dice_2: 0.1649  loss_ce_3: 4.868e-05  loss_mask_3: 0.1125  loss_dice_3: 0.1595  loss_ce_4: 4.648e-05  loss_mask_4: 0.1151  loss_dice_4: 0.1614  loss_ce_5: 5.834e-05  loss_mask_5: 0.1154  loss_dice_5: 0.1665  loss_ce_6: 3.783e-05  loss_mask_6: 0.1166  loss_dice_6: 0.1624  loss_ce_7: 4.719e-05  loss_mask_7: 0.1131  loss_dice_7: 0.1603  loss_ce_8: 6.431e-05  loss_mask_8: 0.1128  loss_dice_8: 0.1618  time: 0.5455  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:26] d2.utils.events INFO:  eta: 0:17:36  iter: 28779  total_loss: 3.046  loss_ce: 3.435e-05  loss_mask: 0.1136  loss_dice: 0.1733  loss_ce_0: 0.1231  loss_mask_0: 0.1145  loss_dice_0: 0.1742  loss_ce_1: 6.816e-05  loss_mask_1: 0.1126  loss_dice_1: 0.1744  loss_ce_2: 6.672e-05  loss_mask_2: 0.1152  loss_dice_2: 0.1724  loss_ce_3: 3.14e-05  loss_mask_3: 0.1165  loss_dice_3: 0.1785  loss_ce_4: 4.586e-05  loss_mask_4: 0.1144  loss_dice_4: 0.1743  loss_ce_5: 6.082e-05  loss_mask_5: 0.1162  loss_dice_5: 0.1763  loss_ce_6: 2.918e-05  loss_mask_6: 0.1111  loss_dice_6: 0.1715  loss_ce_7: 5.196e-05  loss_mask_7: 0.1177  loss_dice_7: 0.1797  loss_ce_8: 6.503e-05  loss_mask_8: 0.1095  loss_dice_8: 0.1731  time: 0.5452  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:15:29] d2.utils.events INFO:  eta: 0:17:32  iter: 28799  total_loss: 2.924  loss_ce: 4.666e-05  loss_mask: 0.1088  loss_dice: 0.1658  loss_ce_0: 0.1164  loss_mask_0: 0.1073  loss_dice_0: 0.1705  loss_ce_1: 7.569e-05  loss_mask_1: 0.1096  loss_dice_1: 0.1676  loss_ce_2: 7.832e-05  loss_mask_2: 0.107  loss_dice_2: 0.1701  loss_ce_3: 4.679e-05  loss_mask_3: 0.107  loss_dice_3: 0.1673  loss_ce_4: 4.87e-05  loss_mask_4: 0.107  loss_dice_4: 0.1665  loss_ce_5: 6.56e-05  loss_mask_5: 0.1064  loss_dice_5: 0.1662  loss_ce_6: 3.733e-05  loss_mask_6: 0.1096  loss_dice_6: 0.1681  loss_ce_7: 5.474e-05  loss_mask_7: 0.1079  loss_dice_7: 0.1672  loss_ce_8: 6.789e-05  loss_mask_8: 0.1105  loss_dice_8: 0.1697  time: 0.5450  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:33] d2.utils.events INFO:  eta: 0:17:28  iter: 28819  total_loss: 2.801  loss_ce: 3.398e-05  loss_mask: 0.1069  loss_dice: 0.1647  loss_ce_0: 0.1238  loss_mask_0: 0.1064  loss_dice_0: 0.1697  loss_ce_1: 6.973e-05  loss_mask_1: 0.1042  loss_dice_1: 0.1655  loss_ce_2: 6.899e-05  loss_mask_2: 0.1088  loss_dice_2: 0.1661  loss_ce_3: 3.523e-05  loss_mask_3: 0.1071  loss_dice_3: 0.1683  loss_ce_4: 4.375e-05  loss_mask_4: 0.1071  loss_dice_4: 0.1634  loss_ce_5: 4.818e-05  loss_mask_5: 0.1038  loss_dice_5: 0.1561  loss_ce_6: 2.964e-05  loss_mask_6: 0.1078  loss_dice_6: 0.1625  loss_ce_7: 4.88e-05  loss_mask_7: 0.1031  loss_dice_7: 0.1596  loss_ce_8: 5.108e-05  loss_mask_8: 0.1073  loss_dice_8: 0.1708  time: 0.5447  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:36] d2.utils.events INFO:  eta: 0:17:25  iter: 28839  total_loss: 2.8  loss_ce: 3.193e-05  loss_mask: 0.1089  loss_dice: 0.1595  loss_ce_0: 0.1248  loss_mask_0: 0.1077  loss_dice_0: 0.167  loss_ce_1: 6.058e-05  loss_mask_1: 0.1068  loss_dice_1: 0.1646  loss_ce_2: 5.952e-05  loss_mask_2: 0.1062  loss_dice_2: 0.1609  loss_ce_3: 2.772e-05  loss_mask_3: 0.1057  loss_dice_3: 0.1647  loss_ce_4: 4.257e-05  loss_mask_4: 0.1068  loss_dice_4: 0.1604  loss_ce_5: 4.732e-05  loss_mask_5: 0.1058  loss_dice_5: 0.1592  loss_ce_6: 2.713e-05  loss_mask_6: 0.1062  loss_dice_6: 0.1636  loss_ce_7: 4.8e-05  loss_mask_7: 0.1105  loss_dice_7: 0.1656  loss_ce_8: 4.992e-05  loss_mask_8: 0.1087  loss_dice_8: 0.1645  time: 0.5444  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:39] d2.utils.events INFO:  eta: 0:17:21  iter: 28859  total_loss: 2.832  loss_ce: 3.521e-05  loss_mask: 0.1064  loss_dice: 0.16  loss_ce_0: 0.1246  loss_mask_0: 0.1097  loss_dice_0: 0.1592  loss_ce_1: 6.585e-05  loss_mask_1: 0.1069  loss_dice_1: 0.157  loss_ce_2: 5.811e-05  loss_mask_2: 0.1112  loss_dice_2: 0.1605  loss_ce_3: 4.152e-05  loss_mask_3: 0.1086  loss_dice_3: 0.1579  loss_ce_4: 4.23e-05  loss_mask_4: 0.1085  loss_dice_4: 0.1562  loss_ce_5: 4.71e-05  loss_mask_5: 0.1099  loss_dice_5: 0.1565  loss_ce_6: 3.288e-05  loss_mask_6: 0.1093  loss_dice_6: 0.1555  loss_ce_7: 4.556e-05  loss_mask_7: 0.1075  loss_dice_7: 0.1615  loss_ce_8: 4.94e-05  loss_mask_8: 0.1096  loss_dice_8: 0.162  time: 0.5442  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:15:43] d2.utils.events INFO:  eta: 0:17:17  iter: 28879  total_loss: 2.864  loss_ce: 4.435e-05  loss_mask: 0.1106  loss_dice: 0.1694  loss_ce_0: 0.1249  loss_mask_0: 0.1054  loss_dice_0: 0.165  loss_ce_1: 5.266e-05  loss_mask_1: 0.1102  loss_dice_1: 0.1712  loss_ce_2: 5.828e-05  loss_mask_2: 0.1094  loss_dice_2: 0.1664  loss_ce_3: 3.901e-05  loss_mask_3: 0.1083  loss_dice_3: 0.1637  loss_ce_4: 4.243e-05  loss_mask_4: 0.105  loss_dice_4: 0.1622  loss_ce_5: 4.723e-05  loss_mask_5: 0.1059  loss_dice_5: 0.1632  loss_ce_6: 3.38e-05  loss_mask_6: 0.1066  loss_dice_6: 0.1663  loss_ce_7: 4.845e-05  loss_mask_7: 0.1068  loss_dice_7: 0.1641  loss_ce_8: 4.929e-05  loss_mask_8: 0.1075  loss_dice_8: 0.1635  time: 0.5439  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:46] d2.utils.events INFO:  eta: 0:17:13  iter: 28899  total_loss: 2.889  loss_ce: 3.358e-05  loss_mask: 0.1059  loss_dice: 0.1631  loss_ce_0: 0.1249  loss_mask_0: 0.1072  loss_dice_0: 0.1683  loss_ce_1: 6.969e-05  loss_mask_1: 0.1088  loss_dice_1: 0.173  loss_ce_2: 5.803e-05  loss_mask_2: 0.1098  loss_dice_2: 0.1774  loss_ce_3: 2.722e-05  loss_mask_3: 0.1126  loss_dice_3: 0.1707  loss_ce_4: 4.463e-05  loss_mask_4: 0.114  loss_dice_4: 0.1754  loss_ce_5: 5.816e-05  loss_mask_5: 0.1118  loss_dice_5: 0.1704  loss_ce_6: 2.727e-05  loss_mask_6: 0.1103  loss_dice_6: 0.1707  loss_ce_7: 4.739e-05  loss_mask_7: 0.1097  loss_dice_7: 0.1669  loss_ce_8: 6.78e-05  loss_mask_8: 0.1127  loss_dice_8: 0.172  time: 0.5437  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:49] d2.utils.events INFO:  eta: 0:17:09  iter: 28919  total_loss: 2.861  loss_ce: 4.518e-05  loss_mask: 0.1097  loss_dice: 0.1651  loss_ce_0: 0.1229  loss_mask_0: 0.1074  loss_dice_0: 0.1671  loss_ce_1: 6.504e-05  loss_mask_1: 0.1143  loss_dice_1: 0.1682  loss_ce_2: 7.213e-05  loss_mask_2: 0.1097  loss_dice_2: 0.1687  loss_ce_3: 4.923e-05  loss_mask_3: 0.11  loss_dice_3: 0.1647  loss_ce_4: 4.535e-05  loss_mask_4: 0.1106  loss_dice_4: 0.1635  loss_ce_5: 4.7e-05  loss_mask_5: 0.1106  loss_dice_5: 0.169  loss_ce_6: 3.811e-05  loss_mask_6: 0.1091  loss_dice_6: 0.1657  loss_ce_7: 4.854e-05  loss_mask_7: 0.1135  loss_dice_7: 0.1649  loss_ce_8: 4.989e-05  loss_mask_8: 0.1097  loss_dice_8: 0.1637  time: 0.5434  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:53] d2.utils.events INFO:  eta: 0:17:05  iter: 28939  total_loss: 2.907  loss_ce: 3.395e-05  loss_mask: 0.1119  loss_dice: 0.1696  loss_ce_0: 0.1237  loss_mask_0: 0.1116  loss_dice_0: 0.1663  loss_ce_1: 6.345e-05  loss_mask_1: 0.1095  loss_dice_1: 0.1681  loss_ce_2: 6.541e-05  loss_mask_2: 0.1098  loss_dice_2: 0.1651  loss_ce_3: 3.433e-05  loss_mask_3: 0.1126  loss_dice_3: 0.1666  loss_ce_4: 4.214e-05  loss_mask_4: 0.1068  loss_dice_4: 0.1631  loss_ce_5: 4.613e-05  loss_mask_5: 0.1142  loss_dice_5: 0.1639  loss_ce_6: 3.06e-05  loss_mask_6: 0.1136  loss_dice_6: 0.1669  loss_ce_7: 4.579e-05  loss_mask_7: 0.1118  loss_dice_7: 0.165  loss_ce_8: 4.828e-05  loss_mask_8: 0.1122  loss_dice_8: 0.1674  time: 0.5431  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:56] d2.utils.events INFO:  eta: 0:17:01  iter: 28959  total_loss: 3.017  loss_ce: 3.163e-05  loss_mask: 0.1169  loss_dice: 0.1745  loss_ce_0: 0.1231  loss_mask_0: 0.1168  loss_dice_0: 0.1713  loss_ce_1: 6.039e-05  loss_mask_1: 0.114  loss_dice_1: 0.1809  loss_ce_2: 7.066e-05  loss_mask_2: 0.1139  loss_dice_2: 0.1733  loss_ce_3: 2.427e-05  loss_mask_3: 0.114  loss_dice_3: 0.1778  loss_ce_4: 4.312e-05  loss_mask_4: 0.1166  loss_dice_4: 0.1764  loss_ce_5: 4.604e-05  loss_mask_5: 0.116  loss_dice_5: 0.1719  loss_ce_6: 2.532e-05  loss_mask_6: 0.1131  loss_dice_6: 0.1732  loss_ce_7: 4.787e-05  loss_mask_7: 0.1148  loss_dice_7: 0.1696  loss_ce_8: 5.056e-05  loss_mask_8: 0.1129  loss_dice_8: 0.1786  time: 0.5429  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:15:59] d2.utils.events INFO:  eta: 0:16:57  iter: 28979  total_loss: 2.856  loss_ce: 3.257e-05  loss_mask: 0.1086  loss_dice: 0.1617  loss_ce_0: 0.1269  loss_mask_0: 0.108  loss_dice_0: 0.1571  loss_ce_1: 7.088e-05  loss_mask_1: 0.1074  loss_dice_1: 0.1669  loss_ce_2: 5.827e-05  loss_mask_2: 0.1077  loss_dice_2: 0.1668  loss_ce_3: 2.444e-05  loss_mask_3: 0.1097  loss_dice_3: 0.1633  loss_ce_4: 4.222e-05  loss_mask_4: 0.1084  loss_dice_4: 0.1645  loss_ce_5: 4.577e-05  loss_mask_5: 0.1095  loss_dice_5: 0.1603  loss_ce_6: 2.562e-05  loss_mask_6: 0.1056  loss_dice_6: 0.1593  loss_ce_7: 4.499e-05  loss_mask_7: 0.1089  loss_dice_7: 0.16  loss_ce_8: 5.106e-05  loss_mask_8: 0.1069  loss_dice_8: 0.1645  time: 0.5426  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:16:03] d2.utils.events INFO:  eta: 0:16:54  iter: 28999  total_loss: 2.777  loss_ce: 3.29e-05  loss_mask: 0.1101  loss_dice: 0.1643  loss_ce_0: 0.1238  loss_mask_0: 0.106  loss_dice_0: 0.1547  loss_ce_1: 4.899e-05  loss_mask_1: 0.1127  loss_dice_1: 0.1619  loss_ce_2: 4.957e-05  loss_mask_2: 0.1104  loss_dice_2: 0.1612  loss_ce_3: 2.285e-05  loss_mask_3: 0.1116  loss_dice_3: 0.1589  loss_ce_4: 3.146e-05  loss_mask_4: 0.113  loss_dice_4: 0.1554  loss_ce_5: 3.76e-05  loss_mask_5: 0.1067  loss_dice_5: 0.1562  loss_ce_6: 2.33e-05  loss_mask_6: 0.108  loss_dice_6: 0.1625  loss_ce_7: 4.055e-05  loss_mask_7: 0.1086  loss_dice_7: 0.1593  loss_ce_8: 4.246e-05  loss_mask_8: 0.1087  loss_dice_8: 0.1556  time: 0.5424  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:16:06] d2.utils.events INFO:  eta: 0:16:50  iter: 29019  total_loss: 2.829  loss_ce: 3.846e-05  loss_mask: 0.1085  loss_dice: 0.1658  loss_ce_0: 0.1237  loss_mask_0: 0.1078  loss_dice_0: 0.167  loss_ce_1: 6.285e-05  loss_mask_1: 0.111  loss_dice_1: 0.1672  loss_ce_2: 7.101e-05  loss_mask_2: 0.1089  loss_dice_2: 0.1667  loss_ce_3: 4.118e-05  loss_mask_3: 0.1108  loss_dice_3: 0.1677  loss_ce_4: 4.382e-05  loss_mask_4: 0.1051  loss_dice_4: 0.1598  loss_ce_5: 4.716e-05  loss_mask_5: 0.1072  loss_dice_5: 0.1685  loss_ce_6: 3.347e-05  loss_mask_6: 0.1065  loss_dice_6: 0.1614  loss_ce_7: 5.048e-05  loss_mask_7: 0.1038  loss_dice_7: 0.1647  loss_ce_8: 4.843e-05  loss_mask_8: 0.1078  loss_dice_8: 0.1654  time: 0.5421  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:16:09] d2.utils.events INFO:  eta: 0:16:46  iter: 29039  total_loss: 2.803  loss_ce: 3.254e-05  loss_mask: 0.1094  loss_dice: 0.1683  loss_ce_0: 0.1237  loss_mask_0: 0.111  loss_dice_0: 0.1642  loss_ce_1: 5.819e-05  loss_mask_1: 0.1052  loss_dice_1: 0.1627  loss_ce_2: 5.806e-05  loss_mask_2: 0.11  loss_dice_2: 0.1647  loss_ce_3: 3.078e-05  loss_mask_3: 0.1052  loss_dice_3: 0.1598  loss_ce_4: 4.023e-05  loss_mask_4: 0.1079  loss_dice_4: 0.166  loss_ce_5: 5.147e-05  loss_mask_5: 0.1056  loss_dice_5: 0.1559  loss_ce_6: 2.762e-05  loss_mask_6: 0.1078  loss_dice_6: 0.1634  loss_ce_7: 4.263e-05  loss_mask_7: 0.1111  loss_dice_7: 0.1588  loss_ce_8: 5.321e-05  loss_mask_8: 0.1109  loss_dice_8: 0.1694  time: 0.5418  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:16:13] d2.utils.events INFO:  eta: 0:16:42  iter: 29059  total_loss: 2.833  loss_ce: 3.379e-05  loss_mask: 0.1107  loss_dice: 0.1669  loss_ce_0: 0.1236  loss_mask_0: 0.1112  loss_dice_0: 0.164  loss_ce_1: 6.256e-05  loss_mask_1: 0.1093  loss_dice_1: 0.1649  loss_ce_2: 6.292e-05  loss_mask_2: 0.1113  loss_dice_2: 0.162  loss_ce_3: 3.792e-05  loss_mask_3: 0.1064  loss_dice_3: 0.1578  loss_ce_4: 4.249e-05  loss_mask_4: 0.1077  loss_dice_4: 0.1574  loss_ce_5: 5.566e-05  loss_mask_5: 0.1112  loss_dice_5: 0.1608  loss_ce_6: 3.232e-05  loss_mask_6: 0.1093  loss_dice_6: 0.1613  loss_ce_7: 4.552e-05  loss_mask_7: 0.1102  loss_dice_7: 0.1634  loss_ce_8: 5.86e-05  loss_mask_8: 0.1091  loss_dice_8: 0.1664  time: 0.5416  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:16:16] d2.utils.events INFO:  eta: 0:16:38  iter: 29079  total_loss: 2.828  loss_ce: 3.131e-05  loss_mask: 0.1085  loss_dice: 0.1609  loss_ce_0: 0.1247  loss_mask_0: 0.1136  loss_dice_0: 0.1688  loss_ce_1: 4.224e-05  loss_mask_1: 0.1054  loss_dice_1: 0.1614  loss_ce_2: 4.133e-05  loss_mask_2: 0.106  loss_dice_2: 0.1605  loss_ce_3: 2.56e-05  loss_mask_3: 0.1088  loss_dice_3: 0.162  loss_ce_4: 2.892e-05  loss_mask_4: 0.1078  loss_dice_4: 0.1673  loss_ce_5: 3.041e-05  loss_mask_5: 0.1078  loss_dice_5: 0.1605  loss_ce_6: 2.615e-05  loss_mask_6: 0.109  loss_dice_6: 0.1636  loss_ce_7: 3.409e-05  loss_mask_7: 0.1091  loss_dice_7: 0.1609  loss_ce_8: 3.696e-05  loss_mask_8: 0.1113  loss_dice_8: 0.1636  time: 0.5413  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:16:20] d2.utils.events INFO:  eta: 0:16:34  iter: 29099  total_loss: 2.873  loss_ce: 3.019e-05  loss_mask: 0.1123  loss_dice: 0.1586  loss_ce_0: 0.1241  loss_mask_0: 0.1106  loss_dice_0: 0.1673  loss_ce_1: 5.033e-05  loss_mask_1: 0.1089  loss_dice_1: 0.1569  loss_ce_2: 4.843e-05  loss_mask_2: 0.1094  loss_dice_2: 0.1562  loss_ce_3: 2.464e-05  loss_mask_3: 0.1128  loss_dice_3: 0.1594  loss_ce_4: 3.382e-05  loss_mask_4: 0.1095  loss_dice_4: 0.1656  loss_ce_5: 3.74e-05  loss_mask_5: 0.1129  loss_dice_5: 0.164  loss_ce_6: 2.547e-05  loss_mask_6: 0.1117  loss_dice_6: 0.1642  loss_ce_7: 3.735e-05  loss_mask_7: 0.1137  loss_dice_7: 0.1653  loss_ce_8: 4.175e-05  loss_mask_8: 0.1117  loss_dice_8: 0.1598  time: 0.5411  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:16:23] d2.utils.events INFO:  eta: 0:16:31  iter: 29119  total_loss: 2.82  loss_ce: 2.988e-05  loss_mask: 0.1085  loss_dice: 0.1638  loss_ce_0: 0.1233  loss_mask_0: 0.1098  loss_dice_0: 0.1705  loss_ce_1: 5.034e-05  loss_mask_1: 0.1059  loss_dice_1: 0.1595  loss_ce_2: 4.722e-05  loss_mask_2: 0.1087  loss_dice_2: 0.1626  loss_ce_3: 2.312e-05  loss_mask_3: 0.1082  loss_dice_3: 0.1643  loss_ce_4: 2.863e-05  loss_mask_4: 0.107  loss_dice_4: 0.1578  loss_ce_5: 3.829e-05  loss_mask_5: 0.107  loss_dice_5: 0.1631  loss_ce_6: 2.546e-05  loss_mask_6: 0.1042  loss_dice_6: 0.1585  loss_ce_7: 3.628e-05  loss_mask_7: 0.1095  loss_dice_7: 0.1592  loss_ce_8: 4.078e-05  loss_mask_8: 0.1074  loss_dice_8: 0.1607  time: 0.5408  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:16:26] d2.utils.events INFO:  eta: 0:16:27  iter: 29139  total_loss: 2.933  loss_ce: 3.986e-05  loss_mask: 0.112  loss_dice: 0.1686  loss_ce_0: 0.1225  loss_mask_0: 0.1108  loss_dice_0: 0.1737  loss_ce_1: 6.332e-05  loss_mask_1: 0.11  loss_dice_1: 0.1658  loss_ce_2: 6.546e-05  loss_mask_2: 0.1124  loss_dice_2: 0.1693  loss_ce_3: 4.24e-05  loss_mask_3: 0.107  loss_dice_3: 0.1678  loss_ce_4: 4.234e-05  loss_mask_4: 0.1144  loss_dice_4: 0.1625  loss_ce_5: 5.075e-05  loss_mask_5: 0.1112  loss_dice_5: 0.171  loss_ce_6: 3.377e-05  loss_mask_6: 0.1087  loss_dice_6: 0.1684  loss_ce_7: 4.65e-05  loss_mask_7: 0.1117  loss_dice_7: 0.1661  loss_ce_8: 5.166e-05  loss_mask_8: 0.1136  loss_dice_8: 0.1705  time: 0.5406  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:16:30] d2.utils.events INFO:  eta: 0:16:23  iter: 29159  total_loss: 2.802  loss_ce: 3.412e-05  loss_mask: 0.1061  loss_dice: 0.164  loss_ce_0: 0.1237  loss_mask_0: 0.1072  loss_dice_0: 0.1626  loss_ce_1: 6.261e-05  loss_mask_1: 0.1044  loss_dice_1: 0.1601  loss_ce_2: 6.712e-05  loss_mask_2: 0.1054  loss_dice_2: 0.1638  loss_ce_3: 4.129e-05  loss_mask_3: 0.1111  loss_dice_3: 0.1658  loss_ce_4: 4.246e-05  loss_mask_4: 0.105  loss_dice_4: 0.1574  loss_ce_5: 4.451e-05  loss_mask_5: 0.1072  loss_dice_5: 0.1628  loss_ce_6: 3.181e-05  loss_mask_6: 0.1091  loss_dice_6: 0.1562  loss_ce_7: 4.545e-05  loss_mask_7: 0.1064  loss_dice_7: 0.1585  loss_ce_8: 4.827e-05  loss_mask_8: 0.1098  loss_dice_8: 0.1587  time: 0.5403  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:16:33] d2.utils.events INFO:  eta: 0:16:20  iter: 29179  total_loss: 2.841  loss_ce: 3.542e-05  loss_mask: 0.1093  loss_dice: 0.1635  loss_ce_0: 0.1246  loss_mask_0: 0.1076  loss_dice_0: 0.1613  loss_ce_1: 5.78e-05  loss_mask_1: 0.1058  loss_dice_1: 0.164  loss_ce_2: 5.665e-05  loss_mask_2: 0.1074  loss_dice_2: 0.1629  loss_ce_3: 3.773e-05  loss_mask_3: 0.1082  loss_dice_3: 0.1668  loss_ce_4: 4.17e-05  loss_mask_4: 0.1105  loss_dice_4: 0.1583  loss_ce_5: 5.024e-05  loss_mask_5: 0.1107  loss_dice_5: 0.1643  loss_ce_6: 2.959e-05  loss_mask_6: 0.1073  loss_dice_6: 0.1592  loss_ce_7: 4.326e-05  loss_mask_7: 0.1102  loss_dice_7: 0.1594  loss_ce_8: 5.265e-05  loss_mask_8: 0.1108  loss_dice_8: 0.1658  time: 0.5400  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:16:36] d2.utils.events INFO:  eta: 0:16:16  iter: 29199  total_loss: 2.904  loss_ce: 3.391e-05  loss_mask: 0.1127  loss_dice: 0.1744  loss_ce_0: 0.1236  loss_mask_0: 0.1135  loss_dice_0: 0.1692  loss_ce_1: 5.508e-05  loss_mask_1: 0.1143  loss_dice_1: 0.1668  loss_ce_2: 6.023e-05  loss_mask_2: 0.113  loss_dice_2: 0.1668  loss_ce_3: 3.762e-05  loss_mask_3: 0.1115  loss_dice_3: 0.1656  loss_ce_4: 4.135e-05  loss_mask_4: 0.1133  loss_dice_4: 0.162  loss_ce_5: 4.405e-05  loss_mask_5: 0.1167  loss_dice_5: 0.1732  loss_ce_6: 3.071e-05  loss_mask_6: 0.1122  loss_dice_6: 0.1716  loss_ce_7: 4.256e-05  loss_mask_7: 0.1093  loss_dice_7: 0.1681  loss_ce_8: 4.681e-05  loss_mask_8: 0.1146  loss_dice_8: 0.1692  time: 0.5398  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:16:40] d2.utils.events INFO:  eta: 0:16:13  iter: 29219  total_loss: 3.045  loss_ce: 3.181e-05  loss_mask: 0.1134  loss_dice: 0.1768  loss_ce_0: 0.1236  loss_mask_0: 0.1129  loss_dice_0: 0.1737  loss_ce_1: 5.927e-05  loss_mask_1: 0.1101  loss_dice_1: 0.1766  loss_ce_2: 5.499e-05  loss_mask_2: 0.1162  loss_dice_2: 0.1859  loss_ce_3: 2.488e-05  loss_mask_3: 0.1172  loss_dice_3: 0.1723  loss_ce_4: 3.943e-05  loss_mask_4: 0.1138  loss_dice_4: 0.1727  loss_ce_5: 4.37e-05  loss_mask_5: 0.1133  loss_dice_5: 0.1714  loss_ce_6: 2.549e-05  loss_mask_6: 0.1128  loss_dice_6: 0.1727  loss_ce_7: 4.516e-05  loss_mask_7: 0.1131  loss_dice_7: 0.1744  loss_ce_8: 4.649e-05  loss_mask_8: 0.1147  loss_dice_8: 0.1812  time: 0.5395  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:16:43] d2.utils.events INFO:  eta: 0:16:09  iter: 29239  total_loss: 2.871  loss_ce: 3.159e-05  loss_mask: 0.1076  loss_dice: 0.1616  loss_ce_0: 0.1239  loss_mask_0: 0.1085  loss_dice_0: 0.1632  loss_ce_1: 5.645e-05  loss_mask_1: 0.1074  loss_dice_1: 0.1628  loss_ce_2: 5.573e-05  loss_mask_2: 0.1058  loss_dice_2: 0.1652  loss_ce_3: 2.659e-05  loss_mask_3: 0.1067  loss_dice_3: 0.1611  loss_ce_4: 4.029e-05  loss_mask_4: 0.1102  loss_dice_4: 0.1617  loss_ce_5: 4.367e-05  loss_mask_5: 0.1069  loss_dice_5: 0.1623  loss_ce_6: 2.635e-05  loss_mask_6: 0.1116  loss_dice_6: 0.1649  loss_ce_7: 4.358e-05  loss_mask_7: 0.1059  loss_dice_7: 0.1639  loss_ce_8: 4.664e-05  loss_mask_8: 0.1047  loss_dice_8: 0.1659  time: 0.5393  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:16:46] d2.utils.events INFO:  eta: 0:16:05  iter: 29259  total_loss: 3.031  loss_ce: 3.176e-05  loss_mask: 0.1141  loss_dice: 0.1735  loss_ce_0: 0.1161  loss_mask_0: 0.1194  loss_dice_0: 0.1736  loss_ce_1: 7.476e-05  loss_mask_1: 0.1181  loss_dice_1: 0.1756  loss_ce_2: 7.126e-05  loss_mask_2: 0.1195  loss_dice_2: 0.1768  loss_ce_3: 2.797e-05  loss_mask_3: 0.1179  loss_dice_3: 0.1769  loss_ce_4: 4.112e-05  loss_mask_4: 0.1138  loss_dice_4: 0.1661  loss_ce_5: 5.506e-05  loss_mask_5: 0.1197  loss_dice_5: 0.1799  loss_ce_6: 2.642e-05  loss_mask_6: 0.1149  loss_dice_6: 0.1779  loss_ce_7: 4.442e-05  loss_mask_7: 0.1141  loss_dice_7: 0.1732  loss_ce_8: 6.92e-05  loss_mask_8: 0.1168  loss_dice_8: 0.1817  time: 0.5390  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:16:50] d2.utils.events INFO:  eta: 0:16:02  iter: 29279  total_loss: 2.76  loss_ce: 3.228e-05  loss_mask: 0.1104  loss_dice: 0.1632  loss_ce_0: 0.1248  loss_mask_0: 0.1056  loss_dice_0: 0.1557  loss_ce_1: 5.968e-05  loss_mask_1: 0.1053  loss_dice_1: 0.1569  loss_ce_2: 5.99e-05  loss_mask_2: 0.1061  loss_dice_2: 0.1566  loss_ce_3: 2.756e-05  loss_mask_3: 0.1061  loss_dice_3: 0.1522  loss_ce_4: 4.052e-05  loss_mask_4: 0.1039  loss_dice_4: 0.1532  loss_ce_5: 4.35e-05  loss_mask_5: 0.1053  loss_dice_5: 0.159  loss_ce_6: 2.617e-05  loss_mask_6: 0.1071  loss_dice_6: 0.158  loss_ce_7: 4.235e-05  loss_mask_7: 0.1044  loss_dice_7: 0.1591  loss_ce_8: 4.748e-05  loss_mask_8: 0.104  loss_dice_8: 0.1574  time: 0.5388  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:16:53] d2.utils.events INFO:  eta: 0:15:59  iter: 29299  total_loss: 2.821  loss_ce: 3.127e-05  loss_mask: 0.1113  loss_dice: 0.1611  loss_ce_0: 0.1237  loss_mask_0: 0.1078  loss_dice_0: 0.1601  loss_ce_1: 6.792e-05  loss_mask_1: 0.1074  loss_dice_1: 0.1606  loss_ce_2: 6.561e-05  loss_mask_2: 0.1113  loss_dice_2: 0.1675  loss_ce_3: 3.499e-05  loss_mask_3: 0.1093  loss_dice_3: 0.1578  loss_ce_4: 4.108e-05  loss_mask_4: 0.1094  loss_dice_4: 0.1656  loss_ce_5: 5.557e-05  loss_mask_5: 0.1118  loss_dice_5: 0.1654  loss_ce_6: 2.888e-05  loss_mask_6: 0.1067  loss_dice_6: 0.1596  loss_ce_7: 4.504e-05  loss_mask_7: 0.1107  loss_dice_7: 0.162  loss_ce_8: 6.125e-05  loss_mask_8: 0.1067  loss_dice_8: 0.1556  time: 0.5385  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:16:57] d2.utils.events INFO:  eta: 0:15:55  iter: 29319  total_loss: 2.938  loss_ce: 3.152e-05  loss_mask: 0.1137  loss_dice: 0.1714  loss_ce_0: 0.1239  loss_mask_0: 0.1129  loss_dice_0: 0.1732  loss_ce_1: 5.801e-05  loss_mask_1: 0.1144  loss_dice_1: 0.1697  loss_ce_2: 5.226e-05  loss_mask_2: 0.1152  loss_dice_2: 0.1696  loss_ce_3: 2.474e-05  loss_mask_3: 0.1084  loss_dice_3: 0.1656  loss_ce_4: 3.91e-05  loss_mask_4: 0.1127  loss_dice_4: 0.1662  loss_ce_5: 4.246e-05  loss_mask_5: 0.1116  loss_dice_5: 0.167  loss_ce_6: 2.539e-05  loss_mask_6: 0.1132  loss_dice_6: 0.1689  loss_ce_7: 4.145e-05  loss_mask_7: 0.116  loss_dice_7: 0.1692  loss_ce_8: 4.465e-05  loss_mask_8: 0.1079  loss_dice_8: 0.1644  time: 0.5383  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:17:00] d2.utils.events INFO:  eta: 0:15:52  iter: 29339  total_loss: 2.754  loss_ce: 2.996e-05  loss_mask: 0.106  loss_dice: 0.1539  loss_ce_0: 0.1235  loss_mask_0: 0.107  loss_dice_0: 0.1513  loss_ce_1: 6.008e-05  loss_mask_1: 0.1063  loss_dice_1: 0.1552  loss_ce_2: 5.927e-05  loss_mask_2: 0.1051  loss_dice_2: 0.1533  loss_ce_3: 2.804e-05  loss_mask_3: 0.1018  loss_dice_3: 0.1511  loss_ce_4: 3.876e-05  loss_mask_4: 0.1071  loss_dice_4: 0.1583  loss_ce_5: 4.288e-05  loss_mask_5: 0.1081  loss_dice_5: 0.1513  loss_ce_6: 2.694e-05  loss_mask_6: 0.1068  loss_dice_6: 0.1561  loss_ce_7: 4.085e-05  loss_mask_7: 0.1083  loss_dice_7: 0.1564  loss_ce_8: 4.554e-05  loss_mask_8: 0.1081  loss_dice_8: 0.1575  time: 0.5380  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:17:03] d2.utils.events INFO:  eta: 0:15:49  iter: 29359  total_loss: 2.818  loss_ce: 3.028e-05  loss_mask: 0.1083  loss_dice: 0.1638  loss_ce_0: 0.1231  loss_mask_0: 0.1092  loss_dice_0: 0.1589  loss_ce_1: 5.49e-05  loss_mask_1: 0.1099  loss_dice_1: 0.1635  loss_ce_2: 5.303e-05  loss_mask_2: 0.111  loss_dice_2: 0.1613  loss_ce_3: 2.361e-05  loss_mask_3: 0.1096  loss_dice_3: 0.1543  loss_ce_4: 3.917e-05  loss_mask_4: 0.1106  loss_dice_4: 0.1619  loss_ce_5: 4.287e-05  loss_mask_5: 0.1088  loss_dice_5: 0.157  loss_ce_6: 2.505e-05  loss_mask_6: 0.1124  loss_dice_6: 0.1626  loss_ce_7: 3.936e-05  loss_mask_7: 0.1094  loss_dice_7: 0.1562  loss_ce_8: 4.409e-05  loss_mask_8: 0.1077  loss_dice_8: 0.158  time: 0.5378  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:17:07] d2.utils.events INFO:  eta: 0:15:45  iter: 29379  total_loss: 2.925  loss_ce: 3.06e-05  loss_mask: 0.1116  loss_dice: 0.1644  loss_ce_0: 0.1244  loss_mask_0: 0.1143  loss_dice_0: 0.1661  loss_ce_1: 5.05e-05  loss_mask_1: 0.1178  loss_dice_1: 0.1692  loss_ce_2: 5.135e-05  loss_mask_2: 0.1125  loss_dice_2: 0.1695  loss_ce_3: 2.567e-05  loss_mask_3: 0.1113  loss_dice_3: 0.1663  loss_ce_4: 3.579e-05  loss_mask_4: 0.1141  loss_dice_4: 0.1678  loss_ce_5: 4.26e-05  loss_mask_5: 0.112  loss_dice_5: 0.1662  loss_ce_6: 2.533e-05  loss_mask_6: 0.1114  loss_dice_6: 0.1658  loss_ce_7: 4.067e-05  loss_mask_7: 0.11  loss_dice_7: 0.1629  loss_ce_8: 4.503e-05  loss_mask_8: 0.1142  loss_dice_8: 0.1691  time: 0.5375  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:17:10] d2.utils.events INFO:  eta: 0:15:42  iter: 29399  total_loss: 2.918  loss_ce: 3.722e-05  loss_mask: 0.1101  loss_dice: 0.166  loss_ce_0: 0.1242  loss_mask_0: 0.1123  loss_dice_0: 0.1676  loss_ce_1: 5.881e-05  loss_mask_1: 0.1125  loss_dice_1: 0.1738  loss_ce_2: 6.707e-05  loss_mask_2: 0.1145  loss_dice_2: 0.1661  loss_ce_3: 4.03e-05  loss_mask_3: 0.1097  loss_dice_3: 0.1667  loss_ce_4: 4.105e-05  loss_mask_4: 0.1108  loss_dice_4: 0.1695  loss_ce_5: 6.561e-05  loss_mask_5: 0.111  loss_dice_5: 0.1622  loss_ce_6: 3.225e-05  loss_mask_6: 0.1155  loss_dice_6: 0.1745  loss_ce_7: 4.733e-05  loss_mask_7: 0.1101  loss_dice_7: 0.1729  loss_ce_8: 5.736e-05  loss_mask_8: 0.1133  loss_dice_8: 0.1708  time: 0.5372  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:17:13] d2.utils.events INFO:  eta: 0:15:39  iter: 29419  total_loss: 2.848  loss_ce: 3.231e-05  loss_mask: 0.1122  loss_dice: 0.1663  loss_ce_0: 0.1233  loss_mask_0: 0.1074  loss_dice_0: 0.1638  loss_ce_1: 5.786e-05  loss_mask_1: 0.1142  loss_dice_1: 0.1728  loss_ce_2: 5.158e-05  loss_mask_2: 0.1099  loss_dice_2: 0.1633  loss_ce_3: 2.695e-05  loss_mask_3: 0.1091  loss_dice_3: 0.168  loss_ce_4: 3.907e-05  loss_mask_4: 0.1115  loss_dice_4: 0.1636  loss_ce_5: 5.172e-05  loss_mask_5: 0.1119  loss_dice_5: 0.169  loss_ce_6: 2.771e-05  loss_mask_6: 0.1102  loss_dice_6: 0.1637  loss_ce_7: 4.323e-05  loss_mask_7: 0.1133  loss_dice_7: 0.1629  loss_ce_8: 5.602e-05  loss_mask_8: 0.1116  loss_dice_8: 0.1706  time: 0.5370  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:17:17] d2.utils.events INFO:  eta: 0:15:35  iter: 29439  total_loss: 2.902  loss_ce: 2.981e-05  loss_mask: 0.1138  loss_dice: 0.1736  loss_ce_0: 0.1233  loss_mask_0: 0.1088  loss_dice_0: 0.1727  loss_ce_1: 4.286e-05  loss_mask_1: 0.1123  loss_dice_1: 0.1712  loss_ce_2: 3.984e-05  loss_mask_2: 0.1127  loss_dice_2: 0.1721  loss_ce_3: 1.84e-05  loss_mask_3: 0.1101  loss_dice_3: 0.168  loss_ce_4: 2.44e-05  loss_mask_4: 0.1106  loss_dice_4: 0.1675  loss_ce_5: 2.743e-05  loss_mask_5: 0.1092  loss_dice_5: 0.1663  loss_ce_6: 2.082e-05  loss_mask_6: 0.1082  loss_dice_6: 0.1719  loss_ce_7: 3.136e-05  loss_mask_7: 0.1107  loss_dice_7: 0.1722  loss_ce_8: 3.376e-05  loss_mask_8: 0.1079  loss_dice_8: 0.1668  time: 0.5367  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:17:20] d2.utils.events INFO:  eta: 0:15:32  iter: 29459  total_loss: 2.851  loss_ce: 3.47e-05  loss_mask: 0.1085  loss_dice: 0.1635  loss_ce_0: 0.1229  loss_mask_0: 0.1055  loss_dice_0: 0.1617  loss_ce_1: 5.402e-05  loss_mask_1: 0.1074  loss_dice_1: 0.1646  loss_ce_2: 5.028e-05  loss_mask_2: 0.1114  loss_dice_2: 0.1658  loss_ce_3: 2.644e-05  loss_mask_3: 0.1114  loss_dice_3: 0.1632  loss_ce_4: 3.595e-05  loss_mask_4: 0.1089  loss_dice_4: 0.1661  loss_ce_5: 4.616e-05  loss_mask_5: 0.1074  loss_dice_5: 0.1628  loss_ce_6: 2.729e-05  loss_mask_6: 0.1108  loss_dice_6: 0.1646  loss_ce_7: 4.279e-05  loss_mask_7: 0.1126  loss_dice_7: 0.1682  loss_ce_8: 4.927e-05  loss_mask_8: 0.1128  loss_dice_8: 0.165  time: 0.5365  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:17:24] d2.utils.events INFO:  eta: 0:15:29  iter: 29479  total_loss: 2.825  loss_ce: 3.041e-05  loss_mask: 0.1105  loss_dice: 0.1645  loss_ce_0: 0.1226  loss_mask_0: 0.1102  loss_dice_0: 0.1666  loss_ce_1: 5.168e-05  loss_mask_1: 0.111  loss_dice_1: 0.1635  loss_ce_2: 5.623e-05  loss_mask_2: 0.1148  loss_dice_2: 0.1653  loss_ce_3: 2.338e-05  loss_mask_3: 0.107  loss_dice_3: 0.1597  loss_ce_4: 3.82e-05  loss_mask_4: 0.1151  loss_dice_4: 0.1622  loss_ce_5: 4.678e-05  loss_mask_5: 0.1102  loss_dice_5: 0.1624  loss_ce_6: 2.575e-05  loss_mask_6: 0.1088  loss_dice_6: 0.16  loss_ce_7: 4.113e-05  loss_mask_7: 0.1051  loss_dice_7: 0.1599  loss_ce_8: 4.99e-05  loss_mask_8: 0.1099  loss_dice_8: 0.1678  time: 0.5362  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:17:27] d2.utils.events INFO:  eta: 0:15:25  iter: 29499  total_loss: 2.968  loss_ce: 3.045e-05  loss_mask: 0.1161  loss_dice: 0.176  loss_ce_0: 0.1176  loss_mask_0: 0.1166  loss_dice_0: 0.1692  loss_ce_1: 5.372e-05  loss_mask_1: 0.1132  loss_dice_1: 0.1753  loss_ce_2: 6.587e-05  loss_mask_2: 0.1117  loss_dice_2: 0.1754  loss_ce_3: 2.969e-05  loss_mask_3: 0.1168  loss_dice_3: 0.1683  loss_ce_4: 3.957e-05  loss_mask_4: 0.1143  loss_dice_4: 0.1647  loss_ce_5: 4.307e-05  loss_mask_5: 0.1143  loss_dice_5: 0.1774  loss_ce_6: 2.693e-05  loss_mask_6: 0.1109  loss_dice_6: 0.1682  loss_ce_7: 4.476e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1661  loss_ce_8: 4.567e-05  loss_mask_8: 0.1156  loss_dice_8: 0.1683  time: 0.5360  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:17:30] d2.utils.events INFO:  eta: 0:15:21  iter: 29519  total_loss: 2.906  loss_ce: 3.095e-05  loss_mask: 0.1169  loss_dice: 0.1575  loss_ce_0: 0.1246  loss_mask_0: 0.1177  loss_dice_0: 0.1609  loss_ce_1: 5.964e-05  loss_mask_1: 0.1148  loss_dice_1: 0.1585  loss_ce_2: 5.115e-05  loss_mask_2: 0.1152  loss_dice_2: 0.1607  loss_ce_3: 2.537e-05  loss_mask_3: 0.1182  loss_dice_3: 0.1619  loss_ce_4: 3.808e-05  loss_mask_4: 0.1135  loss_dice_4: 0.159  loss_ce_5: 4.588e-05  loss_mask_5: 0.1108  loss_dice_5: 0.1576  loss_ce_6: 2.557e-05  loss_mask_6: 0.1176  loss_dice_6: 0.1619  loss_ce_7: 3.979e-05  loss_mask_7: 0.1147  loss_dice_7: 0.1635  loss_ce_8: 4.949e-05  loss_mask_8: 0.1143  loss_dice_8: 0.1584  time: 0.5357  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:17:34] d2.utils.events INFO:  eta: 0:15:18  iter: 29539  total_loss: 2.925  loss_ce: 2.717e-05  loss_mask: 0.1076  loss_dice: 0.1682  loss_ce_0: 0.1224  loss_mask_0: 0.1099  loss_dice_0: 0.172  loss_ce_1: 5.727e-05  loss_mask_1: 0.1125  loss_dice_1: 0.1636  loss_ce_2: 5.633e-05  loss_mask_2: 0.1128  loss_dice_2: 0.1673  loss_ce_3: 2.225e-05  loss_mask_3: 0.1148  loss_dice_3: 0.1656  loss_ce_4: 3.77e-05  loss_mask_4: 0.1146  loss_dice_4: 0.1697  loss_ce_5: 4.53e-05  loss_mask_5: 0.1091  loss_dice_5: 0.167  loss_ce_6: 2.317e-05  loss_mask_6: 0.114  loss_dice_6: 0.1656  loss_ce_7: 4.258e-05  loss_mask_7: 0.1072  loss_dice_7: 0.167  loss_ce_8: 4.893e-05  loss_mask_8: 0.1135  loss_dice_8: 0.1697  time: 0.5355  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:17:37] d2.utils.events INFO:  eta: 0:15:15  iter: 29559  total_loss: 2.997  loss_ce: 3.79e-05  loss_mask: 0.1091  loss_dice: 0.1814  loss_ce_0: 0.1247  loss_mask_0: 0.1091  loss_dice_0: 0.1732  loss_ce_1: 5.215e-05  loss_mask_1: 0.1075  loss_dice_1: 0.1744  loss_ce_2: 6.155e-05  loss_mask_2: 0.1085  loss_dice_2: 0.1755  loss_ce_3: 3.771e-05  loss_mask_3: 0.108  loss_dice_3: 0.1726  loss_ce_4: 4.08e-05  loss_mask_4: 0.1115  loss_dice_4: 0.1712  loss_ce_5: 4.213e-05  loss_mask_5: 0.1125  loss_dice_5: 0.1711  loss_ce_6: 3.216e-05  loss_mask_6: 0.1086  loss_dice_6: 0.1711  loss_ce_7: 4.252e-05  loss_mask_7: 0.1069  loss_dice_7: 0.1764  loss_ce_8: 4.506e-05  loss_mask_8: 0.1118  loss_dice_8: 0.1818  time: 0.5352  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:17:40] d2.utils.events INFO:  eta: 0:15:11  iter: 29579  total_loss: 2.805  loss_ce: 2.988e-05  loss_mask: 0.1109  loss_dice: 0.1608  loss_ce_0: 0.1265  loss_mask_0: 0.1035  loss_dice_0: 0.1523  loss_ce_1: 4.88e-05  loss_mask_1: 0.1114  loss_dice_1: 0.1615  loss_ce_2: 5.017e-05  loss_mask_2: 0.1096  loss_dice_2: 0.1641  loss_ce_3: 2.173e-05  loss_mask_3: 0.1081  loss_dice_3: 0.1574  loss_ce_4: 3.69e-05  loss_mask_4: 0.1071  loss_dice_4: 0.1545  loss_ce_5: 4.166e-05  loss_mask_5: 0.1083  loss_dice_5: 0.1536  loss_ce_6: 2.332e-05  loss_mask_6: 0.1101  loss_dice_6: 0.156  loss_ce_7: 3.815e-05  loss_mask_7: 0.1081  loss_dice_7: 0.16  loss_ce_8: 4.274e-05  loss_mask_8: 0.1106  loss_dice_8: 0.1599  time: 0.5350  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:17:44] d2.utils.events INFO:  eta: 0:15:08  iter: 29599  total_loss: 2.767  loss_ce: 3.053e-05  loss_mask: 0.111  loss_dice: 0.1612  loss_ce_0: 0.1229  loss_mask_0: 0.1081  loss_dice_0: 0.1568  loss_ce_1: 4.796e-05  loss_mask_1: 0.1114  loss_dice_1: 0.1651  loss_ce_2: 4.984e-05  loss_mask_2: 0.1106  loss_dice_2: 0.16  loss_ce_3: 2.476e-05  loss_mask_3: 0.1113  loss_dice_3: 0.1571  loss_ce_4: 3.664e-05  loss_mask_4: 0.1102  loss_dice_4: 0.1572  loss_ce_5: 4.132e-05  loss_mask_5: 0.11  loss_dice_5: 0.1569  loss_ce_6: 2.337e-05  loss_mask_6: 0.1093  loss_dice_6: 0.1529  loss_ce_7: 3.818e-05  loss_mask_7: 0.1068  loss_dice_7: 0.158  loss_ce_8: 4.282e-05  loss_mask_8: 0.1113  loss_dice_8: 0.1565  time: 0.5348  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:17:47] d2.utils.events INFO:  eta: 0:15:05  iter: 29619  total_loss: 2.817  loss_ce: 3.16e-05  loss_mask: 0.1082  loss_dice: 0.1612  loss_ce_0: 0.1244  loss_mask_0: 0.1062  loss_dice_0: 0.1569  loss_ce_1: 4.904e-05  loss_mask_1: 0.1107  loss_dice_1: 0.1633  loss_ce_2: 4.52e-05  loss_mask_2: 0.1106  loss_dice_2: 0.1615  loss_ce_3: 2.678e-05  loss_mask_3: 0.1103  loss_dice_3: 0.1595  loss_ce_4: 3.372e-05  loss_mask_4: 0.1075  loss_dice_4: 0.1561  loss_ce_5: 3.382e-05  loss_mask_5: 0.1071  loss_dice_5: 0.1592  loss_ce_6: 2.728e-05  loss_mask_6: 0.1118  loss_dice_6: 0.1599  loss_ce_7: 3.82e-05  loss_mask_7: 0.1079  loss_dice_7: 0.1599  loss_ce_8: 3.997e-05  loss_mask_8: 0.1125  loss_dice_8: 0.1615  time: 0.5345  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:17:50] d2.utils.events INFO:  eta: 0:15:01  iter: 29639  total_loss: 2.87  loss_ce: 2.736e-05  loss_mask: 0.1091  loss_dice: 0.1608  loss_ce_0: 0.1226  loss_mask_0: 0.1116  loss_dice_0: 0.1657  loss_ce_1: 4.793e-05  loss_mask_1: 0.1105  loss_dice_1: 0.1591  loss_ce_2: 5.029e-05  loss_mask_2: 0.1106  loss_dice_2: 0.1606  loss_ce_3: 2.441e-05  loss_mask_3: 0.112  loss_dice_3: 0.1604  loss_ce_4: 3.48e-05  loss_mask_4: 0.1119  loss_dice_4: 0.1639  loss_ce_5: 4.173e-05  loss_mask_5: 0.1115  loss_dice_5: 0.1658  loss_ce_6: 2.374e-05  loss_mask_6: 0.1121  loss_dice_6: 0.1635  loss_ce_7: 4.02e-05  loss_mask_7: 0.1111  loss_dice_7: 0.1642  loss_ce_8: 4.364e-05  loss_mask_8: 0.1108  loss_dice_8: 0.1641  time: 0.5343  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:17:54] d2.utils.events INFO:  eta: 0:14:58  iter: 29659  total_loss: 2.846  loss_ce: 3.064e-05  loss_mask: 0.1089  loss_dice: 0.1652  loss_ce_0: 0.1221  loss_mask_0: 0.1064  loss_dice_0: 0.1697  loss_ce_1: 5.068e-05  loss_mask_1: 0.1037  loss_dice_1: 0.1561  loss_ce_2: 6.36e-05  loss_mask_2: 0.1108  loss_dice_2: 0.1628  loss_ce_3: 3.745e-05  loss_mask_3: 0.1066  loss_dice_3: 0.1659  loss_ce_4: 3.795e-05  loss_mask_4: 0.1069  loss_dice_4: 0.1614  loss_ce_5: 4.155e-05  loss_mask_5: 0.1115  loss_dice_5: 0.1634  loss_ce_6: 2.808e-05  loss_mask_6: 0.113  loss_dice_6: 0.1612  loss_ce_7: 4.22e-05  loss_mask_7: 0.1104  loss_dice_7: 0.1665  loss_ce_8: 4.442e-05  loss_mask_8: 0.1109  loss_dice_8: 0.1664  time: 0.5340  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:17:57] d2.utils.events INFO:  eta: 0:14:55  iter: 29679  total_loss: 2.713  loss_ce: 2.958e-05  loss_mask: 0.1036  loss_dice: 0.1535  loss_ce_0: 0.1234  loss_mask_0: 0.1069  loss_dice_0: 0.1602  loss_ce_1: 4.78e-05  loss_mask_1: 0.1026  loss_dice_1: 0.1514  loss_ce_2: 5.583e-05  loss_mask_2: 0.1045  loss_dice_2: 0.1572  loss_ce_3: 2.825e-05  loss_mask_3: 0.1026  loss_dice_3: 0.1518  loss_ce_4: 3.75e-05  loss_mask_4: 0.1081  loss_dice_4: 0.1516  loss_ce_5: 4.118e-05  loss_mask_5: 0.1057  loss_dice_5: 0.1553  loss_ce_6: 2.594e-05  loss_mask_6: 0.1046  loss_dice_6: 0.1569  loss_ce_7: 3.694e-05  loss_mask_7: 0.1048  loss_dice_7: 0.1516  loss_ce_8: 4.343e-05  loss_mask_8: 0.1046  loss_dice_8: 0.1551  time: 0.5338  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:18:01] d2.utils.events INFO:  eta: 0:14:52  iter: 29699  total_loss: 2.947  loss_ce: 3.094e-05  loss_mask: 0.1145  loss_dice: 0.1729  loss_ce_0: 0.1154  loss_mask_0: 0.1112  loss_dice_0: 0.1696  loss_ce_1: 6.575e-05  loss_mask_1: 0.1156  loss_dice_1: 0.1739  loss_ce_2: 6.428e-05  loss_mask_2: 0.1119  loss_dice_2: 0.1684  loss_ce_3: 2.514e-05  loss_mask_3: 0.1151  loss_dice_3: 0.1665  loss_ce_4: 3.91e-05  loss_mask_4: 0.1133  loss_dice_4: 0.1661  loss_ce_5: 6.115e-05  loss_mask_5: 0.1133  loss_dice_5: 0.1661  loss_ce_6: 2.544e-05  loss_mask_6: 0.1164  loss_dice_6: 0.1688  loss_ce_7: 4.329e-05  loss_mask_7: 0.1159  loss_dice_7: 0.1668  loss_ce_8: 6.255e-05  loss_mask_8: 0.1143  loss_dice_8: 0.1714  time: 0.5335  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:04] d2.utils.events INFO:  eta: 0:14:49  iter: 29719  total_loss: 2.803  loss_ce: 2.951e-05  loss_mask: 0.11  loss_dice: 0.1624  loss_ce_0: 0.1181  loss_mask_0: 0.1083  loss_dice_0: 0.1636  loss_ce_1: 5.172e-05  loss_mask_1: 0.1092  loss_dice_1: 0.1637  loss_ce_2: 6.321e-05  loss_mask_2: 0.1115  loss_dice_2: 0.159  loss_ce_3: 2.742e-05  loss_mask_3: 0.1112  loss_dice_3: 0.1565  loss_ce_4: 3.628e-05  loss_mask_4: 0.11  loss_dice_4: 0.1599  loss_ce_5: 4.084e-05  loss_mask_5: 0.1106  loss_dice_5: 0.1587  loss_ce_6: 2.516e-05  loss_mask_6: 0.1107  loss_dice_6: 0.1594  loss_ce_7: 3.895e-05  loss_mask_7: 0.1095  loss_dice_7: 0.1596  loss_ce_8: 4.303e-05  loss_mask_8: 0.107  loss_dice_8: 0.1596  time: 0.5333  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:07] d2.utils.events INFO:  eta: 0:14:46  iter: 29739  total_loss: 2.882  loss_ce: 3.225e-05  loss_mask: 0.1112  loss_dice: 0.1604  loss_ce_0: 0.1269  loss_mask_0: 0.1117  loss_dice_0: 0.1617  loss_ce_1: 5.844e-05  loss_mask_1: 0.1122  loss_dice_1: 0.1605  loss_ce_2: 5.518e-05  loss_mask_2: 0.113  loss_dice_2: 0.1646  loss_ce_3: 2.996e-05  loss_mask_3: 0.1112  loss_dice_3: 0.161  loss_ce_4: 3.717e-05  loss_mask_4: 0.1122  loss_dice_4: 0.1646  loss_ce_5: 5.002e-05  loss_mask_5: 0.11  loss_dice_5: 0.1614  loss_ce_6: 2.805e-05  loss_mask_6: 0.114  loss_dice_6: 0.1605  loss_ce_7: 4.432e-05  loss_mask_7: 0.1067  loss_dice_7: 0.1577  loss_ce_8: 5.332e-05  loss_mask_8: 0.1114  loss_dice_8: 0.1614  time: 0.5330  data_time: 0.0012  lr: 1e-05  max_mem: 8444M
[08/01 22:18:11] d2.utils.events INFO:  eta: 0:14:42  iter: 29759  total_loss: 2.809  loss_ce: 2.936e-05  loss_mask: 0.1029  loss_dice: 0.1606  loss_ce_0: 0.1212  loss_mask_0: 0.105  loss_dice_0: 0.1629  loss_ce_1: 6.112e-05  loss_mask_1: 0.1053  loss_dice_1: 0.1569  loss_ce_2: 4.917e-05  loss_mask_2: 0.1057  loss_dice_2: 0.1631  loss_ce_3: 2.411e-05  loss_mask_3: 0.105  loss_dice_3: 0.1563  loss_ce_4: 3.413e-05  loss_mask_4: 0.1037  loss_dice_4: 0.1614  loss_ce_5: 4.435e-05  loss_mask_5: 0.1071  loss_dice_5: 0.1706  loss_ce_6: 2.36e-05  loss_mask_6: 0.1049  loss_dice_6: 0.1615  loss_ce_7: 4.152e-05  loss_mask_7: 0.1064  loss_dice_7: 0.1646  loss_ce_8: 4.755e-05  loss_mask_8: 0.1054  loss_dice_8: 0.1633  time: 0.5328  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:14] d2.utils.events INFO:  eta: 0:14:39  iter: 29779  total_loss: 2.87  loss_ce: 2.965e-05  loss_mask: 0.1081  loss_dice: 0.1571  loss_ce_0: 0.1166  loss_mask_0: 0.1086  loss_dice_0: 0.1644  loss_ce_1: 5.599e-05  loss_mask_1: 0.1078  loss_dice_1: 0.1629  loss_ce_2: 6.055e-05  loss_mask_2: 0.1107  loss_dice_2: 0.1687  loss_ce_3: 2.818e-05  loss_mask_3: 0.1129  loss_dice_3: 0.1651  loss_ce_4: 3.638e-05  loss_mask_4: 0.1094  loss_dice_4: 0.1629  loss_ce_5: 4.076e-05  loss_mask_5: 0.1108  loss_dice_5: 0.1612  loss_ce_6: 2.616e-05  loss_mask_6: 0.1106  loss_dice_6: 0.1666  loss_ce_7: 3.912e-05  loss_mask_7: 0.1093  loss_dice_7: 0.1606  loss_ce_8: 4.306e-05  loss_mask_8: 0.1145  loss_dice_8: 0.1714  time: 0.5325  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:17] d2.utils.events INFO:  eta: 0:14:36  iter: 29799  total_loss: 2.877  loss_ce: 3.137e-05  loss_mask: 0.1082  loss_dice: 0.1668  loss_ce_0: 0.1219  loss_mask_0: 0.1069  loss_dice_0: 0.1649  loss_ce_1: 5.888e-05  loss_mask_1: 0.1095  loss_dice_1: 0.1657  loss_ce_2: 6.192e-05  loss_mask_2: 0.1088  loss_dice_2: 0.1675  loss_ce_3: 3.359e-05  loss_mask_3: 0.1119  loss_dice_3: 0.1697  loss_ce_4: 3.766e-05  loss_mask_4: 0.109  loss_dice_4: 0.1649  loss_ce_5: 4.786e-05  loss_mask_5: 0.1099  loss_dice_5: 0.1662  loss_ce_6: 2.962e-05  loss_mask_6: 0.1082  loss_dice_6: 0.1622  loss_ce_7: 4.17e-05  loss_mask_7: 0.1078  loss_dice_7: 0.1677  loss_ce_8: 5.136e-05  loss_mask_8: 0.1077  loss_dice_8: 0.1654  time: 0.5323  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:21] d2.utils.events INFO:  eta: 0:14:32  iter: 29819  total_loss: 2.922  loss_ce: 2.942e-05  loss_mask: 0.11  loss_dice: 0.173  loss_ce_0: 0.1271  loss_mask_0: 0.1094  loss_dice_0: 0.1675  loss_ce_1: 5.868e-05  loss_mask_1: 0.1165  loss_dice_1: 0.1731  loss_ce_2: 4.695e-05  loss_mask_2: 0.1147  loss_dice_2: 0.1725  loss_ce_3: 2.445e-05  loss_mask_3: 0.1092  loss_dice_3: 0.1684  loss_ce_4: 3.458e-05  loss_mask_4: 0.1137  loss_dice_4: 0.169  loss_ce_5: 4.728e-05  loss_mask_5: 0.1067  loss_dice_5: 0.1671  loss_ce_6: 2.396e-05  loss_mask_6: 0.1107  loss_dice_6: 0.1702  loss_ce_7: 3.882e-05  loss_mask_7: 0.1111  loss_dice_7: 0.168  loss_ce_8: 5.499e-05  loss_mask_8: 0.1098  loss_dice_8: 0.169  time: 0.5320  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:24] d2.utils.events INFO:  eta: 0:14:29  iter: 29839  total_loss: 2.839  loss_ce: 2.857e-05  loss_mask: 0.1054  loss_dice: 0.1636  loss_ce_0: 0.1248  loss_mask_0: 0.1053  loss_dice_0: 0.1578  loss_ce_1: 5.079e-05  loss_mask_1: 0.1071  loss_dice_1: 0.1682  loss_ce_2: 5.304e-05  loss_mask_2: 0.1087  loss_dice_2: 0.1653  loss_ce_3: 2.425e-05  loss_mask_3: 0.1078  loss_dice_3: 0.1652  loss_ce_4: 3.391e-05  loss_mask_4: 0.1052  loss_dice_4: 0.1597  loss_ce_5: 4.042e-05  loss_mask_5: 0.1068  loss_dice_5: 0.1681  loss_ce_6: 2.374e-05  loss_mask_6: 0.1108  loss_dice_6: 0.1647  loss_ce_7: 3.772e-05  loss_mask_7: 0.1041  loss_dice_7: 0.1611  loss_ce_8: 4.251e-05  loss_mask_8: 0.1087  loss_dice_8: 0.1635  time: 0.5318  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:28] d2.utils.events INFO:  eta: 0:14:25  iter: 29859  total_loss: 2.89  loss_ce: 2.883e-05  loss_mask: 0.1108  loss_dice: 0.1671  loss_ce_0: 0.1315  loss_mask_0: 0.1152  loss_dice_0: 0.1749  loss_ce_1: 4.905e-05  loss_mask_1: 0.1107  loss_dice_1: 0.1685  loss_ce_2: 4.661e-05  loss_mask_2: 0.1111  loss_dice_2: 0.1705  loss_ce_3: 2.431e-05  loss_mask_3: 0.1103  loss_dice_3: 0.1709  loss_ce_4: 3.661e-05  loss_mask_4: 0.1155  loss_dice_4: 0.169  loss_ce_5: 4.332e-05  loss_mask_5: 0.1109  loss_dice_5: 0.1707  loss_ce_6: 2.489e-05  loss_mask_6: 0.1127  loss_dice_6: 0.1701  loss_ce_7: 3.612e-05  loss_mask_7: 0.1153  loss_dice_7: 0.1714  loss_ce_8: 4.481e-05  loss_mask_8: 0.112  loss_dice_8: 0.1753  time: 0.5316  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:31] d2.utils.events INFO:  eta: 0:14:22  iter: 29879  total_loss: 2.95  loss_ce: 2.999e-05  loss_mask: 0.1142  loss_dice: 0.1695  loss_ce_0: 0.1233  loss_mask_0: 0.1154  loss_dice_0: 0.1794  loss_ce_1: 5.039e-05  loss_mask_1: 0.1133  loss_dice_1: 0.1728  loss_ce_2: 5.23e-05  loss_mask_2: 0.1121  loss_dice_2: 0.1727  loss_ce_3: 2.266e-05  loss_mask_3: 0.1132  loss_dice_3: 0.1736  loss_ce_4: 3.779e-05  loss_mask_4: 0.1116  loss_dice_4: 0.1688  loss_ce_5: 5.279e-05  loss_mask_5: 0.1107  loss_dice_5: 0.1714  loss_ce_6: 2.355e-05  loss_mask_6: 0.113  loss_dice_6: 0.1724  loss_ce_7: 4.304e-05  loss_mask_7: 0.1124  loss_dice_7: 0.1741  loss_ce_8: 5.098e-05  loss_mask_8: 0.1136  loss_dice_8: 0.1773  time: 0.5313  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:34] d2.utils.events INFO:  eta: 0:14:19  iter: 29899  total_loss: 2.92  loss_ce: 2.891e-05  loss_mask: 0.1053  loss_dice: 0.1646  loss_ce_0: 0.1232  loss_mask_0: 0.1098  loss_dice_0: 0.1681  loss_ce_1: 4.993e-05  loss_mask_1: 0.1103  loss_dice_1: 0.1673  loss_ce_2: 4.779e-05  loss_mask_2: 0.1102  loss_dice_2: 0.1717  loss_ce_3: 1.961e-05  loss_mask_3: 0.1102  loss_dice_3: 0.1654  loss_ce_4: 3.48e-05  loss_mask_4: 0.1102  loss_dice_4: 0.1663  loss_ce_5: 3.98e-05  loss_mask_5: 0.103  loss_dice_5: 0.1601  loss_ce_6: 2.204e-05  loss_mask_6: 0.1114  loss_dice_6: 0.1642  loss_ce_7: 3.65e-05  loss_mask_7: 0.1119  loss_dice_7: 0.1687  loss_ce_8: 4.105e-05  loss_mask_8: 0.1104  loss_dice_8: 0.1661  time: 0.5311  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:38] d2.utils.events INFO:  eta: 0:14:15  iter: 29919  total_loss: 2.816  loss_ce: 2.827e-05  loss_mask: 0.1122  loss_dice: 0.1598  loss_ce_0: 0.123  loss_mask_0: 0.109  loss_dice_0: 0.1585  loss_ce_1: 3.907e-05  loss_mask_1: 0.1112  loss_dice_1: 0.1546  loss_ce_2: 4.08e-05  loss_mask_2: 0.109  loss_dice_2: 0.1581  loss_ce_3: 2.222e-05  loss_mask_3: 0.1097  loss_dice_3: 0.1572  loss_ce_4: 2.643e-05  loss_mask_4: 0.1093  loss_dice_4: 0.1517  loss_ce_5: 3.235e-05  loss_mask_5: 0.1071  loss_dice_5: 0.1572  loss_ce_6: 2.279e-05  loss_mask_6: 0.1118  loss_dice_6: 0.1612  loss_ce_7: 3.35e-05  loss_mask_7: 0.1067  loss_dice_7: 0.1559  loss_ce_8: 3.5e-05  loss_mask_8: 0.1107  loss_dice_8: 0.1514  time: 0.5308  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:41] d2.utils.events INFO:  eta: 0:14:12  iter: 29939  total_loss: 2.998  loss_ce: 2.682e-05  loss_mask: 0.1134  loss_dice: 0.1676  loss_ce_0: 0.1226  loss_mask_0: 0.1176  loss_dice_0: 0.1777  loss_ce_1: 5.423e-05  loss_mask_1: 0.1129  loss_dice_1: 0.1698  loss_ce_2: 4.594e-05  loss_mask_2: 0.1143  loss_dice_2: 0.1742  loss_ce_3: 2.182e-05  loss_mask_3: 0.1154  loss_dice_3: 0.1746  loss_ce_4: 3.243e-05  loss_mask_4: 0.1155  loss_dice_4: 0.177  loss_ce_5: 4.651e-05  loss_mask_5: 0.1125  loss_dice_5: 0.1688  loss_ce_6: 2.389e-05  loss_mask_6: 0.1132  loss_dice_6: 0.1709  loss_ce_7: 3.83e-05  loss_mask_7: 0.1148  loss_dice_7: 0.1758  loss_ce_8: 5.143e-05  loss_mask_8: 0.1127  loss_dice_8: 0.1716  time: 0.5306  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:45] d2.utils.events INFO:  eta: 0:14:09  iter: 29959  total_loss: 2.962  loss_ce: 2.805e-05  loss_mask: 0.1071  loss_dice: 0.1675  loss_ce_0: 0.1229  loss_mask_0: 0.1078  loss_dice_0: 0.1613  loss_ce_1: 4.653e-05  loss_mask_1: 0.1124  loss_dice_1: 0.1743  loss_ce_2: 5.803e-05  loss_mask_2: 0.1119  loss_dice_2: 0.1719  loss_ce_3: 2.747e-05  loss_mask_3: 0.1115  loss_dice_3: 0.1676  loss_ce_4: 3.421e-05  loss_mask_4: 0.1115  loss_dice_4: 0.1691  loss_ce_5: 3.954e-05  loss_mask_5: 0.1132  loss_dice_5: 0.172  loss_ce_6: 2.552e-05  loss_mask_6: 0.1093  loss_dice_6: 0.1616  loss_ce_7: 3.727e-05  loss_mask_7: 0.109  loss_dice_7: 0.1636  loss_ce_8: 4.136e-05  loss_mask_8: 0.1115  loss_dice_8: 0.1745  time: 0.5303  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:48] d2.utils.events INFO:  eta: 0:14:06  iter: 29979  total_loss: 2.767  loss_ce: 3.197e-05  loss_mask: 0.1062  loss_dice: 0.1533  loss_ce_0: 0.127  loss_mask_0: 0.109  loss_dice_0: 0.1606  loss_ce_1: 5e-05  loss_mask_1: 0.1077  loss_dice_1: 0.158  loss_ce_2: 5.814e-05  loss_mask_2: 0.1056  loss_dice_2: 0.1561  loss_ce_3: 2.948e-05  loss_mask_3: 0.1044  loss_dice_3: 0.1585  loss_ce_4: 3.577e-05  loss_mask_4: 0.1113  loss_dice_4: 0.1565  loss_ce_5: 4.615e-05  loss_mask_5: 0.1044  loss_dice_5: 0.1556  loss_ce_6: 2.604e-05  loss_mask_6: 0.1069  loss_dice_6: 0.1545  loss_ce_7: 3.731e-05  loss_mask_7: 0.1059  loss_dice_7: 0.1568  loss_ce_8: 4.582e-05  loss_mask_8: 0.1048  loss_dice_8: 0.1551  time: 0.5301  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:18:51] fvcore.common.checkpoint INFO: Saving checkpoint to ./R101_overlap/model_0029999.pth
[08/01 22:18:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(256, 256), max_size=256, sample_style='choice')]
[08/01 22:18:52] d2.data.common INFO: Serializing 535 elements to byte tensors and concatenating them all ...
[08/01 22:18:52] d2.data.common INFO: Serialized dataset takes 0.22 MiB
[08/01 22:18:52] d2.evaluation.evaluator INFO: Start inference on 535 batches
[08/01 22:19:03] d2.evaluation.evaluator INFO: Inference done 11/535. Dataloading: 0.0006 s/iter. Inference: 0.0976 s/iter. Eval: 0.9051 s/iter. Total: 1.0033 s/iter. ETA=0:08:45
[08/01 22:19:08] d2.evaluation.evaluator INFO: Inference done 16/535. Dataloading: 0.0006 s/iter. Inference: 0.0950 s/iter. Eval: 0.9077 s/iter. Total: 1.0034 s/iter. ETA=0:08:40
[08/01 22:19:13] d2.evaluation.evaluator INFO: Inference done 21/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9071 s/iter. Total: 1.0029 s/iter. ETA=0:08:35
[08/01 22:19:18] d2.evaluation.evaluator INFO: Inference done 26/535. Dataloading: 0.0007 s/iter. Inference: 0.0963 s/iter. Eval: 0.9063 s/iter. Total: 1.0033 s/iter. ETA=0:08:30
[08/01 22:19:23] d2.evaluation.evaluator INFO: Inference done 31/535. Dataloading: 0.0007 s/iter. Inference: 0.0960 s/iter. Eval: 0.9060 s/iter. Total: 1.0028 s/iter. ETA=0:08:25
[08/01 22:19:28] d2.evaluation.evaluator INFO: Inference done 36/535. Dataloading: 0.0007 s/iter. Inference: 0.0963 s/iter. Eval: 0.9061 s/iter. Total: 1.0032 s/iter. ETA=0:08:20
[08/01 22:19:34] d2.evaluation.evaluator INFO: Inference done 42/535. Dataloading: 0.0007 s/iter. Inference: 0.0962 s/iter. Eval: 0.9055 s/iter. Total: 1.0025 s/iter. ETA=0:08:14
[08/01 22:19:39] d2.evaluation.evaluator INFO: Inference done 47/535. Dataloading: 0.0007 s/iter. Inference: 0.0957 s/iter. Eval: 0.9060 s/iter. Total: 1.0025 s/iter. ETA=0:08:09
[08/01 22:19:44] d2.evaluation.evaluator INFO: Inference done 52/535. Dataloading: 0.0007 s/iter. Inference: 0.0960 s/iter. Eval: 0.9057 s/iter. Total: 1.0025 s/iter. ETA=0:08:04
[08/01 22:19:50] d2.evaluation.evaluator INFO: Inference done 58/535. Dataloading: 0.0007 s/iter. Inference: 0.0955 s/iter. Eval: 0.9052 s/iter. Total: 1.0015 s/iter. ETA=0:07:57
[08/01 22:19:55] d2.evaluation.evaluator INFO: Inference done 63/535. Dataloading: 0.0007 s/iter. Inference: 0.0955 s/iter. Eval: 0.9051 s/iter. Total: 1.0014 s/iter. ETA=0:07:52
[08/01 22:20:01] d2.evaluation.evaluator INFO: Inference done 69/535. Dataloading: 0.0007 s/iter. Inference: 0.0954 s/iter. Eval: 0.9048 s/iter. Total: 1.0010 s/iter. ETA=0:07:46
[08/01 22:20:07] d2.evaluation.evaluator INFO: Inference done 75/535. Dataloading: 0.0007 s/iter. Inference: 0.0955 s/iter. Eval: 0.9045 s/iter. Total: 1.0008 s/iter. ETA=0:07:40
[08/01 22:20:13] d2.evaluation.evaluator INFO: Inference done 81/535. Dataloading: 0.0007 s/iter. Inference: 0.0953 s/iter. Eval: 0.9045 s/iter. Total: 1.0005 s/iter. ETA=0:07:34
[08/01 22:20:18] d2.evaluation.evaluator INFO: Inference done 86/535. Dataloading: 0.0007 s/iter. Inference: 0.0953 s/iter. Eval: 0.9047 s/iter. Total: 1.0008 s/iter. ETA=0:07:29
[08/01 22:20:23] d2.evaluation.evaluator INFO: Inference done 91/535. Dataloading: 0.0007 s/iter. Inference: 0.0951 s/iter. Eval: 0.9050 s/iter. Total: 1.0008 s/iter. ETA=0:07:24
[08/01 22:20:28] d2.evaluation.evaluator INFO: Inference done 96/535. Dataloading: 0.0007 s/iter. Inference: 0.0955 s/iter. Eval: 0.9050 s/iter. Total: 1.0013 s/iter. ETA=0:07:19
[08/01 22:20:34] d2.evaluation.evaluator INFO: Inference done 102/535. Dataloading: 0.0007 s/iter. Inference: 0.0951 s/iter. Eval: 0.9052 s/iter. Total: 1.0011 s/iter. ETA=0:07:13
[08/01 22:20:39] d2.evaluation.evaluator INFO: Inference done 107/535. Dataloading: 0.0007 s/iter. Inference: 0.0951 s/iter. Eval: 0.9055 s/iter. Total: 1.0014 s/iter. ETA=0:07:08
[08/01 22:20:44] d2.evaluation.evaluator INFO: Inference done 112/535. Dataloading: 0.0007 s/iter. Inference: 0.0951 s/iter. Eval: 0.9055 s/iter. Total: 1.0014 s/iter. ETA=0:07:03
[08/01 22:20:50] d2.evaluation.evaluator INFO: Inference done 118/535. Dataloading: 0.0007 s/iter. Inference: 0.0951 s/iter. Eval: 0.9056 s/iter. Total: 1.0014 s/iter. ETA=0:06:57
[08/01 22:20:55] d2.evaluation.evaluator INFO: Inference done 123/535. Dataloading: 0.0007 s/iter. Inference: 0.0953 s/iter. Eval: 0.9058 s/iter. Total: 1.0020 s/iter. ETA=0:06:52
[08/01 22:21:00] d2.evaluation.evaluator INFO: Inference done 128/535. Dataloading: 0.0007 s/iter. Inference: 0.0952 s/iter. Eval: 0.9060 s/iter. Total: 1.0020 s/iter. ETA=0:06:47
[08/01 22:21:05] d2.evaluation.evaluator INFO: Inference done 133/535. Dataloading: 0.0007 s/iter. Inference: 0.0954 s/iter. Eval: 0.9063 s/iter. Total: 1.0025 s/iter. ETA=0:06:42
[08/01 22:21:10] d2.evaluation.evaluator INFO: Inference done 138/535. Dataloading: 0.0007 s/iter. Inference: 0.0954 s/iter. Eval: 0.9064 s/iter. Total: 1.0026 s/iter. ETA=0:06:38
[08/01 22:21:16] d2.evaluation.evaluator INFO: Inference done 144/535. Dataloading: 0.0007 s/iter. Inference: 0.0953 s/iter. Eval: 0.9065 s/iter. Total: 1.0025 s/iter. ETA=0:06:31
[08/01 22:21:21] d2.evaluation.evaluator INFO: Inference done 149/535. Dataloading: 0.0007 s/iter. Inference: 0.0951 s/iter. Eval: 0.9066 s/iter. Total: 1.0025 s/iter. ETA=0:06:26
[08/01 22:21:26] d2.evaluation.evaluator INFO: Inference done 154/535. Dataloading: 0.0007 s/iter. Inference: 0.0953 s/iter. Eval: 0.9066 s/iter. Total: 1.0028 s/iter. ETA=0:06:22
[08/01 22:21:31] d2.evaluation.evaluator INFO: Inference done 159/535. Dataloading: 0.0007 s/iter. Inference: 0.0954 s/iter. Eval: 0.9067 s/iter. Total: 1.0029 s/iter. ETA=0:06:17
[08/01 22:21:36] d2.evaluation.evaluator INFO: Inference done 164/535. Dataloading: 0.0007 s/iter. Inference: 0.0953 s/iter. Eval: 0.9068 s/iter. Total: 1.0028 s/iter. ETA=0:06:12
[08/01 22:21:41] d2.evaluation.evaluator INFO: Inference done 169/535. Dataloading: 0.0007 s/iter. Inference: 0.0953 s/iter. Eval: 0.9068 s/iter. Total: 1.0029 s/iter. ETA=0:06:07
[08/01 22:21:46] d2.evaluation.evaluator INFO: Inference done 174/535. Dataloading: 0.0007 s/iter. Inference: 0.0956 s/iter. Eval: 0.9068 s/iter. Total: 1.0031 s/iter. ETA=0:06:02
[08/01 22:21:52] d2.evaluation.evaluator INFO: Inference done 180/535. Dataloading: 0.0007 s/iter. Inference: 0.0953 s/iter. Eval: 0.9066 s/iter. Total: 1.0028 s/iter. ETA=0:05:55
[08/01 22:21:58] d2.evaluation.evaluator INFO: Inference done 186/535. Dataloading: 0.0007 s/iter. Inference: 0.0953 s/iter. Eval: 0.9066 s/iter. Total: 1.0026 s/iter. ETA=0:05:49
[08/01 22:22:04] d2.evaluation.evaluator INFO: Inference done 192/535. Dataloading: 0.0007 s/iter. Inference: 0.0953 s/iter. Eval: 0.9065 s/iter. Total: 1.0025 s/iter. ETA=0:05:43
[08/01 22:22:09] d2.evaluation.evaluator INFO: Inference done 197/535. Dataloading: 0.0007 s/iter. Inference: 0.0952 s/iter. Eval: 0.9065 s/iter. Total: 1.0025 s/iter. ETA=0:05:38
[08/01 22:22:15] d2.evaluation.evaluator INFO: Inference done 203/535. Dataloading: 0.0007 s/iter. Inference: 0.0951 s/iter. Eval: 0.9066 s/iter. Total: 1.0025 s/iter. ETA=0:05:32
[08/01 22:22:20] d2.evaluation.evaluator INFO: Inference done 208/535. Dataloading: 0.0007 s/iter. Inference: 0.0952 s/iter. Eval: 0.9066 s/iter. Total: 1.0026 s/iter. ETA=0:05:27
[08/01 22:22:26] d2.evaluation.evaluator INFO: Inference done 214/535. Dataloading: 0.0007 s/iter. Inference: 0.0951 s/iter. Eval: 0.9066 s/iter. Total: 1.0025 s/iter. ETA=0:05:21
[08/01 22:22:31] d2.evaluation.evaluator INFO: Inference done 219/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9067 s/iter. Total: 1.0025 s/iter. ETA=0:05:16
[08/01 22:22:37] d2.evaluation.evaluator INFO: Inference done 224/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9067 s/iter. Total: 1.0026 s/iter. ETA=0:05:11
[08/01 22:22:42] d2.evaluation.evaluator INFO: Inference done 229/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9068 s/iter. Total: 1.0026 s/iter. ETA=0:05:06
[08/01 22:22:47] d2.evaluation.evaluator INFO: Inference done 234/535. Dataloading: 0.0007 s/iter. Inference: 0.0955 s/iter. Eval: 0.9068 s/iter. Total: 1.0030 s/iter. ETA=0:05:01
[08/01 22:22:52] d2.evaluation.evaluator INFO: Inference done 239/535. Dataloading: 0.0007 s/iter. Inference: 0.0954 s/iter. Eval: 0.9068 s/iter. Total: 1.0030 s/iter. ETA=0:04:56
[08/01 22:22:57] d2.evaluation.evaluator INFO: Inference done 244/535. Dataloading: 0.0007 s/iter. Inference: 0.0954 s/iter. Eval: 0.9068 s/iter. Total: 1.0031 s/iter. ETA=0:04:51
[08/01 22:23:02] d2.evaluation.evaluator INFO: Inference done 249/535. Dataloading: 0.0007 s/iter. Inference: 0.0956 s/iter. Eval: 0.9068 s/iter. Total: 1.0032 s/iter. ETA=0:04:46
[08/01 22:23:08] d2.evaluation.evaluator INFO: Inference done 255/535. Dataloading: 0.0007 s/iter. Inference: 0.0955 s/iter. Eval: 0.9068 s/iter. Total: 1.0031 s/iter. ETA=0:04:40
[08/01 22:23:13] d2.evaluation.evaluator INFO: Inference done 260/535. Dataloading: 0.0007 s/iter. Inference: 0.0955 s/iter. Eval: 0.9069 s/iter. Total: 1.0032 s/iter. ETA=0:04:35
[08/01 22:23:18] d2.evaluation.evaluator INFO: Inference done 265/535. Dataloading: 0.0007 s/iter. Inference: 0.0955 s/iter. Eval: 0.9068 s/iter. Total: 1.0031 s/iter. ETA=0:04:30
[08/01 22:23:24] d2.evaluation.evaluator INFO: Inference done 271/535. Dataloading: 0.0007 s/iter. Inference: 0.0955 s/iter. Eval: 0.9068 s/iter. Total: 1.0030 s/iter. ETA=0:04:24
[08/01 22:23:29] d2.evaluation.evaluator INFO: Inference done 276/535. Dataloading: 0.0007 s/iter. Inference: 0.0954 s/iter. Eval: 0.9068 s/iter. Total: 1.0030 s/iter. ETA=0:04:19
[08/01 22:23:34] d2.evaluation.evaluator INFO: Inference done 281/535. Dataloading: 0.0007 s/iter. Inference: 0.0955 s/iter. Eval: 0.9068 s/iter. Total: 1.0030 s/iter. ETA=0:04:14
[08/01 22:23:40] d2.evaluation.evaluator INFO: Inference done 287/535. Dataloading: 0.0007 s/iter. Inference: 0.0954 s/iter. Eval: 0.9068 s/iter. Total: 1.0030 s/iter. ETA=0:04:08
[08/01 22:23:45] d2.evaluation.evaluator INFO: Inference done 292/535. Dataloading: 0.0007 s/iter. Inference: 0.0954 s/iter. Eval: 0.9067 s/iter. Total: 1.0029 s/iter. ETA=0:04:03
[08/01 22:23:51] d2.evaluation.evaluator INFO: Inference done 298/535. Dataloading: 0.0007 s/iter. Inference: 0.0953 s/iter. Eval: 0.9068 s/iter. Total: 1.0029 s/iter. ETA=0:03:57
[08/01 22:23:57] d2.evaluation.evaluator INFO: Inference done 304/535. Dataloading: 0.0007 s/iter. Inference: 0.0952 s/iter. Eval: 0.9067 s/iter. Total: 1.0028 s/iter. ETA=0:03:51
[08/01 22:24:03] d2.evaluation.evaluator INFO: Inference done 310/535. Dataloading: 0.0007 s/iter. Inference: 0.0951 s/iter. Eval: 0.9067 s/iter. Total: 1.0026 s/iter. ETA=0:03:45
[08/01 22:24:08] d2.evaluation.evaluator INFO: Inference done 315/535. Dataloading: 0.0007 s/iter. Inference: 0.0952 s/iter. Eval: 0.9067 s/iter. Total: 1.0027 s/iter. ETA=0:03:40
[08/01 22:24:13] d2.evaluation.evaluator INFO: Inference done 320/535. Dataloading: 0.0007 s/iter. Inference: 0.0952 s/iter. Eval: 0.9067 s/iter. Total: 1.0027 s/iter. ETA=0:03:35
[08/01 22:24:19] d2.evaluation.evaluator INFO: Inference done 326/535. Dataloading: 0.0007 s/iter. Inference: 0.0951 s/iter. Eval: 0.9067 s/iter. Total: 1.0026 s/iter. ETA=0:03:29
[08/01 22:24:24] d2.evaluation.evaluator INFO: Inference done 331/535. Dataloading: 0.0007 s/iter. Inference: 0.0951 s/iter. Eval: 0.9067 s/iter. Total: 1.0026 s/iter. ETA=0:03:24
[08/01 22:24:30] d2.evaluation.evaluator INFO: Inference done 337/535. Dataloading: 0.0007 s/iter. Inference: 0.0951 s/iter. Eval: 0.9067 s/iter. Total: 1.0025 s/iter. ETA=0:03:18
[08/01 22:24:36] d2.evaluation.evaluator INFO: Inference done 343/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9066 s/iter. Total: 1.0024 s/iter. ETA=0:03:12
[08/01 22:24:41] d2.evaluation.evaluator INFO: Inference done 348/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9066 s/iter. Total: 1.0024 s/iter. ETA=0:03:07
[08/01 22:24:46] d2.evaluation.evaluator INFO: Inference done 353/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9066 s/iter. Total: 1.0024 s/iter. ETA=0:03:02
[08/01 22:24:51] d2.evaluation.evaluator INFO: Inference done 358/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9067 s/iter. Total: 1.0025 s/iter. ETA=0:02:57
[08/01 22:24:56] d2.evaluation.evaluator INFO: Inference done 363/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9067 s/iter. Total: 1.0025 s/iter. ETA=0:02:52
[08/01 22:25:01] d2.evaluation.evaluator INFO: Inference done 368/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9067 s/iter. Total: 1.0025 s/iter. ETA=0:02:47
[08/01 22:25:07] d2.evaluation.evaluator INFO: Inference done 374/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9066 s/iter. Total: 1.0024 s/iter. ETA=0:02:41
[08/01 22:25:12] d2.evaluation.evaluator INFO: Inference done 379/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9066 s/iter. Total: 1.0024 s/iter. ETA=0:02:36
[08/01 22:25:17] d2.evaluation.evaluator INFO: Inference done 384/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9066 s/iter. Total: 1.0024 s/iter. ETA=0:02:31
[08/01 22:25:23] d2.evaluation.evaluator INFO: Inference done 390/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9066 s/iter. Total: 1.0023 s/iter. ETA=0:02:25
[08/01 22:25:28] d2.evaluation.evaluator INFO: Inference done 395/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9065 s/iter. Total: 1.0023 s/iter. ETA=0:02:20
[08/01 22:25:34] d2.evaluation.evaluator INFO: Inference done 401/535. Dataloading: 0.0007 s/iter. Inference: 0.0949 s/iter. Eval: 0.9065 s/iter. Total: 1.0023 s/iter. ETA=0:02:14
[08/01 22:25:39] d2.evaluation.evaluator INFO: Inference done 406/535. Dataloading: 0.0007 s/iter. Inference: 0.0949 s/iter. Eval: 0.9065 s/iter. Total: 1.0022 s/iter. ETA=0:02:09
[08/01 22:25:44] d2.evaluation.evaluator INFO: Inference done 411/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9066 s/iter. Total: 1.0023 s/iter. ETA=0:02:04
[08/01 22:25:49] d2.evaluation.evaluator INFO: Inference done 416/535. Dataloading: 0.0007 s/iter. Inference: 0.0949 s/iter. Eval: 0.9066 s/iter. Total: 1.0023 s/iter. ETA=0:01:59
[08/01 22:25:54] d2.evaluation.evaluator INFO: Inference done 421/535. Dataloading: 0.0007 s/iter. Inference: 0.0949 s/iter. Eval: 0.9067 s/iter. Total: 1.0023 s/iter. ETA=0:01:54
[08/01 22:25:59] d2.evaluation.evaluator INFO: Inference done 426/535. Dataloading: 0.0007 s/iter. Inference: 0.0949 s/iter. Eval: 0.9067 s/iter. Total: 1.0024 s/iter. ETA=0:01:49
[08/01 22:26:05] d2.evaluation.evaluator INFO: Inference done 432/535. Dataloading: 0.0007 s/iter. Inference: 0.0948 s/iter. Eval: 0.9068 s/iter. Total: 1.0024 s/iter. ETA=0:01:43
[08/01 22:26:11] d2.evaluation.evaluator INFO: Inference done 438/535. Dataloading: 0.0007 s/iter. Inference: 0.0947 s/iter. Eval: 0.9068 s/iter. Total: 1.0023 s/iter. ETA=0:01:37
[08/01 22:26:17] d2.evaluation.evaluator INFO: Inference done 444/535. Dataloading: 0.0007 s/iter. Inference: 0.0947 s/iter. Eval: 0.9068 s/iter. Total: 1.0022 s/iter. ETA=0:01:31
[08/01 22:26:23] d2.evaluation.evaluator INFO: Inference done 450/535. Dataloading: 0.0007 s/iter. Inference: 0.0947 s/iter. Eval: 0.9068 s/iter. Total: 1.0022 s/iter. ETA=0:01:25
[08/01 22:26:28] d2.evaluation.evaluator INFO: Inference done 455/535. Dataloading: 0.0007 s/iter. Inference: 0.0949 s/iter. Eval: 0.9068 s/iter. Total: 1.0025 s/iter. ETA=0:01:20
[08/01 22:26:34] d2.evaluation.evaluator INFO: Inference done 461/535. Dataloading: 0.0007 s/iter. Inference: 0.0948 s/iter. Eval: 0.9067 s/iter. Total: 1.0024 s/iter. ETA=0:01:14
[08/01 22:26:40] d2.evaluation.evaluator INFO: Inference done 467/535. Dataloading: 0.0007 s/iter. Inference: 0.0948 s/iter. Eval: 0.9067 s/iter. Total: 1.0023 s/iter. ETA=0:01:08
[08/01 22:26:45] d2.evaluation.evaluator INFO: Inference done 472/535. Dataloading: 0.0007 s/iter. Inference: 0.0948 s/iter. Eval: 0.9067 s/iter. Total: 1.0023 s/iter. ETA=0:01:03
[08/01 22:26:51] d2.evaluation.evaluator INFO: Inference done 478/535. Dataloading: 0.0007 s/iter. Inference: 0.0948 s/iter. Eval: 0.9067 s/iter. Total: 1.0023 s/iter. ETA=0:00:57
[08/01 22:26:56] d2.evaluation.evaluator INFO: Inference done 483/535. Dataloading: 0.0007 s/iter. Inference: 0.0948 s/iter. Eval: 0.9067 s/iter. Total: 1.0023 s/iter. ETA=0:00:52
[08/01 22:27:02] d2.evaluation.evaluator INFO: Inference done 489/535. Dataloading: 0.0007 s/iter. Inference: 0.0948 s/iter. Eval: 0.9067 s/iter. Total: 1.0023 s/iter. ETA=0:00:46
[08/01 22:27:08] d2.evaluation.evaluator INFO: Inference done 495/535. Dataloading: 0.0007 s/iter. Inference: 0.0947 s/iter. Eval: 0.9068 s/iter. Total: 1.0023 s/iter. ETA=0:00:40
[08/01 22:27:13] d2.evaluation.evaluator INFO: Inference done 500/535. Dataloading: 0.0007 s/iter. Inference: 0.0947 s/iter. Eval: 0.9068 s/iter. Total: 1.0022 s/iter. ETA=0:00:35
[08/01 22:27:19] d2.evaluation.evaluator INFO: Inference done 506/535. Dataloading: 0.0007 s/iter. Inference: 0.0946 s/iter. Eval: 0.9067 s/iter. Total: 1.0022 s/iter. ETA=0:00:29
[08/01 22:27:25] d2.evaluation.evaluator INFO: Inference done 512/535. Dataloading: 0.0007 s/iter. Inference: 0.0946 s/iter. Eval: 0.9067 s/iter. Total: 1.0021 s/iter. ETA=0:00:23
[08/01 22:27:30] d2.evaluation.evaluator INFO: Inference done 517/535. Dataloading: 0.0007 s/iter. Inference: 0.0946 s/iter. Eval: 0.9067 s/iter. Total: 1.0021 s/iter. ETA=0:00:18
[08/01 22:27:36] d2.evaluation.evaluator INFO: Inference done 523/535. Dataloading: 0.0007 s/iter. Inference: 0.0946 s/iter. Eval: 0.9067 s/iter. Total: 1.0021 s/iter. ETA=0:00:12
[08/01 22:27:42] d2.evaluation.evaluator INFO: Inference done 529/535. Dataloading: 0.0007 s/iter. Inference: 0.0946 s/iter. Eval: 0.9066 s/iter. Total: 1.0021 s/iter. ETA=0:00:06
[08/01 22:27:48] d2.evaluation.evaluator INFO: Inference done 535/535. Dataloading: 0.0007 s/iter. Inference: 0.0946 s/iter. Eval: 0.9067 s/iter. Total: 1.0020 s/iter. ETA=0:00:00
[08/01 22:27:48] d2.evaluation.evaluator INFO: Total inference time: 0:08:51.148735 (1.002167 s / iter per device, on 1 devices)
[08/01 22:27:48] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:50 (0.094556 s / iter per device, on 1 devices)
[08/01 22:27:49] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[08/01 22:27:49] d2.evaluation.coco_evaluation INFO: Saving results to ./R101_overlap/inference/coco_instances_results.json
[08/01 22:27:49] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[08/01 22:27:51] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 |  nan  | 0.000 |
[08/01 22:27:51] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 22:27:51] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| normal     | 0.000 | defect     | 0.000 |
[08/01 22:27:57] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75  |  APs   |  APm  |  APl   |
|:------:|:-------:|:------:|:------:|:-----:|:------:|
| 99.091 | 100.000 | 99.505 | 94.424 |  nan  | 99.091 |
[08/01 22:27:57] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 22:27:57] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| normal     | 99.455 | defect     | 98.726 |
[08/01 22:27:57] d2.engine.defaults INFO: Evaluation results for front2class_2017_val_overlap_panoptic in csv format:
[08/01 22:27:57] d2.evaluation.testing INFO: copypaste: Task: bbox
[08/01 22:27:57] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 22:27:57] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,nan,0.0000
[08/01 22:27:57] d2.evaluation.testing INFO: copypaste: Task: segm
[08/01 22:27:57] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 22:27:57] d2.evaluation.testing INFO: copypaste: 99.0905,100.0000,99.5050,94.4242,nan,99.0905
[08/01 22:27:57] d2.utils.events INFO:  eta: 0:14:03  iter: 29999  total_loss: 2.801  loss_ce: 3.507e-05  loss_mask: 0.1081  loss_dice: 0.1604  loss_ce_0: 0.1258  loss_mask_0: 0.1079  loss_dice_0: 0.161  loss_ce_1: 4.991e-05  loss_mask_1: 0.1075  loss_dice_1: 0.1626  loss_ce_2: 5.772e-05  loss_mask_2: 0.11  loss_dice_2: 0.1589  loss_ce_3: 3.989e-05  loss_mask_3: 0.1061  loss_dice_3: 0.1573  loss_ce_4: 3.992e-05  loss_mask_4: 0.1106  loss_dice_4: 0.1593  loss_ce_5: 5.113e-05  loss_mask_5: 0.1091  loss_dice_5: 0.164  loss_ce_6: 2.965e-05  loss_mask_6: 0.1092  loss_dice_6: 0.1609  loss_ce_7: 4.469e-05  loss_mask_7: 0.1086  loss_dice_7: 0.1651  loss_ce_8: 4.963e-05  loss_mask_8: 0.106  loss_dice_8: 0.1571  time: 0.5299  data_time: 0.0011  lr: 1e-05  max_mem: 8444M
[08/01 22:27:57] d2.engine.hooks INFO: Not saving as latest eval score for total_loss is 2.95719, not better than best score 2.42329 @ iteration 24999.
[08/01 22:28:00] d2.utils.events INFO:  eta: 0:13:59  iter: 30019  total_loss: 2.854  loss_ce: 2.825e-05  loss_mask: 0.1092  loss_dice: 0.1648  loss_ce_0: 0.1248  loss_mask_0: 0.1089  loss_dice_0: 0.1657  loss_ce_1: 4.463e-05  loss_mask_1: 0.1086  loss_dice_1: 0.1629  loss_ce_2: 4.743e-05  loss_mask_2: 0.1074  loss_dice_2: 0.1653  loss_ce_3: 2.524e-05  loss_mask_3: 0.1081  loss_dice_3: 0.162  loss_ce_4: 3.403e-05  loss_mask_4: 0.1084  loss_dice_4: 0.1595  loss_ce_5: 4.282e-05  loss_mask_5: 0.1091  loss_dice_5: 0.1626  loss_ce_6: 2.426e-05  loss_mask_6: 0.1067  loss_dice_6: 0.1606  loss_ce_7: 3.605e-05  loss_mask_7: 0.1084  loss_dice_7: 0.1622  loss_ce_8: 4.312e-05  loss_mask_8: 0.1086  loss_dice_8: 0.1629  time: 0.5296  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:28:04] d2.utils.events INFO:  eta: 0:13:56  iter: 30039  total_loss: 2.975  loss_ce: 2.833e-05  loss_mask: 0.1115  loss_dice: 0.1708  loss_ce_0: 0.1245  loss_mask_0: 0.1161  loss_dice_0: 0.1716  loss_ce_1: 5.222e-05  loss_mask_1: 0.1137  loss_dice_1: 0.17  loss_ce_2: 4.528e-05  loss_mask_2: 0.1146  loss_dice_2: 0.1735  loss_ce_3: 2.239e-05  loss_mask_3: 0.1171  loss_dice_3: 0.1754  loss_ce_4: 3.222e-05  loss_mask_4: 0.1143  loss_dice_4: 0.1708  loss_ce_5: 4.665e-05  loss_mask_5: 0.111  loss_dice_5: 0.1706  loss_ce_6: 2.307e-05  loss_mask_6: 0.112  loss_dice_6: 0.1757  loss_ce_7: 3.594e-05  loss_mask_7: 0.1141  loss_dice_7: 0.1703  loss_ce_8: 5.305e-05  loss_mask_8: 0.1139  loss_dice_8: 0.1691  time: 0.5294  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:28:07] d2.utils.events INFO:  eta: 0:13:53  iter: 30059  total_loss: 2.705  loss_ce: 2.765e-05  loss_mask: 0.1021  loss_dice: 0.1534  loss_ce_0: 0.128  loss_mask_0: 0.1089  loss_dice_0: 0.163  loss_ce_1: 5.49e-05  loss_mask_1: 0.1042  loss_dice_1: 0.1569  loss_ce_2: 4.512e-05  loss_mask_2: 0.1042  loss_dice_2: 0.1613  loss_ce_3: 2.347e-05  loss_mask_3: 0.1058  loss_dice_3: 0.1563  loss_ce_4: 3.37e-05  loss_mask_4: 0.107  loss_dice_4: 0.1567  loss_ce_5: 4.188e-05  loss_mask_5: 0.1025  loss_dice_5: 0.1567  loss_ce_6: 2.254e-05  loss_mask_6: 0.1069  loss_dice_6: 0.1547  loss_ce_7: 3.496e-05  loss_mask_7: 0.1079  loss_dice_7: 0.1528  loss_ce_8: 4.819e-05  loss_mask_8: 0.1031  loss_dice_8: 0.1576  time: 0.5291  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:28:10] d2.utils.events INFO:  eta: 0:13:49  iter: 30079  total_loss: 3.065  loss_ce: 3.082e-05  loss_mask: 0.1142  loss_dice: 0.1701  loss_ce_0: 0.1243  loss_mask_0: 0.1157  loss_dice_0: 0.1768  loss_ce_1: 4.273e-05  loss_mask_1: 0.115  loss_dice_1: 0.176  loss_ce_2: 5.049e-05  loss_mask_2: 0.1167  loss_dice_2: 0.176  loss_ce_3: 3.798e-05  loss_mask_3: 0.1152  loss_dice_3: 0.1764  loss_ce_4: 3.587e-05  loss_mask_4: 0.1121  loss_dice_4: 0.1764  loss_ce_5: 3.823e-05  loss_mask_5: 0.115  loss_dice_5: 0.1707  loss_ce_6: 2.866e-05  loss_mask_6: 0.1177  loss_dice_6: 0.175  loss_ce_7: 3.474e-05  loss_mask_7: 0.1143  loss_dice_7: 0.1713  loss_ce_8: 3.99e-05  loss_mask_8: 0.1125  loss_dice_8: 0.1733  time: 0.5289  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:28:14] d2.utils.events INFO:  eta: 0:13:46  iter: 30099  total_loss: 2.799  loss_ce: 2.875e-05  loss_mask: 0.1055  loss_dice: 0.1656  loss_ce_0: 0.1243  loss_mask_0: 0.1094  loss_dice_0: 0.1636  loss_ce_1: 5.298e-05  loss_mask_1: 0.1075  loss_dice_1: 0.1606  loss_ce_2: 5.795e-05  loss_mask_2: 0.1088  loss_dice_2: 0.16  loss_ce_3: 2.877e-05  loss_mask_3: 0.1069  loss_dice_3: 0.1645  loss_ce_4: 3.52e-05  loss_mask_4: 0.1075  loss_dice_4: 0.1626  loss_ce_5: 4.545e-05  loss_mask_5: 0.107  loss_dice_5: 0.162  loss_ce_6: 2.53e-05  loss_mask_6: 0.1096  loss_dice_6: 0.1673  loss_ce_7: 3.849e-05  loss_mask_7: 0.1102  loss_dice_7: 0.1686  loss_ce_8: 4.988e-05  loss_mask_8: 0.1083  loss_dice_8: 0.1634  time: 0.5287  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:28:17] d2.utils.events INFO:  eta: 0:13:42  iter: 30119  total_loss: 2.861  loss_ce: 3.306e-05  loss_mask: 0.111  loss_dice: 0.1635  loss_ce_0: 0.1243  loss_mask_0: 0.1103  loss_dice_0: 0.1631  loss_ce_1: 4.488e-05  loss_mask_1: 0.1125  loss_dice_1: 0.1606  loss_ce_2: 5.844e-05  loss_mask_2: 0.1105  loss_dice_2: 0.1653  loss_ce_3: 3.276e-05  loss_mask_3: 0.109  loss_dice_3: 0.1609  loss_ce_4: 3.688e-05  loss_mask_4: 0.1099  loss_dice_4: 0.162  loss_ce_5: 4.724e-05  loss_mask_5: 0.1124  loss_dice_5: 0.1633  loss_ce_6: 2.839e-05  loss_mask_6: 0.1101  loss_dice_6: 0.1634  loss_ce_7: 3.798e-05  loss_mask_7: 0.1131  loss_dice_7: 0.159  loss_ce_8: 4.414e-05  loss_mask_8: 0.1072  loss_dice_8: 0.1617  time: 0.5284  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:28:20] d2.utils.events INFO:  eta: 0:13:39  iter: 30139  total_loss: 2.829  loss_ce: 2.961e-05  loss_mask: 0.1088  loss_dice: 0.1617  loss_ce_0: 0.1244  loss_mask_0: 0.1072  loss_dice_0: 0.1574  loss_ce_1: 4.602e-05  loss_mask_1: 0.1093  loss_dice_1: 0.1633  loss_ce_2: 5.493e-05  loss_mask_2: 0.1076  loss_dice_2: 0.1608  loss_ce_3: 2.6e-05  loss_mask_3: 0.1068  loss_dice_3: 0.157  loss_ce_4: 3.47e-05  loss_mask_4: 0.108  loss_dice_4: 0.1585  loss_ce_5: 3.817e-05  loss_mask_5: 0.1099  loss_dice_5: 0.1626  loss_ce_6: 2.508e-05  loss_mask_6: 0.1088  loss_dice_6: 0.1572  loss_ce_7: 3.6e-05  loss_mask_7: 0.1101  loss_dice_7: 0.1606  loss_ce_8: 4.054e-05  loss_mask_8: 0.108  loss_dice_8: 0.1594  time: 0.5282  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:28:24] d2.utils.events INFO:  eta: 0:13:36  iter: 30159  total_loss: 2.919  loss_ce: 2.423e-05  loss_mask: 0.1096  loss_dice: 0.1628  loss_ce_0: 0.1243  loss_mask_0: 0.1127  loss_dice_0: 0.1698  loss_ce_1: 4.259e-05  loss_mask_1: 0.1169  loss_dice_1: 0.17  loss_ce_2: 4.5e-05  loss_mask_2: 0.11  loss_dice_2: 0.1662  loss_ce_3: 2.029e-05  loss_mask_3: 0.1124  loss_dice_3: 0.1638  loss_ce_4: 3.336e-05  loss_mask_4: 0.1114  loss_dice_4: 0.1657  loss_ce_5: 3.795e-05  loss_mask_5: 0.113  loss_dice_5: 0.1697  loss_ce_6: 2.188e-05  loss_mask_6: 0.1126  loss_dice_6: 0.1718  loss_ce_7: 3.419e-05  loss_mask_7: 0.1134  loss_dice_7: 0.1681  loss_ce_8: 3.939e-05  loss_mask_8: 0.1155  loss_dice_8: 0.174  time: 0.5279  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:28:27] d2.utils.events INFO:  eta: 0:13:33  iter: 30179  total_loss: 2.874  loss_ce: 2.768e-05  loss_mask: 0.1127  loss_dice: 0.1653  loss_ce_0: 0.1281  loss_mask_0: 0.1056  loss_dice_0: 0.1654  loss_ce_1: 4.816e-05  loss_mask_1: 0.1113  loss_dice_1: 0.1683  loss_ce_2: 4.721e-05  loss_mask_2: 0.1109  loss_dice_2: 0.1725  loss_ce_3: 2.342e-05  loss_mask_3: 0.1055  loss_dice_3: 0.1617  loss_ce_4: 3.335e-05  loss_mask_4: 0.1085  loss_dice_4: 0.1637  loss_ce_5: 3.846e-05  loss_mask_5: 0.1098  loss_dice_5: 0.1664  loss_ce_6: 2.319e-05  loss_mask_6: 0.1058  loss_dice_6: 0.162  loss_ce_7: 3.642e-05  loss_mask_7: 0.1074  loss_dice_7: 0.1632  loss_ce_8: 4.017e-05  loss_mask_8: 0.1052  loss_dice_8: 0.1672  time: 0.5277  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:28:31] d2.utils.events INFO:  eta: 0:13:30  iter: 30199  total_loss: 2.826  loss_ce: 2.861e-05  loss_mask: 0.1057  loss_dice: 0.1609  loss_ce_0: 0.1245  loss_mask_0: 0.1058  loss_dice_0: 0.1597  loss_ce_1: 4.401e-05  loss_mask_1: 0.1102  loss_dice_1: 0.1681  loss_ce_2: 4.519e-05  loss_mask_2: 0.1065  loss_dice_2: 0.1624  loss_ce_3: 2.758e-05  loss_mask_3: 0.1073  loss_dice_3: 0.1609  loss_ce_4: 3.441e-05  loss_mask_4: 0.111  loss_dice_4: 0.1638  loss_ce_5: 3.808e-05  loss_mask_5: 0.106  loss_dice_5: 0.1594  loss_ce_6: 2.383e-05  loss_mask_6: 0.1046  loss_dice_6: 0.1603  loss_ce_7: 3.491e-05  loss_mask_7: 0.1047  loss_dice_7: 0.161  loss_ce_8: 3.919e-05  loss_mask_8: 0.1098  loss_dice_8: 0.1612  time: 0.5275  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:28:34] d2.utils.events INFO:  eta: 0:13:27  iter: 30219  total_loss: 2.884  loss_ce: 3.006e-05  loss_mask: 0.1137  loss_dice: 0.1673  loss_ce_0: 0.1244  loss_mask_0: 0.112  loss_dice_0: 0.1659  loss_ce_1: 4.868e-05  loss_mask_1: 0.1139  loss_dice_1: 0.1615  loss_ce_2: 5.535e-05  loss_mask_2: 0.1118  loss_dice_2: 0.1683  loss_ce_3: 3.381e-05  loss_mask_3: 0.114  loss_dice_3: 0.1668  loss_ce_4: 3.61e-05  loss_mask_4: 0.1122  loss_dice_4: 0.1665  loss_ce_5: 4.557e-05  loss_mask_5: 0.1125  loss_dice_5: 0.1662  loss_ce_6: 2.628e-05  loss_mask_6: 0.1178  loss_dice_6: 0.169  loss_ce_7: 3.928e-05  loss_mask_7: 0.1134  loss_dice_7: 0.1728  loss_ce_8: 4.831e-05  loss_mask_8: 0.1136  loss_dice_8: 0.1658  time: 0.5272  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:28:37] d2.utils.events INFO:  eta: 0:13:24  iter: 30239  total_loss: 2.888  loss_ce: 2.839e-05  loss_mask: 0.113  loss_dice: 0.1701  loss_ce_0: 0.1245  loss_mask_0: 0.11  loss_dice_0: 0.1653  loss_ce_1: 4.025e-05  loss_mask_1: 0.1071  loss_dice_1: 0.1624  loss_ce_2: 3.99e-05  loss_mask_2: 0.1115  loss_dice_2: 0.1667  loss_ce_3: 1.934e-05  loss_mask_3: 0.1068  loss_dice_3: 0.1619  loss_ce_4: 2.584e-05  loss_mask_4: 0.1072  loss_dice_4: 0.1673  loss_ce_5: 3.123e-05  loss_mask_5: 0.1103  loss_dice_5: 0.1647  loss_ce_6: 2.19e-05  loss_mask_6: 0.1134  loss_dice_6: 0.1675  loss_ce_7: 3.373e-05  loss_mask_7: 0.1057  loss_dice_7: 0.1595  loss_ce_8: 3.408e-05  loss_mask_8: 0.1082  loss_dice_8: 0.1671  time: 0.5270  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:28:41] d2.utils.events INFO:  eta: 0:13:21  iter: 30259  total_loss: 2.766  loss_ce: 2.676e-05  loss_mask: 0.1064  loss_dice: 0.1608  loss_ce_0: 0.1244  loss_mask_0: 0.1071  loss_dice_0: 0.1654  loss_ce_1: 4.604e-05  loss_mask_1: 0.1053  loss_dice_1: 0.1616  loss_ce_2: 4.511e-05  loss_mask_2: 0.1038  loss_dice_2: 0.1534  loss_ce_3: 2.336e-05  loss_mask_3: 0.1046  loss_dice_3: 0.1623  loss_ce_4: 3.308e-05  loss_mask_4: 0.1091  loss_dice_4: 0.1655  loss_ce_5: 3.827e-05  loss_mask_5: 0.1043  loss_dice_5: 0.1557  loss_ce_6: 2.426e-05  loss_mask_6: 0.1057  loss_dice_6: 0.157  loss_ce_7: 3.465e-05  loss_mask_7: 0.1069  loss_dice_7: 0.1561  loss_ce_8: 3.982e-05  loss_mask_8: 0.1069  loss_dice_8: 0.1667  time: 0.5268  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:28:44] d2.utils.events INFO:  eta: 0:13:18  iter: 30279  total_loss: 2.844  loss_ce: 2.857e-05  loss_mask: 0.107  loss_dice: 0.1622  loss_ce_0: 0.1244  loss_mask_0: 0.1072  loss_dice_0: 0.1605  loss_ce_1: 4.802e-05  loss_mask_1: 0.1047  loss_dice_1: 0.1642  loss_ce_2: 5.465e-05  loss_mask_2: 0.1087  loss_dice_2: 0.1652  loss_ce_3: 2.494e-05  loss_mask_3: 0.1066  loss_dice_3: 0.1612  loss_ce_4: 3.473e-05  loss_mask_4: 0.1078  loss_dice_4: 0.1636  loss_ce_5: 4.658e-05  loss_mask_5: 0.1078  loss_dice_5: 0.162  loss_ce_6: 2.46e-05  loss_mask_6: 0.1058  loss_dice_6: 0.1618  loss_ce_7: 3.69e-05  loss_mask_7: 0.1088  loss_dice_7: 0.1631  loss_ce_8: 4.982e-05  loss_mask_8: 0.108  loss_dice_8: 0.1617  time: 0.5265  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:28:48] d2.utils.events INFO:  eta: 0:13:14  iter: 30299  total_loss: 2.77  loss_ce: 3.005e-05  loss_mask: 0.09975  loss_dice: 0.1604  loss_ce_0: 0.1245  loss_mask_0: 0.1058  loss_dice_0: 0.1619  loss_ce_1: 4.523e-05  loss_mask_1: 0.1051  loss_dice_1: 0.1655  loss_ce_2: 4.591e-05  loss_mask_2: 0.1023  loss_dice_2: 0.1594  loss_ce_3: 2.965e-05  loss_mask_3: 0.1013  loss_dice_3: 0.1498  loss_ce_4: 3.648e-05  loss_mask_4: 0.1012  loss_dice_4: 0.1591  loss_ce_5: 4.185e-05  loss_mask_5: 0.1018  loss_dice_5: 0.1617  loss_ce_6: 2.572e-05  loss_mask_6: 0.104  loss_dice_6: 0.1583  loss_ce_7: 3.774e-05  loss_mask_7: 0.1012  loss_dice_7: 0.1565  loss_ce_8: 4.428e-05  loss_mask_8: 0.1021  loss_dice_8: 0.1603  time: 0.5263  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:28:51] d2.utils.events INFO:  eta: 0:13:10  iter: 30319  total_loss: 2.93  loss_ce: 3.857e-05  loss_mask: 0.1157  loss_dice: 0.1694  loss_ce_0: 0.1243  loss_mask_0: 0.114  loss_dice_0: 0.1723  loss_ce_1: 4.971e-05  loss_mask_1: 0.1135  loss_dice_1: 0.1651  loss_ce_2: 5.797e-05  loss_mask_2: 0.1153  loss_dice_2: 0.1665  loss_ce_3: 4.036e-05  loss_mask_3: 0.1161  loss_dice_3: 0.1643  loss_ce_4: 4.182e-05  loss_mask_4: 0.1143  loss_dice_4: 0.1617  loss_ce_5: 5.759e-05  loss_mask_5: 0.1142  loss_dice_5: 0.166  loss_ce_6: 2.976e-05  loss_mask_6: 0.116  loss_dice_6: 0.1617  loss_ce_7: 4.339e-05  loss_mask_7: 0.1138  loss_dice_7: 0.1683  loss_ce_8: 4.942e-05  loss_mask_8: 0.1138  loss_dice_8: 0.1595  time: 0.5260  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:28:54] d2.utils.events INFO:  eta: 0:13:07  iter: 30339  total_loss: 2.783  loss_ce: 2.808e-05  loss_mask: 0.1119  loss_dice: 0.1572  loss_ce_0: 0.1245  loss_mask_0: 0.1089  loss_dice_0: 0.1582  loss_ce_1: 4.382e-05  loss_mask_1: 0.1081  loss_dice_1: 0.1553  loss_ce_2: 4.403e-05  loss_mask_2: 0.108  loss_dice_2: 0.1576  loss_ce_3: 2.267e-05  loss_mask_3: 0.1125  loss_dice_3: 0.1594  loss_ce_4: 3.29e-05  loss_mask_4: 0.1083  loss_dice_4: 0.1537  loss_ce_5: 3.84e-05  loss_mask_5: 0.1084  loss_dice_5: 0.1602  loss_ce_6: 2.26e-05  loss_mask_6: 0.1066  loss_dice_6: 0.1582  loss_ce_7: 3.426e-05  loss_mask_7: 0.1107  loss_dice_7: 0.1545  loss_ce_8: 3.941e-05  loss_mask_8: 0.1072  loss_dice_8: 0.159  time: 0.5258  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:28:58] d2.utils.events INFO:  eta: 0:13:03  iter: 30359  total_loss: 2.939  loss_ce: 2.731e-05  loss_mask: 0.1102  loss_dice: 0.1666  loss_ce_0: 0.1245  loss_mask_0: 0.11  loss_dice_0: 0.1718  loss_ce_1: 3.681e-05  loss_mask_1: 0.1098  loss_dice_1: 0.1684  loss_ce_2: 3.943e-05  loss_mask_2: 0.111  loss_dice_2: 0.1688  loss_ce_3: 1.713e-05  loss_mask_3: 0.1109  loss_dice_3: 0.171  loss_ce_4: 2.469e-05  loss_mask_4: 0.1113  loss_dice_4: 0.1623  loss_ce_5: 3.089e-05  loss_mask_5: 0.1127  loss_dice_5: 0.1669  loss_ce_6: 2.069e-05  loss_mask_6: 0.107  loss_dice_6: 0.1673  loss_ce_7: 3.503e-05  loss_mask_7: 0.1092  loss_dice_7: 0.1667  loss_ce_8: 3.484e-05  loss_mask_8: 0.1107  loss_dice_8: 0.1678  time: 0.5256  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:01] d2.utils.events INFO:  eta: 0:13:00  iter: 30379  total_loss: 2.812  loss_ce: 2.672e-05  loss_mask: 0.1076  loss_dice: 0.1604  loss_ce_0: 0.1244  loss_mask_0: 0.1091  loss_dice_0: 0.1628  loss_ce_1: 3.218e-05  loss_mask_1: 0.1105  loss_dice_1: 0.1624  loss_ce_2: 3.371e-05  loss_mask_2: 0.1067  loss_dice_2: 0.1634  loss_ce_3: 1.497e-05  loss_mask_3: 0.1134  loss_dice_3: 0.1583  loss_ce_4: 1.853e-05  loss_mask_4: 0.1094  loss_dice_4: 0.1644  loss_ce_5: 2.396e-05  loss_mask_5: 0.1105  loss_dice_5: 0.1571  loss_ce_6: 1.748e-05  loss_mask_6: 0.1072  loss_dice_6: 0.1643  loss_ce_7: 2.743e-05  loss_mask_7: 0.1113  loss_dice_7: 0.1654  loss_ce_8: 2.899e-05  loss_mask_8: 0.1101  loss_dice_8: 0.1629  time: 0.5253  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:04] d2.utils.events INFO:  eta: 0:12:57  iter: 30399  total_loss: 2.79  loss_ce: 2.656e-05  loss_mask: 0.1033  loss_dice: 0.1568  loss_ce_0: 0.1244  loss_mask_0: 0.1087  loss_dice_0: 0.1618  loss_ce_1: 3.42e-05  loss_mask_1: 0.1086  loss_dice_1: 0.1551  loss_ce_2: 3.391e-05  loss_mask_2: 0.1089  loss_dice_2: 0.1598  loss_ce_3: 1.991e-05  loss_mask_3: 0.108  loss_dice_3: 0.155  loss_ce_4: 1.882e-05  loss_mask_4: 0.109  loss_dice_4: 0.1567  loss_ce_5: 2.373e-05  loss_mask_5: 0.1107  loss_dice_5: 0.1593  loss_ce_6: 2.186e-05  loss_mask_6: 0.1104  loss_dice_6: 0.1651  loss_ce_7: 2.838e-05  loss_mask_7: 0.1078  loss_dice_7: 0.1553  loss_ce_8: 2.904e-05  loss_mask_8: 0.1075  loss_dice_8: 0.1569  time: 0.5251  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:08] d2.utils.events INFO:  eta: 0:12:54  iter: 30419  total_loss: 2.787  loss_ce: 3.543e-05  loss_mask: 0.1117  loss_dice: 0.1625  loss_ce_0: 0.1243  loss_mask_0: 0.107  loss_dice_0: 0.1614  loss_ce_1: 5.375e-05  loss_mask_1: 0.1079  loss_dice_1: 0.1623  loss_ce_2: 5.921e-05  loss_mask_2: 0.1116  loss_dice_2: 0.1657  loss_ce_3: 2.821e-05  loss_mask_3: 0.108  loss_dice_3: 0.1648  loss_ce_4: 3.497e-05  loss_mask_4: 0.1096  loss_dice_4: 0.1661  loss_ce_5: 5.091e-05  loss_mask_5: 0.1103  loss_dice_5: 0.1639  loss_ce_6: 2.658e-05  loss_mask_6: 0.1061  loss_dice_6: 0.16  loss_ce_7: 4.032e-05  loss_mask_7: 0.1087  loss_dice_7: 0.1639  loss_ce_8: 4.905e-05  loss_mask_8: 0.1061  loss_dice_8: 0.162  time: 0.5249  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:29:11] d2.utils.events INFO:  eta: 0:12:51  iter: 30439  total_loss: 2.803  loss_ce: 2.796e-05  loss_mask: 0.1064  loss_dice: 0.1629  loss_ce_0: 0.1244  loss_mask_0: 0.1082  loss_dice_0: 0.1577  loss_ce_1: 4.833e-05  loss_mask_1: 0.1065  loss_dice_1: 0.1608  loss_ce_2: 4.339e-05  loss_mask_2: 0.1079  loss_dice_2: 0.1609  loss_ce_3: 1.937e-05  loss_mask_3: 0.106  loss_dice_3: 0.1579  loss_ce_4: 3.191e-05  loss_mask_4: 0.109  loss_dice_4: 0.1513  loss_ce_5: 3.76e-05  loss_mask_5: 0.1085  loss_dice_5: 0.1555  loss_ce_6: 2.14e-05  loss_mask_6: 0.1078  loss_dice_6: 0.1533  loss_ce_7: 3.365e-05  loss_mask_7: 0.1049  loss_dice_7: 0.156  loss_ce_8: 4.006e-05  loss_mask_8: 0.1097  loss_dice_8: 0.1584  time: 0.5246  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:15] d2.utils.events INFO:  eta: 0:12:48  iter: 30459  total_loss: 2.902  loss_ce: 2.908e-05  loss_mask: 0.1133  loss_dice: 0.1697  loss_ce_0: 0.1244  loss_mask_0: 0.1102  loss_dice_0: 0.1649  loss_ce_1: 4.551e-05  loss_mask_1: 0.1085  loss_dice_1: 0.1675  loss_ce_2: 4.532e-05  loss_mask_2: 0.1097  loss_dice_2: 0.1655  loss_ce_3: 2.358e-05  loss_mask_3: 0.1098  loss_dice_3: 0.1624  loss_ce_4: 3.416e-05  loss_mask_4: 0.111  loss_dice_4: 0.1638  loss_ce_5: 4.289e-05  loss_mask_5: 0.1093  loss_dice_5: 0.1611  loss_ce_6: 2.371e-05  loss_mask_6: 0.1058  loss_dice_6: 0.1592  loss_ce_7: 3.671e-05  loss_mask_7: 0.1118  loss_dice_7: 0.1674  loss_ce_8: 4.342e-05  loss_mask_8: 0.1105  loss_dice_8: 0.1669  time: 0.5244  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:18] d2.utils.events INFO:  eta: 0:12:44  iter: 30479  total_loss: 2.91  loss_ce: 2.833e-05  loss_mask: 0.1116  loss_dice: 0.1649  loss_ce_0: 0.1246  loss_mask_0: 0.1127  loss_dice_0: 0.1646  loss_ce_1: 4.71e-05  loss_mask_1: 0.1131  loss_dice_1: 0.1663  loss_ce_2: 4.532e-05  loss_mask_2: 0.1146  loss_dice_2: 0.165  loss_ce_3: 1.975e-05  loss_mask_3: 0.1117  loss_dice_3: 0.1614  loss_ce_4: 3.438e-05  loss_mask_4: 0.1107  loss_dice_4: 0.1588  loss_ce_5: 3.817e-05  loss_mask_5: 0.1083  loss_dice_5: 0.1609  loss_ce_6: 2.13e-05  loss_mask_6: 0.1102  loss_dice_6: 0.1597  loss_ce_7: 3.765e-05  loss_mask_7: 0.1091  loss_dice_7: 0.1611  loss_ce_8: 3.921e-05  loss_mask_8: 0.1093  loss_dice_8: 0.1605  time: 0.5242  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:21] d2.utils.events INFO:  eta: 0:12:41  iter: 30499  total_loss: 2.861  loss_ce: 2.775e-05  loss_mask: 0.1084  loss_dice: 0.1675  loss_ce_0: 0.1245  loss_mask_0: 0.1097  loss_dice_0: 0.1625  loss_ce_1: 4.838e-05  loss_mask_1: 0.111  loss_dice_1: 0.1682  loss_ce_2: 4.495e-05  loss_mask_2: 0.1082  loss_dice_2: 0.1622  loss_ce_3: 2.353e-05  loss_mask_3: 0.1079  loss_dice_3: 0.1611  loss_ce_4: 3.36e-05  loss_mask_4: 0.1097  loss_dice_4: 0.1611  loss_ce_5: 3.808e-05  loss_mask_5: 0.1118  loss_dice_5: 0.1649  loss_ce_6: 2.472e-05  loss_mask_6: 0.1108  loss_dice_6: 0.1609  loss_ce_7: 3.526e-05  loss_mask_7: 0.1103  loss_dice_7: 0.1622  loss_ce_8: 4.045e-05  loss_mask_8: 0.1089  loss_dice_8: 0.1623  time: 0.5239  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:25] d2.utils.events INFO:  eta: 0:12:38  iter: 30519  total_loss: 2.789  loss_ce: 2.729e-05  loss_mask: 0.1039  loss_dice: 0.1622  loss_ce_0: 0.1244  loss_mask_0: 0.1066  loss_dice_0: 0.1702  loss_ce_1: 4.139e-05  loss_mask_1: 0.1024  loss_dice_1: 0.1611  loss_ce_2: 3.935e-05  loss_mask_2: 0.1051  loss_dice_2: 0.1631  loss_ce_3: 1.97e-05  loss_mask_3: 0.107  loss_dice_3: 0.1597  loss_ce_4: 2.895e-05  loss_mask_4: 0.1032  loss_dice_4: 0.1609  loss_ce_5: 3.092e-05  loss_mask_5: 0.1044  loss_dice_5: 0.1665  loss_ce_6: 2.105e-05  loss_mask_6: 0.1066  loss_dice_6: 0.1617  loss_ce_7: 3.075e-05  loss_mask_7: 0.1074  loss_dice_7: 0.1591  loss_ce_8: 3.368e-05  loss_mask_8: 0.1053  loss_dice_8: 0.1663  time: 0.5237  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:28] d2.utils.events INFO:  eta: 0:12:35  iter: 30539  total_loss: 2.899  loss_ce: 2.684e-05  loss_mask: 0.1096  loss_dice: 0.1678  loss_ce_0: 0.1243  loss_mask_0: 0.1102  loss_dice_0: 0.1667  loss_ce_1: 3.229e-05  loss_mask_1: 0.1126  loss_dice_1: 0.1641  loss_ce_2: 3.308e-05  loss_mask_2: 0.1144  loss_dice_2: 0.168  loss_ce_3: 1.861e-05  loss_mask_3: 0.1125  loss_dice_3: 0.1612  loss_ce_4: 1.882e-05  loss_mask_4: 0.1103  loss_dice_4: 0.1594  loss_ce_5: 2.388e-05  loss_mask_5: 0.1113  loss_dice_5: 0.1576  loss_ce_6: 1.986e-05  loss_mask_6: 0.1083  loss_dice_6: 0.1609  loss_ce_7: 2.291e-05  loss_mask_7: 0.1124  loss_dice_7: 0.1645  loss_ce_8: 2.854e-05  loss_mask_8: 0.1116  loss_dice_8: 0.165  time: 0.5235  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:31] d2.utils.events INFO:  eta: 0:12:31  iter: 30559  total_loss: 2.938  loss_ce: 3.117e-05  loss_mask: 0.1149  loss_dice: 0.1725  loss_ce_0: 0.1244  loss_mask_0: 0.1091  loss_dice_0: 0.1681  loss_ce_1: 5.007e-05  loss_mask_1: 0.1123  loss_dice_1: 0.1689  loss_ce_2: 5.717e-05  loss_mask_2: 0.1109  loss_dice_2: 0.1668  loss_ce_3: 2.957e-05  loss_mask_3: 0.1116  loss_dice_3: 0.1679  loss_ce_4: 3.707e-05  loss_mask_4: 0.114  loss_dice_4: 0.1612  loss_ce_5: 5.034e-05  loss_mask_5: 0.1138  loss_dice_5: 0.1657  loss_ce_6: 2.687e-05  loss_mask_6: 0.111  loss_dice_6: 0.1688  loss_ce_7: 3.958e-05  loss_mask_7: 0.1123  loss_dice_7: 0.1658  loss_ce_8: 4.981e-05  loss_mask_8: 0.1069  loss_dice_8: 0.1656  time: 0.5232  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:35] d2.utils.events INFO:  eta: 0:12:28  iter: 30579  total_loss: 2.93  loss_ce: 2.912e-05  loss_mask: 0.1107  loss_dice: 0.1624  loss_ce_0: 0.1244  loss_mask_0: 0.1112  loss_dice_0: 0.1636  loss_ce_1: 5.652e-05  loss_mask_1: 0.1099  loss_dice_1: 0.162  loss_ce_2: 4.544e-05  loss_mask_2: 0.116  loss_dice_2: 0.1663  loss_ce_3: 2.395e-05  loss_mask_3: 0.1146  loss_dice_3: 0.1677  loss_ce_4: 3.352e-05  loss_mask_4: 0.1149  loss_dice_4: 0.1656  loss_ce_5: 4.683e-05  loss_mask_5: 0.1109  loss_dice_5: 0.1624  loss_ce_6: 2.426e-05  loss_mask_6: 0.1121  loss_dice_6: 0.1642  loss_ce_7: 3.8e-05  loss_mask_7: 0.1106  loss_dice_7: 0.1612  loss_ce_8: 5.454e-05  loss_mask_8: 0.1115  loss_dice_8: 0.1596  time: 0.5230  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:38] d2.utils.events INFO:  eta: 0:12:25  iter: 30599  total_loss: 2.893  loss_ce: 2.73e-05  loss_mask: 0.1134  loss_dice: 0.158  loss_ce_0: 0.1243  loss_mask_0: 0.1154  loss_dice_0: 0.1706  loss_ce_1: 3.978e-05  loss_mask_1: 0.1083  loss_dice_1: 0.1689  loss_ce_2: 4.524e-05  loss_mask_2: 0.1079  loss_dice_2: 0.1664  loss_ce_3: 1.516e-05  loss_mask_3: 0.1092  loss_dice_3: 0.1623  loss_ce_4: 2.612e-05  loss_mask_4: 0.1101  loss_dice_4: 0.167  loss_ce_5: 3.084e-05  loss_mask_5: 0.1106  loss_dice_5: 0.1638  loss_ce_6: 1.872e-05  loss_mask_6: 0.1075  loss_dice_6: 0.1655  loss_ce_7: 3.487e-05  loss_mask_7: 0.1098  loss_dice_7: 0.168  loss_ce_8: 3.358e-05  loss_mask_8: 0.1139  loss_dice_8: 0.1685  time: 0.5228  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:29:42] d2.utils.events INFO:  eta: 0:12:21  iter: 30619  total_loss: 2.906  loss_ce: 2.914e-05  loss_mask: 0.1096  loss_dice: 0.1613  loss_ce_0: 0.1244  loss_mask_0: 0.1101  loss_dice_0: 0.1645  loss_ce_1: 4.636e-05  loss_mask_1: 0.1138  loss_dice_1: 0.1642  loss_ce_2: 4.477e-05  loss_mask_2: 0.1111  loss_dice_2: 0.172  loss_ce_3: 2.188e-05  loss_mask_3: 0.111  loss_dice_3: 0.163  loss_ce_4: 3.582e-05  loss_mask_4: 0.1109  loss_dice_4: 0.1608  loss_ce_5: 4.552e-05  loss_mask_5: 0.1103  loss_dice_5: 0.1616  loss_ce_6: 2.36e-05  loss_mask_6: 0.1125  loss_dice_6: 0.1647  loss_ce_7: 3.941e-05  loss_mask_7: 0.1088  loss_dice_7: 0.168  loss_ce_8: 4.858e-05  loss_mask_8: 0.1112  loss_dice_8: 0.1596  time: 0.5225  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:45] d2.utils.events INFO:  eta: 0:12:18  iter: 30639  total_loss: 2.933  loss_ce: 2.837e-05  loss_mask: 0.1129  loss_dice: 0.169  loss_ce_0: 0.1186  loss_mask_0: 0.1128  loss_dice_0: 0.1678  loss_ce_1: 5.826e-05  loss_mask_1: 0.1128  loss_dice_1: 0.1708  loss_ce_2: 5.259e-05  loss_mask_2: 0.1134  loss_dice_2: 0.1717  loss_ce_3: 2.331e-05  loss_mask_3: 0.1122  loss_dice_3: 0.1669  loss_ce_4: 3.493e-05  loss_mask_4: 0.1139  loss_dice_4: 0.1685  loss_ce_5: 4.483e-05  loss_mask_5: 0.1095  loss_dice_5: 0.1701  loss_ce_6: 2.329e-05  loss_mask_6: 0.1124  loss_dice_6: 0.1676  loss_ce_7: 3.788e-05  loss_mask_7: 0.1139  loss_dice_7: 0.1704  loss_ce_8: 5.204e-05  loss_mask_8: 0.1125  loss_dice_8: 0.1658  time: 0.5223  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:29:48] d2.utils.events INFO:  eta: 0:12:15  iter: 30659  total_loss: 2.831  loss_ce: 2.88e-05  loss_mask: 0.1034  loss_dice: 0.1596  loss_ce_0: 0.1127  loss_mask_0: 0.1061  loss_dice_0: 0.162  loss_ce_1: 5.145e-05  loss_mask_1: 0.1113  loss_dice_1: 0.1645  loss_ce_2: 5.846e-05  loss_mask_2: 0.1088  loss_dice_2: 0.1649  loss_ce_3: 2.862e-05  loss_mask_3: 0.1016  loss_dice_3: 0.1575  loss_ce_4: 3.422e-05  loss_mask_4: 0.1076  loss_dice_4: 0.1563  loss_ce_5: 3.779e-05  loss_mask_5: 0.1101  loss_dice_5: 0.1612  loss_ce_6: 2.565e-05  loss_mask_6: 0.1095  loss_dice_6: 0.1608  loss_ce_7: 3.859e-05  loss_mask_7: 0.1079  loss_dice_7: 0.1555  loss_ce_8: 4.034e-05  loss_mask_8: 0.1102  loss_dice_8: 0.1661  time: 0.5221  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:52] d2.utils.events INFO:  eta: 0:12:11  iter: 30679  total_loss: 2.808  loss_ce: 2.87e-05  loss_mask: 0.1083  loss_dice: 0.1627  loss_ce_0: 0.1243  loss_mask_0: 0.1063  loss_dice_0: 0.1609  loss_ce_1: 4.734e-05  loss_mask_1: 0.1037  loss_dice_1: 0.1561  loss_ce_2: 5.522e-05  loss_mask_2: 0.1052  loss_dice_2: 0.1586  loss_ce_3: 3.066e-05  loss_mask_3: 0.1084  loss_dice_3: 0.1569  loss_ce_4: 3.465e-05  loss_mask_4: 0.1086  loss_dice_4: 0.1576  loss_ce_5: 3.785e-05  loss_mask_5: 0.1064  loss_dice_5: 0.1618  loss_ce_6: 2.558e-05  loss_mask_6: 0.1036  loss_dice_6: 0.1564  loss_ce_7: 3.579e-05  loss_mask_7: 0.1067  loss_dice_7: 0.159  loss_ce_8: 3.948e-05  loss_mask_8: 0.1108  loss_dice_8: 0.1617  time: 0.5219  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:55] d2.utils.events INFO:  eta: 0:12:08  iter: 30699  total_loss: 2.826  loss_ce: 3.045e-05  loss_mask: 0.1041  loss_dice: 0.1611  loss_ce_0: 0.1242  loss_mask_0: 0.1091  loss_dice_0: 0.1724  loss_ce_1: 4.086e-05  loss_mask_1: 0.1045  loss_dice_1: 0.1623  loss_ce_2: 3.945e-05  loss_mask_2: 0.1091  loss_dice_2: 0.1668  loss_ce_3: 2.029e-05  loss_mask_3: 0.1049  loss_dice_3: 0.161  loss_ce_4: 2.54e-05  loss_mask_4: 0.1092  loss_dice_4: 0.1637  loss_ce_5: 3.159e-05  loss_mask_5: 0.1078  loss_dice_5: 0.1597  loss_ce_6: 2.297e-05  loss_mask_6: 0.1067  loss_dice_6: 0.1603  loss_ce_7: 3.27e-05  loss_mask_7: 0.1081  loss_dice_7: 0.1612  loss_ce_8: 3.415e-05  loss_mask_8: 0.1055  loss_dice_8: 0.1659  time: 0.5216  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:29:59] d2.utils.events INFO:  eta: 0:12:05  iter: 30719  total_loss: 2.837  loss_ce: 2.721e-05  loss_mask: 0.1065  loss_dice: 0.1611  loss_ce_0: 0.1245  loss_mask_0: 0.1059  loss_dice_0: 0.1633  loss_ce_1: 4.876e-05  loss_mask_1: 0.1045  loss_dice_1: 0.1572  loss_ce_2: 4.519e-05  loss_mask_2: 0.105  loss_dice_2: 0.1591  loss_ce_3: 2.297e-05  loss_mask_3: 0.1036  loss_dice_3: 0.1598  loss_ce_4: 3.352e-05  loss_mask_4: 0.1061  loss_dice_4: 0.16  loss_ce_5: 3.936e-05  loss_mask_5: 0.1074  loss_dice_5: 0.1639  loss_ce_6: 2.292e-05  loss_mask_6: 0.1049  loss_dice_6: 0.1639  loss_ce_7: 3.876e-05  loss_mask_7: 0.1071  loss_dice_7: 0.1616  loss_ce_8: 4.314e-05  loss_mask_8: 0.1064  loss_dice_8: 0.159  time: 0.5214  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:02] d2.utils.events INFO:  eta: 0:12:02  iter: 30739  total_loss: 2.871  loss_ce: 2.715e-05  loss_mask: 0.1058  loss_dice: 0.1623  loss_ce_0: 0.1245  loss_mask_0: 0.1073  loss_dice_0: 0.1636  loss_ce_1: 4.469e-05  loss_mask_1: 0.1069  loss_dice_1: 0.1615  loss_ce_2: 4.996e-05  loss_mask_2: 0.1078  loss_dice_2: 0.1692  loss_ce_3: 1.824e-05  loss_mask_3: 0.1082  loss_dice_3: 0.1635  loss_ce_4: 3.259e-05  loss_mask_4: 0.1073  loss_dice_4: 0.1622  loss_ce_5: 3.822e-05  loss_mask_5: 0.1058  loss_dice_5: 0.1614  loss_ce_6: 2.132e-05  loss_mask_6: 0.1054  loss_dice_6: 0.1595  loss_ce_7: 3.777e-05  loss_mask_7: 0.1069  loss_dice_7: 0.1625  loss_ce_8: 3.987e-05  loss_mask_8: 0.1092  loss_dice_8: 0.1642  time: 0.5212  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:05] d2.utils.events INFO:  eta: 0:11:58  iter: 30759  total_loss: 2.799  loss_ce: 2.869e-05  loss_mask: 0.1043  loss_dice: 0.1613  loss_ce_0: 0.1242  loss_mask_0: 0.1091  loss_dice_0: 0.1657  loss_ce_1: 4.548e-05  loss_mask_1: 0.1055  loss_dice_1: 0.1607  loss_ce_2: 5.075e-05  loss_mask_2: 0.1059  loss_dice_2: 0.1629  loss_ce_3: 2.668e-05  loss_mask_3: 0.1052  loss_dice_3: 0.1622  loss_ce_4: 3.378e-05  loss_mask_4: 0.1087  loss_dice_4: 0.1594  loss_ce_5: 3.809e-05  loss_mask_5: 0.1085  loss_dice_5: 0.161  loss_ce_6: 2.496e-05  loss_mask_6: 0.1098  loss_dice_6: 0.1672  loss_ce_7: 3.54e-05  loss_mask_7: 0.1073  loss_dice_7: 0.1619  loss_ce_8: 3.993e-05  loss_mask_8: 0.1057  loss_dice_8: 0.1575  time: 0.5209  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:09] d2.utils.events INFO:  eta: 0:11:55  iter: 30779  total_loss: 3.056  loss_ce: 2.575e-05  loss_mask: 0.1087  loss_dice: 0.1633  loss_ce_0: 0.1242  loss_mask_0: 0.1144  loss_dice_0: 0.1697  loss_ce_1: 3.165e-05  loss_mask_1: 0.113  loss_dice_1: 0.168  loss_ce_2: 2.988e-05  loss_mask_2: 0.1132  loss_dice_2: 0.1724  loss_ce_3: 1.68e-05  loss_mask_3: 0.1137  loss_dice_3: 0.1684  loss_ce_4: 1.772e-05  loss_mask_4: 0.1135  loss_dice_4: 0.1709  loss_ce_5: 2.336e-05  loss_mask_5: 0.1115  loss_dice_5: 0.1706  loss_ce_6: 1.934e-05  loss_mask_6: 0.1167  loss_dice_6: 0.171  loss_ce_7: 2.226e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1686  loss_ce_8: 2.845e-05  loss_mask_8: 0.1089  loss_dice_8: 0.1645  time: 0.5207  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:12] d2.utils.events INFO:  eta: 0:11:52  iter: 30799  total_loss: 2.919  loss_ce: 2.689e-05  loss_mask: 0.1104  loss_dice: 0.168  loss_ce_0: 0.1241  loss_mask_0: 0.1133  loss_dice_0: 0.172  loss_ce_1: 5.782e-05  loss_mask_1: 0.1147  loss_dice_1: 0.1713  loss_ce_2: 5.646e-05  loss_mask_2: 0.1118  loss_dice_2: 0.1692  loss_ce_3: 2.402e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1703  loss_ce_4: 3.492e-05  loss_mask_4: 0.112  loss_dice_4: 0.1681  loss_ce_5: 5.196e-05  loss_mask_5: 0.1093  loss_dice_5: 0.1698  loss_ce_6: 2.421e-05  loss_mask_6: 0.1154  loss_dice_6: 0.1668  loss_ce_7: 3.911e-05  loss_mask_7: 0.1106  loss_dice_7: 0.1671  loss_ce_8: 5.584e-05  loss_mask_8: 0.1134  loss_dice_8: 0.1703  time: 0.5205  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:15] d2.utils.events INFO:  eta: 0:11:49  iter: 30819  total_loss: 2.868  loss_ce: 2.902e-05  loss_mask: 0.1119  loss_dice: 0.1649  loss_ce_0: 0.1245  loss_mask_0: 0.1113  loss_dice_0: 0.1677  loss_ce_1: 4.359e-05  loss_mask_1: 0.111  loss_dice_1: 0.1639  loss_ce_2: 5.451e-05  loss_mask_2: 0.1108  loss_dice_2: 0.1648  loss_ce_3: 3.301e-05  loss_mask_3: 0.1127  loss_dice_3: 0.1655  loss_ce_4: 3.387e-05  loss_mask_4: 0.1116  loss_dice_4: 0.1615  loss_ce_5: 3.753e-05  loss_mask_5: 0.1121  loss_dice_5: 0.1621  loss_ce_6: 2.678e-05  loss_mask_6: 0.11  loss_dice_6: 0.1648  loss_ce_7: 3.644e-05  loss_mask_7: 0.1113  loss_dice_7: 0.164  loss_ce_8: 3.884e-05  loss_mask_8: 0.1108  loss_dice_8: 0.1615  time: 0.5202  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:19] d2.utils.events INFO:  eta: 0:11:45  iter: 30839  total_loss: 2.721  loss_ce: 2.786e-05  loss_mask: 0.1043  loss_dice: 0.1531  loss_ce_0: 0.1241  loss_mask_0: 0.1045  loss_dice_0: 0.1568  loss_ce_1: 4.701e-05  loss_mask_1: 0.1013  loss_dice_1: 0.15  loss_ce_2: 5.611e-05  loss_mask_2: 0.1043  loss_dice_2: 0.1542  loss_ce_3: 2.497e-05  loss_mask_3: 0.1045  loss_dice_3: 0.1528  loss_ce_4: 3.48e-05  loss_mask_4: 0.1032  loss_dice_4: 0.1557  loss_ce_5: 4.232e-05  loss_mask_5: 0.1019  loss_dice_5: 0.1533  loss_ce_6: 2.4e-05  loss_mask_6: 0.1031  loss_dice_6: 0.1576  loss_ce_7: 3.796e-05  loss_mask_7: 0.1017  loss_dice_7: 0.15  loss_ce_8: 4.288e-05  loss_mask_8: 0.107  loss_dice_8: 0.155  time: 0.5200  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:22] d2.utils.events INFO:  eta: 0:11:41  iter: 30859  total_loss: 2.797  loss_ce: 2.76e-05  loss_mask: 0.1096  loss_dice: 0.1595  loss_ce_0: 0.1241  loss_mask_0: 0.1063  loss_dice_0: 0.1623  loss_ce_1: 4.387e-05  loss_mask_1: 0.1118  loss_dice_1: 0.1605  loss_ce_2: 5.401e-05  loss_mask_2: 0.1079  loss_dice_2: 0.159  loss_ce_3: 2.339e-05  loss_mask_3: 0.1056  loss_dice_3: 0.1597  loss_ce_4: 3.453e-05  loss_mask_4: 0.1078  loss_dice_4: 0.1567  loss_ce_5: 4.117e-05  loss_mask_5: 0.1088  loss_dice_5: 0.1591  loss_ce_6: 2.434e-05  loss_mask_6: 0.1073  loss_dice_6: 0.1592  loss_ce_7: 3.556e-05  loss_mask_7: 0.1069  loss_dice_7: 0.1627  loss_ce_8: 4.417e-05  loss_mask_8: 0.1057  loss_dice_8: 0.1611  time: 0.5198  data_time: 0.0010  lr: 1e-06  max_mem: 8444M
[08/01 22:30:25] d2.utils.events INFO:  eta: 0:11:37  iter: 30879  total_loss: 2.867  loss_ce: 2.691e-05  loss_mask: 0.1089  loss_dice: 0.1606  loss_ce_0: 0.1241  loss_mask_0: 0.1117  loss_dice_0: 0.1664  loss_ce_1: 4.432e-05  loss_mask_1: 0.1106  loss_dice_1: 0.1625  loss_ce_2: 5.137e-05  loss_mask_2: 0.114  loss_dice_2: 0.1671  loss_ce_3: 2.171e-05  loss_mask_3: 0.111  loss_dice_3: 0.1666  loss_ce_4: 3.381e-05  loss_mask_4: 0.1119  loss_dice_4: 0.1635  loss_ce_5: 3.747e-05  loss_mask_5: 0.1124  loss_dice_5: 0.1685  loss_ce_6: 2.29e-05  loss_mask_6: 0.1076  loss_dice_6: 0.1642  loss_ce_7: 3.391e-05  loss_mask_7: 0.1104  loss_dice_7: 0.1683  loss_ce_8: 3.938e-05  loss_mask_8: 0.1126  loss_dice_8: 0.1672  time: 0.5196  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:29] d2.utils.events INFO:  eta: 0:11:34  iter: 30899  total_loss: 2.8  loss_ce: 2.622e-05  loss_mask: 0.1101  loss_dice: 0.1638  loss_ce_0: 0.1281  loss_mask_0: 0.1113  loss_dice_0: 0.1667  loss_ce_1: 4.594e-05  loss_mask_1: 0.1082  loss_dice_1: 0.1584  loss_ce_2: 4.506e-05  loss_mask_2: 0.1074  loss_dice_2: 0.162  loss_ce_3: 2.356e-05  loss_mask_3: 0.1104  loss_dice_3: 0.1562  loss_ce_4: 3.199e-05  loss_mask_4: 0.1089  loss_dice_4: 0.1597  loss_ce_5: 4.162e-05  loss_mask_5: 0.1095  loss_dice_5: 0.1599  loss_ce_6: 2.321e-05  loss_mask_6: 0.1113  loss_dice_6: 0.16  loss_ce_7: 3.476e-05  loss_mask_7: 0.1068  loss_dice_7: 0.1575  loss_ce_8: 4.441e-05  loss_mask_8: 0.1068  loss_dice_8: 0.1545  time: 0.5193  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:32] d2.utils.events INFO:  eta: 0:11:30  iter: 30919  total_loss: 2.798  loss_ce: 2.719e-05  loss_mask: 0.1085  loss_dice: 0.1598  loss_ce_0: 0.1281  loss_mask_0: 0.1064  loss_dice_0: 0.1623  loss_ce_1: 3.196e-05  loss_mask_1: 0.1081  loss_dice_1: 0.1592  loss_ce_2: 3.464e-05  loss_mask_2: 0.109  loss_dice_2: 0.1621  loss_ce_3: 1.486e-05  loss_mask_3: 0.1049  loss_dice_3: 0.1568  loss_ce_4: 1.843e-05  loss_mask_4: 0.105  loss_dice_4: 0.1582  loss_ce_5: 2.47e-05  loss_mask_5: 0.1088  loss_dice_5: 0.1589  loss_ce_6: 1.735e-05  loss_mask_6: 0.1048  loss_dice_6: 0.158  loss_ce_7: 3.122e-05  loss_mask_7: 0.1091  loss_dice_7: 0.1584  loss_ce_8: 2.956e-05  loss_mask_8: 0.1104  loss_dice_8: 0.1633  time: 0.5191  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:35] d2.utils.events INFO:  eta: 0:11:27  iter: 30939  total_loss: 3.041  loss_ce: 2.754e-05  loss_mask: 0.1119  loss_dice: 0.1737  loss_ce_0: 0.1241  loss_mask_0: 0.1115  loss_dice_0: 0.1721  loss_ce_1: 3.917e-05  loss_mask_1: 0.1093  loss_dice_1: 0.1791  loss_ce_2: 4.035e-05  loss_mask_2: 0.115  loss_dice_2: 0.1836  loss_ce_3: 2.515e-05  loss_mask_3: 0.1143  loss_dice_3: 0.1739  loss_ce_4: 2.56e-05  loss_mask_4: 0.1112  loss_dice_4: 0.1742  loss_ce_5: 3.053e-05  loss_mask_5: 0.1147  loss_dice_5: 0.1739  loss_ce_6: 2.492e-05  loss_mask_6: 0.1122  loss_dice_6: 0.1721  loss_ce_7: 3.258e-05  loss_mask_7: 0.1121  loss_dice_7: 0.1764  loss_ce_8: 3.404e-05  loss_mask_8: 0.1153  loss_dice_8: 0.1857  time: 0.5189  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:39] d2.utils.events INFO:  eta: 0:11:23  iter: 30959  total_loss: 2.787  loss_ce: 2.865e-05  loss_mask: 0.111  loss_dice: 0.1636  loss_ce_0: 0.124  loss_mask_0: 0.1084  loss_dice_0: 0.1621  loss_ce_1: 4.385e-05  loss_mask_1: 0.1108  loss_dice_1: 0.1601  loss_ce_2: 4.471e-05  loss_mask_2: 0.1101  loss_dice_2: 0.1608  loss_ce_3: 3.121e-05  loss_mask_3: 0.1098  loss_dice_3: 0.1625  loss_ce_4: 3.35e-05  loss_mask_4: 0.1096  loss_dice_4: 0.164  loss_ce_5: 3.756e-05  loss_mask_5: 0.1084  loss_dice_5: 0.1614  loss_ce_6: 2.593e-05  loss_mask_6: 0.1101  loss_dice_6: 0.1622  loss_ce_7: 3.393e-05  loss_mask_7: 0.1051  loss_dice_7: 0.1573  loss_ce_8: 3.892e-05  loss_mask_8: 0.1093  loss_dice_8: 0.1582  time: 0.5186  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:42] d2.utils.events INFO:  eta: 0:11:20  iter: 30979  total_loss: 2.744  loss_ce: 2.635e-05  loss_mask: 0.1081  loss_dice: 0.1592  loss_ce_0: 0.124  loss_mask_0: 0.1066  loss_dice_0: 0.1618  loss_ce_1: 4.402e-05  loss_mask_1: 0.1044  loss_dice_1: 0.1533  loss_ce_2: 4.372e-05  loss_mask_2: 0.1079  loss_dice_2: 0.1586  loss_ce_3: 2.058e-05  loss_mask_3: 0.1064  loss_dice_3: 0.158  loss_ce_4: 3.335e-05  loss_mask_4: 0.1086  loss_dice_4: 0.1543  loss_ce_5: 3.742e-05  loss_mask_5: 0.1083  loss_dice_5: 0.1563  loss_ce_6: 2.248e-05  loss_mask_6: 0.1063  loss_dice_6: 0.1565  loss_ce_7: 3.352e-05  loss_mask_7: 0.1084  loss_dice_7: 0.1551  loss_ce_8: 3.919e-05  loss_mask_8: 0.1073  loss_dice_8: 0.1611  time: 0.5184  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:46] d2.utils.events INFO:  eta: 0:11:17  iter: 30999  total_loss: 2.837  loss_ce: 3.058e-05  loss_mask: 0.1043  loss_dice: 0.1664  loss_ce_0: 0.1248  loss_mask_0: 0.1062  loss_dice_0: 0.1663  loss_ce_1: 3.705e-05  loss_mask_1: 0.1059  loss_dice_1: 0.167  loss_ce_2: 3.926e-05  loss_mask_2: 0.1055  loss_dice_2: 0.1654  loss_ce_3: 1.955e-05  loss_mask_3: 0.104  loss_dice_3: 0.1567  loss_ce_4: 2.545e-05  loss_mask_4: 0.1091  loss_dice_4: 0.1617  loss_ce_5: 3.138e-05  loss_mask_5: 0.1051  loss_dice_5: 0.159  loss_ce_6: 2.118e-05  loss_mask_6: 0.1042  loss_dice_6: 0.1635  loss_ce_7: 3.181e-05  loss_mask_7: 0.1052  loss_dice_7: 0.1628  loss_ce_8: 3.482e-05  loss_mask_8: 0.1112  loss_dice_8: 0.1686  time: 0.5182  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:49] d2.utils.events INFO:  eta: 0:11:13  iter: 31019  total_loss: 2.792  loss_ce: 2.628e-05  loss_mask: 0.1073  loss_dice: 0.1528  loss_ce_0: 0.124  loss_mask_0: 0.1112  loss_dice_0: 0.1625  loss_ce_1: 3.828e-05  loss_mask_1: 0.108  loss_dice_1: 0.1589  loss_ce_2: 3.952e-05  loss_mask_2: 0.1075  loss_dice_2: 0.1553  loss_ce_3: 1.784e-05  loss_mask_3: 0.1126  loss_dice_3: 0.1511  loss_ce_4: 2.638e-05  loss_mask_4: 0.1091  loss_dice_4: 0.1546  loss_ce_5: 3.109e-05  loss_mask_5: 0.1086  loss_dice_5: 0.1579  loss_ce_6: 1.922e-05  loss_mask_6: 0.1083  loss_dice_6: 0.155  loss_ce_7: 2.76e-05  loss_mask_7: 0.1122  loss_dice_7: 0.1564  loss_ce_8: 3.363e-05  loss_mask_8: 0.1074  loss_dice_8: 0.159  time: 0.5180  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:52] d2.utils.events INFO:  eta: 0:11:10  iter: 31039  total_loss: 2.837  loss_ce: 2.723e-05  loss_mask: 0.1101  loss_dice: 0.1629  loss_ce_0: 0.128  loss_mask_0: 0.1103  loss_dice_0: 0.164  loss_ce_1: 4.401e-05  loss_mask_1: 0.109  loss_dice_1: 0.1669  loss_ce_2: 4.411e-05  loss_mask_2: 0.1104  loss_dice_2: 0.1617  loss_ce_3: 2.151e-05  loss_mask_3: 0.1099  loss_dice_3: 0.1608  loss_ce_4: 3.234e-05  loss_mask_4: 0.1135  loss_dice_4: 0.162  loss_ce_5: 3.77e-05  loss_mask_5: 0.1115  loss_dice_5: 0.168  loss_ce_6: 2.251e-05  loss_mask_6: 0.1098  loss_dice_6: 0.1597  loss_ce_7: 3.345e-05  loss_mask_7: 0.1084  loss_dice_7: 0.162  loss_ce_8: 3.986e-05  loss_mask_8: 0.1093  loss_dice_8: 0.1643  time: 0.5177  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:56] d2.utils.events INFO:  eta: 0:11:06  iter: 31059  total_loss: 2.911  loss_ce: 2.962e-05  loss_mask: 0.1159  loss_dice: 0.1671  loss_ce_0: 0.1184  loss_mask_0: 0.1127  loss_dice_0: 0.1724  loss_ce_1: 5.005e-05  loss_mask_1: 0.1141  loss_dice_1: 0.1639  loss_ce_2: 5.582e-05  loss_mask_2: 0.1108  loss_dice_2: 0.1629  loss_ce_3: 3.032e-05  loss_mask_3: 0.1119  loss_dice_3: 0.1637  loss_ce_4: 3.531e-05  loss_mask_4: 0.1139  loss_dice_4: 0.1636  loss_ce_5: 3.796e-05  loss_mask_5: 0.1134  loss_dice_5: 0.1637  loss_ce_6: 2.671e-05  loss_mask_6: 0.1128  loss_dice_6: 0.1683  loss_ce_7: 3.754e-05  loss_mask_7: 0.1143  loss_dice_7: 0.1657  loss_ce_8: 4.011e-05  loss_mask_8: 0.1128  loss_dice_8: 0.1647  time: 0.5175  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:30:59] d2.utils.events INFO:  eta: 0:11:03  iter: 31079  total_loss: 2.802  loss_ce: 2.684e-05  loss_mask: 0.1132  loss_dice: 0.1631  loss_ce_0: 0.1244  loss_mask_0: 0.1111  loss_dice_0: 0.1639  loss_ce_1: 4.707e-05  loss_mask_1: 0.1065  loss_dice_1: 0.1584  loss_ce_2: 4.701e-05  loss_mask_2: 0.1098  loss_dice_2: 0.1654  loss_ce_3: 2.757e-05  loss_mask_3: 0.11  loss_dice_3: 0.1583  loss_ce_4: 3.451e-05  loss_mask_4: 0.1062  loss_dice_4: 0.1568  loss_ce_5: 4.516e-05  loss_mask_5: 0.109  loss_dice_5: 0.1565  loss_ce_6: 2.503e-05  loss_mask_6: 0.1121  loss_dice_6: 0.1625  loss_ce_7: 3.593e-05  loss_mask_7: 0.1121  loss_dice_7: 0.1647  loss_ce_8: 4.608e-05  loss_mask_8: 0.1099  loss_dice_8: 0.1603  time: 0.5173  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:02] d2.utils.events INFO:  eta: 0:10:59  iter: 31099  total_loss: 2.966  loss_ce: 2.807e-05  loss_mask: 0.108  loss_dice: 0.1689  loss_ce_0: 0.124  loss_mask_0: 0.1086  loss_dice_0: 0.1707  loss_ce_1: 4.816e-05  loss_mask_1: 0.1075  loss_dice_1: 0.1706  loss_ce_2: 5.557e-05  loss_mask_2: 0.1088  loss_dice_2: 0.1665  loss_ce_3: 3.132e-05  loss_mask_3: 0.112  loss_dice_3: 0.1718  loss_ce_4: 3.657e-05  loss_mask_4: 0.1087  loss_dice_4: 0.1725  loss_ce_5: 4.245e-05  loss_mask_5: 0.1109  loss_dice_5: 0.1713  loss_ce_6: 2.667e-05  loss_mask_6: 0.1129  loss_dice_6: 0.172  loss_ce_7: 3.753e-05  loss_mask_7: 0.1064  loss_dice_7: 0.1659  loss_ce_8: 4.347e-05  loss_mask_8: 0.1094  loss_dice_8: 0.174  time: 0.5171  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:06] d2.utils.events INFO:  eta: 0:10:56  iter: 31119  total_loss: 2.836  loss_ce: 2.681e-05  loss_mask: 0.1113  loss_dice: 0.1663  loss_ce_0: 0.124  loss_mask_0: 0.1091  loss_dice_0: 0.1662  loss_ce_1: 4.183e-05  loss_mask_1: 0.1087  loss_dice_1: 0.1622  loss_ce_2: 4.318e-05  loss_mask_2: 0.11  loss_dice_2: 0.167  loss_ce_3: 1.813e-05  loss_mask_3: 0.1096  loss_dice_3: 0.1663  loss_ce_4: 3.213e-05  loss_mask_4: 0.1114  loss_dice_4: 0.1692  loss_ce_5: 3.734e-05  loss_mask_5: 0.109  loss_dice_5: 0.1629  loss_ce_6: 2.104e-05  loss_mask_6: 0.1087  loss_dice_6: 0.161  loss_ce_7: 3.403e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1643  loss_ce_8: 3.769e-05  loss_mask_8: 0.1111  loss_dice_8: 0.1657  time: 0.5168  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:09] d2.utils.events INFO:  eta: 0:10:52  iter: 31139  total_loss: 2.952  loss_ce: 2.691e-05  loss_mask: 0.1151  loss_dice: 0.1652  loss_ce_0: 0.1243  loss_mask_0: 0.1108  loss_dice_0: 0.165  loss_ce_1: 3.441e-05  loss_mask_1: 0.1178  loss_dice_1: 0.1669  loss_ce_2: 3.378e-05  loss_mask_2: 0.1154  loss_dice_2: 0.1643  loss_ce_3: 1.407e-05  loss_mask_3: 0.1186  loss_dice_3: 0.163  loss_ce_4: 1.755e-05  loss_mask_4: 0.1157  loss_dice_4: 0.1662  loss_ce_5: 2.351e-05  loss_mask_5: 0.1138  loss_dice_5: 0.1642  loss_ce_6: 1.668e-05  loss_mask_6: 0.1143  loss_dice_6: 0.1632  loss_ce_7: 2.778e-05  loss_mask_7: 0.1182  loss_dice_7: 0.1716  loss_ce_8: 2.944e-05  loss_mask_8: 0.1176  loss_dice_8: 0.1667  time: 0.5166  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:12] d2.utils.events INFO:  eta: 0:10:49  iter: 31159  total_loss: 2.956  loss_ce: 2.731e-05  loss_mask: 0.1091  loss_dice: 0.1667  loss_ce_0: 0.1239  loss_mask_0: 0.1094  loss_dice_0: 0.1721  loss_ce_1: 4.496e-05  loss_mask_1: 0.1087  loss_dice_1: 0.1682  loss_ce_2: 4.359e-05  loss_mask_2: 0.1122  loss_dice_2: 0.1668  loss_ce_3: 2.284e-05  loss_mask_3: 0.1097  loss_dice_3: 0.1687  loss_ce_4: 3.401e-05  loss_mask_4: 0.1126  loss_dice_4: 0.1699  loss_ce_5: 4.137e-05  loss_mask_5: 0.1113  loss_dice_5: 0.17  loss_ce_6: 2.273e-05  loss_mask_6: 0.107  loss_dice_6: 0.1679  loss_ce_7: 3.352e-05  loss_mask_7: 0.1111  loss_dice_7: 0.1681  loss_ce_8: 4.296e-05  loss_mask_8: 0.1119  loss_dice_8: 0.1737  time: 0.5164  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:16] d2.utils.events INFO:  eta: 0:10:45  iter: 31179  total_loss: 2.879  loss_ce: 2.715e-05  loss_mask: 0.1106  loss_dice: 0.1695  loss_ce_0: 0.128  loss_mask_0: 0.1102  loss_dice_0: 0.1653  loss_ce_1: 5.493e-05  loss_mask_1: 0.1119  loss_dice_1: 0.1693  loss_ce_2: 4.466e-05  loss_mask_2: 0.1117  loss_dice_2: 0.1662  loss_ce_3: 2.481e-05  loss_mask_3: 0.1075  loss_dice_3: 0.1621  loss_ce_4: 3.387e-05  loss_mask_4: 0.1063  loss_dice_4: 0.1597  loss_ce_5: 4.467e-05  loss_mask_5: 0.1092  loss_dice_5: 0.1655  loss_ce_6: 2.356e-05  loss_mask_6: 0.1055  loss_dice_6: 0.1657  loss_ce_7: 3.573e-05  loss_mask_7: 0.1106  loss_dice_7: 0.1656  loss_ce_8: 5.042e-05  loss_mask_8: 0.1081  loss_dice_8: 0.1695  time: 0.5162  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:19] d2.utils.events INFO:  eta: 0:10:41  iter: 31199  total_loss: 2.912  loss_ce: 2.968e-05  loss_mask: 0.1113  loss_dice: 0.1694  loss_ce_0: 0.1248  loss_mask_0: 0.1118  loss_dice_0: 0.1661  loss_ce_1: 5.87e-05  loss_mask_1: 0.1098  loss_dice_1: 0.1746  loss_ce_2: 5.67e-05  loss_mask_2: 0.1116  loss_dice_2: 0.1748  loss_ce_3: 2.423e-05  loss_mask_3: 0.1096  loss_dice_3: 0.1609  loss_ce_4: 3.578e-05  loss_mask_4: 0.1117  loss_dice_4: 0.1757  loss_ce_5: 5.638e-05  loss_mask_5: 0.114  loss_dice_5: 0.1772  loss_ce_6: 2.47e-05  loss_mask_6: 0.1125  loss_dice_6: 0.1761  loss_ce_7: 4.142e-05  loss_mask_7: 0.1122  loss_dice_7: 0.17  loss_ce_8: 5.713e-05  loss_mask_8: 0.1088  loss_dice_8: 0.1681  time: 0.5159  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:22] d2.utils.events INFO:  eta: 0:10:38  iter: 31219  total_loss: 2.79  loss_ce: 2.949e-05  loss_mask: 0.1031  loss_dice: 0.1601  loss_ce_0: 0.1244  loss_mask_0: 0.1057  loss_dice_0: 0.1634  loss_ce_1: 4.359e-05  loss_mask_1: 0.1113  loss_dice_1: 0.1632  loss_ce_2: 4.471e-05  loss_mask_2: 0.1047  loss_dice_2: 0.1608  loss_ce_3: 2.434e-05  loss_mask_3: 0.107  loss_dice_3: 0.1654  loss_ce_4: 3.354e-05  loss_mask_4: 0.1064  loss_dice_4: 0.1622  loss_ce_5: 3.76e-05  loss_mask_5: 0.1058  loss_dice_5: 0.1553  loss_ce_6: 2.377e-05  loss_mask_6: 0.1106  loss_dice_6: 0.163  loss_ce_7: 3.539e-05  loss_mask_7: 0.1096  loss_dice_7: 0.1667  loss_ce_8: 3.879e-05  loss_mask_8: 0.1043  loss_dice_8: 0.1605  time: 0.5157  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:26] d2.utils.events INFO:  eta: 0:10:34  iter: 31239  total_loss: 2.882  loss_ce: 2.71e-05  loss_mask: 0.1113  loss_dice: 0.1674  loss_ce_0: 0.1244  loss_mask_0: 0.1094  loss_dice_0: 0.1673  loss_ce_1: 4.465e-05  loss_mask_1: 0.109  loss_dice_1: 0.1636  loss_ce_2: 4.418e-05  loss_mask_2: 0.1093  loss_dice_2: 0.1632  loss_ce_3: 2.304e-05  loss_mask_3: 0.1126  loss_dice_3: 0.1714  loss_ce_4: 3.155e-05  loss_mask_4: 0.1094  loss_dice_4: 0.1639  loss_ce_5: 3.826e-05  loss_mask_5: 0.1118  loss_dice_5: 0.1645  loss_ce_6: 2.371e-05  loss_mask_6: 0.1118  loss_dice_6: 0.1619  loss_ce_7: 3.563e-05  loss_mask_7: 0.1099  loss_dice_7: 0.1697  loss_ce_8: 3.945e-05  loss_mask_8: 0.1112  loss_dice_8: 0.169  time: 0.5155  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:29] d2.utils.events INFO:  eta: 0:10:31  iter: 31259  total_loss: 2.925  loss_ce: 2.696e-05  loss_mask: 0.113  loss_dice: 0.1686  loss_ce_0: 0.1248  loss_mask_0: 0.1127  loss_dice_0: 0.1693  loss_ce_1: 4.724e-05  loss_mask_1: 0.1107  loss_dice_1: 0.1657  loss_ce_2: 4.385e-05  loss_mask_2: 0.1112  loss_dice_2: 0.1676  loss_ce_3: 2.265e-05  loss_mask_3: 0.1155  loss_dice_3: 0.167  loss_ce_4: 3.198e-05  loss_mask_4: 0.1137  loss_dice_4: 0.1681  loss_ce_5: 4.118e-05  loss_mask_5: 0.1135  loss_dice_5: 0.1664  loss_ce_6: 2.313e-05  loss_mask_6: 0.1131  loss_dice_6: 0.1667  loss_ce_7: 3.446e-05  loss_mask_7: 0.1135  loss_dice_7: 0.1653  loss_ce_8: 4.381e-05  loss_mask_8: 0.1154  loss_dice_8: 0.163  time: 0.5153  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:32] d2.utils.events INFO:  eta: 0:10:27  iter: 31279  total_loss: 2.844  loss_ce: 2.734e-05  loss_mask: 0.1061  loss_dice: 0.1583  loss_ce_0: 0.1245  loss_mask_0: 0.111  loss_dice_0: 0.1643  loss_ce_1: 4.449e-05  loss_mask_1: 0.1086  loss_dice_1: 0.1632  loss_ce_2: 4.495e-05  loss_mask_2: 0.1066  loss_dice_2: 0.1632  loss_ce_3: 2.18e-05  loss_mask_3: 0.1073  loss_dice_3: 0.16  loss_ce_4: 3.306e-05  loss_mask_4: 0.1096  loss_dice_4: 0.1569  loss_ce_5: 3.76e-05  loss_mask_5: 0.1082  loss_dice_5: 0.1623  loss_ce_6: 2.255e-05  loss_mask_6: 0.1102  loss_dice_6: 0.1617  loss_ce_7: 3.529e-05  loss_mask_7: 0.1082  loss_dice_7: 0.1574  loss_ce_8: 3.965e-05  loss_mask_8: 0.1079  loss_dice_8: 0.1586  time: 0.5150  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:36] d2.utils.events INFO:  eta: 0:10:24  iter: 31299  total_loss: 2.918  loss_ce: 2.105e-05  loss_mask: 0.1149  loss_dice: 0.166  loss_ce_0: 0.124  loss_mask_0: 0.1135  loss_dice_0: 0.1661  loss_ce_1: 4.049e-05  loss_mask_1: 0.1158  loss_dice_1: 0.1643  loss_ce_2: 4.468e-05  loss_mask_2: 0.115  loss_dice_2: 0.1752  loss_ce_3: 1.732e-05  loss_mask_3: 0.1092  loss_dice_3: 0.1652  loss_ce_4: 3.11e-05  loss_mask_4: 0.1127  loss_dice_4: 0.166  loss_ce_5: 3.777e-05  loss_mask_5: 0.1146  loss_dice_5: 0.1622  loss_ce_6: 2.077e-05  loss_mask_6: 0.113  loss_dice_6: 0.1661  loss_ce_7: 3.388e-05  loss_mask_7: 0.1157  loss_dice_7: 0.1678  loss_ce_8: 3.805e-05  loss_mask_8: 0.117  loss_dice_8: 0.1665  time: 0.5148  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:39] d2.utils.events INFO:  eta: 0:10:20  iter: 31319  total_loss: 2.915  loss_ce: 2.765e-05  loss_mask: 0.1122  loss_dice: 0.1715  loss_ce_0: 0.124  loss_mask_0: 0.1111  loss_dice_0: 0.1754  loss_ce_1: 3.733e-05  loss_mask_1: 0.1093  loss_dice_1: 0.1752  loss_ce_2: 3.839e-05  loss_mask_2: 0.1115  loss_dice_2: 0.1742  loss_ce_3: 1.783e-05  loss_mask_3: 0.1101  loss_dice_3: 0.159  loss_ce_4: 2.576e-05  loss_mask_4: 0.1098  loss_dice_4: 0.1673  loss_ce_5: 3.086e-05  loss_mask_5: 0.1074  loss_dice_5: 0.1563  loss_ce_6: 1.983e-05  loss_mask_6: 0.1083  loss_dice_6: 0.1676  loss_ce_7: 3.05e-05  loss_mask_7: 0.1098  loss_dice_7: 0.1657  loss_ce_8: 3.37e-05  loss_mask_8: 0.1109  loss_dice_8: 0.1663  time: 0.5146  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:42] d2.utils.events INFO:  eta: 0:10:17  iter: 31339  total_loss: 2.852  loss_ce: 2.736e-05  loss_mask: 0.1074  loss_dice: 0.1657  loss_ce_0: 0.1183  loss_mask_0: 0.1081  loss_dice_0: 0.1709  loss_ce_1: 4.557e-05  loss_mask_1: 0.107  loss_dice_1: 0.1672  loss_ce_2: 5.74e-05  loss_mask_2: 0.1058  loss_dice_2: 0.1637  loss_ce_3: 3.095e-05  loss_mask_3: 0.1085  loss_dice_3: 0.1671  loss_ce_4: 3.497e-05  loss_mask_4: 0.1072  loss_dice_4: 0.1628  loss_ce_5: 3.783e-05  loss_mask_5: 0.1057  loss_dice_5: 0.1679  loss_ce_6: 2.503e-05  loss_mask_6: 0.1136  loss_dice_6: 0.1686  loss_ce_7: 3.683e-05  loss_mask_7: 0.1068  loss_dice_7: 0.1655  loss_ce_8: 4.003e-05  loss_mask_8: 0.1064  loss_dice_8: 0.1662  time: 0.5144  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:46] d2.utils.events INFO:  eta: 0:10:13  iter: 31359  total_loss: 3.028  loss_ce: 2.744e-05  loss_mask: 0.1099  loss_dice: 0.1718  loss_ce_0: 0.1183  loss_mask_0: 0.1109  loss_dice_0: 0.1758  loss_ce_1: 4.949e-05  loss_mask_1: 0.1123  loss_dice_1: 0.1764  loss_ce_2: 5.767e-05  loss_mask_2: 0.1139  loss_dice_2: 0.1771  loss_ce_3: 3.057e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1767  loss_ce_4: 3.469e-05  loss_mask_4: 0.1125  loss_dice_4: 0.1739  loss_ce_5: 3.811e-05  loss_mask_5: 0.1123  loss_dice_5: 0.1731  loss_ce_6: 2.609e-05  loss_mask_6: 0.1128  loss_dice_6: 0.1794  loss_ce_7: 3.753e-05  loss_mask_7: 0.1124  loss_dice_7: 0.1764  loss_ce_8: 4.03e-05  loss_mask_8: 0.1119  loss_dice_8: 0.1819  time: 0.5142  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:49] d2.utils.events INFO:  eta: 0:10:10  iter: 31379  total_loss: 2.983  loss_ce: 3.214e-05  loss_mask: 0.1148  loss_dice: 0.1711  loss_ce_0: 0.1245  loss_mask_0: 0.1092  loss_dice_0: 0.1705  loss_ce_1: 5.488e-05  loss_mask_1: 0.1129  loss_dice_1: 0.1714  loss_ce_2: 5.536e-05  loss_mask_2: 0.1127  loss_dice_2: 0.173  loss_ce_3: 3.075e-05  loss_mask_3: 0.108  loss_dice_3: 0.1706  loss_ce_4: 3.539e-05  loss_mask_4: 0.1111  loss_dice_4: 0.1684  loss_ce_5: 5.07e-05  loss_mask_5: 0.1126  loss_dice_5: 0.1709  loss_ce_6: 2.705e-05  loss_mask_6: 0.111  loss_dice_6: 0.1677  loss_ce_7: 3.92e-05  loss_mask_7: 0.1161  loss_dice_7: 0.1752  loss_ce_8: 4.652e-05  loss_mask_8: 0.112  loss_dice_8: 0.1707  time: 0.5139  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:31:53] d2.utils.events INFO:  eta: 0:10:07  iter: 31399  total_loss: 2.776  loss_ce: 3.823e-05  loss_mask: 0.1065  loss_dice: 0.1584  loss_ce_0: 0.1249  loss_mask_0: 0.1049  loss_dice_0: 0.164  loss_ce_1: 4.654e-05  loss_mask_1: 0.1055  loss_dice_1: 0.1626  loss_ce_2: 5.337e-05  loss_mask_2: 0.1101  loss_dice_2: 0.1632  loss_ce_3: 3.769e-05  loss_mask_3: 0.1052  loss_dice_3: 0.1613  loss_ce_4: 3.571e-05  loss_mask_4: 0.1056  loss_dice_4: 0.159  loss_ce_5: 4.256e-05  loss_mask_5: 0.1051  loss_dice_5: 0.1596  loss_ce_6: 2.948e-05  loss_mask_6: 0.1064  loss_dice_6: 0.1608  loss_ce_7: 3.749e-05  loss_mask_7: 0.1047  loss_dice_7: 0.1592  loss_ce_8: 4.336e-05  loss_mask_8: 0.1061  loss_dice_8: 0.1616  time: 0.5137  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:31:56] d2.utils.events INFO:  eta: 0:10:03  iter: 31419  total_loss: 2.722  loss_ce: 2.668e-05  loss_mask: 0.1013  loss_dice: 0.156  loss_ce_0: 0.1244  loss_mask_0: 0.1021  loss_dice_0: 0.1609  loss_ce_1: 4.142e-05  loss_mask_1: 0.1056  loss_dice_1: 0.1577  loss_ce_2: 4.36e-05  loss_mask_2: 0.1041  loss_dice_2: 0.1581  loss_ce_3: 2.213e-05  loss_mask_3: 0.103  loss_dice_3: 0.1554  loss_ce_4: 3.179e-05  loss_mask_4: 0.1048  loss_dice_4: 0.1578  loss_ce_5: 3.771e-05  loss_mask_5: 0.1006  loss_dice_5: 0.152  loss_ce_6: 2.269e-05  loss_mask_6: 0.1027  loss_dice_6: 0.1591  loss_ce_7: 3.252e-05  loss_mask_7: 0.1028  loss_dice_7: 0.156  loss_ce_8: 3.87e-05  loss_mask_8: 0.1026  loss_dice_8: 0.1584  time: 0.5135  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:31:59] d2.utils.events INFO:  eta: 0:10:00  iter: 31439  total_loss: 2.971  loss_ce: 2.733e-05  loss_mask: 0.1059  loss_dice: 0.1724  loss_ce_0: 0.124  loss_mask_0: 0.1067  loss_dice_0: 0.1714  loss_ce_1: 4.497e-05  loss_mask_1: 0.1088  loss_dice_1: 0.1686  loss_ce_2: 4.399e-05  loss_mask_2: 0.1111  loss_dice_2: 0.1684  loss_ce_3: 2.114e-05  loss_mask_3: 0.1086  loss_dice_3: 0.1712  loss_ce_4: 3.296e-05  loss_mask_4: 0.1078  loss_dice_4: 0.17  loss_ce_5: 3.744e-05  loss_mask_5: 0.1078  loss_dice_5: 0.1654  loss_ce_6: 2.139e-05  loss_mask_6: 0.1101  loss_dice_6: 0.1712  loss_ce_7: 3.467e-05  loss_mask_7: 0.1085  loss_dice_7: 0.1721  loss_ce_8: 3.837e-05  loss_mask_8: 0.1067  loss_dice_8: 0.169  time: 0.5133  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:32:03] d2.utils.events INFO:  eta: 0:09:56  iter: 31459  total_loss: 2.841  loss_ce: 3.006e-05  loss_mask: 0.1074  loss_dice: 0.1596  loss_ce_0: 0.124  loss_mask_0: 0.1058  loss_dice_0: 0.1638  loss_ce_1: 4.467e-05  loss_mask_1: 0.1058  loss_dice_1: 0.1611  loss_ce_2: 4.375e-05  loss_mask_2: 0.1071  loss_dice_2: 0.1607  loss_ce_3: 2.764e-05  loss_mask_3: 0.111  loss_dice_3: 0.1615  loss_ce_4: 3.455e-05  loss_mask_4: 0.1116  loss_dice_4: 0.1642  loss_ce_5: 4.087e-05  loss_mask_5: 0.108  loss_dice_5: 0.1613  loss_ce_6: 2.59e-05  loss_mask_6: 0.1099  loss_dice_6: 0.1626  loss_ce_7: 3.544e-05  loss_mask_7: 0.1116  loss_dice_7: 0.1572  loss_ce_8: 4.411e-05  loss_mask_8: 0.1087  loss_dice_8: 0.1614  time: 0.5131  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:32:06] d2.utils.events INFO:  eta: 0:09:53  iter: 31479  total_loss: 2.828  loss_ce: 2.725e-05  loss_mask: 0.1077  loss_dice: 0.1707  loss_ce_0: 0.1247  loss_mask_0: 0.1085  loss_dice_0: 0.1619  loss_ce_1: 3.765e-05  loss_mask_1: 0.1022  loss_dice_1: 0.1603  loss_ce_2: 4.44e-05  loss_mask_2: 0.1084  loss_dice_2: 0.164  loss_ce_3: 1.762e-05  loss_mask_3: 0.1008  loss_dice_3: 0.1559  loss_ce_4: 2.605e-05  loss_mask_4: 0.1085  loss_dice_4: 0.1678  loss_ce_5: 3.034e-05  loss_mask_5: 0.1023  loss_dice_5: 0.1576  loss_ce_6: 1.966e-05  loss_mask_6: 0.1037  loss_dice_6: 0.1569  loss_ce_7: 3.173e-05  loss_mask_7: 0.1002  loss_dice_7: 0.1587  loss_ce_8: 3.381e-05  loss_mask_8: 0.1026  loss_dice_8: 0.1634  time: 0.5128  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:32:09] d2.utils.events INFO:  eta: 0:09:50  iter: 31499  total_loss: 2.868  loss_ce: 2.754e-05  loss_mask: 0.1083  loss_dice: 0.1651  loss_ce_0: 0.124  loss_mask_0: 0.1124  loss_dice_0: 0.1644  loss_ce_1: 4.591e-05  loss_mask_1: 0.1107  loss_dice_1: 0.1659  loss_ce_2: 4.466e-05  loss_mask_2: 0.1094  loss_dice_2: 0.1693  loss_ce_3: 2.371e-05  loss_mask_3: 0.1097  loss_dice_3: 0.1628  loss_ce_4: 3.293e-05  loss_mask_4: 0.1082  loss_dice_4: 0.1677  loss_ce_5: 3.733e-05  loss_mask_5: 0.1134  loss_dice_5: 0.1693  loss_ce_6: 2.422e-05  loss_mask_6: 0.1111  loss_dice_6: 0.1666  loss_ce_7: 3.44e-05  loss_mask_7: 0.109  loss_dice_7: 0.1676  loss_ce_8: 3.825e-05  loss_mask_8: 0.1087  loss_dice_8: 0.1672  time: 0.5126  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:32:13] d2.utils.events INFO:  eta: 0:09:46  iter: 31519  total_loss: 2.953  loss_ce: 2.76e-05  loss_mask: 0.1103  loss_dice: 0.1645  loss_ce_0: 0.1184  loss_mask_0: 0.1138  loss_dice_0: 0.1687  loss_ce_1: 5.115e-05  loss_mask_1: 0.1161  loss_dice_1: 0.1715  loss_ce_2: 5.068e-05  loss_mask_2: 0.1095  loss_dice_2: 0.1709  loss_ce_3: 2.055e-05  loss_mask_3: 0.1128  loss_dice_3: 0.1688  loss_ce_4: 3.431e-05  loss_mask_4: 0.111  loss_dice_4: 0.17  loss_ce_5: 3.752e-05  loss_mask_5: 0.1133  loss_dice_5: 0.1711  loss_ce_6: 2.19e-05  loss_mask_6: 0.1123  loss_dice_6: 0.1695  loss_ce_7: 3.678e-05  loss_mask_7: 0.1097  loss_dice_7: 0.1684  loss_ce_8: 3.911e-05  loss_mask_8: 0.1116  loss_dice_8: 0.1676  time: 0.5124  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:32:16] d2.utils.events INFO:  eta: 0:09:43  iter: 31539  total_loss: 2.764  loss_ce: 2.78e-05  loss_mask: 0.1089  loss_dice: 0.1654  loss_ce_0: 0.131  loss_mask_0: 0.1105  loss_dice_0: 0.164  loss_ce_1: 4.616e-05  loss_mask_1: 0.1091  loss_dice_1: 0.1585  loss_ce_2: 4.359e-05  loss_mask_2: 0.1078  loss_dice_2: 0.1606  loss_ce_3: 2.371e-05  loss_mask_3: 0.1066  loss_dice_3: 0.1552  loss_ce_4: 3.213e-05  loss_mask_4: 0.1054  loss_dice_4: 0.1539  loss_ce_5: 3.737e-05  loss_mask_5: 0.1025  loss_dice_5: 0.1594  loss_ce_6: 2.445e-05  loss_mask_6: 0.1068  loss_dice_6: 0.152  loss_ce_7: 3.355e-05  loss_mask_7: 0.1066  loss_dice_7: 0.1606  loss_ce_8: 3.907e-05  loss_mask_8: 0.104  loss_dice_8: 0.1619  time: 0.5122  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:32:20] d2.utils.events INFO:  eta: 0:09:40  iter: 31559  total_loss: 3.008  loss_ce: 2.694e-05  loss_mask: 0.1136  loss_dice: 0.1711  loss_ce_0: 0.1244  loss_mask_0: 0.1158  loss_dice_0: 0.1756  loss_ce_1: 3.735e-05  loss_mask_1: 0.113  loss_dice_1: 0.1724  loss_ce_2: 3.871e-05  loss_mask_2: 0.1143  loss_dice_2: 0.1792  loss_ce_3: 1.965e-05  loss_mask_3: 0.1131  loss_dice_3: 0.1748  loss_ce_4: 2.615e-05  loss_mask_4: 0.1169  loss_dice_4: 0.1759  loss_ce_5: 3.082e-05  loss_mask_5: 0.1162  loss_dice_5: 0.1686  loss_ce_6: 2.14e-05  loss_mask_6: 0.1142  loss_dice_6: 0.1742  loss_ce_7: 3.14e-05  loss_mask_7: 0.1126  loss_dice_7: 0.1689  loss_ce_8: 3.429e-05  loss_mask_8: 0.1168  loss_dice_8: 0.177  time: 0.5120  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:32:23] d2.utils.events INFO:  eta: 0:09:36  iter: 31579  total_loss: 2.688  loss_ce: 2.6e-05  loss_mask: 0.1035  loss_dice: 0.1527  loss_ce_0: 0.1239  loss_mask_0: 0.1019  loss_dice_0: 0.1574  loss_ce_1: 3.827e-05  loss_mask_1: 0.1028  loss_dice_1: 0.1585  loss_ce_2: 3.876e-05  loss_mask_2: 0.1036  loss_dice_2: 0.1541  loss_ce_3: 1.99e-05  loss_mask_3: 0.1052  loss_dice_3: 0.1589  loss_ce_4: 2.535e-05  loss_mask_4: 0.1066  loss_dice_4: 0.1566  loss_ce_5: 3.037e-05  loss_mask_5: 0.1016  loss_dice_5: 0.1496  loss_ce_6: 2.207e-05  loss_mask_6: 0.1073  loss_dice_6: 0.1569  loss_ce_7: 2.859e-05  loss_mask_7: 0.1013  loss_dice_7: 0.1517  loss_ce_8: 3.261e-05  loss_mask_8: 0.1038  loss_dice_8: 0.1537  time: 0.5117  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:32:26] d2.utils.events INFO:  eta: 0:09:33  iter: 31599  total_loss: 2.709  loss_ce: 2.773e-05  loss_mask: 0.1037  loss_dice: 0.1545  loss_ce_0: 0.1239  loss_mask_0: 0.1063  loss_dice_0: 0.1574  loss_ce_1: 4.547e-05  loss_mask_1: 0.1044  loss_dice_1: 0.1549  loss_ce_2: 5.682e-05  loss_mask_2: 0.1053  loss_dice_2: 0.1578  loss_ce_3: 2.926e-05  loss_mask_3: 0.1044  loss_dice_3: 0.156  loss_ce_4: 3.427e-05  loss_mask_4: 0.1034  loss_dice_4: 0.1568  loss_ce_5: 3.734e-05  loss_mask_5: 0.1059  loss_dice_5: 0.155  loss_ce_6: 2.553e-05  loss_mask_6: 0.1091  loss_dice_6: 0.1576  loss_ce_7: 3.591e-05  loss_mask_7: 0.1053  loss_dice_7: 0.1549  loss_ce_8: 3.886e-05  loss_mask_8: 0.1032  loss_dice_8: 0.1544  time: 0.5115  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:32:30] d2.utils.events INFO:  eta: 0:09:29  iter: 31619  total_loss: 2.843  loss_ce: 3.07e-05  loss_mask: 0.1055  loss_dice: 0.1634  loss_ce_0: 0.1239  loss_mask_0: 0.1064  loss_dice_0: 0.1624  loss_ce_1: 4.479e-05  loss_mask_1: 0.1084  loss_dice_1: 0.1655  loss_ce_2: 5.313e-05  loss_mask_2: 0.1096  loss_dice_2: 0.1669  loss_ce_3: 3.633e-05  loss_mask_3: 0.1096  loss_dice_3: 0.1676  loss_ce_4: 3.456e-05  loss_mask_4: 0.1067  loss_dice_4: 0.1591  loss_ce_5: 3.744e-05  loss_mask_5: 0.1068  loss_dice_5: 0.1639  loss_ce_6: 2.817e-05  loss_mask_6: 0.1065  loss_dice_6: 0.1647  loss_ce_7: 3.569e-05  loss_mask_7: 0.109  loss_dice_7: 0.1617  loss_ce_8: 4.017e-05  loss_mask_8: 0.1054  loss_dice_8: 0.1609  time: 0.5113  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:32:33] d2.utils.events INFO:  eta: 0:09:26  iter: 31639  total_loss: 2.805  loss_ce: 2.676e-05  loss_mask: 0.105  loss_dice: 0.163  loss_ce_0: 0.1243  loss_mask_0: 0.1081  loss_dice_0: 0.1598  loss_ce_1: 4.403e-05  loss_mask_1: 0.108  loss_dice_1: 0.1671  loss_ce_2: 4.944e-05  loss_mask_2: 0.1067  loss_dice_2: 0.1645  loss_ce_3: 2.2e-05  loss_mask_3: 0.108  loss_dice_3: 0.1595  loss_ce_4: 3.301e-05  loss_mask_4: 0.1073  loss_dice_4: 0.1559  loss_ce_5: 4.063e-05  loss_mask_5: 0.1067  loss_dice_5: 0.1639  loss_ce_6: 2.213e-05  loss_mask_6: 0.107  loss_dice_6: 0.163  loss_ce_7: 3.371e-05  loss_mask_7: 0.1061  loss_dice_7: 0.1534  loss_ce_8: 4.327e-05  loss_mask_8: 0.11  loss_dice_8: 0.167  time: 0.5111  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:32:37] d2.utils.events INFO:  eta: 0:09:23  iter: 31659  total_loss: 2.848  loss_ce: 2.656e-05  loss_mask: 0.1158  loss_dice: 0.1575  loss_ce_0: 0.1239  loss_mask_0: 0.1122  loss_dice_0: 0.1685  loss_ce_1: 4.416e-05  loss_mask_1: 0.1131  loss_dice_1: 0.1608  loss_ce_2: 4.344e-05  loss_mask_2: 0.1122  loss_dice_2: 0.1667  loss_ce_3: 2.045e-05  loss_mask_3: 0.1121  loss_dice_3: 0.1672  loss_ce_4: 3.112e-05  loss_mask_4: 0.1134  loss_dice_4: 0.1638  loss_ce_5: 3.742e-05  loss_mask_5: 0.1091  loss_dice_5: 0.1584  loss_ce_6: 2.149e-05  loss_mask_6: 0.1112  loss_dice_6: 0.1645  loss_ce_7: 3.399e-05  loss_mask_7: 0.1151  loss_dice_7: 0.1644  loss_ce_8: 3.855e-05  loss_mask_8: 0.114  loss_dice_8: 0.1631  time: 0.5109  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:32:40] d2.utils.events INFO:  eta: 0:09:19  iter: 31679  total_loss: 2.814  loss_ce: 2.704e-05  loss_mask: 0.1071  loss_dice: 0.1603  loss_ce_0: 0.1239  loss_mask_0: 0.1086  loss_dice_0: 0.1693  loss_ce_1: 3.08e-05  loss_mask_1: 0.1062  loss_dice_1: 0.1592  loss_ce_2: 3.285e-05  loss_mask_2: 0.1085  loss_dice_2: 0.1608  loss_ce_3: 1.341e-05  loss_mask_3: 0.1063  loss_dice_3: 0.1583  loss_ce_4: 1.792e-05  loss_mask_4: 0.1091  loss_dice_4: 0.1609  loss_ce_5: 2.288e-05  loss_mask_5: 0.108  loss_dice_5: 0.1622  loss_ce_6: 1.697e-05  loss_mask_6: 0.1055  loss_dice_6: 0.1561  loss_ce_7: 2.358e-05  loss_mask_7: 0.1075  loss_dice_7: 0.1576  loss_ce_8: 2.786e-05  loss_mask_8: 0.1049  loss_dice_8: 0.1568  time: 0.5107  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:32:43] d2.utils.events INFO:  eta: 0:09:16  iter: 31699  total_loss: 2.911  loss_ce: 2.673e-05  loss_mask: 0.1109  loss_dice: 0.1682  loss_ce_0: 0.1308  loss_mask_0: 0.1095  loss_dice_0: 0.1698  loss_ce_1: 4.53e-05  loss_mask_1: 0.1063  loss_dice_1: 0.1662  loss_ce_2: 4.214e-05  loss_mask_2: 0.1097  loss_dice_2: 0.1666  loss_ce_3: 2.18e-05  loss_mask_3: 0.1117  loss_dice_3: 0.1642  loss_ce_4: 3.034e-05  loss_mask_4: 0.1079  loss_dice_4: 0.1663  loss_ce_5: 3.719e-05  loss_mask_5: 0.11  loss_dice_5: 0.1717  loss_ce_6: 2.219e-05  loss_mask_6: 0.1077  loss_dice_6: 0.1654  loss_ce_7: 3.474e-05  loss_mask_7: 0.1105  loss_dice_7: 0.1663  loss_ce_8: 3.869e-05  loss_mask_8: 0.105  loss_dice_8: 0.1611  time: 0.5104  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:32:46] d2.utils.events INFO:  eta: 0:09:12  iter: 31719  total_loss: 2.798  loss_ce: 2.934e-05  loss_mask: 0.1116  loss_dice: 0.1619  loss_ce_0: 0.1238  loss_mask_0: 0.1077  loss_dice_0: 0.1566  loss_ce_1: 5.026e-05  loss_mask_1: 0.11  loss_dice_1: 0.1589  loss_ce_2: 5.667e-05  loss_mask_2: 0.1123  loss_dice_2: 0.1606  loss_ce_3: 3.23e-05  loss_mask_3: 0.1118  loss_dice_3: 0.1577  loss_ce_4: 3.42e-05  loss_mask_4: 0.108  loss_dice_4: 0.1554  loss_ce_5: 4.432e-05  loss_mask_5: 0.1131  loss_dice_5: 0.1624  loss_ce_6: 2.634e-05  loss_mask_6: 0.1088  loss_dice_6: 0.1578  loss_ce_7: 3.602e-05  loss_mask_7: 0.1088  loss_dice_7: 0.1576  loss_ce_8: 4.653e-05  loss_mask_8: 0.1091  loss_dice_8: 0.1566  time: 0.5102  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:32:50] d2.utils.events INFO:  eta: 0:09:08  iter: 31739  total_loss: 2.767  loss_ce: 2.686e-05  loss_mask: 0.1071  loss_dice: 0.1551  loss_ce_0: 0.1238  loss_mask_0: 0.1073  loss_dice_0: 0.1594  loss_ce_1: 4.296e-05  loss_mask_1: 0.1064  loss_dice_1: 0.1583  loss_ce_2: 5.36e-05  loss_mask_2: 0.1098  loss_dice_2: 0.1645  loss_ce_3: 2.188e-05  loss_mask_3: 0.109  loss_dice_3: 0.1612  loss_ce_4: 3.352e-05  loss_mask_4: 0.1061  loss_dice_4: 0.1547  loss_ce_5: 4.403e-05  loss_mask_5: 0.104  loss_dice_5: 0.1609  loss_ce_6: 2.408e-05  loss_mask_6: 0.1039  loss_dice_6: 0.1588  loss_ce_7: 3.628e-05  loss_mask_7: 0.1058  loss_dice_7: 0.1558  loss_ce_8: 4.67e-05  loss_mask_8: 0.1069  loss_dice_8: 0.1602  time: 0.5100  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:32:53] d2.utils.events INFO:  eta: 0:09:05  iter: 31759  total_loss: 2.927  loss_ce: 2.701e-05  loss_mask: 0.1107  loss_dice: 0.1704  loss_ce_0: 0.1132  loss_mask_0: 0.1155  loss_dice_0: 0.1815  loss_ce_1: 4.485e-05  loss_mask_1: 0.1092  loss_dice_1: 0.1716  loss_ce_2: 5.68e-05  loss_mask_2: 0.1088  loss_dice_2: 0.1698  loss_ce_3: 2.173e-05  loss_mask_3: 0.1137  loss_dice_3: 0.1701  loss_ce_4: 3.412e-05  loss_mask_4: 0.1087  loss_dice_4: 0.1673  loss_ce_5: 3.733e-05  loss_mask_5: 0.1112  loss_dice_5: 0.1704  loss_ce_6: 2.39e-05  loss_mask_6: 0.1121  loss_dice_6: 0.1692  loss_ce_7: 3.562e-05  loss_mask_7: 0.1141  loss_dice_7: 0.1707  loss_ce_8: 3.919e-05  loss_mask_8: 0.1135  loss_dice_8: 0.1721  time: 0.5098  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:32:56] d2.utils.events INFO:  eta: 0:09:01  iter: 31779  total_loss: 3.014  loss_ce: 2.722e-05  loss_mask: 0.1134  loss_dice: 0.1688  loss_ce_0: 0.1238  loss_mask_0: 0.1109  loss_dice_0: 0.1761  loss_ce_1: 5.986e-05  loss_mask_1: 0.1134  loss_dice_1: 0.1728  loss_ce_2: 4.507e-05  loss_mask_2: 0.1124  loss_dice_2: 0.1733  loss_ce_3: 2.245e-05  loss_mask_3: 0.1096  loss_dice_3: 0.1668  loss_ce_4: 3.37e-05  loss_mask_4: 0.1145  loss_dice_4: 0.1706  loss_ce_5: 4.547e-05  loss_mask_5: 0.1138  loss_dice_5: 0.1746  loss_ce_6: 2.312e-05  loss_mask_6: 0.1139  loss_dice_6: 0.1718  loss_ce_7: 3.737e-05  loss_mask_7: 0.1131  loss_dice_7: 0.1777  loss_ce_8: 5.524e-05  loss_mask_8: 0.1166  loss_dice_8: 0.1768  time: 0.5096  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:00] d2.utils.events INFO:  eta: 0:08:58  iter: 31799  total_loss: 2.771  loss_ce: 2.84e-05  loss_mask: 0.1056  loss_dice: 0.154  loss_ce_0: 0.1243  loss_mask_0: 0.1042  loss_dice_0: 0.1565  loss_ce_1: 4.247e-05  loss_mask_1: 0.1033  loss_dice_1: 0.155  loss_ce_2: 4.378e-05  loss_mask_2: 0.104  loss_dice_2: 0.1613  loss_ce_3: 2.771e-05  loss_mask_3: 0.1056  loss_dice_3: 0.1581  loss_ce_4: 3.387e-05  loss_mask_4: 0.1041  loss_dice_4: 0.1563  loss_ce_5: 3.719e-05  loss_mask_5: 0.1027  loss_dice_5: 0.1547  loss_ce_6: 2.461e-05  loss_mask_6: 0.1071  loss_dice_6: 0.1614  loss_ce_7: 3.321e-05  loss_mask_7: 0.1046  loss_dice_7: 0.1551  loss_ce_8: 3.824e-05  loss_mask_8: 0.1052  loss_dice_8: 0.1573  time: 0.5094  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:03] d2.utils.events INFO:  eta: 0:08:54  iter: 31819  total_loss: 2.824  loss_ce: 2.667e-05  loss_mask: 0.1107  loss_dice: 0.1666  loss_ce_0: 0.1382  loss_mask_0: 0.1091  loss_dice_0: 0.1603  loss_ce_1: 5.41e-05  loss_mask_1: 0.1113  loss_dice_1: 0.1675  loss_ce_2: 4.369e-05  loss_mask_2: 0.1102  loss_dice_2: 0.1612  loss_ce_3: 2.282e-05  loss_mask_3: 0.1103  loss_dice_3: 0.1614  loss_ce_4: 3.246e-05  loss_mask_4: 0.112  loss_dice_4: 0.1678  loss_ce_5: 4.413e-05  loss_mask_5: 0.108  loss_dice_5: 0.1602  loss_ce_6: 2.374e-05  loss_mask_6: 0.1084  loss_dice_6: 0.1619  loss_ce_7: 3.531e-05  loss_mask_7: 0.11  loss_dice_7: 0.1705  loss_ce_8: 5.238e-05  loss_mask_8: 0.1118  loss_dice_8: 0.1634  time: 0.5091  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:07] d2.utils.events INFO:  eta: 0:08:51  iter: 31839  total_loss: 2.81  loss_ce: 2.68e-05  loss_mask: 0.1096  loss_dice: 0.1644  loss_ce_0: 0.1243  loss_mask_0: 0.1058  loss_dice_0: 0.1545  loss_ce_1: 5.099e-05  loss_mask_1: 0.108  loss_dice_1: 0.1589  loss_ce_2: 4.42e-05  loss_mask_2: 0.1089  loss_dice_2: 0.1566  loss_ce_3: 2.109e-05  loss_mask_3: 0.1093  loss_dice_3: 0.1599  loss_ce_4: 3.341e-05  loss_mask_4: 0.1052  loss_dice_4: 0.1516  loss_ce_5: 4.422e-05  loss_mask_5: 0.1107  loss_dice_5: 0.157  loss_ce_6: 2.246e-05  loss_mask_6: 0.1042  loss_dice_6: 0.1617  loss_ce_7: 3.681e-05  loss_mask_7: 0.1069  loss_dice_7: 0.1559  loss_ce_8: 4.761e-05  loss_mask_8: 0.1068  loss_dice_8: 0.1532  time: 0.5089  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:10] d2.utils.events INFO:  eta: 0:08:48  iter: 31859  total_loss: 2.898  loss_ce: 2.716e-05  loss_mask: 0.1147  loss_dice: 0.1657  loss_ce_0: 0.1238  loss_mask_0: 0.1133  loss_dice_0: 0.1672  loss_ce_1: 4.175e-05  loss_mask_1: 0.1154  loss_dice_1: 0.1674  loss_ce_2: 4.771e-05  loss_mask_2: 0.1125  loss_dice_2: 0.1695  loss_ce_3: 2.056e-05  loss_mask_3: 0.1085  loss_dice_3: 0.1653  loss_ce_4: 3.227e-05  loss_mask_4: 0.1125  loss_dice_4: 0.1661  loss_ce_5: 3.76e-05  loss_mask_5: 0.1157  loss_dice_5: 0.1647  loss_ce_6: 2.295e-05  loss_mask_6: 0.1126  loss_dice_6: 0.1652  loss_ce_7: 3.588e-05  loss_mask_7: 0.1105  loss_dice_7: 0.1643  loss_ce_8: 3.833e-05  loss_mask_8: 0.1094  loss_dice_8: 0.1615  time: 0.5087  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:13] d2.utils.events INFO:  eta: 0:08:45  iter: 31879  total_loss: 2.754  loss_ce: 2.769e-05  loss_mask: 0.1058  loss_dice: 0.1572  loss_ce_0: 0.1239  loss_mask_0: 0.108  loss_dice_0: 0.1644  loss_ce_1: 5.49e-05  loss_mask_1: 0.1081  loss_dice_1: 0.1599  loss_ce_2: 4.883e-05  loss_mask_2: 0.1072  loss_dice_2: 0.1605  loss_ce_3: 2.3e-05  loss_mask_3: 0.1025  loss_dice_3: 0.1545  loss_ce_4: 3.406e-05  loss_mask_4: 0.1032  loss_dice_4: 0.1559  loss_ce_5: 4.52e-05  loss_mask_5: 0.1071  loss_dice_5: 0.1593  loss_ce_6: 2.387e-05  loss_mask_6: 0.1051  loss_dice_6: 0.1546  loss_ce_7: 3.621e-05  loss_mask_7: 0.104  loss_dice_7: 0.1527  loss_ce_8: 5.188e-05  loss_mask_8: 0.1049  loss_dice_8: 0.1612  time: 0.5085  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:17] d2.utils.events INFO:  eta: 0:08:41  iter: 31899  total_loss: 2.751  loss_ce: 2.94e-05  loss_mask: 0.11  loss_dice: 0.1647  loss_ce_0: 0.1239  loss_mask_0: 0.1056  loss_dice_0: 0.1593  loss_ce_1: 4.503e-05  loss_mask_1: 0.1049  loss_dice_1: 0.1625  loss_ce_2: 4.833e-05  loss_mask_2: 0.1018  loss_dice_2: 0.1579  loss_ce_3: 2.419e-05  loss_mask_3: 0.1083  loss_dice_3: 0.1595  loss_ce_4: 3.416e-05  loss_mask_4: 0.1058  loss_dice_4: 0.1579  loss_ce_5: 3.766e-05  loss_mask_5: 0.1058  loss_dice_5: 0.1565  loss_ce_6: 2.453e-05  loss_mask_6: 0.1049  loss_dice_6: 0.158  loss_ce_7: 3.448e-05  loss_mask_7: 0.1061  loss_dice_7: 0.1583  loss_ce_8: 3.887e-05  loss_mask_8: 0.1058  loss_dice_8: 0.1609  time: 0.5083  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:20] d2.utils.events INFO:  eta: 0:08:38  iter: 31919  total_loss: 2.808  loss_ce: 2.694e-05  loss_mask: 0.1065  loss_dice: 0.1583  loss_ce_0: 0.1238  loss_mask_0: 0.1061  loss_dice_0: 0.1552  loss_ce_1: 4.446e-05  loss_mask_1: 0.1062  loss_dice_1: 0.1581  loss_ce_2: 3.9e-05  loss_mask_2: 0.1081  loss_dice_2: 0.1573  loss_ce_3: 1.984e-05  loss_mask_3: 0.1058  loss_dice_3: 0.1597  loss_ce_4: 2.473e-05  loss_mask_4: 0.1059  loss_dice_4: 0.1587  loss_ce_5: 3.007e-05  loss_mask_5: 0.1103  loss_dice_5: 0.1586  loss_ce_6: 2.156e-05  loss_mask_6: 0.11  loss_dice_6: 0.1615  loss_ce_7: 2.823e-05  loss_mask_7: 0.1044  loss_dice_7: 0.1582  loss_ce_8: 3.367e-05  loss_mask_8: 0.1129  loss_dice_8: 0.1677  time: 0.5081  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:23] d2.utils.events INFO:  eta: 0:08:35  iter: 31939  total_loss: 2.864  loss_ce: 2.708e-05  loss_mask: 0.1129  loss_dice: 0.1664  loss_ce_0: 0.1237  loss_mask_0: 0.1131  loss_dice_0: 0.1724  loss_ce_1: 4.784e-05  loss_mask_1: 0.1116  loss_dice_1: 0.1609  loss_ce_2: 4.268e-05  loss_mask_2: 0.112  loss_dice_2: 0.1692  loss_ce_3: 2.313e-05  loss_mask_3: 0.1128  loss_dice_3: 0.1661  loss_ce_4: 3.281e-05  loss_mask_4: 0.1111  loss_dice_4: 0.1662  loss_ce_5: 3.741e-05  loss_mask_5: 0.1095  loss_dice_5: 0.1647  loss_ce_6: 2.45e-05  loss_mask_6: 0.1123  loss_dice_6: 0.1611  loss_ce_7: 3.343e-05  loss_mask_7: 0.1138  loss_dice_7: 0.166  loss_ce_8: 3.868e-05  loss_mask_8: 0.1102  loss_dice_8: 0.1673  time: 0.5079  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:27] d2.utils.events INFO:  eta: 0:08:32  iter: 31959  total_loss: 2.877  loss_ce: 3.139e-05  loss_mask: 0.1068  loss_dice: 0.1709  loss_ce_0: 0.1237  loss_mask_0: 0.1074  loss_dice_0: 0.1651  loss_ce_1: 4.295e-05  loss_mask_1: 0.1079  loss_dice_1: 0.1663  loss_ce_2: 5.607e-05  loss_mask_2: 0.1098  loss_dice_2: 0.1677  loss_ce_3: 3.65e-05  loss_mask_3: 0.1118  loss_dice_3: 0.1641  loss_ce_4: 3.382e-05  loss_mask_4: 0.1082  loss_dice_4: 0.167  loss_ce_5: 3.721e-05  loss_mask_5: 0.1084  loss_dice_5: 0.1699  loss_ce_6: 2.751e-05  loss_mask_6: 0.1082  loss_dice_6: 0.1629  loss_ce_7: 3.474e-05  loss_mask_7: 0.1082  loss_dice_7: 0.1679  loss_ce_8: 3.806e-05  loss_mask_8: 0.1075  loss_dice_8: 0.1674  time: 0.5076  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:30] d2.utils.events INFO:  eta: 0:08:28  iter: 31979  total_loss: 2.868  loss_ce: 2.676e-05  loss_mask: 0.1105  loss_dice: 0.1551  loss_ce_0: 0.1236  loss_mask_0: 0.114  loss_dice_0: 0.1689  loss_ce_1: 5.433e-05  loss_mask_1: 0.1097  loss_dice_1: 0.1661  loss_ce_2: 5.637e-05  loss_mask_2: 0.1119  loss_dice_2: 0.1649  loss_ce_3: 2.192e-05  loss_mask_3: 0.1134  loss_dice_3: 0.1659  loss_ce_4: 3.289e-05  loss_mask_4: 0.1113  loss_dice_4: 0.1609  loss_ce_5: 4.431e-05  loss_mask_5: 0.1083  loss_dice_5: 0.1657  loss_ce_6: 2.291e-05  loss_mask_6: 0.1096  loss_dice_6: 0.1603  loss_ce_7: 3.665e-05  loss_mask_7: 0.1096  loss_dice_7: 0.1654  loss_ce_8: 4.706e-05  loss_mask_8: 0.1139  loss_dice_8: 0.1706  time: 0.5074  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:34] d2.utils.events INFO:  eta: 0:08:25  iter: 31999  total_loss: 2.87  loss_ce: 2.671e-05  loss_mask: 0.1084  loss_dice: 0.1662  loss_ce_0: 0.1253  loss_mask_0: 0.1062  loss_dice_0: 0.1613  loss_ce_1: 5.479e-05  loss_mask_1: 0.1074  loss_dice_1: 0.1629  loss_ce_2: 4.255e-05  loss_mask_2: 0.1079  loss_dice_2: 0.1645  loss_ce_3: 2.666e-05  loss_mask_3: 0.1078  loss_dice_3: 0.164  loss_ce_4: 3.27e-05  loss_mask_4: 0.1081  loss_dice_4: 0.1675  loss_ce_5: 4.327e-05  loss_mask_5: 0.1062  loss_dice_5: 0.1612  loss_ce_6: 2.424e-05  loss_mask_6: 0.1084  loss_dice_6: 0.1654  loss_ce_7: 3.493e-05  loss_mask_7: 0.1097  loss_dice_7: 0.1638  loss_ce_8: 4.726e-05  loss_mask_8: 0.1067  loss_dice_8: 0.1625  time: 0.5072  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:37] d2.utils.events INFO:  eta: 0:08:22  iter: 32019  total_loss: 2.892  loss_ce: 2.95e-05  loss_mask: 0.1097  loss_dice: 0.166  loss_ce_0: 0.1236  loss_mask_0: 0.1089  loss_dice_0: 0.1674  loss_ce_1: 4.757e-05  loss_mask_1: 0.1105  loss_dice_1: 0.1664  loss_ce_2: 4.913e-05  loss_mask_2: 0.1098  loss_dice_2: 0.1669  loss_ce_3: 2.744e-05  loss_mask_3: 0.1104  loss_dice_3: 0.165  loss_ce_4: 3.22e-05  loss_mask_4: 0.1109  loss_dice_4: 0.1706  loss_ce_5: 3.745e-05  loss_mask_5: 0.112  loss_dice_5: 0.1735  loss_ce_6: 2.575e-05  loss_mask_6: 0.1106  loss_dice_6: 0.1655  loss_ce_7: 3.619e-05  loss_mask_7: 0.1103  loss_dice_7: 0.1667  loss_ce_8: 3.922e-05  loss_mask_8: 0.1073  loss_dice_8: 0.1719  time: 0.5070  data_time: 0.0010  lr: 1e-06  max_mem: 8444M
[08/01 22:33:40] d2.utils.events INFO:  eta: 0:08:18  iter: 32039  total_loss: 2.928  loss_ce: 2.709e-05  loss_mask: 0.1121  loss_dice: 0.1682  loss_ce_0: 0.1236  loss_mask_0: 0.1111  loss_dice_0: 0.1678  loss_ce_1: 4.701e-05  loss_mask_1: 0.1119  loss_dice_1: 0.1713  loss_ce_2: 5.446e-05  loss_mask_2: 0.1113  loss_dice_2: 0.1628  loss_ce_3: 2.418e-05  loss_mask_3: 0.1132  loss_dice_3: 0.1676  loss_ce_4: 3.429e-05  loss_mask_4: 0.1103  loss_dice_4: 0.1666  loss_ce_5: 4.121e-05  loss_mask_5: 0.1106  loss_dice_5: 0.1643  loss_ce_6: 2.413e-05  loss_mask_6: 0.1088  loss_dice_6: 0.1655  loss_ce_7: 3.536e-05  loss_mask_7: 0.1139  loss_dice_7: 0.1697  loss_ce_8: 4.342e-05  loss_mask_8: 0.1089  loss_dice_8: 0.1653  time: 0.5068  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:33:44] d2.utils.events INFO:  eta: 0:08:15  iter: 32059  total_loss: 2.883  loss_ce: 2.688e-05  loss_mask: 0.1098  loss_dice: 0.1624  loss_ce_0: 0.1236  loss_mask_0: 0.1044  loss_dice_0: 0.1698  loss_ce_1: 3.502e-05  loss_mask_1: 0.1128  loss_dice_1: 0.1667  loss_ce_2: 3.788e-05  loss_mask_2: 0.1096  loss_dice_2: 0.1662  loss_ce_3: 1.524e-05  loss_mask_3: 0.107  loss_dice_3: 0.1658  loss_ce_4: 2.403e-05  loss_mask_4: 0.1108  loss_dice_4: 0.167  loss_ce_5: 3.047e-05  loss_mask_5: 0.109  loss_dice_5: 0.1704  loss_ce_6: 1.848e-05  loss_mask_6: 0.1095  loss_dice_6: 0.1605  loss_ce_7: 3.174e-05  loss_mask_7: 0.1106  loss_dice_7: 0.1668  loss_ce_8: 3.287e-05  loss_mask_8: 0.1096  loss_dice_8: 0.1683  time: 0.5066  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:47] d2.utils.events INFO:  eta: 0:08:12  iter: 32079  total_loss: 2.92  loss_ce: 2.782e-05  loss_mask: 0.1123  loss_dice: 0.1747  loss_ce_0: 0.1235  loss_mask_0: 0.1131  loss_dice_0: 0.1671  loss_ce_1: 4.45e-05  loss_mask_1: 0.1128  loss_dice_1: 0.172  loss_ce_2: 5.276e-05  loss_mask_2: 0.1116  loss_dice_2: 0.1721  loss_ce_3: 2.441e-05  loss_mask_3: 0.1139  loss_dice_3: 0.1665  loss_ce_4: 3.43e-05  loss_mask_4: 0.1103  loss_dice_4: 0.1718  loss_ce_5: 4.067e-05  loss_mask_5: 0.1113  loss_dice_5: 0.1683  loss_ce_6: 2.576e-05  loss_mask_6: 0.1101  loss_dice_6: 0.1684  loss_ce_7: 3.586e-05  loss_mask_7: 0.1131  loss_dice_7: 0.1716  loss_ce_8: 4.184e-05  loss_mask_8: 0.1146  loss_dice_8: 0.1719  time: 0.5064  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:50] d2.utils.events INFO:  eta: 0:08:08  iter: 32099  total_loss: 2.851  loss_ce: 2.798e-05  loss_mask: 0.1069  loss_dice: 0.1628  loss_ce_0: 0.1235  loss_mask_0: 0.1118  loss_dice_0: 0.165  loss_ce_1: 4.443e-05  loss_mask_1: 0.1109  loss_dice_1: 0.168  loss_ce_2: 5.303e-05  loss_mask_2: 0.1106  loss_dice_2: 0.167  loss_ce_3: 3.18e-05  loss_mask_3: 0.1102  loss_dice_3: 0.1627  loss_ce_4: 3.347e-05  loss_mask_4: 0.1101  loss_dice_4: 0.163  loss_ce_5: 3.728e-05  loss_mask_5: 0.1088  loss_dice_5: 0.1608  loss_ce_6: 2.566e-05  loss_mask_6: 0.1069  loss_dice_6: 0.1639  loss_ce_7: 3.68e-05  loss_mask_7: 0.1141  loss_dice_7: 0.1647  loss_ce_8: 3.894e-05  loss_mask_8: 0.1092  loss_dice_8: 0.1651  time: 0.5062  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:54] d2.utils.events INFO:  eta: 0:08:05  iter: 32119  total_loss: 2.943  loss_ce: 2.71e-05  loss_mask: 0.1082  loss_dice: 0.1722  loss_ce_0: 0.1235  loss_mask_0: 0.1106  loss_dice_0: 0.1772  loss_ce_1: 4.26e-05  loss_mask_1: 0.1111  loss_dice_1: 0.1725  loss_ce_2: 5.579e-05  loss_mask_2: 0.1073  loss_dice_2: 0.1692  loss_ce_3: 1.877e-05  loss_mask_3: 0.1097  loss_dice_3: 0.1736  loss_ce_4: 3.153e-05  loss_mask_4: 0.1065  loss_dice_4: 0.1706  loss_ce_5: 3.713e-05  loss_mask_5: 0.112  loss_dice_5: 0.1681  loss_ce_6: 2.124e-05  loss_mask_6: 0.1069  loss_dice_6: 0.1679  loss_ce_7: 3.561e-05  loss_mask_7: 0.1069  loss_dice_7: 0.1647  loss_ce_8: 3.813e-05  loss_mask_8: 0.1094  loss_dice_8: 0.1759  time: 0.5060  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:33:57] d2.utils.events INFO:  eta: 0:08:01  iter: 32139  total_loss: 2.908  loss_ce: 2.512e-05  loss_mask: 0.1101  loss_dice: 0.1654  loss_ce_0: 0.1235  loss_mask_0: 0.1106  loss_dice_0: 0.1641  loss_ce_1: 4.844e-05  loss_mask_1: 0.1108  loss_dice_1: 0.1542  loss_ce_2: 4.329e-05  loss_mask_2: 0.1127  loss_dice_2: 0.1675  loss_ce_3: 1.697e-05  loss_mask_3: 0.1086  loss_dice_3: 0.162  loss_ce_4: 3.159e-05  loss_mask_4: 0.1097  loss_dice_4: 0.1637  loss_ce_5: 3.749e-05  loss_mask_5: 0.11  loss_dice_5: 0.165  loss_ce_6: 2.008e-05  loss_mask_6: 0.1088  loss_dice_6: 0.16  loss_ce_7: 3.549e-05  loss_mask_7: 0.1129  loss_dice_7: 0.1646  loss_ce_8: 3.992e-05  loss_mask_8: 0.1112  loss_dice_8: 0.1656  time: 0.5057  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:34:00] d2.utils.events INFO:  eta: 0:07:58  iter: 32159  total_loss: 2.715  loss_ce: 2.725e-05  loss_mask: 0.1067  loss_dice: 0.1561  loss_ce_0: 0.1235  loss_mask_0: 0.1071  loss_dice_0: 0.1586  loss_ce_1: 4.196e-05  loss_mask_1: 0.107  loss_dice_1: 0.1559  loss_ce_2: 5.505e-05  loss_mask_2: 0.1056  loss_dice_2: 0.156  loss_ce_3: 2.66e-05  loss_mask_3: 0.105  loss_dice_3: 0.1566  loss_ce_4: 3.399e-05  loss_mask_4: 0.1039  loss_dice_4: 0.1511  loss_ce_5: 3.743e-05  loss_mask_5: 0.1048  loss_dice_5: 0.1537  loss_ce_6: 2.344e-05  loss_mask_6: 0.1048  loss_dice_6: 0.1518  loss_ce_7: 3.481e-05  loss_mask_7: 0.1069  loss_dice_7: 0.1588  loss_ce_8: 3.874e-05  loss_mask_8: 0.1069  loss_dice_8: 0.1538  time: 0.5055  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:34:04] d2.utils.events INFO:  eta: 0:07:55  iter: 32179  total_loss: 2.909  loss_ce: 3.396e-05  loss_mask: 0.11  loss_dice: 0.1651  loss_ce_0: 0.1234  loss_mask_0: 0.1098  loss_dice_0: 0.1686  loss_ce_1: 4.828e-05  loss_mask_1: 0.1142  loss_dice_1: 0.1668  loss_ce_2: 5.31e-05  loss_mask_2: 0.1124  loss_dice_2: 0.1629  loss_ce_3: 2.712e-05  loss_mask_3: 0.1124  loss_dice_3: 0.1658  loss_ce_4: 3.541e-05  loss_mask_4: 0.1106  loss_dice_4: 0.1636  loss_ce_5: 4.55e-05  loss_mask_5: 0.1112  loss_dice_5: 0.1611  loss_ce_6: 2.663e-05  loss_mask_6: 0.1071  loss_dice_6: 0.1598  loss_ce_7: 3.802e-05  loss_mask_7: 0.1123  loss_dice_7: 0.1655  loss_ce_8: 4.807e-05  loss_mask_8: 0.113  loss_dice_8: 0.1651  time: 0.5053  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:34:07] d2.utils.events INFO:  eta: 0:07:51  iter: 32199  total_loss: 2.754  loss_ce: 2.647e-05  loss_mask: 0.1069  loss_dice: 0.1601  loss_ce_0: 0.1126  loss_mask_0: 0.1035  loss_dice_0: 0.1561  loss_ce_1: 4.944e-05  loss_mask_1: 0.1101  loss_dice_1: 0.1565  loss_ce_2: 5.642e-05  loss_mask_2: 0.1054  loss_dice_2: 0.1583  loss_ce_3: 2.328e-05  loss_mask_3: 0.1061  loss_dice_3: 0.1553  loss_ce_4: 3.327e-05  loss_mask_4: 0.1048  loss_dice_4: 0.1546  loss_ce_5: 3.792e-05  loss_mask_5: 0.1055  loss_dice_5: 0.1563  loss_ce_6: 2.292e-05  loss_mask_6: 0.1063  loss_dice_6: 0.1563  loss_ce_7: 3.587e-05  loss_mask_7: 0.1053  loss_dice_7: 0.1563  loss_ce_8: 3.928e-05  loss_mask_8: 0.1098  loss_dice_8: 0.1571  time: 0.5051  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:34:11] d2.utils.events INFO:  eta: 0:07:48  iter: 32219  total_loss: 2.79  loss_ce: 2.674e-05  loss_mask: 0.1082  loss_dice: 0.1609  loss_ce_0: 0.1255  loss_mask_0: 0.1065  loss_dice_0: 0.1653  loss_ce_1: 3.168e-05  loss_mask_1: 0.1074  loss_dice_1: 0.1613  loss_ce_2: 3.329e-05  loss_mask_2: 0.1059  loss_dice_2: 0.157  loss_ce_3: 1.334e-05  loss_mask_3: 0.1087  loss_dice_3: 0.1527  loss_ce_4: 1.769e-05  loss_mask_4: 0.106  loss_dice_4: 0.1564  loss_ce_5: 2.3e-05  loss_mask_5: 0.1086  loss_dice_5: 0.1597  loss_ce_6: 1.688e-05  loss_mask_6: 0.1089  loss_dice_6: 0.1516  loss_ce_7: 2.916e-05  loss_mask_7: 0.1071  loss_dice_7: 0.1585  loss_ce_8: 2.773e-05  loss_mask_8: 0.1053  loss_dice_8: 0.159  time: 0.5049  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:34:14] d2.utils.events INFO:  eta: 0:07:45  iter: 32239  total_loss: 2.933  loss_ce: 2.621e-05  loss_mask: 0.1133  loss_dice: 0.1694  loss_ce_0: 0.1233  loss_mask_0: 0.1117  loss_dice_0: 0.1691  loss_ce_1: 3.109e-05  loss_mask_1: 0.1195  loss_dice_1: 0.169  loss_ce_2: 3.325e-05  loss_mask_2: 0.1158  loss_dice_2: 0.1723  loss_ce_3: 1.618e-05  loss_mask_3: 0.1175  loss_dice_3: 0.1707  loss_ce_4: 1.856e-05  loss_mask_4: 0.1133  loss_dice_4: 0.1669  loss_ce_5: 2.31e-05  loss_mask_5: 0.113  loss_dice_5: 0.1726  loss_ce_6: 1.764e-05  loss_mask_6: 0.1181  loss_dice_6: 0.1709  loss_ce_7: 2.59e-05  loss_mask_7: 0.1135  loss_dice_7: 0.1682  loss_ce_8: 2.772e-05  loss_mask_8: 0.1122  loss_dice_8: 0.1719  time: 0.5047  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:34:17] d2.utils.events INFO:  eta: 0:07:41  iter: 32259  total_loss: 2.78  loss_ce: 2.771e-05  loss_mask: 0.105  loss_dice: 0.1612  loss_ce_0: 0.1255  loss_mask_0: 0.1042  loss_dice_0: 0.1642  loss_ce_1: 5.03e-05  loss_mask_1: 0.1052  loss_dice_1: 0.1612  loss_ce_2: 4.362e-05  loss_mask_2: 0.1075  loss_dice_2: 0.1656  loss_ce_3: 2.356e-05  loss_mask_3: 0.1075  loss_dice_3: 0.1629  loss_ce_4: 3.279e-05  loss_mask_4: 0.1044  loss_dice_4: 0.1589  loss_ce_5: 4.403e-05  loss_mask_5: 0.1094  loss_dice_5: 0.1607  loss_ce_6: 2.406e-05  loss_mask_6: 0.1066  loss_dice_6: 0.1652  loss_ce_7: 3.463e-05  loss_mask_7: 0.1065  loss_dice_7: 0.1608  loss_ce_8: 5.004e-05  loss_mask_8: 0.1091  loss_dice_8: 0.1635  time: 0.5045  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:34:21] d2.utils.events INFO:  eta: 0:07:38  iter: 32279  total_loss: 2.707  loss_ce: 2.666e-05  loss_mask: 0.1029  loss_dice: 0.1569  loss_ce_0: 0.1234  loss_mask_0: 0.1064  loss_dice_0: 0.1631  loss_ce_1: 4.22e-05  loss_mask_1: 0.1042  loss_dice_1: 0.1583  loss_ce_2: 5.463e-05  loss_mask_2: 0.1031  loss_dice_2: 0.1586  loss_ce_3: 3.083e-05  loss_mask_3: 0.1057  loss_dice_3: 0.1551  loss_ce_4: 3.379e-05  loss_mask_4: 0.1061  loss_dice_4: 0.1563  loss_ce_5: 3.724e-05  loss_mask_5: 0.1027  loss_dice_5: 0.1569  loss_ce_6: 2.479e-05  loss_mask_6: 0.1053  loss_dice_6: 0.1547  loss_ce_7: 3.435e-05  loss_mask_7: 0.1042  loss_dice_7: 0.1579  loss_ce_8: 3.807e-05  loss_mask_8: 0.1063  loss_dice_8: 0.1538  time: 0.5043  data_time: 0.0010  lr: 1e-06  max_mem: 8444M
[08/01 22:34:24] d2.utils.events INFO:  eta: 0:07:35  iter: 32299  total_loss: 3.016  loss_ce: 2.665e-05  loss_mask: 0.1162  loss_dice: 0.1713  loss_ce_0: 0.1234  loss_mask_0: 0.1187  loss_dice_0: 0.1758  loss_ce_1: 4.399e-05  loss_mask_1: 0.1174  loss_dice_1: 0.1746  loss_ce_2: 4.823e-05  loss_mask_2: 0.112  loss_dice_2: 0.1718  loss_ce_3: 2.246e-05  loss_mask_3: 0.1162  loss_dice_3: 0.1691  loss_ce_4: 3.204e-05  loss_mask_4: 0.1172  loss_dice_4: 0.1699  loss_ce_5: 3.709e-05  loss_mask_5: 0.1167  loss_dice_5: 0.1759  loss_ce_6: 2.414e-05  loss_mask_6: 0.1166  loss_dice_6: 0.1679  loss_ce_7: 3.383e-05  loss_mask_7: 0.1139  loss_dice_7: 0.1708  loss_ce_8: 3.866e-05  loss_mask_8: 0.1183  loss_dice_8: 0.1709  time: 0.5041  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:34:27] d2.utils.events INFO:  eta: 0:07:31  iter: 32319  total_loss: 2.729  loss_ce: 2.692e-05  loss_mask: 0.1068  loss_dice: 0.1524  loss_ce_0: 0.1283  loss_mask_0: 0.1084  loss_dice_0: 0.1584  loss_ce_1: 3.66e-05  loss_mask_1: 0.1077  loss_dice_1: 0.1553  loss_ce_2: 3.726e-05  loss_mask_2: 0.1063  loss_dice_2: 0.1585  loss_ce_3: 1.84e-05  loss_mask_3: 0.1078  loss_dice_3: 0.1544  loss_ce_4: 2.385e-05  loss_mask_4: 0.1053  loss_dice_4: 0.1565  loss_ce_5: 2.982e-05  loss_mask_5: 0.1056  loss_dice_5: 0.1487  loss_ce_6: 1.956e-05  loss_mask_6: 0.1066  loss_dice_6: 0.1517  loss_ce_7: 2.878e-05  loss_mask_7: 0.1093  loss_dice_7: 0.152  loss_ce_8: 3.3e-05  loss_mask_8: 0.1072  loss_dice_8: 0.1545  time: 0.5039  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:34:31] d2.utils.events INFO:  eta: 0:07:28  iter: 32339  total_loss: 2.796  loss_ce: 2.655e-05  loss_mask: 0.1077  loss_dice: 0.1611  loss_ce_0: 0.1233  loss_mask_0: 0.1053  loss_dice_0: 0.1571  loss_ce_1: 4.761e-05  loss_mask_1: 0.1072  loss_dice_1: 0.1623  loss_ce_2: 5.645e-05  loss_mask_2: 0.1055  loss_dice_2: 0.1575  loss_ce_3: 2.173e-05  loss_mask_3: 0.1107  loss_dice_3: 0.1573  loss_ce_4: 3.392e-05  loss_mask_4: 0.1083  loss_dice_4: 0.161  loss_ce_5: 4.47e-05  loss_mask_5: 0.1071  loss_dice_5: 0.1585  loss_ce_6: 2.26e-05  loss_mask_6: 0.1094  loss_dice_6: 0.1665  loss_ce_7: 3.829e-05  loss_mask_7: 0.1042  loss_dice_7: 0.1578  loss_ce_8: 4.536e-05  loss_mask_8: 0.1066  loss_dice_8: 0.1589  time: 0.5037  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:34:34] d2.utils.events INFO:  eta: 0:07:25  iter: 32359  total_loss: 2.77  loss_ce: 2.745e-05  loss_mask: 0.1078  loss_dice: 0.1562  loss_ce_0: 0.1233  loss_mask_0: 0.1105  loss_dice_0: 0.1701  loss_ce_1: 4.263e-05  loss_mask_1: 0.1046  loss_dice_1: 0.1631  loss_ce_2: 4.86e-05  loss_mask_2: 0.1065  loss_dice_2: 0.163  loss_ce_3: 2.284e-05  loss_mask_3: 0.1041  loss_dice_3: 0.1573  loss_ce_4: 3.34e-05  loss_mask_4: 0.1076  loss_dice_4: 0.1578  loss_ce_5: 4.123e-05  loss_mask_5: 0.1075  loss_dice_5: 0.1593  loss_ce_6: 2.291e-05  loss_mask_6: 0.1069  loss_dice_6: 0.1654  loss_ce_7: 3.579e-05  loss_mask_7: 0.1057  loss_dice_7: 0.1563  loss_ce_8: 4.253e-05  loss_mask_8: 0.1057  loss_dice_8: 0.1587  time: 0.5034  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:34:38] d2.utils.events INFO:  eta: 0:07:21  iter: 32379  total_loss: 2.968  loss_ce: 2.609e-05  loss_mask: 0.1213  loss_dice: 0.1675  loss_ce_0: 0.1233  loss_mask_0: 0.1178  loss_dice_0: 0.1666  loss_ce_1: 3.817e-05  loss_mask_1: 0.1207  loss_dice_1: 0.1657  loss_ce_2: 3.896e-05  loss_mask_2: 0.1201  loss_dice_2: 0.1569  loss_ce_3: 1.975e-05  loss_mask_3: 0.1177  loss_dice_3: 0.163  loss_ce_4: 2.362e-05  loss_mask_4: 0.1202  loss_dice_4: 0.1631  loss_ce_5: 2.964e-05  loss_mask_5: 0.1206  loss_dice_5: 0.1694  loss_ce_6: 2.145e-05  loss_mask_6: 0.1164  loss_dice_6: 0.1634  loss_ce_7: 2.96e-05  loss_mask_7: 0.1214  loss_dice_7: 0.1594  loss_ce_8: 3.278e-05  loss_mask_8: 0.1156  loss_dice_8: 0.1666  time: 0.5032  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:34:41] d2.utils.events INFO:  eta: 0:07:18  iter: 32399  total_loss: 2.869  loss_ce: 2.659e-05  loss_mask: 0.1134  loss_dice: 0.1675  loss_ce_0: 0.1233  loss_mask_0: 0.1079  loss_dice_0: 0.1673  loss_ce_1: 4.616e-05  loss_mask_1: 0.1091  loss_dice_1: 0.1578  loss_ce_2: 5.309e-05  loss_mask_2: 0.107  loss_dice_2: 0.1613  loss_ce_3: 1.977e-05  loss_mask_3: 0.1088  loss_dice_3: 0.1681  loss_ce_4: 3.299e-05  loss_mask_4: 0.1105  loss_dice_4: 0.1623  loss_ce_5: 4.119e-05  loss_mask_5: 0.1114  loss_dice_5: 0.1683  loss_ce_6: 2.178e-05  loss_mask_6: 0.1082  loss_dice_6: 0.1647  loss_ce_7: 3.764e-05  loss_mask_7: 0.1074  loss_dice_7: 0.1617  loss_ce_8: 4.323e-05  loss_mask_8: 0.1145  loss_dice_8: 0.1648  time: 0.5030  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:34:44] d2.utils.events INFO:  eta: 0:07:15  iter: 32419  total_loss: 2.883  loss_ce: 2.677e-05  loss_mask: 0.1096  loss_dice: 0.1584  loss_ce_0: 0.1233  loss_mask_0: 0.1106  loss_dice_0: 0.1615  loss_ce_1: 4.598e-05  loss_mask_1: 0.11  loss_dice_1: 0.1554  loss_ce_2: 4.763e-05  loss_mask_2: 0.1112  loss_dice_2: 0.1546  loss_ce_3: 2.156e-05  loss_mask_3: 0.1125  loss_dice_3: 0.1663  loss_ce_4: 3.183e-05  loss_mask_4: 0.1113  loss_dice_4: 0.1643  loss_ce_5: 4.075e-05  loss_mask_5: 0.1098  loss_dice_5: 0.1577  loss_ce_6: 2.311e-05  loss_mask_6: 0.1091  loss_dice_6: 0.16  loss_ce_7: 3.678e-05  loss_mask_7: 0.1136  loss_dice_7: 0.1607  loss_ce_8: 4.308e-05  loss_mask_8: 0.1118  loss_dice_8: 0.1606  time: 0.5028  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:34:48] d2.utils.events INFO:  eta: 0:07:12  iter: 32439  total_loss: 2.833  loss_ce: 2.725e-05  loss_mask: 0.1049  loss_dice: 0.161  loss_ce_0: 0.1233  loss_mask_0: 0.1075  loss_dice_0: 0.1594  loss_ce_1: 4.169e-05  loss_mask_1: 0.1117  loss_dice_1: 0.1673  loss_ce_2: 4.224e-05  loss_mask_2: 0.1076  loss_dice_2: 0.1617  loss_ce_3: 2.189e-05  loss_mask_3: 0.1068  loss_dice_3: 0.1554  loss_ce_4: 3.031e-05  loss_mask_4: 0.1089  loss_dice_4: 0.1651  loss_ce_5: 3.743e-05  loss_mask_5: 0.1087  loss_dice_5: 0.1658  loss_ce_6: 2.339e-05  loss_mask_6: 0.1099  loss_dice_6: 0.1631  loss_ce_7: 3.442e-05  loss_mask_7: 0.1073  loss_dice_7: 0.1555  loss_ce_8: 3.837e-05  loss_mask_8: 0.1082  loss_dice_8: 0.1597  time: 0.5026  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:34:51] d2.utils.events INFO:  eta: 0:07:08  iter: 32459  total_loss: 2.797  loss_ce: 3.026e-05  loss_mask: 0.1071  loss_dice: 0.1562  loss_ce_0: 0.1233  loss_mask_0: 0.1051  loss_dice_0: 0.1651  loss_ce_1: 4.772e-05  loss_mask_1: 0.1065  loss_dice_1: 0.1604  loss_ce_2: 5.399e-05  loss_mask_2: 0.1051  loss_dice_2: 0.1606  loss_ce_3: 2.638e-05  loss_mask_3: 0.1046  loss_dice_3: 0.1609  loss_ce_4: 3.437e-05  loss_mask_4: 0.1094  loss_dice_4: 0.1633  loss_ce_5: 4.907e-05  loss_mask_5: 0.106  loss_dice_5: 0.1579  loss_ce_6: 2.513e-05  loss_mask_6: 0.1125  loss_dice_6: 0.1657  loss_ce_7: 3.868e-05  loss_mask_7: 0.1071  loss_dice_7: 0.1602  loss_ce_8: 4.783e-05  loss_mask_8: 0.1065  loss_dice_8: 0.1651  time: 0.5024  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:34:54] d2.utils.events INFO:  eta: 0:07:05  iter: 32479  total_loss: 2.851  loss_ce: 3.299e-05  loss_mask: 0.1151  loss_dice: 0.1668  loss_ce_0: 0.1244  loss_mask_0: 0.1126  loss_dice_0: 0.17  loss_ce_1: 4.47e-05  loss_mask_1: 0.1133  loss_dice_1: 0.1696  loss_ce_2: 5.278e-05  loss_mask_2: 0.1153  loss_dice_2: 0.1689  loss_ce_3: 3.164e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1629  loss_ce_4: 3.312e-05  loss_mask_4: 0.1133  loss_dice_4: 0.1656  loss_ce_5: 4.042e-05  loss_mask_5: 0.1087  loss_dice_5: 0.161  loss_ce_6: 2.862e-05  loss_mask_6: 0.111  loss_dice_6: 0.1582  loss_ce_7: 3.659e-05  loss_mask_7: 0.1121  loss_dice_7: 0.1611  loss_ce_8: 4.251e-05  loss_mask_8: 0.1124  loss_dice_8: 0.1669  time: 0.5022  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:34:58] d2.utils.events INFO:  eta: 0:07:01  iter: 32499  total_loss: 2.818  loss_ce: 3.074e-05  loss_mask: 0.1057  loss_dice: 0.1594  loss_ce_0: 0.1253  loss_mask_0: 0.11  loss_dice_0: 0.1643  loss_ce_1: 4.036e-05  loss_mask_1: 0.1105  loss_dice_1: 0.1623  loss_ce_2: 4.394e-05  loss_mask_2: 0.1096  loss_dice_2: 0.1657  loss_ce_3: 3.2e-05  loss_mask_3: 0.1097  loss_dice_3: 0.1644  loss_ce_4: 3.327e-05  loss_mask_4: 0.1114  loss_dice_4: 0.1594  loss_ce_5: 3.738e-05  loss_mask_5: 0.1098  loss_dice_5: 0.1622  loss_ce_6: 2.787e-05  loss_mask_6: 0.1066  loss_dice_6: 0.1596  loss_ce_7: 3.494e-05  loss_mask_7: 0.1118  loss_dice_7: 0.1667  loss_ce_8: 3.898e-05  loss_mask_8: 0.1128  loss_dice_8: 0.1697  time: 0.5020  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:01] d2.utils.events INFO:  eta: 0:06:58  iter: 32519  total_loss: 2.896  loss_ce: 2.633e-05  loss_mask: 0.1122  loss_dice: 0.1644  loss_ce_0: 0.1234  loss_mask_0: 0.1131  loss_dice_0: 0.1711  loss_ce_1: 3.643e-05  loss_mask_1: 0.1101  loss_dice_1: 0.1641  loss_ce_2: 3.833e-05  loss_mask_2: 0.11  loss_dice_2: 0.1626  loss_ce_3: 1.931e-05  loss_mask_3: 0.1098  loss_dice_3: 0.1653  loss_ce_4: 2.435e-05  loss_mask_4: 0.1123  loss_dice_4: 0.1642  loss_ce_5: 2.993e-05  loss_mask_5: 0.1118  loss_dice_5: 0.162  loss_ce_6: 2.092e-05  loss_mask_6: 0.1109  loss_dice_6: 0.1644  loss_ce_7: 2.841e-05  loss_mask_7: 0.112  loss_dice_7: 0.1706  loss_ce_8: 3.274e-05  loss_mask_8: 0.11  loss_dice_8: 0.1688  time: 0.5018  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:05] d2.utils.events INFO:  eta: 0:06:54  iter: 32539  total_loss: 2.763  loss_ce: 2.697e-05  loss_mask: 0.1062  loss_dice: 0.1612  loss_ce_0: 0.1251  loss_mask_0: 0.1062  loss_dice_0: 0.1608  loss_ce_1: 3.708e-05  loss_mask_1: 0.1052  loss_dice_1: 0.1615  loss_ce_2: 4.125e-05  loss_mask_2: 0.1071  loss_dice_2: 0.1669  loss_ce_3: 2.122e-05  loss_mask_3: 0.1025  loss_dice_3: 0.1573  loss_ce_4: 3.056e-05  loss_mask_4: 0.1027  loss_dice_4: 0.1529  loss_ce_5: 3.712e-05  loss_mask_5: 0.1063  loss_dice_5: 0.153  loss_ce_6: 2.22e-05  loss_mask_6: 0.1074  loss_dice_6: 0.159  loss_ce_7: 3.057e-05  loss_mask_7: 0.1088  loss_dice_7: 0.1623  loss_ce_8: 3.718e-05  loss_mask_8: 0.1078  loss_dice_8: 0.1606  time: 0.5016  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:08] d2.utils.events INFO:  eta: 0:06:51  iter: 32559  total_loss: 2.824  loss_ce: 2.642e-05  loss_mask: 0.1079  loss_dice: 0.1619  loss_ce_0: 0.1278  loss_mask_0: 0.1078  loss_dice_0: 0.1635  loss_ce_1: 2.941e-05  loss_mask_1: 0.105  loss_dice_1: 0.1601  loss_ce_2: 3.321e-05  loss_mask_2: 0.1082  loss_dice_2: 0.1663  loss_ce_3: 1.318e-05  loss_mask_3: 0.1065  loss_dice_3: 0.1569  loss_ce_4: 1.76e-05  loss_mask_4: 0.1101  loss_dice_4: 0.1619  loss_ce_5: 2.292e-05  loss_mask_5: 0.1077  loss_dice_5: 0.1601  loss_ce_6: 1.648e-05  loss_mask_6: 0.1074  loss_dice_6: 0.1613  loss_ce_7: 2.643e-05  loss_mask_7: 0.1064  loss_dice_7: 0.1594  loss_ce_8: 2.767e-05  loss_mask_8: 0.1099  loss_dice_8: 0.1663  time: 0.5014  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:35:11] d2.utils.events INFO:  eta: 0:06:47  iter: 32579  total_loss: 2.837  loss_ce: 2.733e-05  loss_mask: 0.1056  loss_dice: 0.1591  loss_ce_0: 0.1234  loss_mask_0: 0.1063  loss_dice_0: 0.1627  loss_ce_1: 4.803e-05  loss_mask_1: 0.1079  loss_dice_1: 0.168  loss_ce_2: 5.552e-05  loss_mask_2: 0.1061  loss_dice_2: 0.1661  loss_ce_3: 2.6e-05  loss_mask_3: 0.1079  loss_dice_3: 0.1655  loss_ce_4: 3.174e-05  loss_mask_4: 0.1064  loss_dice_4: 0.159  loss_ce_5: 3.811e-05  loss_mask_5: 0.1087  loss_dice_5: 0.1654  loss_ce_6: 2.305e-05  loss_mask_6: 0.1087  loss_dice_6: 0.163  loss_ce_7: 3.67e-05  loss_mask_7: 0.1059  loss_dice_7: 0.1606  loss_ce_8: 3.941e-05  loss_mask_8: 0.111  loss_dice_8: 0.1609  time: 0.5012  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:35:15] d2.utils.events INFO:  eta: 0:06:44  iter: 32599  total_loss: 2.784  loss_ce: 2.941e-05  loss_mask: 0.1057  loss_dice: 0.1628  loss_ce_0: 0.1242  loss_mask_0: 0.1033  loss_dice_0: 0.1619  loss_ce_1: 5.215e-05  loss_mask_1: 0.1033  loss_dice_1: 0.1625  loss_ce_2: 5.54e-05  loss_mask_2: 0.1067  loss_dice_2: 0.1627  loss_ce_3: 3.159e-05  loss_mask_3: 0.1037  loss_dice_3: 0.1598  loss_ce_4: 3.424e-05  loss_mask_4: 0.1078  loss_dice_4: 0.1597  loss_ce_5: 4.992e-05  loss_mask_5: 0.1038  loss_dice_5: 0.1591  loss_ce_6: 2.604e-05  loss_mask_6: 0.1094  loss_dice_6: 0.1652  loss_ce_7: 3.93e-05  loss_mask_7: 0.1047  loss_dice_7: 0.1561  loss_ce_8: 4.742e-05  loss_mask_8: 0.1066  loss_dice_8: 0.1609  time: 0.5010  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:18] d2.utils.events INFO:  eta: 0:06:41  iter: 32619  total_loss: 2.792  loss_ce: 2.667e-05  loss_mask: 0.1068  loss_dice: 0.1645  loss_ce_0: 0.1235  loss_mask_0: 0.1081  loss_dice_0: 0.1576  loss_ce_1: 4.188e-05  loss_mask_1: 0.1061  loss_dice_1: 0.1565  loss_ce_2: 4.543e-05  loss_mask_2: 0.1095  loss_dice_2: 0.1625  loss_ce_3: 2.429e-05  loss_mask_3: 0.104  loss_dice_3: 0.1536  loss_ce_4: 3.234e-05  loss_mask_4: 0.1067  loss_dice_4: 0.1543  loss_ce_5: 3.66e-05  loss_mask_5: 0.1042  loss_dice_5: 0.1594  loss_ce_6: 2.399e-05  loss_mask_6: 0.108  loss_dice_6: 0.1657  loss_ce_7: 3.452e-05  loss_mask_7: 0.1083  loss_dice_7: 0.1549  loss_ce_8: 3.812e-05  loss_mask_8: 0.1104  loss_dice_8: 0.1628  time: 0.5008  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:21] d2.utils.events INFO:  eta: 0:06:37  iter: 32639  total_loss: 2.895  loss_ce: 2.677e-05  loss_mask: 0.1103  loss_dice: 0.1667  loss_ce_0: 0.1249  loss_mask_0: 0.1092  loss_dice_0: 0.1651  loss_ce_1: 4.268e-05  loss_mask_1: 0.1109  loss_dice_1: 0.1665  loss_ce_2: 5.149e-05  loss_mask_2: 0.1106  loss_dice_2: 0.1672  loss_ce_3: 2.481e-05  loss_mask_3: 0.11  loss_dice_3: 0.1685  loss_ce_4: 3.343e-05  loss_mask_4: 0.1095  loss_dice_4: 0.1645  loss_ce_5: 3.752e-05  loss_mask_5: 0.1098  loss_dice_5: 0.1699  loss_ce_6: 2.353e-05  loss_mask_6: 0.1165  loss_dice_6: 0.1666  loss_ce_7: 3.462e-05  loss_mask_7: 0.1157  loss_dice_7: 0.1703  loss_ce_8: 3.912e-05  loss_mask_8: 0.1113  loss_dice_8: 0.1664  time: 0.5006  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:25] d2.utils.events INFO:  eta: 0:06:34  iter: 32659  total_loss: 2.936  loss_ce: 2.716e-05  loss_mask: 0.1144  loss_dice: 0.1704  loss_ce_0: 0.1242  loss_mask_0: 0.1086  loss_dice_0: 0.1689  loss_ce_1: 4.553e-05  loss_mask_1: 0.1086  loss_dice_1: 0.1653  loss_ce_2: 4.924e-05  loss_mask_2: 0.1166  loss_dice_2: 0.1707  loss_ce_3: 1.939e-05  loss_mask_3: 0.1096  loss_dice_3: 0.1708  loss_ce_4: 3.318e-05  loss_mask_4: 0.1086  loss_dice_4: 0.1658  loss_ce_5: 4.158e-05  loss_mask_5: 0.1083  loss_dice_5: 0.1615  loss_ce_6: 2.141e-05  loss_mask_6: 0.1105  loss_dice_6: 0.1678  loss_ce_7: 3.491e-05  loss_mask_7: 0.108  loss_dice_7: 0.1636  loss_ce_8: 4.169e-05  loss_mask_8: 0.1119  loss_dice_8: 0.1711  time: 0.5004  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:28] d2.utils.events INFO:  eta: 0:06:30  iter: 32679  total_loss: 2.905  loss_ce: 2.694e-05  loss_mask: 0.1091  loss_dice: 0.1693  loss_ce_0: 0.1235  loss_mask_0: 0.111  loss_dice_0: 0.1666  loss_ce_1: 4.04e-05  loss_mask_1: 0.1088  loss_dice_1: 0.1645  loss_ce_2: 4.143e-05  loss_mask_2: 0.1123  loss_dice_2: 0.1641  loss_ce_3: 2.393e-05  loss_mask_3: 0.1114  loss_dice_3: 0.1637  loss_ce_4: 3.034e-05  loss_mask_4: 0.1073  loss_dice_4: 0.1637  loss_ce_5: 3.685e-05  loss_mask_5: 0.1097  loss_dice_5: 0.1656  loss_ce_6: 2.392e-05  loss_mask_6: 0.114  loss_dice_6: 0.1712  loss_ce_7: 3.303e-05  loss_mask_7: 0.1115  loss_dice_7: 0.1689  loss_ce_8: 3.683e-05  loss_mask_8: 0.108  loss_dice_8: 0.1652  time: 0.5002  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:32] d2.utils.events INFO:  eta: 0:06:27  iter: 32699  total_loss: 2.831  loss_ce: 3.003e-05  loss_mask: 0.1025  loss_dice: 0.1681  loss_ce_0: 0.1242  loss_mask_0: 0.1059  loss_dice_0: 0.1646  loss_ce_1: 4.376e-05  loss_mask_1: 0.105  loss_dice_1: 0.1696  loss_ce_2: 4.841e-05  loss_mask_2: 0.1031  loss_dice_2: 0.1674  loss_ce_3: 2.758e-05  loss_mask_3: 0.1034  loss_dice_3: 0.1583  loss_ce_4: 3.21e-05  loss_mask_4: 0.1041  loss_dice_4: 0.1643  loss_ce_5: 3.654e-05  loss_mask_5: 0.105  loss_dice_5: 0.1634  loss_ce_6: 2.657e-05  loss_mask_6: 0.1067  loss_dice_6: 0.1711  loss_ce_7: 3.538e-05  loss_mask_7: 0.1024  loss_dice_7: 0.1655  loss_ce_8: 3.82e-05  loss_mask_8: 0.1069  loss_dice_8: 0.1733  time: 0.5000  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:35] d2.utils.events INFO:  eta: 0:06:24  iter: 32719  total_loss: 2.9  loss_ce: 2.542e-05  loss_mask: 0.115  loss_dice: 0.1658  loss_ce_0: 0.1235  loss_mask_0: 0.1114  loss_dice_0: 0.1638  loss_ce_1: 4.549e-05  loss_mask_1: 0.116  loss_dice_1: 0.1678  loss_ce_2: 4.219e-05  loss_mask_2: 0.1116  loss_dice_2: 0.1636  loss_ce_3: 2.096e-05  loss_mask_3: 0.1141  loss_dice_3: 0.1681  loss_ce_4: 3.165e-05  loss_mask_4: 0.1113  loss_dice_4: 0.1613  loss_ce_5: 3.712e-05  loss_mask_5: 0.1132  loss_dice_5: 0.1609  loss_ce_6: 2.194e-05  loss_mask_6: 0.1135  loss_dice_6: 0.1594  loss_ce_7: 3.327e-05  loss_mask_7: 0.1107  loss_dice_7: 0.1595  loss_ce_8: 3.776e-05  loss_mask_8: 0.1112  loss_dice_8: 0.1632  time: 0.4998  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:38] d2.utils.events INFO:  eta: 0:06:21  iter: 32739  total_loss: 2.878  loss_ce: 2.617e-05  loss_mask: 0.1139  loss_dice: 0.1631  loss_ce_0: 0.1242  loss_mask_0: 0.1127  loss_dice_0: 0.1602  loss_ce_1: 5.349e-05  loss_mask_1: 0.1119  loss_dice_1: 0.1625  loss_ce_2: 4.357e-05  loss_mask_2: 0.108  loss_dice_2: 0.1576  loss_ce_3: 2.234e-05  loss_mask_3: 0.1089  loss_dice_3: 0.1572  loss_ce_4: 3.165e-05  loss_mask_4: 0.1129  loss_dice_4: 0.161  loss_ce_5: 4.467e-05  loss_mask_5: 0.112  loss_dice_5: 0.161  loss_ce_6: 2.296e-05  loss_mask_6: 0.1151  loss_dice_6: 0.154  loss_ce_7: 3.448e-05  loss_mask_7: 0.116  loss_dice_7: 0.1678  loss_ce_8: 5.293e-05  loss_mask_8: 0.1129  loss_dice_8: 0.1551  time: 0.4996  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:42] d2.utils.events INFO:  eta: 0:06:18  iter: 32759  total_loss: 2.86  loss_ce: 2.66e-05  loss_mask: 0.1077  loss_dice: 0.1674  loss_ce_0: 0.1132  loss_mask_0: 0.1099  loss_dice_0: 0.1597  loss_ce_1: 4.696e-05  loss_mask_1: 0.1082  loss_dice_1: 0.1617  loss_ce_2: 5.662e-05  loss_mask_2: 0.1101  loss_dice_2: 0.1614  loss_ce_3: 3.29e-05  loss_mask_3: 0.1104  loss_dice_3: 0.1633  loss_ce_4: 3.346e-05  loss_mask_4: 0.109  loss_dice_4: 0.1616  loss_ce_5: 3.689e-05  loss_mask_5: 0.1101  loss_dice_5: 0.1647  loss_ce_6: 2.6e-05  loss_mask_6: 0.1094  loss_dice_6: 0.1622  loss_ce_7: 3.722e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1639  loss_ce_8: 3.834e-05  loss_mask_8: 0.1091  loss_dice_8: 0.1654  time: 0.4994  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:45] d2.utils.events INFO:  eta: 0:06:14  iter: 32779  total_loss: 2.749  loss_ce: 3.716e-05  loss_mask: 0.1076  loss_dice: 0.1626  loss_ce_0: 0.125  loss_mask_0: 0.1045  loss_dice_0: 0.1678  loss_ce_1: 5.146e-05  loss_mask_1: 0.1077  loss_dice_1: 0.1657  loss_ce_2: 5.182e-05  loss_mask_2: 0.1028  loss_dice_2: 0.1599  loss_ce_3: 3.347e-05  loss_mask_3: 0.1056  loss_dice_3: 0.1613  loss_ce_4: 3.642e-05  loss_mask_4: 0.1003  loss_dice_4: 0.154  loss_ce_5: 4.873e-05  loss_mask_5: 0.1069  loss_dice_5: 0.1527  loss_ce_6: 2.877e-05  loss_mask_6: 0.1058  loss_dice_6: 0.1599  loss_ce_7: 3.955e-05  loss_mask_7: 0.106  loss_dice_7: 0.1615  loss_ce_8: 4.651e-05  loss_mask_8: 0.1038  loss_dice_8: 0.1568  time: 0.4991  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:49] d2.utils.events INFO:  eta: 0:06:11  iter: 32799  total_loss: 2.906  loss_ce: 3.255e-05  loss_mask: 0.1118  loss_dice: 0.166  loss_ce_0: 0.1242  loss_mask_0: 0.1107  loss_dice_0: 0.1702  loss_ce_1: 5.437e-05  loss_mask_1: 0.1132  loss_dice_1: 0.1675  loss_ce_2: 5.352e-05  loss_mask_2: 0.1141  loss_dice_2: 0.1693  loss_ce_3: 3.063e-05  loss_mask_3: 0.1106  loss_dice_3: 0.1662  loss_ce_4: 3.504e-05  loss_mask_4: 0.1179  loss_dice_4: 0.1668  loss_ce_5: 4.579e-05  loss_mask_5: 0.1114  loss_dice_5: 0.1654  loss_ce_6: 2.662e-05  loss_mask_6: 0.1107  loss_dice_6: 0.1639  loss_ce_7: 4.052e-05  loss_mask_7: 0.1066  loss_dice_7: 0.1647  loss_ce_8: 5.093e-05  loss_mask_8: 0.1116  loss_dice_8: 0.169  time: 0.4989  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:52] d2.utils.events INFO:  eta: 0:06:08  iter: 32819  total_loss: 2.843  loss_ce: 2.683e-05  loss_mask: 0.108  loss_dice: 0.1712  loss_ce_0: 0.1236  loss_mask_0: 0.1084  loss_dice_0: 0.164  loss_ce_1: 4.242e-05  loss_mask_1: 0.1126  loss_dice_1: 0.1665  loss_ce_2: 4.322e-05  loss_mask_2: 0.1105  loss_dice_2: 0.1738  loss_ce_3: 1.687e-05  loss_mask_3: 0.1115  loss_dice_3: 0.1698  loss_ce_4: 2.945e-05  loss_mask_4: 0.1038  loss_dice_4: 0.1633  loss_ce_5: 3.662e-05  loss_mask_5: 0.1093  loss_dice_5: 0.1616  loss_ce_6: 2.105e-05  loss_mask_6: 0.1087  loss_dice_6: 0.169  loss_ce_7: 3.355e-05  loss_mask_7: 0.1122  loss_dice_7: 0.1655  loss_ce_8: 3.732e-05  loss_mask_8: 0.1104  loss_dice_8: 0.1627  time: 0.4987  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:55] d2.utils.events INFO:  eta: 0:06:04  iter: 32839  total_loss: 2.838  loss_ce: 2.61e-05  loss_mask: 0.1059  loss_dice: 0.1583  loss_ce_0: 0.1249  loss_mask_0: 0.1076  loss_dice_0: 0.1661  loss_ce_1: 4.451e-05  loss_mask_1: 0.1081  loss_dice_1: 0.1587  loss_ce_2: 4.291e-05  loss_mask_2: 0.1126  loss_dice_2: 0.1635  loss_ce_3: 2.089e-05  loss_mask_3: 0.1129  loss_dice_3: 0.1641  loss_ce_4: 3.026e-05  loss_mask_4: 0.1071  loss_dice_4: 0.1628  loss_ce_5: 4.27e-05  loss_mask_5: 0.1091  loss_dice_5: 0.1659  loss_ce_6: 2.164e-05  loss_mask_6: 0.113  loss_dice_6: 0.1584  loss_ce_7: 3.392e-05  loss_mask_7: 0.1117  loss_dice_7: 0.1622  loss_ce_8: 4.51e-05  loss_mask_8: 0.1104  loss_dice_8: 0.158  time: 0.4985  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:35:59] d2.utils.events INFO:  eta: 0:06:01  iter: 32859  total_loss: 2.838  loss_ce: 2.655e-05  loss_mask: 0.1104  loss_dice: 0.1661  loss_ce_0: 0.1242  loss_mask_0: 0.1091  loss_dice_0: 0.1631  loss_ce_1: 4.111e-05  loss_mask_1: 0.1101  loss_dice_1: 0.1647  loss_ce_2: 4.126e-05  loss_mask_2: 0.1091  loss_dice_2: 0.1636  loss_ce_3: 2.131e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1592  loss_ce_4: 2.864e-05  loss_mask_4: 0.1076  loss_dice_4: 0.1591  loss_ce_5: 3.675e-05  loss_mask_5: 0.1105  loss_dice_5: 0.1615  loss_ce_6: 2.247e-05  loss_mask_6: 0.1111  loss_dice_6: 0.1595  loss_ce_7: 3.215e-05  loss_mask_7: 0.1074  loss_dice_7: 0.1567  loss_ce_8: 3.718e-05  loss_mask_8: 0.1092  loss_dice_8: 0.1636  time: 0.4983  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:36:02] d2.utils.events INFO:  eta: 0:05:58  iter: 32879  total_loss: 2.766  loss_ce: 2.632e-05  loss_mask: 0.1047  loss_dice: 0.16  loss_ce_0: 0.1242  loss_mask_0: 0.1077  loss_dice_0: 0.1637  loss_ce_1: 4.348e-05  loss_mask_1: 0.1049  loss_dice_1: 0.1572  loss_ce_2: 4.228e-05  loss_mask_2: 0.1069  loss_dice_2: 0.1648  loss_ce_3: 2.075e-05  loss_mask_3: 0.1062  loss_dice_3: 0.1578  loss_ce_4: 3.043e-05  loss_mask_4: 0.1045  loss_dice_4: 0.1587  loss_ce_5: 3.675e-05  loss_mask_5: 0.1083  loss_dice_5: 0.1591  loss_ce_6: 2.31e-05  loss_mask_6: 0.1102  loss_dice_6: 0.1681  loss_ce_7: 3.284e-05  loss_mask_7: 0.1092  loss_dice_7: 0.1599  loss_ce_8: 3.791e-05  loss_mask_8: 0.1068  loss_dice_8: 0.1583  time: 0.4981  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:36:06] d2.utils.events INFO:  eta: 0:05:54  iter: 32899  total_loss: 2.837  loss_ce: 2.666e-05  loss_mask: 0.1081  loss_dice: 0.1619  loss_ce_0: 0.1277  loss_mask_0: 0.1102  loss_dice_0: 0.1608  loss_ce_1: 4.727e-05  loss_mask_1: 0.1051  loss_dice_1: 0.1593  loss_ce_2: 4.327e-05  loss_mask_2: 0.1094  loss_dice_2: 0.1635  loss_ce_3: 2.019e-05  loss_mask_3: 0.1074  loss_dice_3: 0.1625  loss_ce_4: 3.166e-05  loss_mask_4: 0.1087  loss_dice_4: 0.1638  loss_ce_5: 4.432e-05  loss_mask_5: 0.1087  loss_dice_5: 0.1602  loss_ce_6: 2.208e-05  loss_mask_6: 0.1074  loss_dice_6: 0.1612  loss_ce_7: 3.527e-05  loss_mask_7: 0.1064  loss_dice_7: 0.1632  loss_ce_8: 4.587e-05  loss_mask_8: 0.1067  loss_dice_8: 0.1632  time: 0.4979  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:36:09] d2.utils.events INFO:  eta: 0:05:51  iter: 32919  total_loss: 2.797  loss_ce: 3.101e-05  loss_mask: 0.105  loss_dice: 0.1574  loss_ce_0: 0.1186  loss_mask_0: 0.1049  loss_dice_0: 0.1586  loss_ce_1: 4.436e-05  loss_mask_1: 0.1058  loss_dice_1: 0.157  loss_ce_2: 5.545e-05  loss_mask_2: 0.1073  loss_dice_2: 0.164  loss_ce_3: 3.652e-05  loss_mask_3: 0.1098  loss_dice_3: 0.1621  loss_ce_4: 3.678e-05  loss_mask_4: 0.1054  loss_dice_4: 0.1557  loss_ce_5: 3.766e-05  loss_mask_5: 0.1059  loss_dice_5: 0.1612  loss_ce_6: 2.792e-05  loss_mask_6: 0.1096  loss_dice_6: 0.1603  loss_ce_7: 3.766e-05  loss_mask_7: 0.1082  loss_dice_7: 0.1565  loss_ce_8: 3.904e-05  loss_mask_8: 0.1046  loss_dice_8: 0.1591  time: 0.4977  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:36:12] d2.utils.events INFO:  eta: 0:05:48  iter: 32939  total_loss: 2.906  loss_ce: 2.618e-05  loss_mask: 0.1112  loss_dice: 0.1677  loss_ce_0: 0.1271  loss_mask_0: 0.1093  loss_dice_0: 0.1617  loss_ce_1: 2.805e-05  loss_mask_1: 0.1109  loss_dice_1: 0.1712  loss_ce_2: 3.184e-05  loss_mask_2: 0.1142  loss_dice_2: 0.1701  loss_ce_3: 1.461e-05  loss_mask_3: 0.1121  loss_dice_3: 0.1673  loss_ce_4: 1.792e-05  loss_mask_4: 0.1091  loss_dice_4: 0.1608  loss_ce_5: 2.249e-05  loss_mask_5: 0.1116  loss_dice_5: 0.1693  loss_ce_6: 1.662e-05  loss_mask_6: 0.1107  loss_dice_6: 0.1652  loss_ce_7: 2.281e-05  loss_mask_7: 0.1132  loss_dice_7: 0.1675  loss_ce_8: 2.739e-05  loss_mask_8: 0.112  loss_dice_8: 0.1727  time: 0.4975  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:36:16] d2.utils.events INFO:  eta: 0:05:45  iter: 32959  total_loss: 2.911  loss_ce: 2.7e-05  loss_mask: 0.1046  loss_dice: 0.1646  loss_ce_0: 0.1237  loss_mask_0: 0.1132  loss_dice_0: 0.1759  loss_ce_1: 4.44e-05  loss_mask_1: 0.1101  loss_dice_1: 0.1626  loss_ce_2: 4.792e-05  loss_mask_2: 0.1068  loss_dice_2: 0.1662  loss_ce_3: 3.27e-05  loss_mask_3: 0.1105  loss_dice_3: 0.172  loss_ce_4: 3.268e-05  loss_mask_4: 0.1122  loss_dice_4: 0.1681  loss_ce_5: 3.643e-05  loss_mask_5: 0.112  loss_dice_5: 0.1667  loss_ce_6: 2.534e-05  loss_mask_6: 0.1086  loss_dice_6: 0.1696  loss_ce_7: 3.189e-05  loss_mask_7: 0.1094  loss_dice_7: 0.1733  loss_ce_8: 3.723e-05  loss_mask_8: 0.1102  loss_dice_8: 0.1758  time: 0.4973  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:36:19] d2.utils.events INFO:  eta: 0:05:41  iter: 32979  total_loss: 2.835  loss_ce: 2.969e-05  loss_mask: 0.1061  loss_dice: 0.1616  loss_ce_0: 0.1236  loss_mask_0: 0.1095  loss_dice_0: 0.168  loss_ce_1: 4.169e-05  loss_mask_1: 0.112  loss_dice_1: 0.1651  loss_ce_2: 4.264e-05  loss_mask_2: 0.1091  loss_dice_2: 0.1596  loss_ce_3: 2.474e-05  loss_mask_3: 0.1164  loss_dice_3: 0.1656  loss_ce_4: 3.005e-05  loss_mask_4: 0.11  loss_dice_4: 0.1631  loss_ce_5: 3.691e-05  loss_mask_5: 0.1114  loss_dice_5: 0.1628  loss_ce_6: 2.582e-05  loss_mask_6: 0.1146  loss_dice_6: 0.1603  loss_ce_7: 3.238e-05  loss_mask_7: 0.1052  loss_dice_7: 0.1575  loss_ce_8: 3.802e-05  loss_mask_8: 0.111  loss_dice_8: 0.1597  time: 0.4971  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:36:23] d2.utils.events INFO:  eta: 0:05:38  iter: 32999  total_loss: 2.775  loss_ce: 2.663e-05  loss_mask: 0.1078  loss_dice: 0.1556  loss_ce_0: 0.1242  loss_mask_0: 0.1072  loss_dice_0: 0.1642  loss_ce_1: 4.901e-05  loss_mask_1: 0.1103  loss_dice_1: 0.1608  loss_ce_2: 4.23e-05  loss_mask_2: 0.1052  loss_dice_2: 0.1575  loss_ce_3: 2.142e-05  loss_mask_3: 0.1083  loss_dice_3: 0.1638  loss_ce_4: 3.287e-05  loss_mask_4: 0.1072  loss_dice_4: 0.1601  loss_ce_5: 4.338e-05  loss_mask_5: 0.1076  loss_dice_5: 0.1584  loss_ce_6: 2.298e-05  loss_mask_6: 0.1091  loss_dice_6: 0.1579  loss_ce_7: 3.549e-05  loss_mask_7: 0.1106  loss_dice_7: 0.1614  loss_ce_8: 4.567e-05  loss_mask_8: 0.1101  loss_dice_8: 0.1606  time: 0.4969  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:36:26] d2.utils.events INFO:  eta: 0:05:34  iter: 33019  total_loss: 2.836  loss_ce: 2.583e-05  loss_mask: 0.109  loss_dice: 0.1633  loss_ce_0: 0.1237  loss_mask_0: 0.1091  loss_dice_0: 0.159  loss_ce_1: 4.509e-05  loss_mask_1: 0.1088  loss_dice_1: 0.1627  loss_ce_2: 4.896e-05  loss_mask_2: 0.1089  loss_dice_2: 0.1619  loss_ce_3: 2.296e-05  loss_mask_3: 0.1079  loss_dice_3: 0.1626  loss_ce_4: 3.169e-05  loss_mask_4: 0.1089  loss_dice_4: 0.1619  loss_ce_5: 4.058e-05  loss_mask_5: 0.1098  loss_dice_5: 0.159  loss_ce_6: 2.293e-05  loss_mask_6: 0.1085  loss_dice_6: 0.162  loss_ce_7: 3.426e-05  loss_mask_7: 0.109  loss_dice_7: 0.1631  loss_ce_8: 4.155e-05  loss_mask_8: 0.1111  loss_dice_8: 0.1597  time: 0.4967  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:36:29] d2.utils.events INFO:  eta: 0:05:31  iter: 33039  total_loss: 2.92  loss_ce: 2.623e-05  loss_mask: 0.1095  loss_dice: 0.1664  loss_ce_0: 0.1236  loss_mask_0: 0.1082  loss_dice_0: 0.1674  loss_ce_1: 5.127e-05  loss_mask_1: 0.1102  loss_dice_1: 0.1672  loss_ce_2: 4.293e-05  loss_mask_2: 0.1104  loss_dice_2: 0.1685  loss_ce_3: 2.216e-05  loss_mask_3: 0.1078  loss_dice_3: 0.1691  loss_ce_4: 3.209e-05  loss_mask_4: 0.1102  loss_dice_4: 0.1607  loss_ce_5: 3.81e-05  loss_mask_5: 0.1077  loss_dice_5: 0.1654  loss_ce_6: 2.266e-05  loss_mask_6: 0.1068  loss_dice_6: 0.1672  loss_ce_7: 3.611e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1671  loss_ce_8: 3.997e-05  loss_mask_8: 0.1074  loss_dice_8: 0.1672  time: 0.4965  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:36:33] d2.utils.events INFO:  eta: 0:05:27  iter: 33059  total_loss: 2.78  loss_ce: 3.034e-05  loss_mask: 0.1058  loss_dice: 0.1611  loss_ce_0: 0.1236  loss_mask_0: 0.107  loss_dice_0: 0.171  loss_ce_1: 4.413e-05  loss_mask_1: 0.1058  loss_dice_1: 0.1673  loss_ce_2: 5.366e-05  loss_mask_2: 0.1048  loss_dice_2: 0.1657  loss_ce_3: 3.234e-05  loss_mask_3: 0.1115  loss_dice_3: 0.1646  loss_ce_4: 3.274e-05  loss_mask_4: 0.1104  loss_dice_4: 0.1621  loss_ce_5: 3.655e-05  loss_mask_5: 0.1043  loss_dice_5: 0.1669  loss_ce_6: 2.606e-05  loss_mask_6: 0.1059  loss_dice_6: 0.1603  loss_ce_7: 3.733e-05  loss_mask_7: 0.1089  loss_dice_7: 0.1675  loss_ce_8: 3.838e-05  loss_mask_8: 0.1064  loss_dice_8: 0.1651  time: 0.4963  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:36:36] d2.utils.events INFO:  eta: 0:05:24  iter: 33079  total_loss: 2.879  loss_ce: 2.58e-05  loss_mask: 0.1059  loss_dice: 0.1653  loss_ce_0: 0.1242  loss_mask_0: 0.1109  loss_dice_0: 0.1681  loss_ce_1: 4.579e-05  loss_mask_1: 0.1088  loss_dice_1: 0.1658  loss_ce_2: 4.259e-05  loss_mask_2: 0.1098  loss_dice_2: 0.1656  loss_ce_3: 1.928e-05  loss_mask_3: 0.107  loss_dice_3: 0.1665  loss_ce_4: 3.041e-05  loss_mask_4: 0.1104  loss_dice_4: 0.1619  loss_ce_5: 3.983e-05  loss_mask_5: 0.1086  loss_dice_5: 0.1638  loss_ce_6: 2.122e-05  loss_mask_6: 0.1094  loss_dice_6: 0.1677  loss_ce_7: 3.145e-05  loss_mask_7: 0.1071  loss_dice_7: 0.1644  loss_ce_8: 4.108e-05  loss_mask_8: 0.1093  loss_dice_8: 0.169  time: 0.4962  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:36:39] d2.utils.events INFO:  eta: 0:05:21  iter: 33099  total_loss: 2.862  loss_ce: 2.666e-05  loss_mask: 0.103  loss_dice: 0.1682  loss_ce_0: 0.1242  loss_mask_0: 0.1077  loss_dice_0: 0.1677  loss_ce_1: 3.221e-05  loss_mask_1: 0.105  loss_dice_1: 0.1673  loss_ce_2: 3.241e-05  loss_mask_2: 0.1075  loss_dice_2: 0.1707  loss_ce_3: 1.76e-05  loss_mask_3: 0.1042  loss_dice_3: 0.162  loss_ce_4: 1.843e-05  loss_mask_4: 0.1062  loss_dice_4: 0.1656  loss_ce_5: 2.358e-05  loss_mask_5: 0.1029  loss_dice_5: 0.1669  loss_ce_6: 1.824e-05  loss_mask_6: 0.1047  loss_dice_6: 0.1646  loss_ce_7: 2.555e-05  loss_mask_7: 0.107  loss_dice_7: 0.1699  loss_ce_8: 2.739e-05  loss_mask_8: 0.1023  loss_dice_8: 0.1663  time: 0.4960  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:36:43] d2.utils.events INFO:  eta: 0:05:17  iter: 33119  total_loss: 2.968  loss_ce: 2.693e-05  loss_mask: 0.1105  loss_dice: 0.1706  loss_ce_0: 0.1185  loss_mask_0: 0.1122  loss_dice_0: 0.1756  loss_ce_1: 4.227e-05  loss_mask_1: 0.1105  loss_dice_1: 0.174  loss_ce_2: 5.342e-05  loss_mask_2: 0.1105  loss_dice_2: 0.1738  loss_ce_3: 3.167e-05  loss_mask_3: 0.1125  loss_dice_3: 0.1692  loss_ce_4: 3.334e-05  loss_mask_4: 0.1107  loss_dice_4: 0.1698  loss_ce_5: 3.998e-05  loss_mask_5: 0.111  loss_dice_5: 0.1723  loss_ce_6: 2.576e-05  loss_mask_6: 0.1115  loss_dice_6: 0.1693  loss_ce_7: 3.369e-05  loss_mask_7: 0.1099  loss_dice_7: 0.1722  loss_ce_8: 4.136e-05  loss_mask_8: 0.1125  loss_dice_8: 0.1754  time: 0.4958  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:36:46] d2.utils.events INFO:  eta: 0:05:14  iter: 33139  total_loss: 2.764  loss_ce: 3.193e-05  loss_mask: 0.1077  loss_dice: 0.1585  loss_ce_0: 0.1242  loss_mask_0: 0.1048  loss_dice_0: 0.1592  loss_ce_1: 4.486e-05  loss_mask_1: 0.1051  loss_dice_1: 0.161  loss_ce_2: 4.71e-05  loss_mask_2: 0.1055  loss_dice_2: 0.1593  loss_ce_3: 2.98e-05  loss_mask_3: 0.1079  loss_dice_3: 0.1601  loss_ce_4: 3.226e-05  loss_mask_4: 0.1051  loss_dice_4: 0.1533  loss_ce_5: 4.256e-05  loss_mask_5: 0.1068  loss_dice_5: 0.1593  loss_ce_6: 2.732e-05  loss_mask_6: 0.108  loss_dice_6: 0.1617  loss_ce_7: 3.582e-05  loss_mask_7: 0.108  loss_dice_7: 0.1567  loss_ce_8: 4.673e-05  loss_mask_8: 0.1079  loss_dice_8: 0.1581  time: 0.4956  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:36:50] d2.utils.events INFO:  eta: 0:05:11  iter: 33159  total_loss: 2.783  loss_ce: 2.597e-05  loss_mask: 0.1109  loss_dice: 0.1568  loss_ce_0: 0.1277  loss_mask_0: 0.108  loss_dice_0: 0.1601  loss_ce_1: 4.452e-05  loss_mask_1: 0.1075  loss_dice_1: 0.1585  loss_ce_2: 4.237e-05  loss_mask_2: 0.1074  loss_dice_2: 0.1593  loss_ce_3: 2.077e-05  loss_mask_3: 0.1081  loss_dice_3: 0.1567  loss_ce_4: 3.026e-05  loss_mask_4: 0.1089  loss_dice_4: 0.1559  loss_ce_5: 3.679e-05  loss_mask_5: 0.1087  loss_dice_5: 0.1549  loss_ce_6: 2.185e-05  loss_mask_6: 0.1084  loss_dice_6: 0.1596  loss_ce_7: 3.352e-05  loss_mask_7: 0.1084  loss_dice_7: 0.1539  loss_ce_8: 3.768e-05  loss_mask_8: 0.1107  loss_dice_8: 0.1634  time: 0.4954  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:36:53] d2.utils.events INFO:  eta: 0:05:07  iter: 33179  total_loss: 2.906  loss_ce: 2.566e-05  loss_mask: 0.1121  loss_dice: 0.1689  loss_ce_0: 0.1242  loss_mask_0: 0.1094  loss_dice_0: 0.1594  loss_ce_1: 4.449e-05  loss_mask_1: 0.1096  loss_dice_1: 0.1647  loss_ce_2: 4.135e-05  loss_mask_2: 0.1118  loss_dice_2: 0.1654  loss_ce_3: 2.155e-05  loss_mask_3: 0.1129  loss_dice_3: 0.1675  loss_ce_4: 3.107e-05  loss_mask_4: 0.1129  loss_dice_4: 0.168  loss_ce_5: 3.64e-05  loss_mask_5: 0.111  loss_dice_5: 0.1619  loss_ce_6: 2.238e-05  loss_mask_6: 0.112  loss_dice_6: 0.1616  loss_ce_7: 3.401e-05  loss_mask_7: 0.1102  loss_dice_7: 0.1662  loss_ce_8: 3.85e-05  loss_mask_8: 0.1083  loss_dice_8: 0.1636  time: 0.4952  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:36:56] d2.utils.events INFO:  eta: 0:05:04  iter: 33199  total_loss: 2.884  loss_ce: 2.711e-05  loss_mask: 0.1118  loss_dice: 0.1627  loss_ce_0: 0.1247  loss_mask_0: 0.1113  loss_dice_0: 0.1637  loss_ce_1: 4.36e-05  loss_mask_1: 0.1112  loss_dice_1: 0.1584  loss_ce_2: 4.344e-05  loss_mask_2: 0.1113  loss_dice_2: 0.1697  loss_ce_3: 2.18e-05  loss_mask_3: 0.1119  loss_dice_3: 0.1637  loss_ce_4: 3.261e-05  loss_mask_4: 0.1066  loss_dice_4: 0.1609  loss_ce_5: 4.027e-05  loss_mask_5: 0.1081  loss_dice_5: 0.1611  loss_ce_6: 2.34e-05  loss_mask_6: 0.1095  loss_dice_6: 0.1651  loss_ce_7: 3.56e-05  loss_mask_7: 0.1146  loss_dice_7: 0.1637  loss_ce_8: 4.147e-05  loss_mask_8: 0.1069  loss_dice_8: 0.1597  time: 0.4950  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:00] d2.utils.events INFO:  eta: 0:05:00  iter: 33219  total_loss: 2.826  loss_ce: 2.75e-05  loss_mask: 0.1093  loss_dice: 0.1594  loss_ce_0: 0.1246  loss_mask_0: 0.1085  loss_dice_0: 0.158  loss_ce_1: 4.897e-05  loss_mask_1: 0.108  loss_dice_1: 0.1606  loss_ce_2: 4.741e-05  loss_mask_2: 0.1089  loss_dice_2: 0.1605  loss_ce_3: 2.376e-05  loss_mask_3: 0.1071  loss_dice_3: 0.1649  loss_ce_4: 3.444e-05  loss_mask_4: 0.1035  loss_dice_4: 0.1585  loss_ce_5: 4.86e-05  loss_mask_5: 0.1071  loss_dice_5: 0.1591  loss_ce_6: 2.311e-05  loss_mask_6: 0.1077  loss_dice_6: 0.1609  loss_ce_7: 3.788e-05  loss_mask_7: 0.1077  loss_dice_7: 0.1621  loss_ce_8: 4.664e-05  loss_mask_8: 0.1093  loss_dice_8: 0.1643  time: 0.4948  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:03] d2.utils.events INFO:  eta: 0:04:57  iter: 33239  total_loss: 2.816  loss_ce: 2.632e-05  loss_mask: 0.1103  loss_dice: 0.1598  loss_ce_0: 0.1238  loss_mask_0: 0.1114  loss_dice_0: 0.172  loss_ce_1: 3.963e-05  loss_mask_1: 0.113  loss_dice_1: 0.1622  loss_ce_2: 4.683e-05  loss_mask_2: 0.1127  loss_dice_2: 0.1603  loss_ce_3: 2.2e-05  loss_mask_3: 0.1109  loss_dice_3: 0.1608  loss_ce_4: 3.136e-05  loss_mask_4: 0.1122  loss_dice_4: 0.1584  loss_ce_5: 4.071e-05  loss_mask_5: 0.1128  loss_dice_5: 0.1669  loss_ce_6: 2.252e-05  loss_mask_6: 0.1109  loss_dice_6: 0.1614  loss_ce_7: 3.567e-05  loss_mask_7: 0.1139  loss_dice_7: 0.1572  loss_ce_8: 4.11e-05  loss_mask_8: 0.1068  loss_dice_8: 0.1556  time: 0.4946  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:37:06] d2.utils.events INFO:  eta: 0:04:53  iter: 33259  total_loss: 3.059  loss_ce: 2.562e-05  loss_mask: 0.1111  loss_dice: 0.1651  loss_ce_0: 0.1237  loss_mask_0: 0.1213  loss_dice_0: 0.184  loss_ce_1: 3.405e-05  loss_mask_1: 0.1158  loss_dice_1: 0.1747  loss_ce_2: 3.783e-05  loss_mask_2: 0.1133  loss_dice_2: 0.1703  loss_ce_3: 2.118e-05  loss_mask_3: 0.1121  loss_dice_3: 0.167  loss_ce_4: 2.649e-05  loss_mask_4: 0.1169  loss_dice_4: 0.1702  loss_ce_5: 2.928e-05  loss_mask_5: 0.1092  loss_dice_5: 0.1666  loss_ce_6: 2.181e-05  loss_mask_6: 0.1175  loss_dice_6: 0.1739  loss_ce_7: 2.959e-05  loss_mask_7: 0.1103  loss_dice_7: 0.1727  loss_ce_8: 3.19e-05  loss_mask_8: 0.1147  loss_dice_8: 0.1735  time: 0.4944  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:10] d2.utils.events INFO:  eta: 0:04:50  iter: 33279  total_loss: 2.825  loss_ce: 2.594e-05  loss_mask: 0.1118  loss_dice: 0.163  loss_ce_0: 0.1242  loss_mask_0: 0.1076  loss_dice_0: 0.1567  loss_ce_1: 3.109e-05  loss_mask_1: 0.1132  loss_dice_1: 0.1623  loss_ce_2: 3.193e-05  loss_mask_2: 0.1084  loss_dice_2: 0.1611  loss_ce_3: 1.504e-05  loss_mask_3: 0.1067  loss_dice_3: 0.1558  loss_ce_4: 1.76e-05  loss_mask_4: 0.1082  loss_dice_4: 0.1621  loss_ce_5: 2.225e-05  loss_mask_5: 0.1077  loss_dice_5: 0.1577  loss_ce_6: 1.905e-05  loss_mask_6: 0.1077  loss_dice_6: 0.1504  loss_ce_7: 2.479e-05  loss_mask_7: 0.11  loss_dice_7: 0.1548  loss_ce_8: 2.678e-05  loss_mask_8: 0.1126  loss_dice_8: 0.1615  time: 0.4942  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:13] d2.utils.events INFO:  eta: 0:04:47  iter: 33299  total_loss: 2.76  loss_ce: 2.979e-05  loss_mask: 0.1053  loss_dice: 0.1589  loss_ce_0: 0.1245  loss_mask_0: 0.1035  loss_dice_0: 0.1594  loss_ce_1: 4.576e-05  loss_mask_1: 0.1046  loss_dice_1: 0.1623  loss_ce_2: 5.15e-05  loss_mask_2: 0.1008  loss_dice_2: 0.1584  loss_ce_3: 2.401e-05  loss_mask_3: 0.1045  loss_dice_3: 0.1573  loss_ce_4: 3.289e-05  loss_mask_4: 0.1068  loss_dice_4: 0.158  loss_ce_5: 5.269e-05  loss_mask_5: 0.105  loss_dice_5: 0.1585  loss_ce_6: 2.448e-05  loss_mask_6: 0.1058  loss_dice_6: 0.1619  loss_ce_7: 3.848e-05  loss_mask_7: 0.103  loss_dice_7: 0.1583  loss_ce_8: 4.662e-05  loss_mask_8: 0.1045  loss_dice_8: 0.1625  time: 0.4940  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:16] d2.utils.events INFO:  eta: 0:04:43  iter: 33319  total_loss: 2.774  loss_ce: 2.716e-05  loss_mask: 0.1106  loss_dice: 0.1664  loss_ce_0: 0.1238  loss_mask_0: 0.1086  loss_dice_0: 0.1563  loss_ce_1: 3.838e-05  loss_mask_1: 0.105  loss_dice_1: 0.1652  loss_ce_2: 4.609e-05  loss_mask_2: 0.1058  loss_dice_2: 0.1592  loss_ce_3: 2.789e-05  loss_mask_3: 0.1069  loss_dice_3: 0.1609  loss_ce_4: 3.153e-05  loss_mask_4: 0.1046  loss_dice_4: 0.1512  loss_ce_5: 3.583e-05  loss_mask_5: 0.1059  loss_dice_5: 0.1593  loss_ce_6: 2.523e-05  loss_mask_6: 0.1058  loss_dice_6: 0.1629  loss_ce_7: 3.23e-05  loss_mask_7: 0.102  loss_dice_7: 0.1543  loss_ce_8: 3.675e-05  loss_mask_8: 0.107  loss_dice_8: 0.1605  time: 0.4938  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:20] d2.utils.events INFO:  eta: 0:04:40  iter: 33339  total_loss: 2.783  loss_ce: 2.978e-05  loss_mask: 0.109  loss_dice: 0.1608  loss_ce_0: 0.1241  loss_mask_0: 0.106  loss_dice_0: 0.1622  loss_ce_1: 4.291e-05  loss_mask_1: 0.1064  loss_dice_1: 0.1598  loss_ce_2: 5.435e-05  loss_mask_2: 0.1129  loss_dice_2: 0.164  loss_ce_3: 2.901e-05  loss_mask_3: 0.1086  loss_dice_3: 0.1643  loss_ce_4: 3.401e-05  loss_mask_4: 0.1102  loss_dice_4: 0.1587  loss_ce_5: 3.704e-05  loss_mask_5: 0.1072  loss_dice_5: 0.1564  loss_ce_6: 2.54e-05  loss_mask_6: 0.1098  loss_dice_6: 0.1582  loss_ce_7: 3.447e-05  loss_mask_7: 0.1067  loss_dice_7: 0.159  loss_ce_8: 3.874e-05  loss_mask_8: 0.1079  loss_dice_8: 0.161  time: 0.4936  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:23] d2.utils.events INFO:  eta: 0:04:36  iter: 33359  total_loss: 2.856  loss_ce: 2.632e-05  loss_mask: 0.1084  loss_dice: 0.17  loss_ce_0: 0.1244  loss_mask_0: 0.1026  loss_dice_0: 0.162  loss_ce_1: 4.017e-05  loss_mask_1: 0.1081  loss_dice_1: 0.1658  loss_ce_2: 4.14e-05  loss_mask_2: 0.1052  loss_dice_2: 0.1656  loss_ce_3: 1.986e-05  loss_mask_3: 0.1065  loss_dice_3: 0.161  loss_ce_4: 3.031e-05  loss_mask_4: 0.1086  loss_dice_4: 0.1685  loss_ce_5: 3.65e-05  loss_mask_5: 0.109  loss_dice_5: 0.1668  loss_ce_6: 2.106e-05  loss_mask_6: 0.1063  loss_dice_6: 0.1646  loss_ce_7: 3.214e-05  loss_mask_7: 0.1051  loss_dice_7: 0.1632  loss_ce_8: 3.742e-05  loss_mask_8: 0.1057  loss_dice_8: 0.1626  time: 0.4934  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:37:26] d2.utils.events INFO:  eta: 0:04:33  iter: 33379  total_loss: 2.946  loss_ce: 2.662e-05  loss_mask: 0.1128  loss_dice: 0.1722  loss_ce_0: 0.1238  loss_mask_0: 0.1102  loss_dice_0: 0.1711  loss_ce_1: 4.328e-05  loss_mask_1: 0.1084  loss_dice_1: 0.1638  loss_ce_2: 4.679e-05  loss_mask_2: 0.1106  loss_dice_2: 0.1759  loss_ce_3: 1.954e-05  loss_mask_3: 0.1139  loss_dice_3: 0.1689  loss_ce_4: 3.206e-05  loss_mask_4: 0.1108  loss_dice_4: 0.1707  loss_ce_5: 3.633e-05  loss_mask_5: 0.1148  loss_dice_5: 0.1774  loss_ce_6: 2.181e-05  loss_mask_6: 0.1153  loss_dice_6: 0.1681  loss_ce_7: 3.303e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1685  loss_ce_8: 3.814e-05  loss_mask_8: 0.1127  loss_dice_8: 0.1706  time: 0.4932  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:30] d2.utils.events INFO:  eta: 0:04:30  iter: 33399  total_loss: 2.81  loss_ce: 2.573e-05  loss_mask: 0.1065  loss_dice: 0.1633  loss_ce_0: 0.1274  loss_mask_0: 0.1035  loss_dice_0: 0.1595  loss_ce_1: 4.524e-05  loss_mask_1: 0.1074  loss_dice_1: 0.1688  loss_ce_2: 4.098e-05  loss_mask_2: 0.1028  loss_dice_2: 0.1624  loss_ce_3: 1.937e-05  loss_mask_3: 0.1058  loss_dice_3: 0.1621  loss_ce_4: 2.996e-05  loss_mask_4: 0.1033  loss_dice_4: 0.1592  loss_ce_5: 4.239e-05  loss_mask_5: 0.106  loss_dice_5: 0.1599  loss_ce_6: 2.083e-05  loss_mask_6: 0.1083  loss_dice_6: 0.1623  loss_ce_7: 3.045e-05  loss_mask_7: 0.1045  loss_dice_7: 0.163  loss_ce_8: 4.707e-05  loss_mask_8: 0.1032  loss_dice_8: 0.1616  time: 0.4930  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:37:33] d2.utils.events INFO:  eta: 0:04:26  iter: 33419  total_loss: 2.909  loss_ce: 2.537e-05  loss_mask: 0.1113  loss_dice: 0.1675  loss_ce_0: 0.1238  loss_mask_0: 0.1113  loss_dice_0: 0.1612  loss_ce_1: 4.646e-05  loss_mask_1: 0.1146  loss_dice_1: 0.1677  loss_ce_2: 4.233e-05  loss_mask_2: 0.1172  loss_dice_2: 0.168  loss_ce_3: 1.76e-05  loss_mask_3: 0.1133  loss_dice_3: 0.167  loss_ce_4: 3.083e-05  loss_mask_4: 0.1124  loss_dice_4: 0.1614  loss_ce_5: 3.69e-05  loss_mask_5: 0.1132  loss_dice_5: 0.1641  loss_ce_6: 2.053e-05  loss_mask_6: 0.1158  loss_dice_6: 0.1672  loss_ce_7: 3.438e-05  loss_mask_7: 0.115  loss_dice_7: 0.1626  loss_ce_8: 3.811e-05  loss_mask_8: 0.115  loss_dice_8: 0.1687  time: 0.4928  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:37] d2.utils.events INFO:  eta: 0:04:23  iter: 33439  total_loss: 2.84  loss_ce: 2.836e-05  loss_mask: 0.109  loss_dice: 0.1625  loss_ce_0: 0.1241  loss_mask_0: 0.1115  loss_dice_0: 0.1702  loss_ce_1: 4.121e-05  loss_mask_1: 0.1104  loss_dice_1: 0.1683  loss_ce_2: 4.102e-05  loss_mask_2: 0.1104  loss_dice_2: 0.1632  loss_ce_3: 2.437e-05  loss_mask_3: 0.1091  loss_dice_3: 0.1652  loss_ce_4: 3.149e-05  loss_mask_4: 0.1112  loss_dice_4: 0.1582  loss_ce_5: 3.977e-05  loss_mask_5: 0.1119  loss_dice_5: 0.1577  loss_ce_6: 2.587e-05  loss_mask_6: 0.113  loss_dice_6: 0.1688  loss_ce_7: 3.406e-05  loss_mask_7: 0.112  loss_dice_7: 0.1602  loss_ce_8: 4.113e-05  loss_mask_8: 0.1106  loss_dice_8: 0.161  time: 0.4926  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:37:40] d2.utils.events INFO:  eta: 0:04:19  iter: 33459  total_loss: 2.957  loss_ce: 2.617e-05  loss_mask: 0.1125  loss_dice: 0.169  loss_ce_0: 0.1238  loss_mask_0: 0.1128  loss_dice_0: 0.1765  loss_ce_1: 4.433e-05  loss_mask_1: 0.1136  loss_dice_1: 0.1728  loss_ce_2: 4.214e-05  loss_mask_2: 0.118  loss_dice_2: 0.1755  loss_ce_3: 2.196e-05  loss_mask_3: 0.1131  loss_dice_3: 0.1703  loss_ce_4: 3.079e-05  loss_mask_4: 0.1105  loss_dice_4: 0.1635  loss_ce_5: 3.975e-05  loss_mask_5: 0.1132  loss_dice_5: 0.1683  loss_ce_6: 2.235e-05  loss_mask_6: 0.1136  loss_dice_6: 0.1746  loss_ce_7: 3.299e-05  loss_mask_7: 0.1118  loss_dice_7: 0.1671  loss_ce_8: 4.101e-05  loss_mask_8: 0.1121  loss_dice_8: 0.1726  time: 0.4924  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:43] d2.utils.events INFO:  eta: 0:04:16  iter: 33479  total_loss: 2.738  loss_ce: 2.667e-05  loss_mask: 0.1076  loss_dice: 0.1577  loss_ce_0: 0.1238  loss_mask_0: 0.1069  loss_dice_0: 0.1558  loss_ce_1: 4.122e-05  loss_mask_1: 0.1052  loss_dice_1: 0.1574  loss_ce_2: 4.209e-05  loss_mask_2: 0.1082  loss_dice_2: 0.156  loss_ce_3: 2.095e-05  loss_mask_3: 0.1054  loss_dice_3: 0.1562  loss_ce_4: 3.205e-05  loss_mask_4: 0.1053  loss_dice_4: 0.1548  loss_ce_5: 3.637e-05  loss_mask_5: 0.1069  loss_dice_5: 0.1568  loss_ce_6: 2.185e-05  loss_mask_6: 0.1108  loss_dice_6: 0.1557  loss_ce_7: 3.35e-05  loss_mask_7: 0.1075  loss_dice_7: 0.1554  loss_ce_8: 3.753e-05  loss_mask_8: 0.1072  loss_dice_8: 0.1587  time: 0.4922  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:47] d2.utils.events INFO:  eta: 0:04:13  iter: 33499  total_loss: 2.81  loss_ce: 2.568e-05  loss_mask: 0.1083  loss_dice: 0.1597  loss_ce_0: 0.1238  loss_mask_0: 0.1073  loss_dice_0: 0.1661  loss_ce_1: 4.224e-05  loss_mask_1: 0.1085  loss_dice_1: 0.1601  loss_ce_2: 4.265e-05  loss_mask_2: 0.1037  loss_dice_2: 0.1591  loss_ce_3: 1.728e-05  loss_mask_3: 0.1095  loss_dice_3: 0.165  loss_ce_4: 3.052e-05  loss_mask_4: 0.107  loss_dice_4: 0.1663  loss_ce_5: 3.646e-05  loss_mask_5: 0.1066  loss_dice_5: 0.1581  loss_ce_6: 2.034e-05  loss_mask_6: 0.11  loss_dice_6: 0.1703  loss_ce_7: 3.302e-05  loss_mask_7: 0.1104  loss_dice_7: 0.1583  loss_ce_8: 3.841e-05  loss_mask_8: 0.1104  loss_dice_8: 0.1713  time: 0.4920  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:50] d2.utils.events INFO:  eta: 0:04:09  iter: 33519  total_loss: 2.923  loss_ce: 2.666e-05  loss_mask: 0.1154  loss_dice: 0.1714  loss_ce_0: 0.1186  loss_mask_0: 0.1107  loss_dice_0: 0.1681  loss_ce_1: 5.102e-05  loss_mask_1: 0.1093  loss_dice_1: 0.164  loss_ce_2: 5.508e-05  loss_mask_2: 0.1124  loss_dice_2: 0.1697  loss_ce_3: 2.87e-05  loss_mask_3: 0.1103  loss_dice_3: 0.1677  loss_ce_4: 3.283e-05  loss_mask_4: 0.1097  loss_dice_4: 0.1633  loss_ce_5: 4.387e-05  loss_mask_5: 0.1135  loss_dice_5: 0.17  loss_ce_6: 2.555e-05  loss_mask_6: 0.1147  loss_dice_6: 0.1718  loss_ce_7: 3.435e-05  loss_mask_7: 0.113  loss_dice_7: 0.1736  loss_ce_8: 4.837e-05  loss_mask_8: 0.1167  loss_dice_8: 0.1691  time: 0.4918  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:53] d2.utils.events INFO:  eta: 0:04:06  iter: 33539  total_loss: 2.906  loss_ce: 2.408e-05  loss_mask: 0.1182  loss_dice: 0.1714  loss_ce_0: 0.1237  loss_mask_0: 0.1107  loss_dice_0: 0.1662  loss_ce_1: 3.328e-05  loss_mask_1: 0.1156  loss_dice_1: 0.167  loss_ce_2: 2.83e-05  loss_mask_2: 0.1075  loss_dice_2: 0.1674  loss_ce_3: 1.518e-05  loss_mask_3: 0.1132  loss_dice_3: 0.1662  loss_ce_4: 1.61e-05  loss_mask_4: 0.1098  loss_dice_4: 0.1624  loss_ce_5: 2.196e-05  loss_mask_5: 0.1151  loss_dice_5: 0.1645  loss_ce_6: 1.615e-05  loss_mask_6: 0.1079  loss_dice_6: 0.1629  loss_ce_7: 2.089e-05  loss_mask_7: 0.1155  loss_dice_7: 0.1695  loss_ce_8: 2.639e-05  loss_mask_8: 0.1125  loss_dice_8: 0.1681  time: 0.4916  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:37:57] d2.utils.events INFO:  eta: 0:04:03  iter: 33559  total_loss: 2.797  loss_ce: 2.649e-05  loss_mask: 0.106  loss_dice: 0.1561  loss_ce_0: 0.1133  loss_mask_0: 0.1075  loss_dice_0: 0.1621  loss_ce_1: 4.384e-05  loss_mask_1: 0.1097  loss_dice_1: 0.1598  loss_ce_2: 5.521e-05  loss_mask_2: 0.1054  loss_dice_2: 0.1588  loss_ce_3: 2.712e-05  loss_mask_3: 0.1047  loss_dice_3: 0.1613  loss_ce_4: 3.297e-05  loss_mask_4: 0.1074  loss_dice_4: 0.1588  loss_ce_5: 3.665e-05  loss_mask_5: 0.1055  loss_dice_5: 0.1636  loss_ce_6: 2.403e-05  loss_mask_6: 0.1051  loss_dice_6: 0.1561  loss_ce_7: 3.433e-05  loss_mask_7: 0.1069  loss_dice_7: 0.1626  loss_ce_8: 3.784e-05  loss_mask_8: 0.105  loss_dice_8: 0.1558  time: 0.4914  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:38:00] d2.utils.events INFO:  eta: 0:03:59  iter: 33579  total_loss: 2.822  loss_ce: 2.597e-05  loss_mask: 0.1087  loss_dice: 0.1634  loss_ce_0: 0.1242  loss_mask_0: 0.1091  loss_dice_0: 0.1602  loss_ce_1: 3.717e-05  loss_mask_1: 0.1075  loss_dice_1: 0.1605  loss_ce_2: 3.685e-05  loss_mask_2: 0.1103  loss_dice_2: 0.1642  loss_ce_3: 2.125e-05  loss_mask_3: 0.1061  loss_dice_3: 0.1609  loss_ce_4: 2.441e-05  loss_mask_4: 0.1066  loss_dice_4: 0.1623  loss_ce_5: 2.921e-05  loss_mask_5: 0.1101  loss_dice_5: 0.1632  loss_ce_6: 2.256e-05  loss_mask_6: 0.1065  loss_dice_6: 0.1638  loss_ce_7: 2.893e-05  loss_mask_7: 0.1104  loss_dice_7: 0.1634  loss_ce_8: 3.172e-05  loss_mask_8: 0.1075  loss_dice_8: 0.1594  time: 0.4913  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:38:04] d2.utils.events INFO:  eta: 0:03:56  iter: 33599  total_loss: 2.85  loss_ce: 2.685e-05  loss_mask: 0.1087  loss_dice: 0.1577  loss_ce_0: 0.1248  loss_mask_0: 0.1076  loss_dice_0: 0.1591  loss_ce_1: 4.316e-05  loss_mask_1: 0.1091  loss_dice_1: 0.1622  loss_ce_2: 4.286e-05  loss_mask_2: 0.1088  loss_dice_2: 0.1575  loss_ce_3: 2.783e-05  loss_mask_3: 0.1114  loss_dice_3: 0.1603  loss_ce_4: 2.998e-05  loss_mask_4: 0.108  loss_dice_4: 0.1602  loss_ce_5: 3.637e-05  loss_mask_5: 0.1092  loss_dice_5: 0.1578  loss_ce_6: 2.399e-05  loss_mask_6: 0.1051  loss_dice_6: 0.16  loss_ce_7: 3.322e-05  loss_mask_7: 0.107  loss_dice_7: 0.1556  loss_ce_8: 3.802e-05  loss_mask_8: 0.109  loss_dice_8: 0.162  time: 0.4911  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:38:07] d2.utils.events INFO:  eta: 0:03:53  iter: 33619  total_loss: 2.793  loss_ce: 3.286e-05  loss_mask: 0.1079  loss_dice: 0.1611  loss_ce_0: 0.1247  loss_mask_0: 0.105  loss_dice_0: 0.1625  loss_ce_1: 4.244e-05  loss_mask_1: 0.1075  loss_dice_1: 0.1608  loss_ce_2: 5.137e-05  loss_mask_2: 0.109  loss_dice_2: 0.1681  loss_ce_3: 3.452e-05  loss_mask_3: 0.1065  loss_dice_3: 0.1615  loss_ce_4: 3.598e-05  loss_mask_4: 0.1102  loss_dice_4: 0.1604  loss_ce_5: 4.791e-05  loss_mask_5: 0.1084  loss_dice_5: 0.1621  loss_ce_6: 2.775e-05  loss_mask_6: 0.1075  loss_dice_6: 0.1618  loss_ce_7: 4.072e-05  loss_mask_7: 0.1042  loss_dice_7: 0.1571  loss_ce_8: 4.544e-05  loss_mask_8: 0.1068  loss_dice_8: 0.1565  time: 0.4909  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:38:10] d2.utils.events INFO:  eta: 0:03:50  iter: 33639  total_loss: 2.785  loss_ce: 2.67e-05  loss_mask: 0.108  loss_dice: 0.1601  loss_ce_0: 0.1246  loss_mask_0: 0.1059  loss_dice_0: 0.1567  loss_ce_1: 3.926e-05  loss_mask_1: 0.1081  loss_dice_1: 0.1584  loss_ce_2: 4.228e-05  loss_mask_2: 0.1085  loss_dice_2: 0.1572  loss_ce_3: 2.143e-05  loss_mask_3: 0.1066  loss_dice_3: 0.1568  loss_ce_4: 3.097e-05  loss_mask_4: 0.1079  loss_dice_4: 0.1564  loss_ce_5: 3.933e-05  loss_mask_5: 0.1054  loss_dice_5: 0.1586  loss_ce_6: 2.216e-05  loss_mask_6: 0.1095  loss_dice_6: 0.1592  loss_ce_7: 3.318e-05  loss_mask_7: 0.1062  loss_dice_7: 0.1555  loss_ce_8: 4.054e-05  loss_mask_8: 0.1085  loss_dice_8: 0.1548  time: 0.4907  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:38:14] d2.utils.events INFO:  eta: 0:03:46  iter: 33659  total_loss: 2.864  loss_ce: 2.587e-05  loss_mask: 0.1106  loss_dice: 0.1674  loss_ce_0: 0.1272  loss_mask_0: 0.1071  loss_dice_0: 0.1703  loss_ce_1: 4.222e-05  loss_mask_1: 0.1073  loss_dice_1: 0.158  loss_ce_2: 3.732e-05  loss_mask_2: 0.1114  loss_dice_2: 0.1658  loss_ce_3: 1.832e-05  loss_mask_3: 0.1089  loss_dice_3: 0.1654  loss_ce_4: 2.257e-05  loss_mask_4: 0.1114  loss_dice_4: 0.1636  loss_ce_5: 2.955e-05  loss_mask_5: 0.1085  loss_dice_5: 0.1644  loss_ce_6: 1.825e-05  loss_mask_6: 0.107  loss_dice_6: 0.1644  loss_ce_7: 2.91e-05  loss_mask_7: 0.1064  loss_dice_7: 0.1597  loss_ce_8: 3.276e-05  loss_mask_8: 0.1091  loss_dice_8: 0.1668  time: 0.4905  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:38:17] d2.utils.events INFO:  eta: 0:03:43  iter: 33679  total_loss: 2.899  loss_ce: 2.615e-05  loss_mask: 0.1145  loss_dice: 0.167  loss_ce_0: 0.1241  loss_mask_0: 0.1137  loss_dice_0: 0.1641  loss_ce_1: 4.704e-05  loss_mask_1: 0.1143  loss_dice_1: 0.1661  loss_ce_2: 4.687e-05  loss_mask_2: 0.1098  loss_dice_2: 0.1648  loss_ce_3: 2.306e-05  loss_mask_3: 0.1119  loss_dice_3: 0.1642  loss_ce_4: 3.121e-05  loss_mask_4: 0.111  loss_dice_4: 0.1617  loss_ce_5: 3.984e-05  loss_mask_5: 0.1104  loss_dice_5: 0.1633  loss_ce_6: 2.309e-05  loss_mask_6: 0.1136  loss_dice_6: 0.161  loss_ce_7: 3.599e-05  loss_mask_7: 0.1104  loss_dice_7: 0.1598  loss_ce_8: 4.313e-05  loss_mask_8: 0.1103  loss_dice_8: 0.1638  time: 0.4903  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:38:20] d2.utils.events INFO:  eta: 0:03:39  iter: 33699  total_loss: 2.792  loss_ce: 2.605e-05  loss_mask: 0.1122  loss_dice: 0.1622  loss_ce_0: 0.1237  loss_mask_0: 0.1099  loss_dice_0: 0.1549  loss_ce_1: 4.092e-05  loss_mask_1: 0.1068  loss_dice_1: 0.1556  loss_ce_2: 4.307e-05  loss_mask_2: 0.1098  loss_dice_2: 0.1566  loss_ce_3: 1.957e-05  loss_mask_3: 0.1086  loss_dice_3: 0.1583  loss_ce_4: 3.134e-05  loss_mask_4: 0.1093  loss_dice_4: 0.1557  loss_ce_5: 3.609e-05  loss_mask_5: 0.1092  loss_dice_5: 0.1603  loss_ce_6: 2.132e-05  loss_mask_6: 0.1112  loss_dice_6: 0.1597  loss_ce_7: 3.23e-05  loss_mask_7: 0.1077  loss_dice_7: 0.1559  loss_ce_8: 3.725e-05  loss_mask_8: 0.106  loss_dice_8: 0.1555  time: 0.4901  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:38:24] d2.utils.events INFO:  eta: 0:03:36  iter: 33719  total_loss: 2.818  loss_ce: 2.655e-05  loss_mask: 0.1053  loss_dice: 0.1662  loss_ce_0: 0.1241  loss_mask_0: 0.1067  loss_dice_0: 0.1672  loss_ce_1: 4.243e-05  loss_mask_1: 0.1055  loss_dice_1: 0.1683  loss_ce_2: 5.103e-05  loss_mask_2: 0.1069  loss_dice_2: 0.1687  loss_ce_3: 2.239e-05  loss_mask_3: 0.1086  loss_dice_3: 0.1686  loss_ce_4: 3.246e-05  loss_mask_4: 0.1052  loss_dice_4: 0.17  loss_ce_5: 3.946e-05  loss_mask_5: 0.1083  loss_dice_5: 0.1657  loss_ce_6: 2.278e-05  loss_mask_6: 0.1084  loss_dice_6: 0.1667  loss_ce_7: 3.577e-05  loss_mask_7: 0.1063  loss_dice_7: 0.1685  loss_ce_8: 4.174e-05  loss_mask_8: 0.106  loss_dice_8: 0.1711  time: 0.4899  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:38:27] d2.utils.events INFO:  eta: 0:03:32  iter: 33739  total_loss: 2.979  loss_ce: 2.592e-05  loss_mask: 0.1138  loss_dice: 0.1763  loss_ce_0: 0.1237  loss_mask_0: 0.1117  loss_dice_0: 0.1694  loss_ce_1: 3.842e-05  loss_mask_1: 0.1103  loss_dice_1: 0.1697  loss_ce_2: 3.612e-05  loss_mask_2: 0.1121  loss_dice_2: 0.1716  loss_ce_3: 1.941e-05  loss_mask_3: 0.1098  loss_dice_3: 0.1707  loss_ce_4: 2.257e-05  loss_mask_4: 0.1102  loss_dice_4: 0.174  loss_ce_5: 2.894e-05  loss_mask_5: 0.11  loss_dice_5: 0.1713  loss_ce_6: 1.845e-05  loss_mask_6: 0.1153  loss_dice_6: 0.1803  loss_ce_7: 2.861e-05  loss_mask_7: 0.1095  loss_dice_7: 0.1663  loss_ce_8: 3.219e-05  loss_mask_8: 0.1116  loss_dice_8: 0.1758  time: 0.4897  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:38:31] d2.utils.events INFO:  eta: 0:03:29  iter: 33759  total_loss: 2.949  loss_ce: 2.599e-05  loss_mask: 0.112  loss_dice: 0.1726  loss_ce_0: 0.1241  loss_mask_0: 0.1107  loss_dice_0: 0.1706  loss_ce_1: 5.147e-05  loss_mask_1: 0.1082  loss_dice_1: 0.1701  loss_ce_2: 5.252e-05  loss_mask_2: 0.1149  loss_dice_2: 0.1724  loss_ce_3: 3.088e-05  loss_mask_3: 0.1111  loss_dice_3: 0.172  loss_ce_4: 3.24e-05  loss_mask_4: 0.1132  loss_dice_4: 0.1765  loss_ce_5: 4.352e-05  loss_mask_5: 0.1102  loss_dice_5: 0.1711  loss_ce_6: 2.561e-05  loss_mask_6: 0.1112  loss_dice_6: 0.1738  loss_ce_7: 3.714e-05  loss_mask_7: 0.1065  loss_dice_7: 0.1716  loss_ce_8: 4.897e-05  loss_mask_8: 0.1123  loss_dice_8: 0.1686  time: 0.4895  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:38:34] d2.utils.events INFO:  eta: 0:03:26  iter: 33779  total_loss: 2.9  loss_ce: 2.542e-05  loss_mask: 0.1125  loss_dice: 0.1669  loss_ce_0: 0.1238  loss_mask_0: 0.1135  loss_dice_0: 0.168  loss_ce_1: 4.608e-05  loss_mask_1: 0.1126  loss_dice_1: 0.1682  loss_ce_2: 4.162e-05  loss_mask_2: 0.1114  loss_dice_2: 0.1664  loss_ce_3: 2.083e-05  loss_mask_3: 0.1125  loss_dice_3: 0.166  loss_ce_4: 3.025e-05  loss_mask_4: 0.1064  loss_dice_4: 0.159  loss_ce_5: 3.919e-05  loss_mask_5: 0.1109  loss_dice_5: 0.1701  loss_ce_6: 2.228e-05  loss_mask_6: 0.1121  loss_dice_6: 0.1669  loss_ce_7: 3.402e-05  loss_mask_7: 0.112  loss_dice_7: 0.1717  loss_ce_8: 4.25e-05  loss_mask_8: 0.1092  loss_dice_8: 0.1636  time: 0.4893  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:38:37] d2.utils.events INFO:  eta: 0:03:22  iter: 33799  total_loss: 2.861  loss_ce: 2.579e-05  loss_mask: 0.1103  loss_dice: 0.1678  loss_ce_0: 0.1238  loss_mask_0: 0.1127  loss_dice_0: 0.1704  loss_ce_1: 4.279e-05  loss_mask_1: 0.1077  loss_dice_1: 0.169  loss_ce_2: 4.032e-05  loss_mask_2: 0.1091  loss_dice_2: 0.1644  loss_ce_3: 2.201e-05  loss_mask_3: 0.1065  loss_dice_3: 0.1643  loss_ce_4: 2.832e-05  loss_mask_4: 0.1102  loss_dice_4: 0.1615  loss_ce_5: 3.545e-05  loss_mask_5: 0.1086  loss_dice_5: 0.1639  loss_ce_6: 2.17e-05  loss_mask_6: 0.111  loss_dice_6: 0.1651  loss_ce_7: 3.204e-05  loss_mask_7: 0.1081  loss_dice_7: 0.1619  loss_ce_8: 3.635e-05  loss_mask_8: 0.1084  loss_dice_8: 0.1687  time: 0.4892  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:38:41] d2.utils.events INFO:  eta: 0:03:19  iter: 33819  total_loss: 2.785  loss_ce: 2.585e-05  loss_mask: 0.1071  loss_dice: 0.1585  loss_ce_0: 0.1238  loss_mask_0: 0.1083  loss_dice_0: 0.1635  loss_ce_1: 4.433e-05  loss_mask_1: 0.1084  loss_dice_1: 0.1577  loss_ce_2: 5.373e-05  loss_mask_2: 0.1097  loss_dice_2: 0.1589  loss_ce_3: 3.11e-05  loss_mask_3: 0.1063  loss_dice_3: 0.1617  loss_ce_4: 3.304e-05  loss_mask_4: 0.1076  loss_dice_4: 0.1588  loss_ce_5: 3.633e-05  loss_mask_5: 0.1069  loss_dice_5: 0.1568  loss_ce_6: 2.5e-05  loss_mask_6: 0.1094  loss_dice_6: 0.1595  loss_ce_7: 3.338e-05  loss_mask_7: 0.1051  loss_dice_7: 0.1533  loss_ce_8: 3.799e-05  loss_mask_8: 0.1087  loss_dice_8: 0.1606  time: 0.4890  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:38:44] d2.utils.events INFO:  eta: 0:03:15  iter: 33839  total_loss: 2.849  loss_ce: 2.709e-05  loss_mask: 0.1095  loss_dice: 0.1672  loss_ce_0: 0.1238  loss_mask_0: 0.1064  loss_dice_0: 0.163  loss_ce_1: 4.354e-05  loss_mask_1: 0.106  loss_dice_1: 0.1646  loss_ce_2: 5.346e-05  loss_mask_2: 0.1076  loss_dice_2: 0.1607  loss_ce_3: 3.288e-05  loss_mask_3: 0.1099  loss_dice_3: 0.1643  loss_ce_4: 3.337e-05  loss_mask_4: 0.1079  loss_dice_4: 0.1633  loss_ce_5: 3.942e-05  loss_mask_5: 0.1084  loss_dice_5: 0.1644  loss_ce_6: 2.515e-05  loss_mask_6: 0.1084  loss_dice_6: 0.1649  loss_ce_7: 3.605e-05  loss_mask_7: 0.1055  loss_dice_7: 0.1641  loss_ce_8: 4.08e-05  loss_mask_8: 0.1074  loss_dice_8: 0.1601  time: 0.4888  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:38:48] d2.utils.events INFO:  eta: 0:03:12  iter: 33859  total_loss: 2.836  loss_ce: 2.459e-05  loss_mask: 0.109  loss_dice: 0.1711  loss_ce_0: 0.1238  loss_mask_0: 0.1109  loss_dice_0: 0.167  loss_ce_1: 5.292e-05  loss_mask_1: 0.11  loss_dice_1: 0.1676  loss_ce_2: 4.197e-05  loss_mask_2: 0.1101  loss_dice_2: 0.1661  loss_ce_3: 1.898e-05  loss_mask_3: 0.1057  loss_dice_3: 0.166  loss_ce_4: 2.968e-05  loss_mask_4: 0.1088  loss_dice_4: 0.1605  loss_ce_5: 3.616e-05  loss_mask_5: 0.1059  loss_dice_5: 0.1627  loss_ce_6: 2.132e-05  loss_mask_6: 0.1076  loss_dice_6: 0.1644  loss_ce_7: 3.397e-05  loss_mask_7: 0.1092  loss_dice_7: 0.1696  loss_ce_8: 3.74e-05  loss_mask_8: 0.108  loss_dice_8: 0.1708  time: 0.4886  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:38:51] d2.utils.events INFO:  eta: 0:03:09  iter: 33879  total_loss: 2.939  loss_ce: 2.594e-05  loss_mask: 0.1109  loss_dice: 0.1643  loss_ce_0: 0.1237  loss_mask_0: 0.1128  loss_dice_0: 0.1694  loss_ce_1: 4.794e-05  loss_mask_1: 0.1106  loss_dice_1: 0.1714  loss_ce_2: 4.203e-05  loss_mask_2: 0.1129  loss_dice_2: 0.1663  loss_ce_3: 2.241e-05  loss_mask_3: 0.1147  loss_dice_3: 0.1695  loss_ce_4: 3.025e-05  loss_mask_4: 0.1137  loss_dice_4: 0.1655  loss_ce_5: 3.636e-05  loss_mask_5: 0.1106  loss_dice_5: 0.1679  loss_ce_6: 2.266e-05  loss_mask_6: 0.1137  loss_dice_6: 0.1665  loss_ce_7: 3.568e-05  loss_mask_7: 0.1095  loss_dice_7: 0.1642  loss_ce_8: 3.78e-05  loss_mask_8: 0.1113  loss_dice_8: 0.1685  time: 0.4884  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:38:54] d2.utils.events INFO:  eta: 0:03:05  iter: 33899  total_loss: 2.924  loss_ce: 2.678e-05  loss_mask: 0.108  loss_dice: 0.163  loss_ce_0: 0.1246  loss_mask_0: 0.1089  loss_dice_0: 0.1655  loss_ce_1: 4.703e-05  loss_mask_1: 0.1098  loss_dice_1: 0.1646  loss_ce_2: 4.632e-05  loss_mask_2: 0.1078  loss_dice_2: 0.1653  loss_ce_3: 2.3e-05  loss_mask_3: 0.1091  loss_dice_3: 0.1669  loss_ce_4: 3.434e-05  loss_mask_4: 0.108  loss_dice_4: 0.1674  loss_ce_5: 4.891e-05  loss_mask_5: 0.1056  loss_dice_5: 0.1619  loss_ce_6: 2.317e-05  loss_mask_6: 0.106  loss_dice_6: 0.1634  loss_ce_7: 3.748e-05  loss_mask_7: 0.1063  loss_dice_7: 0.1651  loss_ce_8: 4.582e-05  loss_mask_8: 0.1045  loss_dice_8: 0.17  time: 0.4882  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:38:58] d2.utils.events INFO:  eta: 0:03:02  iter: 33919  total_loss: 2.822  loss_ce: 2.967e-05  loss_mask: 0.1081  loss_dice: 0.1651  loss_ce_0: 0.1246  loss_mask_0: 0.1129  loss_dice_0: 0.1614  loss_ce_1: 4.948e-05  loss_mask_1: 0.1128  loss_dice_1: 0.1614  loss_ce_2: 5.011e-05  loss_mask_2: 0.1065  loss_dice_2: 0.1609  loss_ce_3: 2.517e-05  loss_mask_3: 0.1109  loss_dice_3: 0.1637  loss_ce_4: 3.363e-05  loss_mask_4: 0.1083  loss_dice_4: 0.161  loss_ce_5: 4.786e-05  loss_mask_5: 0.1134  loss_dice_5: 0.1604  loss_ce_6: 2.519e-05  loss_mask_6: 0.1087  loss_dice_6: 0.1576  loss_ce_7: 3.889e-05  loss_mask_7: 0.1105  loss_dice_7: 0.1578  loss_ce_8: 4.497e-05  loss_mask_8: 0.113  loss_dice_8: 0.1638  time: 0.4880  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:01] d2.utils.events INFO:  eta: 0:02:58  iter: 33939  total_loss: 2.891  loss_ce: 3.388e-05  loss_mask: 0.1102  loss_dice: 0.1595  loss_ce_0: 0.1276  loss_mask_0: 0.1112  loss_dice_0: 0.1608  loss_ce_1: 4.014e-05  loss_mask_1: 0.1108  loss_dice_1: 0.1608  loss_ce_2: 4.165e-05  loss_mask_2: 0.1151  loss_dice_2: 0.1647  loss_ce_3: 2.556e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1632  loss_ce_4: 2.997e-05  loss_mask_4: 0.1123  loss_dice_4: 0.1612  loss_ce_5: 4.222e-05  loss_mask_5: 0.1101  loss_dice_5: 0.159  loss_ce_6: 2.669e-05  loss_mask_6: 0.1134  loss_dice_6: 0.1641  loss_ce_7: 3.43e-05  loss_mask_7: 0.1088  loss_dice_7: 0.1603  loss_ce_8: 4.602e-05  loss_mask_8: 0.1153  loss_dice_8: 0.1628  time: 0.4878  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:04] d2.utils.events INFO:  eta: 0:02:55  iter: 33959  total_loss: 2.882  loss_ce: 2.682e-05  loss_mask: 0.1113  loss_dice: 0.1649  loss_ce_0: 0.124  loss_mask_0: 0.112  loss_dice_0: 0.1647  loss_ce_1: 4.627e-05  loss_mask_1: 0.1109  loss_dice_1: 0.1643  loss_ce_2: 5.395e-05  loss_mask_2: 0.1115  loss_dice_2: 0.1647  loss_ce_3: 2.303e-05  loss_mask_3: 0.1138  loss_dice_3: 0.1687  loss_ce_4: 3.252e-05  loss_mask_4: 0.1103  loss_dice_4: 0.1679  loss_ce_5: 3.617e-05  loss_mask_5: 0.1108  loss_dice_5: 0.1626  loss_ce_6: 2.305e-05  loss_mask_6: 0.1134  loss_dice_6: 0.162  loss_ce_7: 3.593e-05  loss_mask_7: 0.115  loss_dice_7: 0.1686  loss_ce_8: 3.796e-05  loss_mask_8: 0.1092  loss_dice_8: 0.1623  time: 0.4876  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:08] d2.utils.events INFO:  eta: 0:02:52  iter: 33979  total_loss: 2.78  loss_ce: 2.417e-05  loss_mask: 0.1027  loss_dice: 0.1594  loss_ce_0: 0.124  loss_mask_0: 0.1067  loss_dice_0: 0.1679  loss_ce_1: 4.711e-05  loss_mask_1: 0.1069  loss_dice_1: 0.1642  loss_ce_2: 4.744e-05  loss_mask_2: 0.1067  loss_dice_2: 0.1642  loss_ce_3: 2.206e-05  loss_mask_3: 0.1089  loss_dice_3: 0.1611  loss_ce_4: 3.026e-05  loss_mask_4: 0.1049  loss_dice_4: 0.1615  loss_ce_5: 3.639e-05  loss_mask_5: 0.1066  loss_dice_5: 0.1609  loss_ce_6: 2.307e-05  loss_mask_6: 0.1073  loss_dice_6: 0.1585  loss_ce_7: 3.487e-05  loss_mask_7: 0.1066  loss_dice_7: 0.1635  loss_ce_8: 3.814e-05  loss_mask_8: 0.1078  loss_dice_8: 0.1644  time: 0.4875  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:11] d2.utils.events INFO:  eta: 0:02:48  iter: 33999  total_loss: 2.752  loss_ce: 2.608e-05  loss_mask: 0.1027  loss_dice: 0.1629  loss_ce_0: 0.1239  loss_mask_0: 0.1039  loss_dice_0: 0.1593  loss_ce_1: 4.042e-05  loss_mask_1: 0.1041  loss_dice_1: 0.1581  loss_ce_2: 4.657e-05  loss_mask_2: 0.1062  loss_dice_2: 0.1653  loss_ce_3: 2.863e-05  loss_mask_3: 0.1053  loss_dice_3: 0.1589  loss_ce_4: 3.149e-05  loss_mask_4: 0.1076  loss_dice_4: 0.1616  loss_ce_5: 3.559e-05  loss_mask_5: 0.1049  loss_dice_5: 0.1586  loss_ce_6: 2.35e-05  loss_mask_6: 0.1069  loss_dice_6: 0.1579  loss_ce_7: 3.109e-05  loss_mask_7: 0.1045  loss_dice_7: 0.1607  loss_ce_8: 3.626e-05  loss_mask_8: 0.1058  loss_dice_8: 0.1554  time: 0.4873  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:15] d2.utils.events INFO:  eta: 0:02:45  iter: 34019  total_loss: 2.783  loss_ce: 2.648e-05  loss_mask: 0.1089  loss_dice: 0.1525  loss_ce_0: 0.1243  loss_mask_0: 0.1089  loss_dice_0: 0.1575  loss_ce_1: 4.242e-05  loss_mask_1: 0.1077  loss_dice_1: 0.1602  loss_ce_2: 4.201e-05  loss_mask_2: 0.1084  loss_dice_2: 0.1572  loss_ce_3: 2.198e-05  loss_mask_3: 0.1061  loss_dice_3: 0.1536  loss_ce_4: 3.145e-05  loss_mask_4: 0.1111  loss_dice_4: 0.1529  loss_ce_5: 4.262e-05  loss_mask_5: 0.108  loss_dice_5: 0.1518  loss_ce_6: 2.312e-05  loss_mask_6: 0.1098  loss_dice_6: 0.1541  loss_ce_7: 3.355e-05  loss_mask_7: 0.1092  loss_dice_7: 0.1543  loss_ce_8: 4.592e-05  loss_mask_8: 0.11  loss_dice_8: 0.1608  time: 0.4871  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:39:18] d2.utils.events INFO:  eta: 0:02:42  iter: 34039  total_loss: 2.803  loss_ce: 2.584e-05  loss_mask: 0.1054  loss_dice: 0.1622  loss_ce_0: 0.1239  loss_mask_0: 0.1078  loss_dice_0: 0.1633  loss_ce_1: 4.871e-05  loss_mask_1: 0.1105  loss_dice_1: 0.1602  loss_ce_2: 5.173e-05  loss_mask_2: 0.1033  loss_dice_2: 0.1584  loss_ce_3: 2.571e-05  loss_mask_3: 0.1051  loss_dice_3: 0.1612  loss_ce_4: 3.326e-05  loss_mask_4: 0.1034  loss_dice_4: 0.1583  loss_ce_5: 5.142e-05  loss_mask_5: 0.1042  loss_dice_5: 0.1536  loss_ce_6: 2.395e-05  loss_mask_6: 0.1066  loss_dice_6: 0.1613  loss_ce_7: 3.735e-05  loss_mask_7: 0.1081  loss_dice_7: 0.1586  loss_ce_8: 4.525e-05  loss_mask_8: 0.1088  loss_dice_8: 0.1619  time: 0.4869  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:21] d2.utils.events INFO:  eta: 0:02:38  iter: 34059  total_loss: 2.896  loss_ce: 2.533e-05  loss_mask: 0.1108  loss_dice: 0.1746  loss_ce_0: 0.1239  loss_mask_0: 0.1102  loss_dice_0: 0.1654  loss_ce_1: 3.97e-05  loss_mask_1: 0.1093  loss_dice_1: 0.1635  loss_ce_2: 4.5e-05  loss_mask_2: 0.1139  loss_dice_2: 0.1665  loss_ce_3: 1.956e-05  loss_mask_3: 0.1134  loss_dice_3: 0.1715  loss_ce_4: 2.954e-05  loss_mask_4: 0.1106  loss_dice_4: 0.1663  loss_ce_5: 3.571e-05  loss_mask_5: 0.1132  loss_dice_5: 0.1645  loss_ce_6: 2.118e-05  loss_mask_6: 0.1096  loss_dice_6: 0.1611  loss_ce_7: 3.281e-05  loss_mask_7: 0.1071  loss_dice_7: 0.1675  loss_ce_8: 3.714e-05  loss_mask_8: 0.1094  loss_dice_8: 0.168  time: 0.4867  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:25] d2.utils.events INFO:  eta: 0:02:35  iter: 34079  total_loss: 2.865  loss_ce: 2.659e-05  loss_mask: 0.1101  loss_dice: 0.1626  loss_ce_0: 0.1241  loss_mask_0: 0.1077  loss_dice_0: 0.168  loss_ce_1: 3.925e-05  loss_mask_1: 0.1131  loss_dice_1: 0.1657  loss_ce_2: 4.646e-05  loss_mask_2: 0.1112  loss_dice_2: 0.1642  loss_ce_3: 2.618e-05  loss_mask_3: 0.109  loss_dice_3: 0.1645  loss_ce_4: 3.221e-05  loss_mask_4: 0.1085  loss_dice_4: 0.1666  loss_ce_5: 3.603e-05  loss_mask_5: 0.1063  loss_dice_5: 0.163  loss_ce_6: 2.303e-05  loss_mask_6: 0.1102  loss_dice_6: 0.1665  loss_ce_7: 3.157e-05  loss_mask_7: 0.1122  loss_dice_7: 0.1663  loss_ce_8: 3.633e-05  loss_mask_8: 0.1105  loss_dice_8: 0.1652  time: 0.4865  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:28] d2.utils.events INFO:  eta: 0:02:31  iter: 34099  total_loss: 2.778  loss_ce: 2.715e-05  loss_mask: 0.1086  loss_dice: 0.1575  loss_ce_0: 0.1241  loss_mask_0: 0.1058  loss_dice_0: 0.1568  loss_ce_1: 4.539e-05  loss_mask_1: 0.1093  loss_dice_1: 0.1579  loss_ce_2: 4.2e-05  loss_mask_2: 0.1129  loss_dice_2: 0.1587  loss_ce_3: 2.226e-05  loss_mask_3: 0.106  loss_dice_3: 0.1551  loss_ce_4: 3.163e-05  loss_mask_4: 0.1113  loss_dice_4: 0.1602  loss_ce_5: 3.604e-05  loss_mask_5: 0.1032  loss_dice_5: 0.149  loss_ce_6: 2.292e-05  loss_mask_6: 0.1092  loss_dice_6: 0.1547  loss_ce_7: 3.337e-05  loss_mask_7: 0.1043  loss_dice_7: 0.1568  loss_ce_8: 3.672e-05  loss_mask_8: 0.108  loss_dice_8: 0.1568  time: 0.4863  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:39:31] d2.utils.events INFO:  eta: 0:02:28  iter: 34119  total_loss: 2.757  loss_ce: 2.625e-05  loss_mask: 0.1069  loss_dice: 0.1599  loss_ce_0: 0.1241  loss_mask_0: 0.1082  loss_dice_0: 0.1566  loss_ce_1: 4.358e-05  loss_mask_1: 0.1055  loss_dice_1: 0.1589  loss_ce_2: 4.139e-05  loss_mask_2: 0.1074  loss_dice_2: 0.1577  loss_ce_3: 2.832e-05  loss_mask_3: 0.1045  loss_dice_3: 0.1581  loss_ce_4: 3.256e-05  loss_mask_4: 0.1074  loss_dice_4: 0.1607  loss_ce_5: 3.655e-05  loss_mask_5: 0.1058  loss_dice_5: 0.1596  loss_ce_6: 2.561e-05  loss_mask_6: 0.1032  loss_dice_6: 0.161  loss_ce_7: 3.344e-05  loss_mask_7: 0.1057  loss_dice_7: 0.1569  loss_ce_8: 3.777e-05  loss_mask_8: 0.1055  loss_dice_8: 0.1566  time: 0.4861  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:35] d2.utils.events INFO:  eta: 0:02:25  iter: 34139  total_loss: 2.959  loss_ce: 2.605e-05  loss_mask: 0.1133  loss_dice: 0.1721  loss_ce_0: 0.124  loss_mask_0: 0.1116  loss_dice_0: 0.1697  loss_ce_1: 4.078e-05  loss_mask_1: 0.1151  loss_dice_1: 0.1725  loss_ce_2: 4.255e-05  loss_mask_2: 0.1137  loss_dice_2: 0.1734  loss_ce_3: 2.144e-05  loss_mask_3: 0.1123  loss_dice_3: 0.1684  loss_ce_4: 3.056e-05  loss_mask_4: 0.109  loss_dice_4: 0.1644  loss_ce_5: 3.958e-05  loss_mask_5: 0.1139  loss_dice_5: 0.1714  loss_ce_6: 2.291e-05  loss_mask_6: 0.111  loss_dice_6: 0.1674  loss_ce_7: 3.168e-05  loss_mask_7: 0.108  loss_dice_7: 0.1617  loss_ce_8: 3.908e-05  loss_mask_8: 0.1094  loss_dice_8: 0.166  time: 0.4860  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:38] d2.utils.events INFO:  eta: 0:02:21  iter: 34159  total_loss: 2.861  loss_ce: 2.616e-05  loss_mask: 0.1108  loss_dice: 0.1652  loss_ce_0: 0.124  loss_mask_0: 0.1096  loss_dice_0: 0.1654  loss_ce_1: 2.61e-05  loss_mask_1: 0.107  loss_dice_1: 0.1662  loss_ce_2: 3.073e-05  loss_mask_2: 0.1068  loss_dice_2: 0.1586  loss_ce_3: 1.334e-05  loss_mask_3: 0.1106  loss_dice_3: 0.1686  loss_ce_4: 1.759e-05  loss_mask_4: 0.1077  loss_dice_4: 0.1612  loss_ce_5: 2.229e-05  loss_mask_5: 0.1092  loss_dice_5: 0.1646  loss_ce_6: 1.706e-05  loss_mask_6: 0.108  loss_dice_6: 0.1653  loss_ce_7: 2.229e-05  loss_mask_7: 0.1087  loss_dice_7: 0.1657  loss_ce_8: 2.652e-05  loss_mask_8: 0.1073  loss_dice_8: 0.1628  time: 0.4858  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:42] d2.utils.events INFO:  eta: 0:02:18  iter: 34179  total_loss: 2.758  loss_ce: 2.622e-05  loss_mask: 0.1072  loss_dice: 0.1546  loss_ce_0: 0.1241  loss_mask_0: 0.1126  loss_dice_0: 0.154  loss_ce_1: 4.017e-05  loss_mask_1: 0.1118  loss_dice_1: 0.1606  loss_ce_2: 4.033e-05  loss_mask_2: 0.1116  loss_dice_2: 0.157  loss_ce_3: 2.084e-05  loss_mask_3: 0.1111  loss_dice_3: 0.1553  loss_ce_4: 2.916e-05  loss_mask_4: 0.1083  loss_dice_4: 0.1556  loss_ce_5: 3.6e-05  loss_mask_5: 0.105  loss_dice_5: 0.1468  loss_ce_6: 2.293e-05  loss_mask_6: 0.1099  loss_dice_6: 0.1565  loss_ce_7: 3.144e-05  loss_mask_7: 0.1088  loss_dice_7: 0.1559  loss_ce_8: 3.611e-05  loss_mask_8: 0.1085  loss_dice_8: 0.1589  time: 0.4856  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:39:45] d2.utils.events INFO:  eta: 0:02:15  iter: 34199  total_loss: 2.777  loss_ce: 2.766e-05  loss_mask: 0.1077  loss_dice: 0.1609  loss_ce_0: 0.124  loss_mask_0: 0.1037  loss_dice_0: 0.1609  loss_ce_1: 4.776e-05  loss_mask_1: 0.1065  loss_dice_1: 0.1579  loss_ce_2: 5.328e-05  loss_mask_2: 0.1081  loss_dice_2: 0.1607  loss_ce_3: 3.09e-05  loss_mask_3: 0.1053  loss_dice_3: 0.1588  loss_ce_4: 3.268e-05  loss_mask_4: 0.1079  loss_dice_4: 0.1605  loss_ce_5: 3.625e-05  loss_mask_5: 0.1067  loss_dice_5: 0.1601  loss_ce_6: 2.436e-05  loss_mask_6: 0.1095  loss_dice_6: 0.1594  loss_ce_7: 3.498e-05  loss_mask_7: 0.1097  loss_dice_7: 0.1597  loss_ce_8: 3.871e-05  loss_mask_8: 0.1083  loss_dice_8: 0.161  time: 0.4854  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:48] d2.utils.events INFO:  eta: 0:02:11  iter: 34219  total_loss: 2.801  loss_ce: 2.562e-05  loss_mask: 0.1159  loss_dice: 0.1623  loss_ce_0: 0.1239  loss_mask_0: 0.106  loss_dice_0: 0.1624  loss_ce_1: 4.372e-05  loss_mask_1: 0.1079  loss_dice_1: 0.1603  loss_ce_2: 5.382e-05  loss_mask_2: 0.1085  loss_dice_2: 0.159  loss_ce_3: 1.868e-05  loss_mask_3: 0.1084  loss_dice_3: 0.1582  loss_ce_4: 3.123e-05  loss_mask_4: 0.1092  loss_dice_4: 0.1585  loss_ce_5: 3.614e-05  loss_mask_5: 0.1071  loss_dice_5: 0.1547  loss_ce_6: 2.109e-05  loss_mask_6: 0.1086  loss_dice_6: 0.1597  loss_ce_7: 3.459e-05  loss_mask_7: 0.1106  loss_dice_7: 0.1606  loss_ce_8: 3.745e-05  loss_mask_8: 0.1084  loss_dice_8: 0.1588  time: 0.4852  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:52] d2.utils.events INFO:  eta: 0:02:08  iter: 34239  total_loss: 2.857  loss_ce: 2.569e-05  loss_mask: 0.1138  loss_dice: 0.1654  loss_ce_0: 0.1239  loss_mask_0: 0.1106  loss_dice_0: 0.1635  loss_ce_1: 4.175e-05  loss_mask_1: 0.1087  loss_dice_1: 0.1705  loss_ce_2: 5.136e-05  loss_mask_2: 0.1118  loss_dice_2: 0.1639  loss_ce_3: 2.121e-05  loss_mask_3: 0.1115  loss_dice_3: 0.1645  loss_ce_4: 3.18e-05  loss_mask_4: 0.1102  loss_dice_4: 0.1637  loss_ce_5: 3.619e-05  loss_mask_5: 0.1079  loss_dice_5: 0.1631  loss_ce_6: 2.253e-05  loss_mask_6: 0.1137  loss_dice_6: 0.1669  loss_ce_7: 3.349e-05  loss_mask_7: 0.1073  loss_dice_7: 0.1676  loss_ce_8: 3.722e-05  loss_mask_8: 0.1086  loss_dice_8: 0.1641  time: 0.4850  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:39:55] d2.utils.events INFO:  eta: 0:02:05  iter: 34259  total_loss: 2.836  loss_ce: 2.495e-05  loss_mask: 0.1088  loss_dice: 0.1621  loss_ce_0: 0.1239  loss_mask_0: 0.1099  loss_dice_0: 0.1682  loss_ce_1: 3.009e-05  loss_mask_1: 0.1133  loss_dice_1: 0.1645  loss_ce_2: 3.072e-05  loss_mask_2: 0.1102  loss_dice_2: 0.1599  loss_ce_3: 1.264e-05  loss_mask_3: 0.1102  loss_dice_3: 0.1589  loss_ce_4: 1.681e-05  loss_mask_4: 0.1089  loss_dice_4: 0.1618  loss_ce_5: 2.198e-05  loss_mask_5: 0.112  loss_dice_5: 0.1598  loss_ce_6: 1.513e-05  loss_mask_6: 0.1065  loss_dice_6: 0.1594  loss_ce_7: 2.361e-05  loss_mask_7: 0.1087  loss_dice_7: 0.1623  loss_ce_8: 2.672e-05  loss_mask_8: 0.1075  loss_dice_8: 0.1566  time: 0.4848  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:39:59] d2.utils.events INFO:  eta: 0:02:01  iter: 34279  total_loss: 2.83  loss_ce: 2.636e-05  loss_mask: 0.1071  loss_dice: 0.1622  loss_ce_0: 0.1189  loss_mask_0: 0.1045  loss_dice_0: 0.1652  loss_ce_1: 4.786e-05  loss_mask_1: 0.1088  loss_dice_1: 0.1619  loss_ce_2: 5.343e-05  loss_mask_2: 0.1074  loss_dice_2: 0.1608  loss_ce_3: 2.249e-05  loss_mask_3: 0.1077  loss_dice_3: 0.1619  loss_ce_4: 3.272e-05  loss_mask_4: 0.105  loss_dice_4: 0.1611  loss_ce_5: 3.911e-05  loss_mask_5: 0.1082  loss_dice_5: 0.1582  loss_ce_6: 2.256e-05  loss_mask_6: 0.1114  loss_dice_6: 0.1612  loss_ce_7: 3.6e-05  loss_mask_7: 0.1092  loss_dice_7: 0.163  loss_ce_8: 4.062e-05  loss_mask_8: 0.1078  loss_dice_8: 0.1628  time: 0.4847  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:40:02] d2.utils.events INFO:  eta: 0:01:58  iter: 34299  total_loss: 2.837  loss_ce: 2.736e-05  loss_mask: 0.1084  loss_dice: 0.1631  loss_ce_0: 0.1238  loss_mask_0: 0.1112  loss_dice_0: 0.1652  loss_ce_1: 4.347e-05  loss_mask_1: 0.1121  loss_dice_1: 0.1664  loss_ce_2: 5.31e-05  loss_mask_2: 0.1105  loss_dice_2: 0.1596  loss_ce_3: 2.142e-05  loss_mask_3: 0.1087  loss_dice_3: 0.1598  loss_ce_4: 3.325e-05  loss_mask_4: 0.1094  loss_dice_4: 0.1632  loss_ce_5: 3.604e-05  loss_mask_5: 0.1121  loss_dice_5: 0.1661  loss_ce_6: 2.28e-05  loss_mask_6: 0.1093  loss_dice_6: 0.1614  loss_ce_7: 3.342e-05  loss_mask_7: 0.1128  loss_dice_7: 0.161  loss_ce_8: 3.758e-05  loss_mask_8: 0.1096  loss_dice_8: 0.1643  time: 0.4845  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:05] d2.utils.events INFO:  eta: 0:01:55  iter: 34319  total_loss: 3.003  loss_ce: 2.999e-05  loss_mask: 0.1176  loss_dice: 0.1735  loss_ce_0: 0.1238  loss_mask_0: 0.1215  loss_dice_0: 0.1721  loss_ce_1: 4.296e-05  loss_mask_1: 0.115  loss_dice_1: 0.1721  loss_ce_2: 5.342e-05  loss_mask_2: 0.1137  loss_dice_2: 0.1664  loss_ce_3: 3.052e-05  loss_mask_3: 0.111  loss_dice_3: 0.169  loss_ce_4: 3.371e-05  loss_mask_4: 0.1126  loss_dice_4: 0.1644  loss_ce_5: 3.639e-05  loss_mask_5: 0.1162  loss_dice_5: 0.1681  loss_ce_6: 2.604e-05  loss_mask_6: 0.1122  loss_dice_6: 0.1666  loss_ce_7: 3.35e-05  loss_mask_7: 0.1148  loss_dice_7: 0.17  loss_ce_8: 3.755e-05  loss_mask_8: 0.1104  loss_dice_8: 0.1705  time: 0.4843  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:09] d2.utils.events INFO:  eta: 0:01:51  iter: 34339  total_loss: 2.817  loss_ce: 2.546e-05  loss_mask: 0.1058  loss_dice: 0.1628  loss_ce_0: 0.1242  loss_mask_0: 0.1078  loss_dice_0: 0.1598  loss_ce_1: 3.59e-05  loss_mask_1: 0.1062  loss_dice_1: 0.1626  loss_ce_2: 3.547e-05  loss_mask_2: 0.1066  loss_dice_2: 0.1679  loss_ce_3: 1.971e-05  loss_mask_3: 0.1041  loss_dice_3: 0.1607  loss_ce_4: 2.464e-05  loss_mask_4: 0.1059  loss_dice_4: 0.1645  loss_ce_5: 2.895e-05  loss_mask_5: 0.1084  loss_dice_5: 0.1602  loss_ce_6: 2.141e-05  loss_mask_6: 0.1072  loss_dice_6: 0.1655  loss_ce_7: 2.803e-05  loss_mask_7: 0.1075  loss_dice_7: 0.166  loss_ce_8: 3.199e-05  loss_mask_8: 0.1083  loss_dice_8: 0.1659  time: 0.4841  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:12] d2.utils.events INFO:  eta: 0:01:48  iter: 34359  total_loss: 2.896  loss_ce: 2.581e-05  loss_mask: 0.1063  loss_dice: 0.1583  loss_ce_0: 0.1238  loss_mask_0: 0.1095  loss_dice_0: 0.1631  loss_ce_1: 4.4e-05  loss_mask_1: 0.1102  loss_dice_1: 0.1686  loss_ce_2: 5.076e-05  loss_mask_2: 0.1104  loss_dice_2: 0.1625  loss_ce_3: 2.706e-05  loss_mask_3: 0.1103  loss_dice_3: 0.1639  loss_ce_4: 3.263e-05  loss_mask_4: 0.1094  loss_dice_4: 0.1593  loss_ce_5: 3.642e-05  loss_mask_5: 0.1104  loss_dice_5: 0.1624  loss_ce_6: 2.45e-05  loss_mask_6: 0.1097  loss_dice_6: 0.1671  loss_ce_7: 3.499e-05  loss_mask_7: 0.1097  loss_dice_7: 0.166  loss_ce_8: 3.748e-05  loss_mask_8: 0.1085  loss_dice_8: 0.1633  time: 0.4839  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:40:16] d2.utils.events INFO:  eta: 0:01:45  iter: 34379  total_loss: 2.82  loss_ce: 2.378e-05  loss_mask: 0.1121  loss_dice: 0.165  loss_ce_0: 0.1238  loss_mask_0: 0.1117  loss_dice_0: 0.1668  loss_ce_1: 5.36e-05  loss_mask_1: 0.1098  loss_dice_1: 0.164  loss_ce_2: 4.021e-05  loss_mask_2: 0.1096  loss_dice_2: 0.1645  loss_ce_3: 1.837e-05  loss_mask_3: 0.1139  loss_dice_3: 0.1619  loss_ce_4: 2.789e-05  loss_mask_4: 0.1099  loss_dice_4: 0.1601  loss_ce_5: 3.559e-05  loss_mask_5: 0.11  loss_dice_5: 0.1562  loss_ce_6: 1.993e-05  loss_mask_6: 0.109  loss_dice_6: 0.1602  loss_ce_7: 3.281e-05  loss_mask_7: 0.1076  loss_dice_7: 0.162  loss_ce_8: 3.746e-05  loss_mask_8: 0.1105  loss_dice_8: 0.1686  time: 0.4837  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:19] d2.utils.events INFO:  eta: 0:01:41  iter: 34399  total_loss: 2.849  loss_ce: 2.512e-05  loss_mask: 0.1083  loss_dice: 0.1621  loss_ce_0: 0.1237  loss_mask_0: 0.1057  loss_dice_0: 0.1709  loss_ce_1: 4.531e-05  loss_mask_1: 0.1091  loss_dice_1: 0.1639  loss_ce_2: 4.105e-05  loss_mask_2: 0.1108  loss_dice_2: 0.1728  loss_ce_3: 2.123e-05  loss_mask_3: 0.1074  loss_dice_3: 0.1635  loss_ce_4: 3.152e-05  loss_mask_4: 0.1065  loss_dice_4: 0.1563  loss_ce_5: 3.583e-05  loss_mask_5: 0.1091  loss_dice_5: 0.1595  loss_ce_6: 2.156e-05  loss_mask_6: 0.1087  loss_dice_6: 0.1638  loss_ce_7: 3.241e-05  loss_mask_7: 0.1087  loss_dice_7: 0.1656  loss_ce_8: 3.773e-05  loss_mask_8: 0.1089  loss_dice_8: 0.1694  time: 0.4836  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:22] d2.utils.events INFO:  eta: 0:01:38  iter: 34419  total_loss: 2.852  loss_ce: 2.502e-05  loss_mask: 0.1077  loss_dice: 0.1623  loss_ce_0: 0.1237  loss_mask_0: 0.1064  loss_dice_0: 0.1608  loss_ce_1: 3.121e-05  loss_mask_1: 0.1044  loss_dice_1: 0.1634  loss_ce_2: 2.764e-05  loss_mask_2: 0.1082  loss_dice_2: 0.1687  loss_ce_3: 1.217e-05  loss_mask_3: 0.1061  loss_dice_3: 0.1589  loss_ce_4: 1.706e-05  loss_mask_4: 0.1089  loss_dice_4: 0.1635  loss_ce_5: 2.159e-05  loss_mask_5: 0.1081  loss_dice_5: 0.1588  loss_ce_6: 1.583e-05  loss_mask_6: 0.1063  loss_dice_6: 0.1672  loss_ce_7: 2.197e-05  loss_mask_7: 0.1079  loss_dice_7: 0.16  loss_ce_8: 2.633e-05  loss_mask_8: 0.1056  loss_dice_8: 0.1651  time: 0.4834  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:26] d2.utils.events INFO:  eta: 0:01:34  iter: 34439  total_loss: 2.901  loss_ce: 2.625e-05  loss_mask: 0.112  loss_dice: 0.1639  loss_ce_0: 0.1244  loss_mask_0: 0.1111  loss_dice_0: 0.165  loss_ce_1: 4.383e-05  loss_mask_1: 0.1074  loss_dice_1: 0.1629  loss_ce_2: 5.009e-05  loss_mask_2: 0.1103  loss_dice_2: 0.1591  loss_ce_3: 2.358e-05  loss_mask_3: 0.1102  loss_dice_3: 0.1662  loss_ce_4: 3.287e-05  loss_mask_4: 0.1112  loss_dice_4: 0.1584  loss_ce_5: 3.898e-05  loss_mask_5: 0.1116  loss_dice_5: 0.1594  loss_ce_6: 2.397e-05  loss_mask_6: 0.1117  loss_dice_6: 0.1647  loss_ce_7: 3.466e-05  loss_mask_7: 0.1109  loss_dice_7: 0.1585  loss_ce_8: 4.066e-05  loss_mask_8: 0.1122  loss_dice_8: 0.1678  time: 0.4832  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:29] d2.utils.events INFO:  eta: 0:01:31  iter: 34459  total_loss: 2.841  loss_ce: 2.746e-05  loss_mask: 0.1061  loss_dice: 0.1617  loss_ce_0: 0.1236  loss_mask_0: 0.1111  loss_dice_0: 0.1694  loss_ce_1: 4.896e-05  loss_mask_1: 0.1088  loss_dice_1: 0.1653  loss_ce_2: 5.008e-05  loss_mask_2: 0.1059  loss_dice_2: 0.1599  loss_ce_3: 2.79e-05  loss_mask_3: 0.1095  loss_dice_3: 0.1691  loss_ce_4: 3.26e-05  loss_mask_4: 0.1088  loss_dice_4: 0.1687  loss_ce_5: 3.899e-05  loss_mask_5: 0.1079  loss_dice_5: 0.1647  loss_ce_6: 2.688e-05  loss_mask_6: 0.1096  loss_dice_6: 0.1664  loss_ce_7: 3.625e-05  loss_mask_7: 0.1083  loss_dice_7: 0.1676  loss_ce_8: 4.101e-05  loss_mask_8: 0.1096  loss_dice_8: 0.1605  time: 0.4830  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:33] d2.utils.events INFO:  eta: 0:01:28  iter: 34479  total_loss: 2.737  loss_ce: 2.595e-05  loss_mask: 0.1082  loss_dice: 0.1565  loss_ce_0: 0.1244  loss_mask_0: 0.1045  loss_dice_0: 0.1578  loss_ce_1: 3.987e-05  loss_mask_1: 0.1051  loss_dice_1: 0.1557  loss_ce_2: 4.11e-05  loss_mask_2: 0.1079  loss_dice_2: 0.1601  loss_ce_3: 1.968e-05  loss_mask_3: 0.1047  loss_dice_3: 0.155  loss_ce_4: 2.937e-05  loss_mask_4: 0.1086  loss_dice_4: 0.1591  loss_ce_5: 3.577e-05  loss_mask_5: 0.1057  loss_dice_5: 0.158  loss_ce_6: 2.121e-05  loss_mask_6: 0.1039  loss_dice_6: 0.1535  loss_ce_7: 3.113e-05  loss_mask_7: 0.1089  loss_dice_7: 0.1537  loss_ce_8: 3.654e-05  loss_mask_8: 0.105  loss_dice_8: 0.1564  time: 0.4828  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:36] d2.utils.events INFO:  eta: 0:01:24  iter: 34499  total_loss: 2.832  loss_ce: 2.562e-05  loss_mask: 0.1064  loss_dice: 0.1648  loss_ce_0: 0.124  loss_mask_0: 0.1063  loss_dice_0: 0.1679  loss_ce_1: 4.195e-05  loss_mask_1: 0.1057  loss_dice_1: 0.1631  loss_ce_2: 4.546e-05  loss_mask_2: 0.1031  loss_dice_2: 0.1665  loss_ce_3: 2.938e-05  loss_mask_3: 0.109  loss_dice_3: 0.1624  loss_ce_4: 3.256e-05  loss_mask_4: 0.1105  loss_dice_4: 0.1639  loss_ce_5: 3.601e-05  loss_mask_5: 0.1062  loss_dice_5: 0.1605  loss_ce_6: 2.465e-05  loss_mask_6: 0.1055  loss_dice_6: 0.1608  loss_ce_7: 3.287e-05  loss_mask_7: 0.1064  loss_dice_7: 0.1608  loss_ce_8: 3.775e-05  loss_mask_8: 0.1078  loss_dice_8: 0.1616  time: 0.4826  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:39] d2.utils.events INFO:  eta: 0:01:21  iter: 34519  total_loss: 2.811  loss_ce: 2.652e-05  loss_mask: 0.105  loss_dice: 0.1633  loss_ce_0: 0.1237  loss_mask_0: 0.1088  loss_dice_0: 0.1663  loss_ce_1: 5.554e-05  loss_mask_1: 0.1072  loss_dice_1: 0.1609  loss_ce_2: 4.572e-05  loss_mask_2: 0.107  loss_dice_2: 0.1611  loss_ce_3: 2.285e-05  loss_mask_3: 0.1095  loss_dice_3: 0.16  loss_ce_4: 3.21e-05  loss_mask_4: 0.1064  loss_dice_4: 0.1639  loss_ce_5: 4.325e-05  loss_mask_5: 0.1067  loss_dice_5: 0.1603  loss_ce_6: 2.257e-05  loss_mask_6: 0.1089  loss_dice_6: 0.1648  loss_ce_7: 3.463e-05  loss_mask_7: 0.1062  loss_dice_7: 0.1576  loss_ce_8: 4.401e-05  loss_mask_8: 0.1079  loss_dice_8: 0.1688  time: 0.4825  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:40:43] d2.utils.events INFO:  eta: 0:01:17  iter: 34539  total_loss: 2.954  loss_ce: 2.512e-05  loss_mask: 0.1137  loss_dice: 0.1708  loss_ce_0: 0.1237  loss_mask_0: 0.112  loss_dice_0: 0.1749  loss_ce_1: 3.826e-05  loss_mask_1: 0.1104  loss_dice_1: 0.1688  loss_ce_2: 4.14e-05  loss_mask_2: 0.114  loss_dice_2: 0.1713  loss_ce_3: 1.952e-05  loss_mask_3: 0.1102  loss_dice_3: 0.1728  loss_ce_4: 3.132e-05  loss_mask_4: 0.1106  loss_dice_4: 0.1638  loss_ce_5: 3.559e-05  loss_mask_5: 0.1137  loss_dice_5: 0.1673  loss_ce_6: 2.156e-05  loss_mask_6: 0.1083  loss_dice_6: 0.1652  loss_ce_7: 3.279e-05  loss_mask_7: 0.1116  loss_dice_7: 0.1777  loss_ce_8: 3.694e-05  loss_mask_8: 0.112  loss_dice_8: 0.1742  time: 0.4823  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:46] d2.utils.events INFO:  eta: 0:01:14  iter: 34559  total_loss: 2.835  loss_ce: 2.586e-05  loss_mask: 0.1108  loss_dice: 0.1569  loss_ce_0: 0.124  loss_mask_0: 0.1094  loss_dice_0: 0.16  loss_ce_1: 4.01e-05  loss_mask_1: 0.1101  loss_dice_1: 0.1619  loss_ce_2: 4.026e-05  loss_mask_2: 0.1088  loss_dice_2: 0.1611  loss_ce_3: 2.084e-05  loss_mask_3: 0.1112  loss_dice_3: 0.1622  loss_ce_4: 2.936e-05  loss_mask_4: 0.1118  loss_dice_4: 0.16  loss_ce_5: 3.554e-05  loss_mask_5: 0.1151  loss_dice_5: 0.1656  loss_ce_6: 2.204e-05  loss_mask_6: 0.11  loss_dice_6: 0.1604  loss_ce_7: 3.117e-05  loss_mask_7: 0.1114  loss_dice_7: 0.1611  loss_ce_8: 3.623e-05  loss_mask_8: 0.11  loss_dice_8: 0.1638  time: 0.4821  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:49] d2.utils.events INFO:  eta: 0:01:11  iter: 34579  total_loss: 2.875  loss_ce: 2.619e-05  loss_mask: 0.1083  loss_dice: 0.1667  loss_ce_0: 0.1237  loss_mask_0: 0.1107  loss_dice_0: 0.167  loss_ce_1: 4.2e-05  loss_mask_1: 0.1081  loss_dice_1: 0.1669  loss_ce_2: 4.6e-05  loss_mask_2: 0.1087  loss_dice_2: 0.1635  loss_ce_3: 2.435e-05  loss_mask_3: 0.1078  loss_dice_3: 0.1629  loss_ce_4: 3.302e-05  loss_mask_4: 0.1052  loss_dice_4: 0.163  loss_ce_5: 3.889e-05  loss_mask_5: 0.1083  loss_dice_5: 0.1599  loss_ce_6: 2.417e-05  loss_mask_6: 0.1073  loss_dice_6: 0.1636  loss_ce_7: 3.217e-05  loss_mask_7: 0.1083  loss_dice_7: 0.1623  loss_ce_8: 3.947e-05  loss_mask_8: 0.1102  loss_dice_8: 0.1687  time: 0.4819  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:40:53] d2.utils.events INFO:  eta: 0:01:07  iter: 34599  total_loss: 2.888  loss_ce: 2.487e-05  loss_mask: 0.107  loss_dice: 0.1618  loss_ce_0: 0.1237  loss_mask_0: 0.1129  loss_dice_0: 0.1663  loss_ce_1: 4.525e-05  loss_mask_1: 0.1129  loss_dice_1: 0.1686  loss_ce_2: 4.11e-05  loss_mask_2: 0.1102  loss_dice_2: 0.1651  loss_ce_3: 2.164e-05  loss_mask_3: 0.11  loss_dice_3: 0.1674  loss_ce_4: 3.072e-05  loss_mask_4: 0.1143  loss_dice_4: 0.1643  loss_ce_5: 3.584e-05  loss_mask_5: 0.1108  loss_dice_5: 0.1699  loss_ce_6: 2.293e-05  loss_mask_6: 0.112  loss_dice_6: 0.1617  loss_ce_7: 3.362e-05  loss_mask_7: 0.11  loss_dice_7: 0.1667  loss_ce_8: 3.742e-05  loss_mask_8: 0.108  loss_dice_8: 0.1624  time: 0.4817  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:56] d2.utils.events INFO:  eta: 0:01:04  iter: 34619  total_loss: 2.831  loss_ce: 2.549e-05  loss_mask: 0.1082  loss_dice: 0.1572  loss_ce_0: 0.1304  loss_mask_0: 0.1062  loss_dice_0: 0.1633  loss_ce_1: 5.183e-05  loss_mask_1: 0.109  loss_dice_1: 0.1634  loss_ce_2: 4.1e-05  loss_mask_2: 0.1078  loss_dice_2: 0.1614  loss_ce_3: 2.08e-05  loss_mask_3: 0.1107  loss_dice_3: 0.1628  loss_ce_4: 2.978e-05  loss_mask_4: 0.1066  loss_dice_4: 0.1604  loss_ce_5: 3.902e-05  loss_mask_5: 0.1067  loss_dice_5: 0.1646  loss_ce_6: 2.227e-05  loss_mask_6: 0.1078  loss_dice_6: 0.164  loss_ce_7: 3.463e-05  loss_mask_7: 0.1125  loss_dice_7: 0.167  loss_ce_8: 4.112e-05  loss_mask_8: 0.1098  loss_dice_8: 0.1643  time: 0.4816  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:40:59] d2.utils.events INFO:  eta: 0:01:00  iter: 34639  total_loss: 2.883  loss_ce: 2.607e-05  loss_mask: 0.1096  loss_dice: 0.169  loss_ce_0: 0.1237  loss_mask_0: 0.1092  loss_dice_0: 0.1697  loss_ce_1: 4.469e-05  loss_mask_1: 0.1123  loss_dice_1: 0.1648  loss_ce_2: 4.648e-05  loss_mask_2: 0.1106  loss_dice_2: 0.164  loss_ce_3: 2.542e-05  loss_mask_3: 0.1067  loss_dice_3: 0.1637  loss_ce_4: 3.183e-05  loss_mask_4: 0.1111  loss_dice_4: 0.165  loss_ce_5: 3.96e-05  loss_mask_5: 0.1124  loss_dice_5: 0.174  loss_ce_6: 2.5e-05  loss_mask_6: 0.1072  loss_dice_6: 0.1633  loss_ce_7: 3.375e-05  loss_mask_7: 0.1157  loss_dice_7: 0.1724  loss_ce_8: 4.034e-05  loss_mask_8: 0.1098  loss_dice_8: 0.1675  time: 0.4814  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:41:03] d2.utils.events INFO:  eta: 0:00:57  iter: 34659  total_loss: 2.787  loss_ce: 2.522e-05  loss_mask: 0.1056  loss_dice: 0.1594  loss_ce_0: 0.1243  loss_mask_0: 0.1105  loss_dice_0: 0.1623  loss_ce_1: 3.807e-05  loss_mask_1: 0.1133  loss_dice_1: 0.1617  loss_ce_2: 3.337e-05  loss_mask_2: 0.1063  loss_dice_2: 0.1621  loss_ce_3: 1.996e-05  loss_mask_3: 0.1092  loss_dice_3: 0.1585  loss_ce_4: 1.723e-05  loss_mask_4: 0.1077  loss_dice_4: 0.157  loss_ce_5: 2.224e-05  loss_mask_5: 0.1056  loss_dice_5: 0.1532  loss_ce_6: 2.009e-05  loss_mask_6: 0.1105  loss_dice_6: 0.1604  loss_ce_7: 3.105e-05  loss_mask_7: 0.1081  loss_dice_7: 0.1552  loss_ce_8: 2.768e-05  loss_mask_8: 0.1123  loss_dice_8: 0.1623  time: 0.4812  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:41:06] d2.utils.events INFO:  eta: 0:00:54  iter: 34679  total_loss: 2.869  loss_ce: 2.532e-05  loss_mask: 0.1094  loss_dice: 0.1649  loss_ce_0: 0.1237  loss_mask_0: 0.1109  loss_dice_0: 0.1635  loss_ce_1: 4.058e-05  loss_mask_1: 0.1099  loss_dice_1: 0.163  loss_ce_2: 4.295e-05  loss_mask_2: 0.1097  loss_dice_2: 0.1692  loss_ce_3: 2.003e-05  loss_mask_3: 0.1106  loss_dice_3: 0.1619  loss_ce_4: 2.996e-05  loss_mask_4: 0.1101  loss_dice_4: 0.164  loss_ce_5: 3.579e-05  loss_mask_5: 0.1097  loss_dice_5: 0.1635  loss_ce_6: 2.105e-05  loss_mask_6: 0.1092  loss_dice_6: 0.1602  loss_ce_7: 3.305e-05  loss_mask_7: 0.1123  loss_dice_7: 0.1599  loss_ce_8: 3.543e-05  loss_mask_8: 0.1118  loss_dice_8: 0.1663  time: 0.4810  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:41:09] d2.utils.events INFO:  eta: 0:00:50  iter: 34699  total_loss: 2.864  loss_ce: 2.57e-05  loss_mask: 0.1062  loss_dice: 0.1661  loss_ce_0: 0.1242  loss_mask_0: 0.1125  loss_dice_0: 0.1694  loss_ce_1: 3.68e-05  loss_mask_1: 0.1099  loss_dice_1: 0.1647  loss_ce_2: 4.158e-05  loss_mask_2: 0.1072  loss_dice_2: 0.1578  loss_ce_3: 2.152e-05  loss_mask_3: 0.1072  loss_dice_3: 0.1618  loss_ce_4: 2.925e-05  loss_mask_4: 0.1079  loss_dice_4: 0.162  loss_ce_5: 4.331e-05  loss_mask_5: 0.1065  loss_dice_5: 0.1657  loss_ce_6: 2.162e-05  loss_mask_6: 0.1102  loss_dice_6: 0.1599  loss_ce_7: 3.252e-05  loss_mask_7: 0.109  loss_dice_7: 0.1696  loss_ce_8: 4.363e-05  loss_mask_8: 0.1104  loss_dice_8: 0.1677  time: 0.4808  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:41:13] d2.utils.events INFO:  eta: 0:00:47  iter: 34719  total_loss: 2.925  loss_ce: 2.479e-05  loss_mask: 0.1118  loss_dice: 0.1694  loss_ce_0: 0.1237  loss_mask_0: 0.1083  loss_dice_0: 0.1672  loss_ce_1: 3.637e-05  loss_mask_1: 0.1111  loss_dice_1: 0.1644  loss_ce_2: 3.941e-05  loss_mask_2: 0.1068  loss_dice_2: 0.1691  loss_ce_3: 1.642e-05  loss_mask_3: 0.1114  loss_dice_3: 0.1671  loss_ce_4: 2.409e-05  loss_mask_4: 0.1089  loss_dice_4: 0.1585  loss_ce_5: 2.876e-05  loss_mask_5: 0.1079  loss_dice_5: 0.1638  loss_ce_6: 1.844e-05  loss_mask_6: 0.1093  loss_dice_6: 0.168  loss_ce_7: 3.029e-05  loss_mask_7: 0.1088  loss_dice_7: 0.1628  loss_ce_8: 3.19e-05  loss_mask_8: 0.1134  loss_dice_8: 0.1679  time: 0.4807  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:41:16] d2.utils.events INFO:  eta: 0:00:43  iter: 34739  total_loss: 2.95  loss_ce: 2.682e-05  loss_mask: 0.1116  loss_dice: 0.1643  loss_ce_0: 0.1139  loss_mask_0: 0.1096  loss_dice_0: 0.1731  loss_ce_1: 5.529e-05  loss_mask_1: 0.11  loss_dice_1: 0.1632  loss_ce_2: 5.606e-05  loss_mask_2: 0.1105  loss_dice_2: 0.1621  loss_ce_3: 2.82e-05  loss_mask_3: 0.1105  loss_dice_3: 0.1668  loss_ce_4: 3.278e-05  loss_mask_4: 0.1088  loss_dice_4: 0.1662  loss_ce_5: 4.778e-05  loss_mask_5: 0.1105  loss_dice_5: 0.1659  loss_ce_6: 2.299e-05  loss_mask_6: 0.1119  loss_dice_6: 0.1666  loss_ce_7: 3.748e-05  loss_mask_7: 0.1104  loss_dice_7: 0.1658  loss_ce_8: 4.606e-05  loss_mask_8: 0.112  loss_dice_8: 0.1708  time: 0.4805  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:41:20] d2.utils.events INFO:  eta: 0:00:40  iter: 34759  total_loss: 2.853  loss_ce: 2.82e-05  loss_mask: 0.1123  loss_dice: 0.1621  loss_ce_0: 0.1236  loss_mask_0: 0.1118  loss_dice_0: 0.1697  loss_ce_1: 4.055e-05  loss_mask_1: 0.1082  loss_dice_1: 0.1628  loss_ce_2: 5.118e-05  loss_mask_2: 0.1114  loss_dice_2: 0.165  loss_ce_3: 3.094e-05  loss_mask_3: 0.1103  loss_dice_3: 0.1632  loss_ce_4: 3.475e-05  loss_mask_4: 0.1129  loss_dice_4: 0.1578  loss_ce_5: 3.873e-05  loss_mask_5: 0.1136  loss_dice_5: 0.1651  loss_ce_6: 2.59e-05  loss_mask_6: 0.1126  loss_dice_6: 0.1658  loss_ce_7: 3.508e-05  loss_mask_7: 0.1088  loss_dice_7: 0.1641  loss_ce_8: 3.93e-05  loss_mask_8: 0.1138  loss_dice_8: 0.1711  time: 0.4803  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:41:23] d2.utils.events INFO:  eta: 0:00:37  iter: 34779  total_loss: 2.928  loss_ce: 2.265e-05  loss_mask: 0.1126  loss_dice: 0.1668  loss_ce_0: 0.1236  loss_mask_0: 0.1152  loss_dice_0: 0.1706  loss_ce_1: 3.042e-05  loss_mask_1: 0.1111  loss_dice_1: 0.1636  loss_ce_2: 3.047e-05  loss_mask_2: 0.109  loss_dice_2: 0.1644  loss_ce_3: 1.498e-05  loss_mask_3: 0.1143  loss_dice_3: 0.1646  loss_ce_4: 1.572e-05  loss_mask_4: 0.1083  loss_dice_4: 0.1573  loss_ce_5: 2.222e-05  loss_mask_5: 0.113  loss_dice_5: 0.1653  loss_ce_6: 1.628e-05  loss_mask_6: 0.1105  loss_dice_6: 0.1608  loss_ce_7: 2.002e-05  loss_mask_7: 0.1116  loss_dice_7: 0.1584  loss_ce_8: 2.594e-05  loss_mask_8: 0.1093  loss_dice_8: 0.1589  time: 0.4801  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:41:26] d2.utils.events INFO:  eta: 0:00:33  iter: 34799  total_loss: 2.882  loss_ce: 2.634e-05  loss_mask: 0.1094  loss_dice: 0.1642  loss_ce_0: 0.1243  loss_mask_0: 0.1126  loss_dice_0: 0.1652  loss_ce_1: 4.199e-05  loss_mask_1: 0.1104  loss_dice_1: 0.165  loss_ce_2: 4.087e-05  loss_mask_2: 0.1082  loss_dice_2: 0.1619  loss_ce_3: 2.055e-05  loss_mask_3: 0.1116  loss_dice_3: 0.1657  loss_ce_4: 3.046e-05  loss_mask_4: 0.1139  loss_dice_4: 0.1602  loss_ce_5: 3.906e-05  loss_mask_5: 0.1083  loss_dice_5: 0.1619  loss_ce_6: 2.213e-05  loss_mask_6: 0.1103  loss_dice_6: 0.1655  loss_ce_7: 3.324e-05  loss_mask_7: 0.1056  loss_dice_7: 0.1669  loss_ce_8: 4.051e-05  loss_mask_8: 0.1118  loss_dice_8: 0.1706  time: 0.4799  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:41:30] d2.utils.events INFO:  eta: 0:00:30  iter: 34819  total_loss: 2.788  loss_ce: 2.598e-05  loss_mask: 0.1086  loss_dice: 0.1527  loss_ce_0: 0.1243  loss_mask_0: 0.1074  loss_dice_0: 0.158  loss_ce_1: 3.858e-05  loss_mask_1: 0.1087  loss_dice_1: 0.1588  loss_ce_2: 3.547e-05  loss_mask_2: 0.1094  loss_dice_2: 0.1615  loss_ce_3: 1.765e-05  loss_mask_3: 0.1058  loss_dice_3: 0.1538  loss_ce_4: 2.684e-05  loss_mask_4: 0.1062  loss_dice_4: 0.1575  loss_ce_5: 2.97e-05  loss_mask_5: 0.1061  loss_dice_5: 0.1545  loss_ce_6: 2.029e-05  loss_mask_6: 0.1097  loss_dice_6: 0.1623  loss_ce_7: 2.791e-05  loss_mask_7: 0.1102  loss_dice_7: 0.1614  loss_ce_8: 3.169e-05  loss_mask_8: 0.1104  loss_dice_8: 0.161  time: 0.4798  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:41:33] d2.utils.events INFO:  eta: 0:00:27  iter: 34839  total_loss: 2.82  loss_ce: 2.57e-05  loss_mask: 0.1143  loss_dice: 0.1627  loss_ce_0: 0.1236  loss_mask_0: 0.1096  loss_dice_0: 0.1614  loss_ce_1: 4.066e-05  loss_mask_1: 0.1129  loss_dice_1: 0.1668  loss_ce_2: 4.012e-05  loss_mask_2: 0.1115  loss_dice_2: 0.1634  loss_ce_3: 2.001e-05  loss_mask_3: 0.1087  loss_dice_3: 0.157  loss_ce_4: 2.909e-05  loss_mask_4: 0.1101  loss_dice_4: 0.1585  loss_ce_5: 3.552e-05  loss_mask_5: 0.1119  loss_dice_5: 0.168  loss_ce_6: 2.162e-05  loss_mask_6: 0.111  loss_dice_6: 0.1579  loss_ce_7: 3.188e-05  loss_mask_7: 0.1102  loss_dice_7: 0.1615  loss_ce_8: 3.62e-05  loss_mask_8: 0.1109  loss_dice_8: 0.1589  time: 0.4796  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:41:36] d2.utils.events INFO:  eta: 0:00:23  iter: 34859  total_loss: 2.815  loss_ce: 2.555e-05  loss_mask: 0.1082  loss_dice: 0.1682  loss_ce_0: 0.1302  loss_mask_0: 0.1091  loss_dice_0: 0.1644  loss_ce_1: 3.089e-05  loss_mask_1: 0.1085  loss_dice_1: 0.16  loss_ce_2: 3.217e-05  loss_mask_2: 0.1107  loss_dice_2: 0.1639  loss_ce_3: 1.562e-05  loss_mask_3: 0.1106  loss_dice_3: 0.1652  loss_ce_4: 1.78e-05  loss_mask_4: 0.1104  loss_dice_4: 0.161  loss_ce_5: 2.241e-05  loss_mask_5: 0.1061  loss_dice_5: 0.1567  loss_ce_6: 1.706e-05  loss_mask_6: 0.1085  loss_dice_6: 0.1675  loss_ce_7: 2.502e-05  loss_mask_7: 0.1078  loss_dice_7: 0.1567  loss_ce_8: 2.626e-05  loss_mask_8: 0.1062  loss_dice_8: 0.1614  time: 0.4794  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:41:40] d2.utils.events INFO:  eta: 0:00:20  iter: 34879  total_loss: 2.919  loss_ce: 2.603e-05  loss_mask: 0.106  loss_dice: 0.1663  loss_ce_0: 0.1242  loss_mask_0: 0.1074  loss_dice_0: 0.1639  loss_ce_1: 4.156e-05  loss_mask_1: 0.1067  loss_dice_1: 0.163  loss_ce_2: 4.146e-05  loss_mask_2: 0.1097  loss_dice_2: 0.1649  loss_ce_3: 2.287e-05  loss_mask_3: 0.1115  loss_dice_3: 0.1643  loss_ce_4: 3.189e-05  loss_mask_4: 0.1059  loss_dice_4: 0.1603  loss_ce_5: 3.896e-05  loss_mask_5: 0.1098  loss_dice_5: 0.1672  loss_ce_6: 2.359e-05  loss_mask_6: 0.1116  loss_dice_6: 0.1675  loss_ce_7: 3.217e-05  loss_mask_7: 0.1101  loss_dice_7: 0.168  loss_ce_8: 4.044e-05  loss_mask_8: 0.1083  loss_dice_8: 0.1675  time: 0.4792  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:41:43] d2.utils.events INFO:  eta: 0:00:16  iter: 34899  total_loss: 3.027  loss_ce: 2.818e-05  loss_mask: 0.1153  loss_dice: 0.1718  loss_ce_0: 0.1141  loss_mask_0: 0.1192  loss_dice_0: 0.1813  loss_ce_1: 5.509e-05  loss_mask_1: 0.1158  loss_dice_1: 0.1757  loss_ce_2: 5.386e-05  loss_mask_2: 0.1154  loss_dice_2: 0.172  loss_ce_3: 2.12e-05  loss_mask_3: 0.1182  loss_dice_3: 0.1736  loss_ce_4: 3.242e-05  loss_mask_4: 0.1187  loss_dice_4: 0.1838  loss_ce_5: 5.328e-05  loss_mask_5: 0.1174  loss_dice_5: 0.1745  loss_ce_6: 2.286e-05  loss_mask_6: 0.1176  loss_dice_6: 0.1731  loss_ce_7: 3.687e-05  loss_mask_7: 0.1196  loss_dice_7: 0.1763  loss_ce_8: 5.199e-05  loss_mask_8: 0.1149  loss_dice_8: 0.1725  time: 0.4790  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:41:46] d2.utils.events INFO:  eta: 0:00:13  iter: 34919  total_loss: 2.751  loss_ce: 2.53e-05  loss_mask: 0.1094  loss_dice: 0.1644  loss_ce_0: 0.1236  loss_mask_0: 0.1033  loss_dice_0: 0.1583  loss_ce_1: 4.214e-05  loss_mask_1: 0.1031  loss_dice_1: 0.1615  loss_ce_2: 5.147e-05  loss_mask_2: 0.1016  loss_dice_2: 0.1609  loss_ce_3: 2.156e-05  loss_mask_3: 0.1028  loss_dice_3: 0.1605  loss_ce_4: 3.168e-05  loss_mask_4: 0.1065  loss_dice_4: 0.1613  loss_ce_5: 4e-05  loss_mask_5: 0.1036  loss_dice_5: 0.1604  loss_ce_6: 2.189e-05  loss_mask_6: 0.1016  loss_dice_6: 0.1575  loss_ce_7: 3.551e-05  loss_mask_7: 0.1062  loss_dice_7: 0.1649  loss_ce_8: 4.087e-05  loss_mask_8: 0.1027  loss_dice_8: 0.162  time: 0.4789  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:41:50] d2.utils.events INFO:  eta: 0:00:10  iter: 34939  total_loss: 2.836  loss_ce: 2.493e-05  loss_mask: 0.1071  loss_dice: 0.168  loss_ce_0: 0.1239  loss_mask_0: 0.1089  loss_dice_0: 0.1676  loss_ce_1: 3.573e-05  loss_mask_1: 0.1078  loss_dice_1: 0.1648  loss_ce_2: 3.555e-05  loss_mask_2: 0.1065  loss_dice_2: 0.1655  loss_ce_3: 1.958e-05  loss_mask_3: 0.1078  loss_dice_3: 0.1686  loss_ce_4: 2.252e-05  loss_mask_4: 0.1085  loss_dice_4: 0.1693  loss_ce_5: 2.873e-05  loss_mask_5: 0.1107  loss_dice_5: 0.1679  loss_ce_6: 2.109e-05  loss_mask_6: 0.1037  loss_dice_6: 0.1588  loss_ce_7: 2.614e-05  loss_mask_7: 0.1055  loss_dice_7: 0.1657  loss_ce_8: 3.085e-05  loss_mask_8: 0.1085  loss_dice_8: 0.1723  time: 0.4787  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:41:53] d2.utils.events INFO:  eta: 0:00:06  iter: 34959  total_loss: 2.782  loss_ce: 2.546e-05  loss_mask: 0.1107  loss_dice: 0.1579  loss_ce_0: 0.1236  loss_mask_0: 0.1096  loss_dice_0: 0.1591  loss_ce_1: 4.337e-05  loss_mask_1: 0.1099  loss_dice_1: 0.1636  loss_ce_2: 4.141e-05  loss_mask_2: 0.1107  loss_dice_2: 0.1651  loss_ce_3: 2.321e-05  loss_mask_3: 0.11  loss_dice_3: 0.1637  loss_ce_4: 3.128e-05  loss_mask_4: 0.1067  loss_dice_4: 0.1562  loss_ce_5: 3.551e-05  loss_mask_5: 0.1114  loss_dice_5: 0.1641  loss_ce_6: 2.298e-05  loss_mask_6: 0.1113  loss_dice_6: 0.1589  loss_ce_7: 3.52e-05  loss_mask_7: 0.113  loss_dice_7: 0.1643  loss_ce_8: 3.66e-05  loss_mask_8: 0.1103  loss_dice_8: 0.1589  time: 0.4785  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:41:57] d2.utils.events INFO:  eta: 0:00:03  iter: 34979  total_loss: 2.856  loss_ce: 2.954e-05  loss_mask: 0.1073  loss_dice: 0.1666  loss_ce_0: 0.1235  loss_mask_0: 0.1083  loss_dice_0: 0.171  loss_ce_1: 4.869e-05  loss_mask_1: 0.1059  loss_dice_1: 0.1632  loss_ce_2: 4.108e-05  loss_mask_2: 0.1105  loss_dice_2: 0.1736  loss_ce_3: 2.331e-05  loss_mask_3: 0.1122  loss_dice_3: 0.1732  loss_ce_4: 3.267e-05  loss_mask_4: 0.1118  loss_dice_4: 0.1684  loss_ce_5: 4.162e-05  loss_mask_5: 0.1107  loss_dice_5: 0.1711  loss_ce_6: 2.359e-05  loss_mask_6: 0.1072  loss_dice_6: 0.1677  loss_ce_7: 3.394e-05  loss_mask_7: 0.1075  loss_dice_7: 0.169  loss_ce_8: 4.636e-05  loss_mask_8: 0.1083  loss_dice_8: 0.1658  time: 0.4783  data_time: 0.0011  lr: 1e-06  max_mem: 8444M
[08/01 22:42:00] fvcore.common.checkpoint INFO: Saving checkpoint to ./R101_overlap/model_0034999.pth
[08/01 22:42:00] fvcore.common.checkpoint INFO: Saving checkpoint to ./R101_overlap/model_final.pth
[08/01 22:42:00] d2.utils.events INFO:  eta: 0:00:00  iter: 34999  total_loss: 2.897  loss_ce: 2.779e-05  loss_mask: 0.111  loss_dice: 0.1686  loss_ce_0: 0.1243  loss_mask_0: 0.1155  loss_dice_0: 0.1692  loss_ce_1: 4.425e-05  loss_mask_1: 0.11  loss_dice_1: 0.1724  loss_ce_2: 4.164e-05  loss_mask_2: 0.1108  loss_dice_2: 0.1632  loss_ce_3: 2.362e-05  loss_mask_3: 0.1084  loss_dice_3: 0.169  loss_ce_4: 3.194e-05  loss_mask_4: 0.1125  loss_dice_4: 0.17  loss_ce_5: 4.296e-05  loss_mask_5: 0.1074  loss_dice_5: 0.1654  loss_ce_6: 2.368e-05  loss_mask_6: 0.11  loss_dice_6: 0.1722  loss_ce_7: 3.4e-05  loss_mask_7: 0.1085  loss_dice_7: 0.165  loss_ce_8: 4.473e-05  loss_mask_8: 0.1114  loss_dice_8: 0.1696  time: 0.4781  data_time: 0.0012  lr: 1e-06  max_mem: 8444M
[08/01 22:42:00] d2.engine.hooks INFO: Overall training speed: 34998 iterations in 4:38:54 (0.4782 s / it)
[08/01 22:42:00] d2.engine.hooks INFO: Total training time: 6:11:34 (1:32:40 on hooks)
[08/01 22:42:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(256, 256), max_size=256, sample_style='choice')]
[08/01 22:42:00] d2.data.common INFO: Serializing 535 elements to byte tensors and concatenating them all ...
[08/01 22:42:00] d2.data.common INFO: Serialized dataset takes 0.22 MiB
[08/01 22:42:01] d2.evaluation.evaluator INFO: Start inference on 535 batches
[08/01 22:42:12] d2.evaluation.evaluator INFO: Inference done 11/535. Dataloading: 0.0037 s/iter. Inference: 0.0961 s/iter. Eval: 0.9100 s/iter. Total: 1.0097 s/iter. ETA=0:08:49
[08/01 22:42:17] d2.evaluation.evaluator INFO: Inference done 16/535. Dataloading: 0.0023 s/iter. Inference: 0.0948 s/iter. Eval: 0.9101 s/iter. Total: 1.0073 s/iter. ETA=0:08:42
[08/01 22:42:22] d2.evaluation.evaluator INFO: Inference done 21/535. Dataloading: 0.0018 s/iter. Inference: 0.0963 s/iter. Eval: 0.9100 s/iter. Total: 1.0082 s/iter. ETA=0:08:38
[08/01 22:42:27] d2.evaluation.evaluator INFO: Inference done 26/535. Dataloading: 0.0015 s/iter. Inference: 0.0951 s/iter. Eval: 0.9104 s/iter. Total: 1.0071 s/iter. ETA=0:08:32
[08/01 22:42:32] d2.evaluation.evaluator INFO: Inference done 31/535. Dataloading: 0.0014 s/iter. Inference: 0.0958 s/iter. Eval: 0.9106 s/iter. Total: 1.0078 s/iter. ETA=0:08:27
[08/01 22:42:37] d2.evaluation.evaluator INFO: Inference done 36/535. Dataloading: 0.0013 s/iter. Inference: 0.0954 s/iter. Eval: 0.9104 s/iter. Total: 1.0072 s/iter. ETA=0:08:22
[08/01 22:42:42] d2.evaluation.evaluator INFO: Inference done 41/535. Dataloading: 0.0012 s/iter. Inference: 0.0959 s/iter. Eval: 0.9105 s/iter. Total: 1.0077 s/iter. ETA=0:08:17
[08/01 22:42:47] d2.evaluation.evaluator INFO: Inference done 46/535. Dataloading: 0.0011 s/iter. Inference: 0.0952 s/iter. Eval: 0.9104 s/iter. Total: 1.0068 s/iter. ETA=0:08:12
[08/01 22:42:52] d2.evaluation.evaluator INFO: Inference done 51/535. Dataloading: 0.0011 s/iter. Inference: 0.0955 s/iter. Eval: 0.9103 s/iter. Total: 1.0069 s/iter. ETA=0:08:07
[08/01 22:42:57] d2.evaluation.evaluator INFO: Inference done 56/535. Dataloading: 0.0010 s/iter. Inference: 0.0959 s/iter. Eval: 0.9099 s/iter. Total: 1.0070 s/iter. ETA=0:08:02
[08/01 22:43:02] d2.evaluation.evaluator INFO: Inference done 61/535. Dataloading: 0.0010 s/iter. Inference: 0.0958 s/iter. Eval: 0.9096 s/iter. Total: 1.0064 s/iter. ETA=0:07:57
[08/01 22:43:07] d2.evaluation.evaluator INFO: Inference done 66/535. Dataloading: 0.0010 s/iter. Inference: 0.0957 s/iter. Eval: 0.9095 s/iter. Total: 1.0062 s/iter. ETA=0:07:51
[08/01 22:43:12] d2.evaluation.evaluator INFO: Inference done 71/535. Dataloading: 0.0010 s/iter. Inference: 0.0958 s/iter. Eval: 0.9099 s/iter. Total: 1.0067 s/iter. ETA=0:07:47
[08/01 22:43:17] d2.evaluation.evaluator INFO: Inference done 76/535. Dataloading: 0.0009 s/iter. Inference: 0.0958 s/iter. Eval: 0.9097 s/iter. Total: 1.0066 s/iter. ETA=0:07:42
[08/01 22:43:23] d2.evaluation.evaluator INFO: Inference done 82/535. Dataloading: 0.0009 s/iter. Inference: 0.0956 s/iter. Eval: 0.9095 s/iter. Total: 1.0061 s/iter. ETA=0:07:35
[08/01 22:43:29] d2.evaluation.evaluator INFO: Inference done 87/535. Dataloading: 0.0009 s/iter. Inference: 0.0960 s/iter. Eval: 0.9107 s/iter. Total: 1.0077 s/iter. ETA=0:07:31
[08/01 22:43:34] d2.evaluation.evaluator INFO: Inference done 92/535. Dataloading: 0.0009 s/iter. Inference: 0.0962 s/iter. Eval: 0.9107 s/iter. Total: 1.0079 s/iter. ETA=0:07:26
[08/01 22:43:39] d2.evaluation.evaluator INFO: Inference done 97/535. Dataloading: 0.0009 s/iter. Inference: 0.0960 s/iter. Eval: 0.9107 s/iter. Total: 1.0077 s/iter. ETA=0:07:21
[08/01 22:43:44] d2.evaluation.evaluator INFO: Inference done 102/535. Dataloading: 0.0009 s/iter. Inference: 0.0961 s/iter. Eval: 0.9106 s/iter. Total: 1.0077 s/iter. ETA=0:07:16
[08/01 22:43:49] d2.evaluation.evaluator INFO: Inference done 107/535. Dataloading: 0.0009 s/iter. Inference: 0.0960 s/iter. Eval: 0.9105 s/iter. Total: 1.0075 s/iter. ETA=0:07:11
[08/01 22:43:54] d2.evaluation.evaluator INFO: Inference done 112/535. Dataloading: 0.0009 s/iter. Inference: 0.0958 s/iter. Eval: 0.9104 s/iter. Total: 1.0072 s/iter. ETA=0:07:06
[08/01 22:43:59] d2.evaluation.evaluator INFO: Inference done 117/535. Dataloading: 0.0009 s/iter. Inference: 0.0960 s/iter. Eval: 0.9105 s/iter. Total: 1.0075 s/iter. ETA=0:07:01
[08/01 22:44:04] d2.evaluation.evaluator INFO: Inference done 122/535. Dataloading: 0.0008 s/iter. Inference: 0.0960 s/iter. Eval: 0.9105 s/iter. Total: 1.0075 s/iter. ETA=0:06:56
[08/01 22:44:10] d2.evaluation.evaluator INFO: Inference done 128/535. Dataloading: 0.0008 s/iter. Inference: 0.0958 s/iter. Eval: 0.9104 s/iter. Total: 1.0071 s/iter. ETA=0:06:49
[08/01 22:44:15] d2.evaluation.evaluator INFO: Inference done 133/535. Dataloading: 0.0008 s/iter. Inference: 0.0959 s/iter. Eval: 0.9102 s/iter. Total: 1.0070 s/iter. ETA=0:06:44
[08/01 22:44:20] d2.evaluation.evaluator INFO: Inference done 138/535. Dataloading: 0.0008 s/iter. Inference: 0.0957 s/iter. Eval: 0.9103 s/iter. Total: 1.0069 s/iter. ETA=0:06:39
[08/01 22:44:25] d2.evaluation.evaluator INFO: Inference done 143/535. Dataloading: 0.0008 s/iter. Inference: 0.0957 s/iter. Eval: 0.9104 s/iter. Total: 1.0070 s/iter. ETA=0:06:34
[08/01 22:44:30] d2.evaluation.evaluator INFO: Inference done 148/535. Dataloading: 0.0008 s/iter. Inference: 0.0956 s/iter. Eval: 0.9104 s/iter. Total: 1.0069 s/iter. ETA=0:06:29
[08/01 22:44:35] d2.evaluation.evaluator INFO: Inference done 153/535. Dataloading: 0.0008 s/iter. Inference: 0.0954 s/iter. Eval: 0.9105 s/iter. Total: 1.0069 s/iter. ETA=0:06:24
[08/01 22:44:40] d2.evaluation.evaluator INFO: Inference done 158/535. Dataloading: 0.0008 s/iter. Inference: 0.0956 s/iter. Eval: 0.9106 s/iter. Total: 1.0071 s/iter. ETA=0:06:19
[08/01 22:44:45] d2.evaluation.evaluator INFO: Inference done 163/535. Dataloading: 0.0008 s/iter. Inference: 0.0957 s/iter. Eval: 0.9106 s/iter. Total: 1.0072 s/iter. ETA=0:06:14
[08/01 22:44:50] d2.evaluation.evaluator INFO: Inference done 168/535. Dataloading: 0.0008 s/iter. Inference: 0.0957 s/iter. Eval: 0.9105 s/iter. Total: 1.0071 s/iter. ETA=0:06:09
[08/01 22:44:56] d2.evaluation.evaluator INFO: Inference done 174/535. Dataloading: 0.0008 s/iter. Inference: 0.0956 s/iter. Eval: 0.9104 s/iter. Total: 1.0069 s/iter. ETA=0:06:03
[08/01 22:45:01] d2.evaluation.evaluator INFO: Inference done 179/535. Dataloading: 0.0008 s/iter. Inference: 0.0955 s/iter. Eval: 0.9103 s/iter. Total: 1.0067 s/iter. ETA=0:05:58
[08/01 22:45:06] d2.evaluation.evaluator INFO: Inference done 184/535. Dataloading: 0.0008 s/iter. Inference: 0.0957 s/iter. Eval: 0.9106 s/iter. Total: 1.0072 s/iter. ETA=0:05:53
[08/01 22:45:11] d2.evaluation.evaluator INFO: Inference done 189/535. Dataloading: 0.0008 s/iter. Inference: 0.0957 s/iter. Eval: 0.9107 s/iter. Total: 1.0074 s/iter. ETA=0:05:48
[08/01 22:45:16] d2.evaluation.evaluator INFO: Inference done 194/535. Dataloading: 0.0008 s/iter. Inference: 0.0958 s/iter. Eval: 0.9108 s/iter. Total: 1.0075 s/iter. ETA=0:05:43
[08/01 22:45:21] d2.evaluation.evaluator INFO: Inference done 199/535. Dataloading: 0.0008 s/iter. Inference: 0.0957 s/iter. Eval: 0.9109 s/iter. Total: 1.0075 s/iter. ETA=0:05:38
[08/01 22:45:26] d2.evaluation.evaluator INFO: Inference done 204/535. Dataloading: 0.0008 s/iter. Inference: 0.0957 s/iter. Eval: 0.9109 s/iter. Total: 1.0075 s/iter. ETA=0:05:33
[08/01 22:45:31] d2.evaluation.evaluator INFO: Inference done 209/535. Dataloading: 0.0008 s/iter. Inference: 0.0957 s/iter. Eval: 0.9109 s/iter. Total: 1.0074 s/iter. ETA=0:05:28
[08/01 22:45:36] d2.evaluation.evaluator INFO: Inference done 214/535. Dataloading: 0.0008 s/iter. Inference: 0.0956 s/iter. Eval: 0.9108 s/iter. Total: 1.0073 s/iter. ETA=0:05:23
[08/01 22:45:42] d2.evaluation.evaluator INFO: Inference done 219/535. Dataloading: 0.0008 s/iter. Inference: 0.0957 s/iter. Eval: 0.9109 s/iter. Total: 1.0075 s/iter. ETA=0:05:18
[08/01 22:45:47] d2.evaluation.evaluator INFO: Inference done 224/535. Dataloading: 0.0008 s/iter. Inference: 0.0958 s/iter. Eval: 0.9108 s/iter. Total: 1.0075 s/iter. ETA=0:05:13
[08/01 22:45:52] d2.evaluation.evaluator INFO: Inference done 229/535. Dataloading: 0.0008 s/iter. Inference: 0.0957 s/iter. Eval: 0.9108 s/iter. Total: 1.0073 s/iter. ETA=0:05:08
[08/01 22:45:57] d2.evaluation.evaluator INFO: Inference done 234/535. Dataloading: 0.0008 s/iter. Inference: 0.0957 s/iter. Eval: 0.9107 s/iter. Total: 1.0072 s/iter. ETA=0:05:03
[08/01 22:46:02] d2.evaluation.evaluator INFO: Inference done 239/535. Dataloading: 0.0008 s/iter. Inference: 0.0956 s/iter. Eval: 0.9106 s/iter. Total: 1.0071 s/iter. ETA=0:04:58
[08/01 22:46:07] d2.evaluation.evaluator INFO: Inference done 244/535. Dataloading: 0.0008 s/iter. Inference: 0.0957 s/iter. Eval: 0.9105 s/iter. Total: 1.0071 s/iter. ETA=0:04:53
[08/01 22:46:12] d2.evaluation.evaluator INFO: Inference done 249/535. Dataloading: 0.0008 s/iter. Inference: 0.0956 s/iter. Eval: 0.9105 s/iter. Total: 1.0070 s/iter. ETA=0:04:48
[08/01 22:46:17] d2.evaluation.evaluator INFO: Inference done 254/535. Dataloading: 0.0008 s/iter. Inference: 0.0956 s/iter. Eval: 0.9105 s/iter. Total: 1.0070 s/iter. ETA=0:04:42
[08/01 22:46:22] d2.evaluation.evaluator INFO: Inference done 259/535. Dataloading: 0.0008 s/iter. Inference: 0.0956 s/iter. Eval: 0.9105 s/iter. Total: 1.0070 s/iter. ETA=0:04:37
[08/01 22:46:27] d2.evaluation.evaluator INFO: Inference done 264/535. Dataloading: 0.0008 s/iter. Inference: 0.0955 s/iter. Eval: 0.9105 s/iter. Total: 1.0069 s/iter. ETA=0:04:32
[08/01 22:46:32] d2.evaluation.evaluator INFO: Inference done 269/535. Dataloading: 0.0008 s/iter. Inference: 0.0956 s/iter. Eval: 0.9105 s/iter. Total: 1.0069 s/iter. ETA=0:04:27
[08/01 22:46:37] d2.evaluation.evaluator INFO: Inference done 274/535. Dataloading: 0.0008 s/iter. Inference: 0.0955 s/iter. Eval: 0.9104 s/iter. Total: 1.0068 s/iter. ETA=0:04:22
[08/01 22:46:42] d2.evaluation.evaluator INFO: Inference done 279/535. Dataloading: 0.0008 s/iter. Inference: 0.0955 s/iter. Eval: 0.9104 s/iter. Total: 1.0067 s/iter. ETA=0:04:17
[08/01 22:46:48] d2.evaluation.evaluator INFO: Inference done 285/535. Dataloading: 0.0008 s/iter. Inference: 0.0954 s/iter. Eval: 0.9103 s/iter. Total: 1.0066 s/iter. ETA=0:04:11
[08/01 22:46:54] d2.evaluation.evaluator INFO: Inference done 291/535. Dataloading: 0.0008 s/iter. Inference: 0.0953 s/iter. Eval: 0.9104 s/iter. Total: 1.0066 s/iter. ETA=0:04:05
[08/01 22:46:59] d2.evaluation.evaluator INFO: Inference done 296/535. Dataloading: 0.0008 s/iter. Inference: 0.0953 s/iter. Eval: 0.9112 s/iter. Total: 1.0073 s/iter. ETA=0:04:00
[08/01 22:47:04] d2.evaluation.evaluator INFO: Inference done 301/535. Dataloading: 0.0008 s/iter. Inference: 0.0952 s/iter. Eval: 0.9115 s/iter. Total: 1.0076 s/iter. ETA=0:03:55
[08/01 22:47:09] d2.evaluation.evaluator INFO: Inference done 306/535. Dataloading: 0.0008 s/iter. Inference: 0.0951 s/iter. Eval: 0.9117 s/iter. Total: 1.0077 s/iter. ETA=0:03:50
[08/01 22:47:14] d2.evaluation.evaluator INFO: Inference done 311/535. Dataloading: 0.0008 s/iter. Inference: 0.0954 s/iter. Eval: 0.9118 s/iter. Total: 1.0080 s/iter. ETA=0:03:45
[08/01 22:47:19] d2.evaluation.evaluator INFO: Inference done 316/535. Dataloading: 0.0008 s/iter. Inference: 0.0954 s/iter. Eval: 0.9119 s/iter. Total: 1.0081 s/iter. ETA=0:03:40
[08/01 22:47:24] d2.evaluation.evaluator INFO: Inference done 321/535. Dataloading: 0.0008 s/iter. Inference: 0.0954 s/iter. Eval: 0.9120 s/iter. Total: 1.0082 s/iter. ETA=0:03:35
[08/01 22:47:30] d2.evaluation.evaluator INFO: Inference done 326/535. Dataloading: 0.0008 s/iter. Inference: 0.0952 s/iter. Eval: 0.9121 s/iter. Total: 1.0082 s/iter. ETA=0:03:30
[08/01 22:47:35] d2.evaluation.evaluator INFO: Inference done 331/535. Dataloading: 0.0008 s/iter. Inference: 0.0953 s/iter. Eval: 0.9122 s/iter. Total: 1.0083 s/iter. ETA=0:03:25
[08/01 22:47:40] d2.evaluation.evaluator INFO: Inference done 336/535. Dataloading: 0.0008 s/iter. Inference: 0.0952 s/iter. Eval: 0.9122 s/iter. Total: 1.0083 s/iter. ETA=0:03:20
[08/01 22:47:45] d2.evaluation.evaluator INFO: Inference done 341/535. Dataloading: 0.0008 s/iter. Inference: 0.0952 s/iter. Eval: 0.9123 s/iter. Total: 1.0083 s/iter. ETA=0:03:15
[08/01 22:47:50] d2.evaluation.evaluator INFO: Inference done 346/535. Dataloading: 0.0008 s/iter. Inference: 0.0951 s/iter. Eval: 0.9124 s/iter. Total: 1.0083 s/iter. ETA=0:03:10
[08/01 22:47:55] d2.evaluation.evaluator INFO: Inference done 351/535. Dataloading: 0.0007 s/iter. Inference: 0.0951 s/iter. Eval: 0.9125 s/iter. Total: 1.0084 s/iter. ETA=0:03:05
[08/01 22:48:00] d2.evaluation.evaluator INFO: Inference done 356/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9125 s/iter. Total: 1.0084 s/iter. ETA=0:03:00
[08/01 22:48:05] d2.evaluation.evaluator INFO: Inference done 361/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9126 s/iter. Total: 1.0084 s/iter. ETA=0:02:55
[08/01 22:48:10] d2.evaluation.evaluator INFO: Inference done 366/535. Dataloading: 0.0007 s/iter. Inference: 0.0950 s/iter. Eval: 0.9127 s/iter. Total: 1.0085 s/iter. ETA=0:02:50
[08/01 22:48:15] d2.evaluation.evaluator INFO: Inference done 371/535. Dataloading: 0.0007 s/iter. Inference: 0.0949 s/iter. Eval: 0.9129 s/iter. Total: 1.0087 s/iter. ETA=0:02:45
[08/01 22:48:20] d2.evaluation.evaluator INFO: Inference done 376/535. Dataloading: 0.0007 s/iter. Inference: 0.0949 s/iter. Eval: 0.9131 s/iter. Total: 1.0088 s/iter. ETA=0:02:40
[08/01 22:48:25] d2.evaluation.evaluator INFO: Inference done 381/535. Dataloading: 0.0007 s/iter. Inference: 0.0948 s/iter. Eval: 0.9132 s/iter. Total: 1.0089 s/iter. ETA=0:02:35
[08/01 22:48:30] d2.evaluation.evaluator INFO: Inference done 386/535. Dataloading: 0.0007 s/iter. Inference: 0.0948 s/iter. Eval: 0.9133 s/iter. Total: 1.0090 s/iter. ETA=0:02:30
[08/01 22:48:35] d2.evaluation.evaluator INFO: Inference done 391/535. Dataloading: 0.0007 s/iter. Inference: 0.0947 s/iter. Eval: 0.9135 s/iter. Total: 1.0090 s/iter. ETA=0:02:25
[08/01 22:48:40] d2.evaluation.evaluator INFO: Inference done 396/535. Dataloading: 0.0007 s/iter. Inference: 0.0947 s/iter. Eval: 0.9135 s/iter. Total: 1.0091 s/iter. ETA=0:02:20
[08/01 22:48:46] d2.evaluation.evaluator INFO: Inference done 401/535. Dataloading: 0.0007 s/iter. Inference: 0.0947 s/iter. Eval: 0.9136 s/iter. Total: 1.0091 s/iter. ETA=0:02:15
[08/01 22:48:51] d2.evaluation.evaluator INFO: Inference done 406/535. Dataloading: 0.0007 s/iter. Inference: 0.0947 s/iter. Eval: 0.9137 s/iter. Total: 1.0092 s/iter. ETA=0:02:10
[08/01 22:48:56] d2.evaluation.evaluator INFO: Inference done 411/535. Dataloading: 0.0007 s/iter. Inference: 0.0947 s/iter. Eval: 0.9137 s/iter. Total: 1.0092 s/iter. ETA=0:02:05
[08/01 22:49:01] d2.evaluation.evaluator INFO: Inference done 416/535. Dataloading: 0.0007 s/iter. Inference: 0.0946 s/iter. Eval: 0.9138 s/iter. Total: 1.0093 s/iter. ETA=0:02:00
[08/01 22:49:06] d2.evaluation.evaluator INFO: Inference done 421/535. Dataloading: 0.0007 s/iter. Inference: 0.0946 s/iter. Eval: 0.9139 s/iter. Total: 1.0093 s/iter. ETA=0:01:55
[08/01 22:49:11] d2.evaluation.evaluator INFO: Inference done 426/535. Dataloading: 0.0007 s/iter. Inference: 0.0946 s/iter. Eval: 0.9140 s/iter. Total: 1.0094 s/iter. ETA=0:01:50
[08/01 22:49:16] d2.evaluation.evaluator INFO: Inference done 431/535. Dataloading: 0.0007 s/iter. Inference: 0.0946 s/iter. Eval: 0.9140 s/iter. Total: 1.0094 s/iter. ETA=0:01:44
[08/01 22:49:21] d2.evaluation.evaluator INFO: Inference done 436/535. Dataloading: 0.0007 s/iter. Inference: 0.0945 s/iter. Eval: 0.9141 s/iter. Total: 1.0094 s/iter. ETA=0:01:39
[08/01 22:49:26] d2.evaluation.evaluator INFO: Inference done 441/535. Dataloading: 0.0007 s/iter. Inference: 0.0946 s/iter. Eval: 0.9141 s/iter. Total: 1.0095 s/iter. ETA=0:01:34
[08/01 22:49:31] d2.evaluation.evaluator INFO: Inference done 446/535. Dataloading: 0.0007 s/iter. Inference: 0.0945 s/iter. Eval: 0.9142 s/iter. Total: 1.0096 s/iter. ETA=0:01:29
[08/01 22:49:36] d2.evaluation.evaluator INFO: Inference done 451/535. Dataloading: 0.0007 s/iter. Inference: 0.0945 s/iter. Eval: 0.9143 s/iter. Total: 1.0097 s/iter. ETA=0:01:24
[08/01 22:49:41] d2.evaluation.evaluator INFO: Inference done 456/535. Dataloading: 0.0007 s/iter. Inference: 0.0945 s/iter. Eval: 0.9144 s/iter. Total: 1.0097 s/iter. ETA=0:01:19
[08/01 22:49:46] d2.evaluation.evaluator INFO: Inference done 461/535. Dataloading: 0.0007 s/iter. Inference: 0.0945 s/iter. Eval: 0.9144 s/iter. Total: 1.0097 s/iter. ETA=0:01:14
[08/01 22:49:51] d2.evaluation.evaluator INFO: Inference done 466/535. Dataloading: 0.0007 s/iter. Inference: 0.0944 s/iter. Eval: 0.9145 s/iter. Total: 1.0098 s/iter. ETA=0:01:09
[08/01 22:49:56] d2.evaluation.evaluator INFO: Inference done 471/535. Dataloading: 0.0007 s/iter. Inference: 0.0944 s/iter. Eval: 0.9146 s/iter. Total: 1.0099 s/iter. ETA=0:01:04
[08/01 22:50:02] d2.evaluation.evaluator INFO: Inference done 476/535. Dataloading: 0.0007 s/iter. Inference: 0.0944 s/iter. Eval: 0.9147 s/iter. Total: 1.0098 s/iter. ETA=0:00:59
[08/01 22:50:07] d2.evaluation.evaluator INFO: Inference done 481/535. Dataloading: 0.0007 s/iter. Inference: 0.0944 s/iter. Eval: 0.9147 s/iter. Total: 1.0099 s/iter. ETA=0:00:54
[08/01 22:50:12] d2.evaluation.evaluator INFO: Inference done 486/535. Dataloading: 0.0007 s/iter. Inference: 0.0944 s/iter. Eval: 0.9148 s/iter. Total: 1.0099 s/iter. ETA=0:00:49
[08/01 22:50:17] d2.evaluation.evaluator INFO: Inference done 491/535. Dataloading: 0.0007 s/iter. Inference: 0.0944 s/iter. Eval: 0.9148 s/iter. Total: 1.0100 s/iter. ETA=0:00:44
[08/01 22:50:22] d2.evaluation.evaluator INFO: Inference done 496/535. Dataloading: 0.0007 s/iter. Inference: 0.0944 s/iter. Eval: 0.9149 s/iter. Total: 1.0101 s/iter. ETA=0:00:39
[08/01 22:50:27] d2.evaluation.evaluator INFO: Inference done 501/535. Dataloading: 0.0007 s/iter. Inference: 0.0943 s/iter. Eval: 0.9149 s/iter. Total: 1.0101 s/iter. ETA=0:00:34
[08/01 22:50:32] d2.evaluation.evaluator INFO: Inference done 506/535. Dataloading: 0.0007 s/iter. Inference: 0.0943 s/iter. Eval: 0.9149 s/iter. Total: 1.0101 s/iter. ETA=0:00:29
[08/01 22:50:37] d2.evaluation.evaluator INFO: Inference done 511/535. Dataloading: 0.0007 s/iter. Inference: 0.0943 s/iter. Eval: 0.9150 s/iter. Total: 1.0101 s/iter. ETA=0:00:24
[08/01 22:50:42] d2.evaluation.evaluator INFO: Inference done 516/535. Dataloading: 0.0007 s/iter. Inference: 0.0944 s/iter. Eval: 0.9150 s/iter. Total: 1.0102 s/iter. ETA=0:00:19
[08/01 22:50:47] d2.evaluation.evaluator INFO: Inference done 521/535. Dataloading: 0.0007 s/iter. Inference: 0.0943 s/iter. Eval: 0.9150 s/iter. Total: 1.0102 s/iter. ETA=0:00:14
[08/01 22:50:52] d2.evaluation.evaluator INFO: Inference done 526/535. Dataloading: 0.0007 s/iter. Inference: 0.0943 s/iter. Eval: 0.9151 s/iter. Total: 1.0102 s/iter. ETA=0:00:09
[08/01 22:50:57] d2.evaluation.evaluator INFO: Inference done 531/535. Dataloading: 0.0007 s/iter. Inference: 0.0943 s/iter. Eval: 0.9154 s/iter. Total: 1.0104 s/iter. ETA=0:00:04
[08/01 22:51:02] d2.evaluation.evaluator INFO: Total inference time: 0:08:55.614148 (1.010593 s / iter per device, on 1 devices)
[08/01 22:51:02] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:49 (0.094219 s / iter per device, on 1 devices)
[08/01 22:51:02] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[08/01 22:51:02] d2.evaluation.coco_evaluation INFO: Saving results to ./R101_overlap/inference/coco_instances_results.json
[08/01 22:51:03] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[08/01 22:51:04] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 |  nan  | 0.000 |
[08/01 22:51:04] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 22:51:04] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| normal     | 0.000 | defect     | 0.000 |
[08/01 22:51:10] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50   |  AP75  |  APs   |  APm  |  APl   |
|:------:|:-------:|:------:|:------:|:-----:|:------:|
| 99.074 | 100.000 | 99.505 | 94.258 |  nan  | 99.074 |
[08/01 22:51:10] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/01 22:51:10] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| normal     | 99.454 | defect     | 98.695 |
[08/01 22:51:10] d2.engine.defaults INFO: Evaluation results for front2class_2017_val_overlap_panoptic in csv format:
[08/01 22:51:10] d2.evaluation.testing INFO: copypaste: Task: bbox
[08/01 22:51:10] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 22:51:10] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,nan,0.0000
[08/01 22:51:10] d2.evaluation.testing INFO: copypaste: Task: segm
[08/01 22:51:10] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/01 22:51:10] d2.evaluation.testing INFO: copypaste: 99.0744,100.0000,99.5050,94.2577,nan,99.0744
[08/01 22:51:10] d2.engine.hooks INFO: Not saving as latest eval score for total_loss is 2.81776, not better than best score 2.42329 @ iteration 24999.
[08/02 14:03:36] detectron2 INFO: Rank of current process: 0. World size: 1
[08/02 14:03:37] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.20.1
detectron2              0.6 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.1
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA RTX A6000 (arch=8.6)
Driver version          470.129.06
CUDA_HOME               /usr
Pillow                  8.1.0
torchvision             0.10.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220305
iopath                  0.1.9
cv2                     4.5.5
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[08/02 14:03:37] detectron2 INFO: Command line arguments: Namespace(config_file='/home/tqsang/Mask2Former/R101_overlap/config_test.yaml', dist_url='tcp://127.0.0.1:50158', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/home/tqsang/Mask2Former/R101_overlap/model_final.pth'], resume=False)
[08/02 14:03:37] detectron2 INFO: Contents of args.config_file=/home/tqsang/Mask2Former/R101_overlap/config_test.yaml:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_test_overlap_panoptic[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/MSRA/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/02 14:03:37] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_test_overlap_panoptic[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/tqsang/Mask2Former/R101_overlap/model_final.pth[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/02 14:03:37] detectron2 INFO: Full config saved to ./R101_overlap/config.yaml
[08/02 14:03:37] d2.utils.env INFO: Using a generated random seed 40062638
[08/02 14:03:41] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (deconv_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv2_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=3, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 2
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/02 14:03:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/tqsang/Mask2Former/R101_overlap/model_final.pth ...
[08/02 14:04:02] detectron2 INFO: Rank of current process: 0. World size: 1
[08/02 14:04:03] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.20.1
detectron2              0.6 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.1
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA RTX A6000 (arch=8.6)
Driver version          470.129.06
CUDA_HOME               /usr
Pillow                  8.1.0
torchvision             0.10.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220305
iopath                  0.1.9
cv2                     4.5.5
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[08/02 14:04:03] detectron2 INFO: Command line arguments: Namespace(config_file='/home/tqsang/Mask2Former/R101_overlap/config_test.yaml', dist_url='tcp://127.0.0.1:50158', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/home/tqsang/Mask2Former/R101_overlap/model_final.pth'], resume=False)
[08/02 14:04:03] detectron2 INFO: Contents of args.config_file=/home/tqsang/Mask2Former/R101_overlap/config_test.yaml:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_test_overlap_panoptic[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_instance_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/MSRA/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/02 14:04:03] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_test_overlap_panoptic[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_instance_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/tqsang/Mask2Former/R101_overlap/model_final.pth[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/02 14:04:03] detectron2 INFO: Full config saved to ./R101_overlap/config.yaml
[08/02 14:04:03] d2.utils.env INFO: Using a generated random seed 5302678
[08/02 14:04:06] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (deconv_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv2_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=3, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 2
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/02 14:04:06] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/tqsang/Mask2Former/R101_overlap/model_final.pth ...
[08/02 14:04:54] detectron2 INFO: Rank of current process: 0. World size: 1
[08/02 14:04:56] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.20.1
detectron2              0.6 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.1
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA RTX A6000 (arch=8.6)
Driver version          470.129.06
CUDA_HOME               /usr
Pillow                  8.1.0
torchvision             0.10.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220305
iopath                  0.1.9
cv2                     4.5.5
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[08/02 14:04:56] detectron2 INFO: Command line arguments: Namespace(config_file='/home/tqsang/Mask2Former/R101_overlap/config_test.yaml', dist_url='tcp://127.0.0.1:50158', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/home/tqsang/Mask2Former/R101_overlap/model_final.pth'], resume=False)
[08/02 14:04:56] detectron2 INFO: Contents of args.config_file=/home/tqsang/Mask2Former/R101_overlap/config_test.yaml:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mchick_dataset_test_overlap[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/MSRA/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/02 14:04:56] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mchick_dataset_test_overlap[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/tqsang/Mask2Former/R101_overlap/model_final.pth[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/02 14:04:56] detectron2 INFO: Full config saved to ./R101_overlap/config.yaml
[08/02 14:04:56] d2.utils.env INFO: Using a generated random seed 58242883
[08/02 14:04:59] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (deconv_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv2_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=3, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 2
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/02 14:04:59] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/tqsang/Mask2Former/R101_overlap/model_final.pth ...
[08/02 14:04:59] d2.data.datasets.coco INFO: Loaded 392 images in COCO format from /home/tqsang/V100/tqsang/crop_obj/front_2_class_overlap/annotations/instances_test2017.json
[08/02 14:04:59] d2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|   normal   | 359          |   defect   | 267          |
|            |              |            |              |
|   total    | 626          |            |              |[0m
[08/02 14:04:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(256, 256), max_size=256, sample_style='choice')]
[08/02 14:04:59] d2.data.common INFO: Serializing 392 elements to byte tensors and concatenating them all ...
[08/02 14:04:59] d2.data.common INFO: Serialized dataset takes 5.71 MiB
[08/02 14:04:59] d2.evaluation.evaluator INFO: Start inference on 392 batches
[08/02 14:05:10] d2.evaluation.evaluator INFO: Inference done 11/392. Dataloading: 0.0006 s/iter. Inference: 0.0679 s/iter. Eval: 0.8317 s/iter. Total: 0.9002 s/iter. ETA=0:05:42
[08/02 14:05:16] d2.evaluation.evaluator INFO: Inference done 17/392. Dataloading: 0.0006 s/iter. Inference: 0.0683 s/iter. Eval: 0.8579 s/iter. Total: 0.9269 s/iter. ETA=0:05:47
[08/02 14:05:22] d2.evaluation.evaluator INFO: Inference done 23/392. Dataloading: 0.0007 s/iter. Inference: 0.0694 s/iter. Eval: 0.8683 s/iter. Total: 0.9384 s/iter. ETA=0:05:46
[08/02 14:05:28] d2.evaluation.evaluator INFO: Inference done 29/392. Dataloading: 0.0007 s/iter. Inference: 0.0678 s/iter. Eval: 0.8748 s/iter. Total: 0.9433 s/iter. ETA=0:05:42
[08/02 14:05:33] d2.evaluation.evaluator INFO: Inference done 35/392. Dataloading: 0.0007 s/iter. Inference: 0.0679 s/iter. Eval: 0.8775 s/iter. Total: 0.9461 s/iter. ETA=0:05:37
[08/02 14:05:39] d2.evaluation.evaluator INFO: Inference done 41/392. Dataloading: 0.0007 s/iter. Inference: 0.0682 s/iter. Eval: 0.8794 s/iter. Total: 0.9484 s/iter. ETA=0:05:32
[08/02 14:05:45] d2.evaluation.evaluator INFO: Inference done 47/392. Dataloading: 0.0007 s/iter. Inference: 0.0678 s/iter. Eval: 0.8808 s/iter. Total: 0.9494 s/iter. ETA=0:05:27
[08/02 14:05:50] d2.evaluation.evaluator INFO: Inference done 53/392. Dataloading: 0.0007 s/iter. Inference: 0.0684 s/iter. Eval: 0.8795 s/iter. Total: 0.9486 s/iter. ETA=0:05:21
[08/02 14:05:56] d2.evaluation.evaluator INFO: Inference done 59/392. Dataloading: 0.0007 s/iter. Inference: 0.0689 s/iter. Eval: 0.8793 s/iter. Total: 0.9491 s/iter. ETA=0:05:16
[08/02 14:06:02] d2.evaluation.evaluator INFO: Inference done 65/392. Dataloading: 0.0007 s/iter. Inference: 0.0686 s/iter. Eval: 0.8801 s/iter. Total: 0.9495 s/iter. ETA=0:05:10
[08/02 14:06:08] d2.evaluation.evaluator INFO: Inference done 71/392. Dataloading: 0.0007 s/iter. Inference: 0.0679 s/iter. Eval: 0.8801 s/iter. Total: 0.9487 s/iter. ETA=0:05:04
[08/02 14:06:13] d2.evaluation.evaluator INFO: Inference done 77/392. Dataloading: 0.0007 s/iter. Inference: 0.0679 s/iter. Eval: 0.8820 s/iter. Total: 0.9506 s/iter. ETA=0:04:59
[08/02 14:06:19] d2.evaluation.evaluator INFO: Inference done 83/392. Dataloading: 0.0007 s/iter. Inference: 0.0679 s/iter. Eval: 0.8815 s/iter. Total: 0.9502 s/iter. ETA=0:04:53
[08/02 14:06:25] d2.evaluation.evaluator INFO: Inference done 89/392. Dataloading: 0.0007 s/iter. Inference: 0.0678 s/iter. Eval: 0.8829 s/iter. Total: 0.9515 s/iter. ETA=0:04:48
[08/02 14:06:31] d2.evaluation.evaluator INFO: Inference done 95/392. Dataloading: 0.0007 s/iter. Inference: 0.0679 s/iter. Eval: 0.8839 s/iter. Total: 0.9525 s/iter. ETA=0:04:42
[08/02 14:06:36] d2.evaluation.evaluator INFO: Inference done 101/392. Dataloading: 0.0007 s/iter. Inference: 0.0680 s/iter. Eval: 0.8846 s/iter. Total: 0.9534 s/iter. ETA=0:04:37
[08/02 14:06:42] d2.evaluation.evaluator INFO: Inference done 107/392. Dataloading: 0.0007 s/iter. Inference: 0.0682 s/iter. Eval: 0.8843 s/iter. Total: 0.9532 s/iter. ETA=0:04:31
[08/02 14:06:48] d2.evaluation.evaluator INFO: Inference done 113/392. Dataloading: 0.0007 s/iter. Inference: 0.0683 s/iter. Eval: 0.8836 s/iter. Total: 0.9527 s/iter. ETA=0:04:25
[08/02 14:06:54] d2.evaluation.evaluator INFO: Inference done 119/392. Dataloading: 0.0007 s/iter. Inference: 0.0682 s/iter. Eval: 0.8838 s/iter. Total: 0.9528 s/iter. ETA=0:04:20
[08/02 14:06:59] d2.evaluation.evaluator INFO: Inference done 125/392. Dataloading: 0.0007 s/iter. Inference: 0.0682 s/iter. Eval: 0.8852 s/iter. Total: 0.9542 s/iter. ETA=0:04:14
[08/02 14:07:05] d2.evaluation.evaluator INFO: Inference done 131/392. Dataloading: 0.0007 s/iter. Inference: 0.0680 s/iter. Eval: 0.8846 s/iter. Total: 0.9533 s/iter. ETA=0:04:08
[08/02 14:07:11] d2.evaluation.evaluator INFO: Inference done 137/392. Dataloading: 0.0007 s/iter. Inference: 0.0679 s/iter. Eval: 0.8848 s/iter. Total: 0.9535 s/iter. ETA=0:04:03
[08/02 14:07:17] d2.evaluation.evaluator INFO: Inference done 143/392. Dataloading: 0.0007 s/iter. Inference: 0.0680 s/iter. Eval: 0.8847 s/iter. Total: 0.9535 s/iter. ETA=0:03:57
[08/02 14:07:22] d2.evaluation.evaluator INFO: Inference done 149/392. Dataloading: 0.0007 s/iter. Inference: 0.0680 s/iter. Eval: 0.8843 s/iter. Total: 0.9530 s/iter. ETA=0:03:51
[08/02 14:07:28] d2.evaluation.evaluator INFO: Inference done 155/392. Dataloading: 0.0007 s/iter. Inference: 0.0677 s/iter. Eval: 0.8833 s/iter. Total: 0.9518 s/iter. ETA=0:03:45
[08/02 14:07:34] d2.evaluation.evaluator INFO: Inference done 161/392. Dataloading: 0.0007 s/iter. Inference: 0.0677 s/iter. Eval: 0.8846 s/iter. Total: 0.9531 s/iter. ETA=0:03:40
[08/02 14:07:40] d2.evaluation.evaluator INFO: Inference done 167/392. Dataloading: 0.0007 s/iter. Inference: 0.0677 s/iter. Eval: 0.8863 s/iter. Total: 0.9547 s/iter. ETA=0:03:34
[08/02 14:07:45] d2.evaluation.evaluator INFO: Inference done 173/392. Dataloading: 0.0007 s/iter. Inference: 0.0678 s/iter. Eval: 0.8870 s/iter. Total: 0.9556 s/iter. ETA=0:03:29
[08/02 14:07:51] d2.evaluation.evaluator INFO: Inference done 179/392. Dataloading: 0.0007 s/iter. Inference: 0.0678 s/iter. Eval: 0.8878 s/iter. Total: 0.9563 s/iter. ETA=0:03:23
[08/02 14:07:57] d2.evaluation.evaluator INFO: Inference done 185/392. Dataloading: 0.0007 s/iter. Inference: 0.0677 s/iter. Eval: 0.8880 s/iter. Total: 0.9565 s/iter. ETA=0:03:17
[08/02 14:08:02] d2.evaluation.evaluator INFO: Inference done 190/392. Dataloading: 0.0007 s/iter. Inference: 0.0679 s/iter. Eval: 0.8894 s/iter. Total: 0.9581 s/iter. ETA=0:03:13
[08/02 14:08:07] d2.evaluation.evaluator INFO: Inference done 195/392. Dataloading: 0.0007 s/iter. Inference: 0.0681 s/iter. Eval: 0.8912 s/iter. Total: 0.9600 s/iter. ETA=0:03:09
[08/02 14:08:12] d2.evaluation.evaluator INFO: Inference done 200/392. Dataloading: 0.0007 s/iter. Inference: 0.0681 s/iter. Eval: 0.8925 s/iter. Total: 0.9614 s/iter. ETA=0:03:04
[08/02 14:08:18] d2.evaluation.evaluator INFO: Inference done 206/392. Dataloading: 0.0007 s/iter. Inference: 0.0681 s/iter. Eval: 0.8936 s/iter. Total: 0.9625 s/iter. ETA=0:02:59
[08/02 14:08:24] d2.evaluation.evaluator INFO: Inference done 211/392. Dataloading: 0.0007 s/iter. Inference: 0.0682 s/iter. Eval: 0.8950 s/iter. Total: 0.9640 s/iter. ETA=0:02:54
[08/02 14:08:29] d2.evaluation.evaluator INFO: Inference done 216/392. Dataloading: 0.0007 s/iter. Inference: 0.0683 s/iter. Eval: 0.8967 s/iter. Total: 0.9657 s/iter. ETA=0:02:49
[08/02 14:08:34] d2.evaluation.evaluator INFO: Inference done 221/392. Dataloading: 0.0007 s/iter. Inference: 0.0686 s/iter. Eval: 0.8980 s/iter. Total: 0.9673 s/iter. ETA=0:02:45
[08/02 14:08:39] d2.evaluation.evaluator INFO: Inference done 226/392. Dataloading: 0.0007 s/iter. Inference: 0.0687 s/iter. Eval: 0.8991 s/iter. Total: 0.9686 s/iter. ETA=0:02:40
[08/02 14:08:44] d2.evaluation.evaluator INFO: Inference done 231/392. Dataloading: 0.0007 s/iter. Inference: 0.0689 s/iter. Eval: 0.8998 s/iter. Total: 0.9694 s/iter. ETA=0:02:36
[08/02 14:08:50] d2.evaluation.evaluator INFO: Inference done 237/392. Dataloading: 0.0007 s/iter. Inference: 0.0689 s/iter. Eval: 0.9004 s/iter. Total: 0.9701 s/iter. ETA=0:02:30
[08/02 14:08:55] d2.evaluation.evaluator INFO: Inference done 242/392. Dataloading: 0.0007 s/iter. Inference: 0.0690 s/iter. Eval: 0.9012 s/iter. Total: 0.9710 s/iter. ETA=0:02:25
[08/02 14:09:01] d2.evaluation.evaluator INFO: Inference done 248/392. Dataloading: 0.0007 s/iter. Inference: 0.0690 s/iter. Eval: 0.9018 s/iter. Total: 0.9716 s/iter. ETA=0:02:19
[08/02 14:09:06] d2.evaluation.evaluator INFO: Inference done 253/392. Dataloading: 0.0007 s/iter. Inference: 0.0691 s/iter. Eval: 0.9024 s/iter. Total: 0.9722 s/iter. ETA=0:02:15
[08/02 14:09:11] d2.evaluation.evaluator INFO: Inference done 258/392. Dataloading: 0.0007 s/iter. Inference: 0.0693 s/iter. Eval: 0.9031 s/iter. Total: 0.9731 s/iter. ETA=0:02:10
[08/02 14:09:16] d2.evaluation.evaluator INFO: Inference done 263/392. Dataloading: 0.0007 s/iter. Inference: 0.0693 s/iter. Eval: 0.9038 s/iter. Total: 0.9739 s/iter. ETA=0:02:05
[08/02 14:09:22] d2.evaluation.evaluator INFO: Inference done 269/392. Dataloading: 0.0007 s/iter. Inference: 0.0694 s/iter. Eval: 0.9044 s/iter. Total: 0.9746 s/iter. ETA=0:01:59
[08/02 14:09:27] d2.evaluation.evaluator INFO: Inference done 274/392. Dataloading: 0.0007 s/iter. Inference: 0.0695 s/iter. Eval: 0.9054 s/iter. Total: 0.9756 s/iter. ETA=0:01:55
[08/02 14:09:33] d2.evaluation.evaluator INFO: Inference done 279/392. Dataloading: 0.0007 s/iter. Inference: 0.0695 s/iter. Eval: 0.9066 s/iter. Total: 0.9769 s/iter. ETA=0:01:50
[08/02 14:09:38] d2.evaluation.evaluator INFO: Inference done 284/392. Dataloading: 0.0007 s/iter. Inference: 0.0697 s/iter. Eval: 0.9072 s/iter. Total: 0.9777 s/iter. ETA=0:01:45
[08/02 14:09:43] d2.evaluation.evaluator INFO: Inference done 289/392. Dataloading: 0.0007 s/iter. Inference: 0.0698 s/iter. Eval: 0.9082 s/iter. Total: 0.9788 s/iter. ETA=0:01:40
[08/02 14:09:48] d2.evaluation.evaluator INFO: Inference done 294/392. Dataloading: 0.0007 s/iter. Inference: 0.0698 s/iter. Eval: 0.9093 s/iter. Total: 0.9799 s/iter. ETA=0:01:36
[08/02 14:09:53] d2.evaluation.evaluator INFO: Inference done 299/392. Dataloading: 0.0007 s/iter. Inference: 0.0698 s/iter. Eval: 0.9100 s/iter. Total: 0.9806 s/iter. ETA=0:01:31
[08/02 14:09:58] d2.evaluation.evaluator INFO: Inference done 304/392. Dataloading: 0.0007 s/iter. Inference: 0.0698 s/iter. Eval: 0.9112 s/iter. Total: 0.9817 s/iter. ETA=0:01:26
[08/02 14:10:04] d2.evaluation.evaluator INFO: Inference done 309/392. Dataloading: 0.0007 s/iter. Inference: 0.0699 s/iter. Eval: 0.9118 s/iter. Total: 0.9825 s/iter. ETA=0:01:21
[08/02 14:10:09] d2.evaluation.evaluator INFO: Inference done 314/392. Dataloading: 0.0007 s/iter. Inference: 0.0699 s/iter. Eval: 0.9123 s/iter. Total: 0.9829 s/iter. ETA=0:01:16
[08/02 14:10:14] d2.evaluation.evaluator INFO: Inference done 319/392. Dataloading: 0.0007 s/iter. Inference: 0.0700 s/iter. Eval: 0.9136 s/iter. Total: 0.9844 s/iter. ETA=0:01:11
[08/02 14:10:19] d2.evaluation.evaluator INFO: Inference done 324/392. Dataloading: 0.0007 s/iter. Inference: 0.0702 s/iter. Eval: 0.9144 s/iter. Total: 0.9854 s/iter. ETA=0:01:07
[08/02 14:10:24] d2.evaluation.evaluator INFO: Inference done 329/392. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.9149 s/iter. Total: 0.9860 s/iter. ETA=0:01:02
[08/02 14:10:30] d2.evaluation.evaluator INFO: Inference done 334/392. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.9154 s/iter. Total: 0.9866 s/iter. ETA=0:00:57
[08/02 14:10:35] d2.evaluation.evaluator INFO: Inference done 339/392. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.9159 s/iter. Total: 0.9872 s/iter. ETA=0:00:52
[08/02 14:10:40] d2.evaluation.evaluator INFO: Inference done 344/392. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.9165 s/iter. Total: 0.9879 s/iter. ETA=0:00:47
[08/02 14:10:45] d2.evaluation.evaluator INFO: Inference done 349/392. Dataloading: 0.0007 s/iter. Inference: 0.0706 s/iter. Eval: 0.9169 s/iter. Total: 0.9883 s/iter. ETA=0:00:42
[08/02 14:10:50] d2.evaluation.evaluator INFO: Inference done 354/392. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.9172 s/iter. Total: 0.9885 s/iter. ETA=0:00:37
[08/02 14:10:55] d2.evaluation.evaluator INFO: Inference done 359/392. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.9181 s/iter. Total: 0.9893 s/iter. ETA=0:00:32
[08/02 14:11:00] d2.evaluation.evaluator INFO: Inference done 364/392. Dataloading: 0.0007 s/iter. Inference: 0.0705 s/iter. Eval: 0.9185 s/iter. Total: 0.9897 s/iter. ETA=0:00:27
[08/02 14:11:05] d2.evaluation.evaluator INFO: Inference done 369/392. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.9191 s/iter. Total: 0.9902 s/iter. ETA=0:00:22
[08/02 14:11:11] d2.evaluation.evaluator INFO: Inference done 374/392. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.9198 s/iter. Total: 0.9909 s/iter. ETA=0:00:17
[08/02 14:11:16] d2.evaluation.evaluator INFO: Inference done 379/392. Dataloading: 0.0007 s/iter. Inference: 0.0703 s/iter. Eval: 0.9202 s/iter. Total: 0.9914 s/iter. ETA=0:00:12
[08/02 14:11:21] d2.evaluation.evaluator INFO: Inference done 384/392. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.9207 s/iter. Total: 0.9919 s/iter. ETA=0:00:07
[08/02 14:11:26] d2.evaluation.evaluator INFO: Inference done 389/392. Dataloading: 0.0007 s/iter. Inference: 0.0704 s/iter. Eval: 0.9211 s/iter. Total: 0.9922 s/iter. ETA=0:00:02
[08/02 14:11:29] d2.evaluation.evaluator INFO: Total inference time: 0:06:24.135466 (0.992598 s / iter per device, on 1 devices)
[08/02 14:11:29] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:27 (0.070314 s / iter per device, on 1 devices)
[08/02 14:11:30] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[08/02 14:11:30] d2.evaluation.coco_evaluation INFO: Saving results to ./R101_overlap/inference/coco_instances_results.json
[08/02 14:11:30] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[08/02 14:11:32] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 |  nan  | 0.000 |
[08/02 14:11:32] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/02 14:11:32] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| normal     | 0.000 | defect     | 0.000 |
[08/02 14:11:36] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl   |
|:------:|:------:|:------:|:------:|:-----:|:------:|
| 92.863 | 98.659 | 98.180 | 49.048 |  nan  | 92.863 |
[08/02 14:11:36] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/02 14:11:36] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| normal     | 98.930 | defect     | 86.796 |
[08/02 14:11:36] d2.engine.defaults INFO: Evaluation results for chick_dataset_test_overlap in csv format:
[08/02 14:11:36] d2.evaluation.testing INFO: copypaste: Task: bbox
[08/02 14:11:36] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/02 14:11:36] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,nan,0.0000
[08/02 14:11:36] d2.evaluation.testing INFO: copypaste: Task: segm
[08/02 14:11:36] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/02 14:11:36] d2.evaluation.testing INFO: copypaste: 92.8632,98.6589,98.1798,49.0480,nan,92.8632
[08/05 00:59:29] detectron2 INFO: Rank of current process: 0. World size: 1
[08/05 00:59:30] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.20.1
detectron2              0.6 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.1
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA RTX A6000 (arch=8.6)
Driver version          470.129.06
CUDA_HOME               /usr
Pillow                  8.1.0
torchvision             0.10.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220305
iopath                  0.1.9
cv2                     4.5.5
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[08/05 00:59:30] detectron2 INFO: Command line arguments: Namespace(config_file='/home/tqsang/Mask2Former/R101_overlap/config_test.yaml', dist_url='tcp://127.0.0.1:50158', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/home/tqsang/Mask2Former/R101_overlap/model_final.pth'], resume=False)
[08/05 00:59:30] detectron2 INFO: Contents of args.config_file=/home/tqsang/Mask2Former/R101_overlap/config_test.yaml:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mchick_dataset_test_overlap[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/MSRA/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/05 00:59:30] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mchick_dataset_test_overlap[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/tqsang/Mask2Former/R101_overlap/model_final.pth[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/05 00:59:30] detectron2 INFO: Full config saved to ./R101_overlap/config.yaml
[08/05 00:59:30] d2.utils.env INFO: Using a generated random seed 34156999
[08/05 00:59:33] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (deconv_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv2_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=3, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 2
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/05 00:59:33] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/tqsang/Mask2Former/R101_overlap/model_final.pth ...
[08/05 00:59:33] d2.data.datasets.coco INFO: Loaded 392 images in COCO format from /home/tqsang/V100/tqsang/crop_obj/front_2_class_overlap/annotations/instances_test2017.json
[08/05 00:59:33] d2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|   normal   | 359          |   defect   | 267          |
|            |              |            |              |
|   total    | 626          |            |              |[0m
[08/05 00:59:33] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(256, 256), max_size=256, sample_style='choice')]
[08/05 00:59:33] d2.data.common INFO: Serializing 392 elements to byte tensors and concatenating them all ...
[08/05 00:59:33] d2.data.common INFO: Serialized dataset takes 5.71 MiB
[08/05 00:59:33] d2.evaluation.evaluator INFO: Start inference on 392 batches
[08/05 00:59:44] d2.evaluation.evaluator INFO: Inference done 11/392. Dataloading: 0.0004 s/iter. Inference: 0.0620 s/iter. Eval: 0.8356 s/iter. Total: 0.8980 s/iter. ETA=0:05:42
[08/05 00:59:49] d2.evaluation.evaluator INFO: Inference done 17/392. Dataloading: 0.0006 s/iter. Inference: 0.0616 s/iter. Eval: 0.8259 s/iter. Total: 0.8881 s/iter. ETA=0:05:33
[08/05 00:59:54] d2.evaluation.evaluator INFO: Inference done 23/392. Dataloading: 0.0006 s/iter. Inference: 0.0618 s/iter. Eval: 0.8153 s/iter. Total: 0.8778 s/iter. ETA=0:05:23
[08/05 01:00:00] d2.evaluation.evaluator INFO: Inference done 29/392. Dataloading: 0.0006 s/iter. Inference: 0.0620 s/iter. Eval: 0.8130 s/iter. Total: 0.8757 s/iter. ETA=0:05:17
[08/05 01:00:05] d2.evaluation.evaluator INFO: Inference done 35/392. Dataloading: 0.0007 s/iter. Inference: 0.0620 s/iter. Eval: 0.8150 s/iter. Total: 0.8777 s/iter. ETA=0:05:13
[08/05 01:00:10] d2.evaluation.evaluator INFO: Inference done 41/392. Dataloading: 0.0007 s/iter. Inference: 0.0618 s/iter. Eval: 0.8183 s/iter. Total: 0.8808 s/iter. ETA=0:05:09
[08/05 01:00:16] d2.evaluation.evaluator INFO: Inference done 47/392. Dataloading: 0.0007 s/iter. Inference: 0.0620 s/iter. Eval: 0.8252 s/iter. Total: 0.8879 s/iter. ETA=0:05:06
[08/05 01:00:22] d2.evaluation.evaluator INFO: Inference done 53/392. Dataloading: 0.0007 s/iter. Inference: 0.0621 s/iter. Eval: 0.8346 s/iter. Total: 0.8975 s/iter. ETA=0:05:04
[08/05 01:00:27] d2.evaluation.evaluator INFO: Inference done 59/392. Dataloading: 0.0007 s/iter. Inference: 0.0628 s/iter. Eval: 0.8407 s/iter. Total: 0.9042 s/iter. ETA=0:05:01
[08/05 01:00:33] d2.evaluation.evaluator INFO: Inference done 65/392. Dataloading: 0.0007 s/iter. Inference: 0.0627 s/iter. Eval: 0.8463 s/iter. Total: 0.9098 s/iter. ETA=0:04:57
[08/05 01:00:39] d2.evaluation.evaluator INFO: Inference done 71/392. Dataloading: 0.0007 s/iter. Inference: 0.0633 s/iter. Eval: 0.8506 s/iter. Total: 0.9146 s/iter. ETA=0:04:53
[08/05 01:00:45] d2.evaluation.evaluator INFO: Inference done 77/392. Dataloading: 0.0007 s/iter. Inference: 0.0634 s/iter. Eval: 0.8531 s/iter. Total: 0.9172 s/iter. ETA=0:04:48
[08/05 01:00:50] d2.evaluation.evaluator INFO: Inference done 83/392. Dataloading: 0.0007 s/iter. Inference: 0.0637 s/iter. Eval: 0.8558 s/iter. Total: 0.9202 s/iter. ETA=0:04:44
[08/05 01:00:56] d2.evaluation.evaluator INFO: Inference done 89/392. Dataloading: 0.0007 s/iter. Inference: 0.0640 s/iter. Eval: 0.8581 s/iter. Total: 0.9228 s/iter. ETA=0:04:39
[08/05 01:01:02] d2.evaluation.evaluator INFO: Inference done 95/392. Dataloading: 0.0007 s/iter. Inference: 0.0641 s/iter. Eval: 0.8608 s/iter. Total: 0.9257 s/iter. ETA=0:04:34
[08/05 01:01:08] d2.evaluation.evaluator INFO: Inference done 101/392. Dataloading: 0.0007 s/iter. Inference: 0.0645 s/iter. Eval: 0.8627 s/iter. Total: 0.9280 s/iter. ETA=0:04:30
[08/05 01:01:13] d2.evaluation.evaluator INFO: Inference done 107/392. Dataloading: 0.0007 s/iter. Inference: 0.0648 s/iter. Eval: 0.8642 s/iter. Total: 0.9297 s/iter. ETA=0:04:24
[08/05 01:01:19] d2.evaluation.evaluator INFO: Inference done 113/392. Dataloading: 0.0007 s/iter. Inference: 0.0650 s/iter. Eval: 0.8655 s/iter. Total: 0.9313 s/iter. ETA=0:04:19
[08/05 01:01:25] d2.evaluation.evaluator INFO: Inference done 119/392. Dataloading: 0.0007 s/iter. Inference: 0.0648 s/iter. Eval: 0.8664 s/iter. Total: 0.9320 s/iter. ETA=0:04:14
[08/05 01:01:31] d2.evaluation.evaluator INFO: Inference done 125/392. Dataloading: 0.0007 s/iter. Inference: 0.0651 s/iter. Eval: 0.8670 s/iter. Total: 0.9329 s/iter. ETA=0:04:09
[08/05 01:01:36] d2.evaluation.evaluator INFO: Inference done 131/392. Dataloading: 0.0007 s/iter. Inference: 0.0656 s/iter. Eval: 0.8679 s/iter. Total: 0.9342 s/iter. ETA=0:04:03
[08/05 01:01:42] d2.evaluation.evaluator INFO: Inference done 137/392. Dataloading: 0.0007 s/iter. Inference: 0.0657 s/iter. Eval: 0.8693 s/iter. Total: 0.9358 s/iter. ETA=0:03:58
[08/05 01:01:48] d2.evaluation.evaluator INFO: Inference done 143/392. Dataloading: 0.0007 s/iter. Inference: 0.0657 s/iter. Eval: 0.8704 s/iter. Total: 0.9369 s/iter. ETA=0:03:53
[08/05 01:01:54] d2.evaluation.evaluator INFO: Inference done 149/392. Dataloading: 0.0007 s/iter. Inference: 0.0658 s/iter. Eval: 0.8714 s/iter. Total: 0.9379 s/iter. ETA=0:03:47
[08/05 01:02:00] d2.evaluation.evaluator INFO: Inference done 155/392. Dataloading: 0.0007 s/iter. Inference: 0.0659 s/iter. Eval: 0.8726 s/iter. Total: 0.9392 s/iter. ETA=0:03:42
[08/05 01:02:05] d2.evaluation.evaluator INFO: Inference done 161/392. Dataloading: 0.0007 s/iter. Inference: 0.0658 s/iter. Eval: 0.8736 s/iter. Total: 0.9401 s/iter. ETA=0:03:37
[08/05 01:02:11] d2.evaluation.evaluator INFO: Inference done 167/392. Dataloading: 0.0007 s/iter. Inference: 0.0660 s/iter. Eval: 0.8744 s/iter. Total: 0.9412 s/iter. ETA=0:03:31
[08/05 01:02:17] d2.evaluation.evaluator INFO: Inference done 173/392. Dataloading: 0.0007 s/iter. Inference: 0.0660 s/iter. Eval: 0.8750 s/iter. Total: 0.9418 s/iter. ETA=0:03:26
[08/05 01:02:23] d2.evaluation.evaluator INFO: Inference done 179/392. Dataloading: 0.0007 s/iter. Inference: 0.0658 s/iter. Eval: 0.8755 s/iter. Total: 0.9421 s/iter. ETA=0:03:20
[08/05 01:02:28] d2.evaluation.evaluator INFO: Inference done 185/392. Dataloading: 0.0007 s/iter. Inference: 0.0662 s/iter. Eval: 0.8762 s/iter. Total: 0.9432 s/iter. ETA=0:03:15
[08/05 01:02:34] d2.evaluation.evaluator INFO: Inference done 191/392. Dataloading: 0.0007 s/iter. Inference: 0.0663 s/iter. Eval: 0.8768 s/iter. Total: 0.9438 s/iter. ETA=0:03:09
[08/05 01:02:40] d2.evaluation.evaluator INFO: Inference done 197/392. Dataloading: 0.0007 s/iter. Inference: 0.0663 s/iter. Eval: 0.8772 s/iter. Total: 0.9443 s/iter. ETA=0:03:04
[08/05 01:02:46] d2.evaluation.evaluator INFO: Inference done 203/392. Dataloading: 0.0007 s/iter. Inference: 0.0662 s/iter. Eval: 0.8777 s/iter. Total: 0.9447 s/iter. ETA=0:02:58
[08/05 01:02:52] d2.evaluation.evaluator INFO: Inference done 209/392. Dataloading: 0.0007 s/iter. Inference: 0.0661 s/iter. Eval: 0.8784 s/iter. Total: 0.9453 s/iter. ETA=0:02:52
[08/05 01:02:57] d2.evaluation.evaluator INFO: Inference done 215/392. Dataloading: 0.0007 s/iter. Inference: 0.0661 s/iter. Eval: 0.8786 s/iter. Total: 0.9455 s/iter. ETA=0:02:47
[08/05 01:03:03] d2.evaluation.evaluator INFO: Inference done 221/392. Dataloading: 0.0007 s/iter. Inference: 0.0660 s/iter. Eval: 0.8793 s/iter. Total: 0.9460 s/iter. ETA=0:02:41
[08/05 01:03:09] d2.evaluation.evaluator INFO: Inference done 227/392. Dataloading: 0.0007 s/iter. Inference: 0.0659 s/iter. Eval: 0.8796 s/iter. Total: 0.9463 s/iter. ETA=0:02:36
[08/05 01:03:14] d2.evaluation.evaluator INFO: Inference done 233/392. Dataloading: 0.0007 s/iter. Inference: 0.0658 s/iter. Eval: 0.8798 s/iter. Total: 0.9464 s/iter. ETA=0:02:30
[08/05 01:03:20] d2.evaluation.evaluator INFO: Inference done 239/392. Dataloading: 0.0007 s/iter. Inference: 0.0657 s/iter. Eval: 0.8799 s/iter. Total: 0.9464 s/iter. ETA=0:02:24
[08/05 01:03:26] d2.evaluation.evaluator INFO: Inference done 245/392. Dataloading: 0.0007 s/iter. Inference: 0.0657 s/iter. Eval: 0.8802 s/iter. Total: 0.9466 s/iter. ETA=0:02:19
[08/05 01:03:32] d2.evaluation.evaluator INFO: Inference done 251/392. Dataloading: 0.0007 s/iter. Inference: 0.0656 s/iter. Eval: 0.8804 s/iter. Total: 0.9467 s/iter. ETA=0:02:13
[08/05 01:03:37] d2.evaluation.evaluator INFO: Inference done 257/392. Dataloading: 0.0007 s/iter. Inference: 0.0655 s/iter. Eval: 0.8806 s/iter. Total: 0.9469 s/iter. ETA=0:02:07
[08/05 01:03:43] d2.evaluation.evaluator INFO: Inference done 263/392. Dataloading: 0.0007 s/iter. Inference: 0.0654 s/iter. Eval: 0.8808 s/iter. Total: 0.9469 s/iter. ETA=0:02:02
[08/05 01:03:49] d2.evaluation.evaluator INFO: Inference done 269/392. Dataloading: 0.0007 s/iter. Inference: 0.0653 s/iter. Eval: 0.8811 s/iter. Total: 0.9471 s/iter. ETA=0:01:56
[08/05 01:03:54] d2.evaluation.evaluator INFO: Inference done 275/392. Dataloading: 0.0007 s/iter. Inference: 0.0652 s/iter. Eval: 0.8811 s/iter. Total: 0.9471 s/iter. ETA=0:01:50
[08/05 01:04:00] d2.evaluation.evaluator INFO: Inference done 281/392. Dataloading: 0.0007 s/iter. Inference: 0.0652 s/iter. Eval: 0.8812 s/iter. Total: 0.9471 s/iter. ETA=0:01:45
[08/05 01:04:06] d2.evaluation.evaluator INFO: Inference done 287/392. Dataloading: 0.0007 s/iter. Inference: 0.0651 s/iter. Eval: 0.8813 s/iter. Total: 0.9472 s/iter. ETA=0:01:39
[08/05 01:04:11] d2.evaluation.evaluator INFO: Inference done 293/392. Dataloading: 0.0007 s/iter. Inference: 0.0650 s/iter. Eval: 0.8815 s/iter. Total: 0.9473 s/iter. ETA=0:01:33
[08/05 01:04:17] d2.evaluation.evaluator INFO: Inference done 299/392. Dataloading: 0.0007 s/iter. Inference: 0.0650 s/iter. Eval: 0.8819 s/iter. Total: 0.9477 s/iter. ETA=0:01:28
[08/05 01:04:23] d2.evaluation.evaluator INFO: Inference done 305/392. Dataloading: 0.0007 s/iter. Inference: 0.0650 s/iter. Eval: 0.8822 s/iter. Total: 0.9479 s/iter. ETA=0:01:22
[08/05 01:04:29] d2.evaluation.evaluator INFO: Inference done 311/392. Dataloading: 0.0007 s/iter. Inference: 0.0649 s/iter. Eval: 0.8823 s/iter. Total: 0.9480 s/iter. ETA=0:01:16
[08/05 01:04:35] d2.evaluation.evaluator INFO: Inference done 317/392. Dataloading: 0.0007 s/iter. Inference: 0.0649 s/iter. Eval: 0.8827 s/iter. Total: 0.9483 s/iter. ETA=0:01:11
[08/05 01:04:40] d2.evaluation.evaluator INFO: Inference done 323/392. Dataloading: 0.0007 s/iter. Inference: 0.0648 s/iter. Eval: 0.8829 s/iter. Total: 0.9485 s/iter. ETA=0:01:05
[08/05 01:04:46] d2.evaluation.evaluator INFO: Inference done 329/392. Dataloading: 0.0007 s/iter. Inference: 0.0648 s/iter. Eval: 0.8832 s/iter. Total: 0.9487 s/iter. ETA=0:00:59
[08/05 01:04:52] d2.evaluation.evaluator INFO: Inference done 335/392. Dataloading: 0.0007 s/iter. Inference: 0.0647 s/iter. Eval: 0.8834 s/iter. Total: 0.9489 s/iter. ETA=0:00:54
[08/05 01:04:58] d2.evaluation.evaluator INFO: Inference done 341/392. Dataloading: 0.0007 s/iter. Inference: 0.0647 s/iter. Eval: 0.8836 s/iter. Total: 0.9491 s/iter. ETA=0:00:48
[08/05 01:05:03] d2.evaluation.evaluator INFO: Inference done 347/392. Dataloading: 0.0007 s/iter. Inference: 0.0647 s/iter. Eval: 0.8840 s/iter. Total: 0.9494 s/iter. ETA=0:00:42
[08/05 01:05:09] d2.evaluation.evaluator INFO: Inference done 353/392. Dataloading: 0.0007 s/iter. Inference: 0.0646 s/iter. Eval: 0.8842 s/iter. Total: 0.9496 s/iter. ETA=0:00:37
[08/05 01:05:15] d2.evaluation.evaluator INFO: Inference done 359/392. Dataloading: 0.0007 s/iter. Inference: 0.0646 s/iter. Eval: 0.8848 s/iter. Total: 0.9501 s/iter. ETA=0:00:31
[08/05 01:05:21] d2.evaluation.evaluator INFO: Inference done 365/392. Dataloading: 0.0007 s/iter. Inference: 0.0646 s/iter. Eval: 0.8844 s/iter. Total: 0.9498 s/iter. ETA=0:00:25
[08/05 01:05:26] d2.evaluation.evaluator INFO: Inference done 371/392. Dataloading: 0.0007 s/iter. Inference: 0.0646 s/iter. Eval: 0.8842 s/iter. Total: 0.9496 s/iter. ETA=0:00:19
[08/05 01:05:32] d2.evaluation.evaluator INFO: Inference done 377/392. Dataloading: 0.0007 s/iter. Inference: 0.0646 s/iter. Eval: 0.8841 s/iter. Total: 0.9495 s/iter. ETA=0:00:14
[08/05 01:05:38] d2.evaluation.evaluator INFO: Inference done 383/392. Dataloading: 0.0007 s/iter. Inference: 0.0646 s/iter. Eval: 0.8840 s/iter. Total: 0.9493 s/iter. ETA=0:00:08
[08/05 01:05:43] d2.evaluation.evaluator INFO: Inference done 389/392. Dataloading: 0.0007 s/iter. Inference: 0.0648 s/iter. Eval: 0.8842 s/iter. Total: 0.9498 s/iter. ETA=0:00:02
[08/05 01:05:46] d2.evaluation.evaluator INFO: Total inference time: 0:06:07.690489 (0.950105 s / iter per device, on 1 devices)
[08/05 01:05:46] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:25 (0.064822 s / iter per device, on 1 devices)
[08/05 01:05:47] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[08/05 01:05:47] d2.evaluation.coco_evaluation INFO: Saving results to ./R101_overlap/inference/coco_instances_results.json
[08/05 01:05:47] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[08/05 01:05:49] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 |  nan  | 0.000 |
[08/05 01:05:49] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/05 01:05:49] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| normal     | 0.000 | defect     | 0.000 |
[08/05 01:05:53] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl   |
|:------:|:------:|:------:|:------:|:-----:|:------:|
| 92.863 | 98.659 | 98.180 | 49.048 |  nan  | 92.863 |
[08/05 01:05:53] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/05 01:05:53] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| normal     | 98.930 | defect     | 86.796 |
[08/05 01:05:53] d2.engine.defaults INFO: Evaluation results for chick_dataset_test_overlap in csv format:
[08/05 01:05:53] d2.evaluation.testing INFO: copypaste: Task: bbox
[08/05 01:05:53] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/05 01:05:53] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,nan,0.0000
[08/05 01:05:53] d2.evaluation.testing INFO: copypaste: Task: segm
[08/05 01:05:53] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/05 01:05:53] d2.evaluation.testing INFO: copypaste: 92.8632,98.6589,98.1798,49.0480,nan,92.8632
[08/06 10:55:26] detectron2 INFO: Rank of current process: 0. World size: 1
[08/06 10:55:27] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.20.1
detectron2              0.6 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.1
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA RTX A6000 (arch=8.6)
Driver version          470.129.06
CUDA_HOME               /usr
Pillow                  8.1.0
torchvision             0.10.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220305
iopath                  0.1.9
cv2                     4.5.5
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[08/06 10:55:27] detectron2 INFO: Command line arguments: Namespace(config_file='/home/tqsang/Mask2Former/R101_overlap/config_test.yaml', dist_url='tcp://127.0.0.1:50158', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/home/tqsang/Mask2Former/R101_overlap/model_final.pth'], resume=False)
[08/06 10:55:27] detectron2 INFO: Contents of args.config_file=/home/tqsang/Mask2Former/R101_overlap/config_test.yaml:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mchick_dataset_test_overlap[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/MSRA/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/06 10:55:27] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mchick_dataset_test_overlap[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/tqsang/Mask2Former/R101_overlap/model_final.pth[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/06 10:55:27] detectron2 INFO: Full config saved to ./R101_overlap/config.yaml
[08/06 10:55:27] d2.utils.env INFO: Using a generated random seed 30926080
[08/06 10:55:30] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (deconv_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv2_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=3, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 2
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/06 10:55:30] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/tqsang/Mask2Former/R101_overlap/model_final.pth ...
[08/06 10:55:30] d2.data.datasets.coco INFO: Loaded 392 images in COCO format from /home/tqsang/V100/tqsang/crop_obj/front_2_class_overlap/annotations/instances_test2017.json
[08/06 10:55:30] d2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|   normal   | 359          |   defect   | 267          |
|            |              |            |              |
|   total    | 626          |            |              |[0m
[08/06 10:55:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(256, 256), max_size=256, sample_style='choice')]
[08/06 10:55:30] d2.data.common INFO: Serializing 392 elements to byte tensors and concatenating them all ...
[08/06 10:55:30] d2.data.common INFO: Serialized dataset takes 5.71 MiB
[08/06 10:55:30] d2.evaluation.evaluator INFO: Start inference on 392 batches
[08/06 10:55:40] d2.evaluation.evaluator INFO: Inference done 11/392. Dataloading: 0.0005 s/iter. Inference: 0.0609 s/iter. Eval: 0.8287 s/iter. Total: 0.8902 s/iter. ETA=0:05:39
[08/06 10:55:46] d2.evaluation.evaluator INFO: Inference done 17/392. Dataloading: 0.0006 s/iter. Inference: 0.0569 s/iter. Eval: 0.8393 s/iter. Total: 0.8968 s/iter. ETA=0:05:36
[08/06 10:55:51] d2.evaluation.evaluator INFO: Inference done 23/392. Dataloading: 0.0006 s/iter. Inference: 0.0561 s/iter. Eval: 0.8487 s/iter. Total: 0.9055 s/iter. ETA=0:05:34
[08/06 10:55:57] d2.evaluation.evaluator INFO: Inference done 29/392. Dataloading: 0.0006 s/iter. Inference: 0.0566 s/iter. Eval: 0.8531 s/iter. Total: 0.9105 s/iter. ETA=0:05:30
[08/06 10:56:03] d2.evaluation.evaluator INFO: Inference done 35/392. Dataloading: 0.0006 s/iter. Inference: 0.0570 s/iter. Eval: 0.8569 s/iter. Total: 0.9146 s/iter. ETA=0:05:26
[08/06 10:56:08] d2.evaluation.evaluator INFO: Inference done 41/392. Dataloading: 0.0007 s/iter. Inference: 0.0573 s/iter. Eval: 0.8582 s/iter. Total: 0.9162 s/iter. ETA=0:05:21
[08/06 10:56:14] d2.evaluation.evaluator INFO: Inference done 47/392. Dataloading: 0.0007 s/iter. Inference: 0.0572 s/iter. Eval: 0.8590 s/iter. Total: 0.9170 s/iter. ETA=0:05:16
[08/06 10:56:19] d2.evaluation.evaluator INFO: Inference done 53/392. Dataloading: 0.0007 s/iter. Inference: 0.0574 s/iter. Eval: 0.8601 s/iter. Total: 0.9183 s/iter. ETA=0:05:11
[08/06 10:56:25] d2.evaluation.evaluator INFO: Inference done 59/392. Dataloading: 0.0007 s/iter. Inference: 0.0575 s/iter. Eval: 0.8615 s/iter. Total: 0.9198 s/iter. ETA=0:05:06
[08/06 10:56:30] d2.evaluation.evaluator INFO: Inference done 65/392. Dataloading: 0.0007 s/iter. Inference: 0.0577 s/iter. Eval: 0.8629 s/iter. Total: 0.9213 s/iter. ETA=0:05:01
[08/06 10:56:36] d2.evaluation.evaluator INFO: Inference done 71/392. Dataloading: 0.0007 s/iter. Inference: 0.0578 s/iter. Eval: 0.8637 s/iter. Total: 0.9222 s/iter. ETA=0:04:56
[08/06 10:56:41] d2.evaluation.evaluator INFO: Inference done 77/392. Dataloading: 0.0007 s/iter. Inference: 0.0578 s/iter. Eval: 0.8638 s/iter. Total: 0.9223 s/iter. ETA=0:04:50
[08/06 10:56:47] d2.evaluation.evaluator INFO: Inference done 83/392. Dataloading: 0.0007 s/iter. Inference: 0.0579 s/iter. Eval: 0.8644 s/iter. Total: 0.9230 s/iter. ETA=0:04:45
[08/06 10:56:53] d2.evaluation.evaluator INFO: Inference done 89/392. Dataloading: 0.0007 s/iter. Inference: 0.0579 s/iter. Eval: 0.8646 s/iter. Total: 0.9233 s/iter. ETA=0:04:39
[08/06 10:56:58] d2.evaluation.evaluator INFO: Inference done 95/392. Dataloading: 0.0007 s/iter. Inference: 0.0580 s/iter. Eval: 0.8650 s/iter. Total: 0.9238 s/iter. ETA=0:04:34
[08/06 10:57:04] d2.evaluation.evaluator INFO: Inference done 101/392. Dataloading: 0.0007 s/iter. Inference: 0.0580 s/iter. Eval: 0.8656 s/iter. Total: 0.9244 s/iter. ETA=0:04:29
[08/06 10:57:09] d2.evaluation.evaluator INFO: Inference done 107/392. Dataloading: 0.0007 s/iter. Inference: 0.0581 s/iter. Eval: 0.8662 s/iter. Total: 0.9250 s/iter. ETA=0:04:23
[08/06 10:57:15] d2.evaluation.evaluator INFO: Inference done 113/392. Dataloading: 0.0007 s/iter. Inference: 0.0579 s/iter. Eval: 0.8667 s/iter. Total: 0.9254 s/iter. ETA=0:04:18
[08/06 10:57:21] d2.evaluation.evaluator INFO: Inference done 119/392. Dataloading: 0.0007 s/iter. Inference: 0.0580 s/iter. Eval: 0.8674 s/iter. Total: 0.9262 s/iter. ETA=0:04:12
[08/06 10:57:26] d2.evaluation.evaluator INFO: Inference done 125/392. Dataloading: 0.0007 s/iter. Inference: 0.0585 s/iter. Eval: 0.8676 s/iter. Total: 0.9269 s/iter. ETA=0:04:07
[08/06 10:57:32] d2.evaluation.evaluator INFO: Inference done 131/392. Dataloading: 0.0007 s/iter. Inference: 0.0586 s/iter. Eval: 0.8678 s/iter. Total: 0.9271 s/iter. ETA=0:04:01
[08/06 10:57:38] d2.evaluation.evaluator INFO: Inference done 137/392. Dataloading: 0.0007 s/iter. Inference: 0.0583 s/iter. Eval: 0.8694 s/iter. Total: 0.9285 s/iter. ETA=0:03:56
[08/06 10:57:43] d2.evaluation.evaluator INFO: Inference done 143/392. Dataloading: 0.0007 s/iter. Inference: 0.0580 s/iter. Eval: 0.8703 s/iter. Total: 0.9291 s/iter. ETA=0:03:51
[08/06 10:57:49] d2.evaluation.evaluator INFO: Inference done 149/392. Dataloading: 0.0007 s/iter. Inference: 0.0578 s/iter. Eval: 0.8711 s/iter. Total: 0.9297 s/iter. ETA=0:03:45
[08/06 10:57:55] d2.evaluation.evaluator INFO: Inference done 155/392. Dataloading: 0.0007 s/iter. Inference: 0.0576 s/iter. Eval: 0.8720 s/iter. Total: 0.9304 s/iter. ETA=0:03:40
[08/06 10:58:00] d2.evaluation.evaluator INFO: Inference done 161/392. Dataloading: 0.0007 s/iter. Inference: 0.0574 s/iter. Eval: 0.8725 s/iter. Total: 0.9306 s/iter. ETA=0:03:34
[08/06 10:58:06] d2.evaluation.evaluator INFO: Inference done 167/392. Dataloading: 0.0007 s/iter. Inference: 0.0572 s/iter. Eval: 0.8728 s/iter. Total: 0.9308 s/iter. ETA=0:03:29
[08/06 10:58:12] d2.evaluation.evaluator INFO: Inference done 173/392. Dataloading: 0.0007 s/iter. Inference: 0.0570 s/iter. Eval: 0.8733 s/iter. Total: 0.9311 s/iter. ETA=0:03:23
[08/06 10:58:17] d2.evaluation.evaluator INFO: Inference done 179/392. Dataloading: 0.0007 s/iter. Inference: 0.0569 s/iter. Eval: 0.8738 s/iter. Total: 0.9314 s/iter. ETA=0:03:18
[08/06 10:58:23] d2.evaluation.evaluator INFO: Inference done 185/392. Dataloading: 0.0007 s/iter. Inference: 0.0567 s/iter. Eval: 0.8742 s/iter. Total: 0.9317 s/iter. ETA=0:03:12
[08/06 10:58:28] d2.evaluation.evaluator INFO: Inference done 191/392. Dataloading: 0.0007 s/iter. Inference: 0.0566 s/iter. Eval: 0.8746 s/iter. Total: 0.9320 s/iter. ETA=0:03:07
[08/06 10:58:34] d2.evaluation.evaluator INFO: Inference done 197/392. Dataloading: 0.0007 s/iter. Inference: 0.0565 s/iter. Eval: 0.8751 s/iter. Total: 0.9323 s/iter. ETA=0:03:01
[08/06 10:58:40] d2.evaluation.evaluator INFO: Inference done 203/392. Dataloading: 0.0007 s/iter. Inference: 0.0563 s/iter. Eval: 0.8756 s/iter. Total: 0.9327 s/iter. ETA=0:02:56
[08/06 10:58:45] d2.evaluation.evaluator INFO: Inference done 209/392. Dataloading: 0.0007 s/iter. Inference: 0.0562 s/iter. Eval: 0.8761 s/iter. Total: 0.9331 s/iter. ETA=0:02:50
[08/06 10:58:51] d2.evaluation.evaluator INFO: Inference done 215/392. Dataloading: 0.0007 s/iter. Inference: 0.0561 s/iter. Eval: 0.8767 s/iter. Total: 0.9336 s/iter. ETA=0:02:45
[08/06 10:58:57] d2.evaluation.evaluator INFO: Inference done 221/392. Dataloading: 0.0007 s/iter. Inference: 0.0560 s/iter. Eval: 0.8771 s/iter. Total: 0.9339 s/iter. ETA=0:02:39
[08/06 10:59:02] d2.evaluation.evaluator INFO: Inference done 227/392. Dataloading: 0.0007 s/iter. Inference: 0.0559 s/iter. Eval: 0.8775 s/iter. Total: 0.9342 s/iter. ETA=0:02:34
[08/06 10:59:08] d2.evaluation.evaluator INFO: Inference done 233/392. Dataloading: 0.0007 s/iter. Inference: 0.0558 s/iter. Eval: 0.8780 s/iter. Total: 0.9346 s/iter. ETA=0:02:28
[08/06 10:59:14] d2.evaluation.evaluator INFO: Inference done 239/392. Dataloading: 0.0007 s/iter. Inference: 0.0557 s/iter. Eval: 0.8783 s/iter. Total: 0.9348 s/iter. ETA=0:02:23
[08/06 10:59:20] d2.evaluation.evaluator INFO: Inference done 245/392. Dataloading: 0.0007 s/iter. Inference: 0.0557 s/iter. Eval: 0.8788 s/iter. Total: 0.9352 s/iter. ETA=0:02:17
[08/06 10:59:25] d2.evaluation.evaluator INFO: Inference done 251/392. Dataloading: 0.0007 s/iter. Inference: 0.0556 s/iter. Eval: 0.8792 s/iter. Total: 0.9356 s/iter. ETA=0:02:11
[08/06 10:59:31] d2.evaluation.evaluator INFO: Inference done 257/392. Dataloading: 0.0007 s/iter. Inference: 0.0555 s/iter. Eval: 0.8796 s/iter. Total: 0.9359 s/iter. ETA=0:02:06
[08/06 10:59:37] d2.evaluation.evaluator INFO: Inference done 263/392. Dataloading: 0.0007 s/iter. Inference: 0.0555 s/iter. Eval: 0.8799 s/iter. Total: 0.9362 s/iter. ETA=0:02:00
[08/06 10:59:42] d2.evaluation.evaluator INFO: Inference done 269/392. Dataloading: 0.0007 s/iter. Inference: 0.0554 s/iter. Eval: 0.8802 s/iter. Total: 0.9364 s/iter. ETA=0:01:55
[08/06 10:59:48] d2.evaluation.evaluator INFO: Inference done 275/392. Dataloading: 0.0007 s/iter. Inference: 0.0554 s/iter. Eval: 0.8804 s/iter. Total: 0.9366 s/iter. ETA=0:01:49
[08/06 10:59:54] d2.evaluation.evaluator INFO: Inference done 281/392. Dataloading: 0.0007 s/iter. Inference: 0.0553 s/iter. Eval: 0.8806 s/iter. Total: 0.9367 s/iter. ETA=0:01:43
[08/06 10:59:59] d2.evaluation.evaluator INFO: Inference done 287/392. Dataloading: 0.0007 s/iter. Inference: 0.0552 s/iter. Eval: 0.8808 s/iter. Total: 0.9369 s/iter. ETA=0:01:38
[08/06 11:00:05] d2.evaluation.evaluator INFO: Inference done 293/392. Dataloading: 0.0007 s/iter. Inference: 0.0552 s/iter. Eval: 0.8810 s/iter. Total: 0.9370 s/iter. ETA=0:01:32
[08/06 11:00:11] d2.evaluation.evaluator INFO: Inference done 299/392. Dataloading: 0.0007 s/iter. Inference: 0.0551 s/iter. Eval: 0.8811 s/iter. Total: 0.9370 s/iter. ETA=0:01:27
[08/06 11:00:16] d2.evaluation.evaluator INFO: Inference done 305/392. Dataloading: 0.0007 s/iter. Inference: 0.0551 s/iter. Eval: 0.8812 s/iter. Total: 0.9371 s/iter. ETA=0:01:21
[08/06 11:00:22] d2.evaluation.evaluator INFO: Inference done 311/392. Dataloading: 0.0007 s/iter. Inference: 0.0550 s/iter. Eval: 0.8813 s/iter. Total: 0.9371 s/iter. ETA=0:01:15
[08/06 11:00:27] d2.evaluation.evaluator INFO: Inference done 317/392. Dataloading: 0.0007 s/iter. Inference: 0.0550 s/iter. Eval: 0.8814 s/iter. Total: 0.9372 s/iter. ETA=0:01:10
[08/06 11:00:33] d2.evaluation.evaluator INFO: Inference done 323/392. Dataloading: 0.0007 s/iter. Inference: 0.0549 s/iter. Eval: 0.8816 s/iter. Total: 0.9373 s/iter. ETA=0:01:04
[08/06 11:00:39] d2.evaluation.evaluator INFO: Inference done 329/392. Dataloading: 0.0007 s/iter. Inference: 0.0549 s/iter. Eval: 0.8817 s/iter. Total: 0.9374 s/iter. ETA=0:00:59
[08/06 11:00:44] d2.evaluation.evaluator INFO: Inference done 335/392. Dataloading: 0.0007 s/iter. Inference: 0.0548 s/iter. Eval: 0.8818 s/iter. Total: 0.9374 s/iter. ETA=0:00:53
[08/06 11:00:50] d2.evaluation.evaluator INFO: Inference done 341/392. Dataloading: 0.0007 s/iter. Inference: 0.0548 s/iter. Eval: 0.8819 s/iter. Total: 0.9375 s/iter. ETA=0:00:47
[08/06 11:00:56] d2.evaluation.evaluator INFO: Inference done 347/392. Dataloading: 0.0007 s/iter. Inference: 0.0547 s/iter. Eval: 0.8821 s/iter. Total: 0.9377 s/iter. ETA=0:00:42
[08/06 11:01:01] d2.evaluation.evaluator INFO: Inference done 353/392. Dataloading: 0.0007 s/iter. Inference: 0.0547 s/iter. Eval: 0.8823 s/iter. Total: 0.9377 s/iter. ETA=0:00:36
[08/06 11:01:07] d2.evaluation.evaluator INFO: Inference done 359/392. Dataloading: 0.0007 s/iter. Inference: 0.0547 s/iter. Eval: 0.8826 s/iter. Total: 0.9380 s/iter. ETA=0:00:30
[08/06 11:01:13] d2.evaluation.evaluator INFO: Inference done 365/392. Dataloading: 0.0007 s/iter. Inference: 0.0546 s/iter. Eval: 0.8827 s/iter. Total: 0.9381 s/iter. ETA=0:00:25
[08/06 11:01:18] d2.evaluation.evaluator INFO: Inference done 371/392. Dataloading: 0.0007 s/iter. Inference: 0.0546 s/iter. Eval: 0.8828 s/iter. Total: 0.9382 s/iter. ETA=0:00:19
[08/06 11:01:24] d2.evaluation.evaluator INFO: Inference done 377/392. Dataloading: 0.0007 s/iter. Inference: 0.0546 s/iter. Eval: 0.8828 s/iter. Total: 0.9382 s/iter. ETA=0:00:14
[08/06 11:01:30] d2.evaluation.evaluator INFO: Inference done 383/392. Dataloading: 0.0007 s/iter. Inference: 0.0545 s/iter. Eval: 0.8829 s/iter. Total: 0.9383 s/iter. ETA=0:00:08
[08/06 11:01:35] d2.evaluation.evaluator INFO: Inference done 389/392. Dataloading: 0.0007 s/iter. Inference: 0.0545 s/iter. Eval: 0.8831 s/iter. Total: 0.9384 s/iter. ETA=0:00:02
[08/06 11:01:38] d2.evaluation.evaluator INFO: Total inference time: 0:06:03.270261 (0.938683 s / iter per device, on 1 devices)
[08/06 11:01:38] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:21 (0.054499 s / iter per device, on 1 devices)
[08/06 11:01:39] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[08/06 11:01:39] d2.evaluation.coco_evaluation INFO: Saving results to ./R101_overlap/inference/coco_instances_results.json
[08/06 11:01:39] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[08/06 11:01:41] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 |  nan  | 0.000 |
[08/06 11:01:41] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/06 11:01:41] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| normal     | 0.000 | defect     | 0.000 |
[08/06 11:01:45] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl   |
|:------:|:------:|:------:|:------:|:-----:|:------:|
| 92.863 | 98.659 | 98.180 | 49.048 |  nan  | 92.863 |
[08/06 11:01:45] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/06 11:01:45] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| normal     | 98.930 | defect     | 86.796 |
[08/06 11:01:45] d2.engine.defaults INFO: Evaluation results for chick_dataset_test_overlap in csv format:
[08/06 11:01:45] d2.evaluation.testing INFO: copypaste: Task: bbox
[08/06 11:01:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/06 11:01:45] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,nan,0.0000
[08/06 11:01:45] d2.evaluation.testing INFO: copypaste: Task: segm
[08/06 11:01:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/06 11:01:45] d2.evaluation.testing INFO: copypaste: 92.8632,98.6589,98.1798,49.0480,nan,92.8632
[08/06 11:49:35] detectron2 INFO: Rank of current process: 0. World size: 1
[08/06 11:49:36] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.20.1
detectron2              0.6 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.1
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA RTX A6000 (arch=8.6)
Driver version          470.129.06
CUDA_HOME               /usr
Pillow                  8.1.0
torchvision             0.10.0 @/home/tqsang/miniconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220305
iopath                  0.1.9
cv2                     4.5.5
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.0-Product Build 20211112 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[08/06 11:49:36] detectron2 INFO: Command line arguments: Namespace(config_file='/home/tqsang/Mask2Former/R101_overlap/config_test.yaml', dist_url='tcp://127.0.0.1:50158', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', '/home/tqsang/Mask2Former/R101_overlap/model_final.pth'], resume=False)
[08/06 11:49:36] detectron2 INFO: Contents of args.config_file=/home/tqsang/Mask2Former/R101_overlap/config_test.yaml:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mchick_dataset_test_overlap[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/MSRA/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/06 11:49:36] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mchick_dataset_test_overlap[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfront2class_2017_train_overlap_panoptic[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcoco_panoptic_lsj[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormer[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/tqsang/Mask2Former/R101_overlap/model_final.pth[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./R101_overlap[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m35000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m25000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[08/06 11:49:36] detectron2 INFO: Full config saved to ./R101_overlap/config.yaml
[08/06 11:49:36] d2.utils.env INFO: Using a generated random seed 40436690
[08/06 11:49:39] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (deconv_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv2_mask_features): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (adapter_1): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(100, 256)
      (query_embed): Embedding(100, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=3, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 2
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[08/06 11:49:39] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/tqsang/Mask2Former/R101_overlap/model_final.pth ...
[08/06 11:49:40] d2.data.datasets.coco INFO: Loaded 392 images in COCO format from /home/tqsang/V100/tqsang/crop_obj/front_2_class_overlap/annotations/instances_test2017.json
[08/06 11:49:40] d2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|   normal   | 359          |   defect   | 267          |
|            |              |            |              |
|   total    | 626          |            |              |[0m
[08/06 11:49:40] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(256, 256), max_size=256, sample_style='choice')]
[08/06 11:49:40] d2.data.common INFO: Serializing 392 elements to byte tensors and concatenating them all ...
[08/06 11:49:40] d2.data.common INFO: Serialized dataset takes 5.71 MiB
[08/06 11:49:40] d2.evaluation.evaluator INFO: Start inference on 392 batches
[08/06 11:49:51] d2.evaluation.evaluator INFO: Inference done 11/392. Dataloading: 0.0005 s/iter. Inference: 0.0535 s/iter. Eval: 0.8723 s/iter. Total: 0.9264 s/iter. ETA=0:05:52
[08/06 11:49:57] d2.evaluation.evaluator INFO: Inference done 17/392. Dataloading: 0.0006 s/iter. Inference: 0.0557 s/iter. Eval: 0.8649 s/iter. Total: 0.9212 s/iter. ETA=0:05:45
[08/06 11:50:02] d2.evaluation.evaluator INFO: Inference done 23/392. Dataloading: 0.0007 s/iter. Inference: 0.0559 s/iter. Eval: 0.8589 s/iter. Total: 0.9155 s/iter. ETA=0:05:37
[08/06 11:50:08] d2.evaluation.evaluator INFO: Inference done 29/392. Dataloading: 0.0007 s/iter. Inference: 0.0589 s/iter. Eval: 0.8567 s/iter. Total: 0.9164 s/iter. ETA=0:05:32
[08/06 11:50:13] d2.evaluation.evaluator INFO: Inference done 35/392. Dataloading: 0.0007 s/iter. Inference: 0.0624 s/iter. Eval: 0.8543 s/iter. Total: 0.9174 s/iter. ETA=0:05:27
[08/06 11:50:19] d2.evaluation.evaluator INFO: Inference done 41/392. Dataloading: 0.0007 s/iter. Inference: 0.0614 s/iter. Eval: 0.8515 s/iter. Total: 0.9136 s/iter. ETA=0:05:20
[08/06 11:50:24] d2.evaluation.evaluator INFO: Inference done 47/392. Dataloading: 0.0007 s/iter. Inference: 0.0602 s/iter. Eval: 0.8526 s/iter. Total: 0.9135 s/iter. ETA=0:05:15
[08/06 11:50:30] d2.evaluation.evaluator INFO: Inference done 53/392. Dataloading: 0.0007 s/iter. Inference: 0.0594 s/iter. Eval: 0.8538 s/iter. Total: 0.9140 s/iter. ETA=0:05:09
[08/06 11:50:35] d2.evaluation.evaluator INFO: Inference done 59/392. Dataloading: 0.0007 s/iter. Inference: 0.0590 s/iter. Eval: 0.8545 s/iter. Total: 0.9143 s/iter. ETA=0:05:04
[08/06 11:50:41] d2.evaluation.evaluator INFO: Inference done 65/392. Dataloading: 0.0007 s/iter. Inference: 0.0588 s/iter. Eval: 0.8550 s/iter. Total: 0.9145 s/iter. ETA=0:04:59
[08/06 11:50:46] d2.evaluation.evaluator INFO: Inference done 71/392. Dataloading: 0.0007 s/iter. Inference: 0.0582 s/iter. Eval: 0.8554 s/iter. Total: 0.9144 s/iter. ETA=0:04:53
[08/06 11:50:51] d2.evaluation.evaluator INFO: Inference done 77/392. Dataloading: 0.0007 s/iter. Inference: 0.0580 s/iter. Eval: 0.8557 s/iter. Total: 0.9145 s/iter. ETA=0:04:48
[08/06 11:50:57] d2.evaluation.evaluator INFO: Inference done 83/392. Dataloading: 0.0007 s/iter. Inference: 0.0580 s/iter. Eval: 0.8565 s/iter. Total: 0.9152 s/iter. ETA=0:04:42
[08/06 11:51:03] d2.evaluation.evaluator INFO: Inference done 89/392. Dataloading: 0.0007 s/iter. Inference: 0.0580 s/iter. Eval: 0.8575 s/iter. Total: 0.9162 s/iter. ETA=0:04:37
[08/06 11:51:08] d2.evaluation.evaluator INFO: Inference done 95/392. Dataloading: 0.0007 s/iter. Inference: 0.0580 s/iter. Eval: 0.8577 s/iter. Total: 0.9164 s/iter. ETA=0:04:32
[08/06 11:51:14] d2.evaluation.evaluator INFO: Inference done 101/392. Dataloading: 0.0007 s/iter. Inference: 0.0581 s/iter. Eval: 0.8579 s/iter. Total: 0.9168 s/iter. ETA=0:04:26
[08/06 11:51:19] d2.evaluation.evaluator INFO: Inference done 107/392. Dataloading: 0.0007 s/iter. Inference: 0.0580 s/iter. Eval: 0.8582 s/iter. Total: 0.9169 s/iter. ETA=0:04:21
[08/06 11:51:25] d2.evaluation.evaluator INFO: Inference done 113/392. Dataloading: 0.0007 s/iter. Inference: 0.0579 s/iter. Eval: 0.8581 s/iter. Total: 0.9168 s/iter. ETA=0:04:15
[08/06 11:51:30] d2.evaluation.evaluator INFO: Inference done 119/392. Dataloading: 0.0007 s/iter. Inference: 0.0577 s/iter. Eval: 0.8582 s/iter. Total: 0.9167 s/iter. ETA=0:04:10
[08/06 11:51:36] d2.evaluation.evaluator INFO: Inference done 125/392. Dataloading: 0.0007 s/iter. Inference: 0.0577 s/iter. Eval: 0.8585 s/iter. Total: 0.9170 s/iter. ETA=0:04:04
[08/06 11:51:41] d2.evaluation.evaluator INFO: Inference done 131/392. Dataloading: 0.0007 s/iter. Inference: 0.0578 s/iter. Eval: 0.8591 s/iter. Total: 0.9176 s/iter. ETA=0:03:59
[08/06 11:51:47] d2.evaluation.evaluator INFO: Inference done 137/392. Dataloading: 0.0007 s/iter. Inference: 0.0579 s/iter. Eval: 0.8602 s/iter. Total: 0.9188 s/iter. ETA=0:03:54
[08/06 11:51:52] d2.evaluation.evaluator INFO: Inference done 143/392. Dataloading: 0.0007 s/iter. Inference: 0.0579 s/iter. Eval: 0.8604 s/iter. Total: 0.9190 s/iter. ETA=0:03:48
[08/06 11:51:58] d2.evaluation.evaluator INFO: Inference done 149/392. Dataloading: 0.0007 s/iter. Inference: 0.0582 s/iter. Eval: 0.8602 s/iter. Total: 0.9192 s/iter. ETA=0:03:43
[08/06 11:52:04] d2.evaluation.evaluator INFO: Inference done 155/392. Dataloading: 0.0007 s/iter. Inference: 0.0584 s/iter. Eval: 0.8603 s/iter. Total: 0.9196 s/iter. ETA=0:03:37
[08/06 11:52:09] d2.evaluation.evaluator INFO: Inference done 161/392. Dataloading: 0.0007 s/iter. Inference: 0.0584 s/iter. Eval: 0.8605 s/iter. Total: 0.9197 s/iter. ETA=0:03:32
[08/06 11:52:15] d2.evaluation.evaluator INFO: Inference done 167/392. Dataloading: 0.0007 s/iter. Inference: 0.0585 s/iter. Eval: 0.8609 s/iter. Total: 0.9201 s/iter. ETA=0:03:27
[08/06 11:52:20] d2.evaluation.evaluator INFO: Inference done 173/392. Dataloading: 0.0007 s/iter. Inference: 0.0585 s/iter. Eval: 0.8614 s/iter. Total: 0.9207 s/iter. ETA=0:03:21
[08/06 11:52:26] d2.evaluation.evaluator INFO: Inference done 179/392. Dataloading: 0.0007 s/iter. Inference: 0.0586 s/iter. Eval: 0.8620 s/iter. Total: 0.9214 s/iter. ETA=0:03:16
[08/06 11:52:31] d2.evaluation.evaluator INFO: Inference done 185/392. Dataloading: 0.0007 s/iter. Inference: 0.0584 s/iter. Eval: 0.8618 s/iter. Total: 0.9210 s/iter. ETA=0:03:10
[08/06 11:52:37] d2.evaluation.evaluator INFO: Inference done 191/392. Dataloading: 0.0007 s/iter. Inference: 0.0588 s/iter. Eval: 0.8615 s/iter. Total: 0.9211 s/iter. ETA=0:03:05
[08/06 11:52:42] d2.evaluation.evaluator INFO: Inference done 197/392. Dataloading: 0.0007 s/iter. Inference: 0.0592 s/iter. Eval: 0.8612 s/iter. Total: 0.9212 s/iter. ETA=0:02:59
[08/06 11:52:48] d2.evaluation.evaluator INFO: Inference done 203/392. Dataloading: 0.0007 s/iter. Inference: 0.0592 s/iter. Eval: 0.8613 s/iter. Total: 0.9212 s/iter. ETA=0:02:54
[08/06 11:52:54] d2.evaluation.evaluator INFO: Inference done 209/392. Dataloading: 0.0007 s/iter. Inference: 0.0592 s/iter. Eval: 0.8613 s/iter. Total: 0.9213 s/iter. ETA=0:02:48
[08/06 11:52:59] d2.evaluation.evaluator INFO: Inference done 215/392. Dataloading: 0.0007 s/iter. Inference: 0.0590 s/iter. Eval: 0.8614 s/iter. Total: 0.9211 s/iter. ETA=0:02:43
[08/06 11:53:05] d2.evaluation.evaluator INFO: Inference done 221/392. Dataloading: 0.0007 s/iter. Inference: 0.0588 s/iter. Eval: 0.8613 s/iter. Total: 0.9209 s/iter. ETA=0:02:37
[08/06 11:53:10] d2.evaluation.evaluator INFO: Inference done 227/392. Dataloading: 0.0007 s/iter. Inference: 0.0591 s/iter. Eval: 0.8612 s/iter. Total: 0.9211 s/iter. ETA=0:02:31
[08/06 11:53:16] d2.evaluation.evaluator INFO: Inference done 233/392. Dataloading: 0.0007 s/iter. Inference: 0.0590 s/iter. Eval: 0.8613 s/iter. Total: 0.9211 s/iter. ETA=0:02:26
[08/06 11:53:21] d2.evaluation.evaluator INFO: Inference done 239/392. Dataloading: 0.0007 s/iter. Inference: 0.0589 s/iter. Eval: 0.8614 s/iter. Total: 0.9211 s/iter. ETA=0:02:20
[08/06 11:53:27] d2.evaluation.evaluator INFO: Inference done 245/392. Dataloading: 0.0007 s/iter. Inference: 0.0589 s/iter. Eval: 0.8615 s/iter. Total: 0.9212 s/iter. ETA=0:02:15
[08/06 11:53:32] d2.evaluation.evaluator INFO: Inference done 251/392. Dataloading: 0.0007 s/iter. Inference: 0.0588 s/iter. Eval: 0.8617 s/iter. Total: 0.9212 s/iter. ETA=0:02:09
[08/06 11:53:38] d2.evaluation.evaluator INFO: Inference done 257/392. Dataloading: 0.0007 s/iter. Inference: 0.0587 s/iter. Eval: 0.8617 s/iter. Total: 0.9212 s/iter. ETA=0:02:04
[08/06 11:53:43] d2.evaluation.evaluator INFO: Inference done 263/392. Dataloading: 0.0007 s/iter. Inference: 0.0586 s/iter. Eval: 0.8618 s/iter. Total: 0.9212 s/iter. ETA=0:01:58
[08/06 11:53:49] d2.evaluation.evaluator INFO: Inference done 269/392. Dataloading: 0.0007 s/iter. Inference: 0.0585 s/iter. Eval: 0.8617 s/iter. Total: 0.9210 s/iter. ETA=0:01:53
[08/06 11:53:54] d2.evaluation.evaluator INFO: Inference done 275/392. Dataloading: 0.0007 s/iter. Inference: 0.0585 s/iter. Eval: 0.8615 s/iter. Total: 0.9208 s/iter. ETA=0:01:47
[08/06 11:54:00] d2.evaluation.evaluator INFO: Inference done 281/392. Dataloading: 0.0007 s/iter. Inference: 0.0586 s/iter. Eval: 0.8615 s/iter. Total: 0.9209 s/iter. ETA=0:01:42
[08/06 11:54:05] d2.evaluation.evaluator INFO: Inference done 287/392. Dataloading: 0.0007 s/iter. Inference: 0.0585 s/iter. Eval: 0.8618 s/iter. Total: 0.9210 s/iter. ETA=0:01:36
[08/06 11:54:11] d2.evaluation.evaluator INFO: Inference done 293/392. Dataloading: 0.0007 s/iter. Inference: 0.0583 s/iter. Eval: 0.8619 s/iter. Total: 0.9210 s/iter. ETA=0:01:31
[08/06 11:54:16] d2.evaluation.evaluator INFO: Inference done 299/392. Dataloading: 0.0007 s/iter. Inference: 0.0582 s/iter. Eval: 0.8621 s/iter. Total: 0.9211 s/iter. ETA=0:01:25
[08/06 11:54:22] d2.evaluation.evaluator INFO: Inference done 305/392. Dataloading: 0.0007 s/iter. Inference: 0.0581 s/iter. Eval: 0.8622 s/iter. Total: 0.9211 s/iter. ETA=0:01:20
[08/06 11:54:27] d2.evaluation.evaluator INFO: Inference done 311/392. Dataloading: 0.0007 s/iter. Inference: 0.0581 s/iter. Eval: 0.8620 s/iter. Total: 0.9209 s/iter. ETA=0:01:14
[08/06 11:54:33] d2.evaluation.evaluator INFO: Inference done 317/392. Dataloading: 0.0007 s/iter. Inference: 0.0580 s/iter. Eval: 0.8621 s/iter. Total: 0.9209 s/iter. ETA=0:01:09
[08/06 11:54:38] d2.evaluation.evaluator INFO: Inference done 323/392. Dataloading: 0.0007 s/iter. Inference: 0.0580 s/iter. Eval: 0.8621 s/iter. Total: 0.9208 s/iter. ETA=0:01:03
[08/06 11:54:44] d2.evaluation.evaluator INFO: Inference done 329/392. Dataloading: 0.0007 s/iter. Inference: 0.0579 s/iter. Eval: 0.8621 s/iter. Total: 0.9208 s/iter. ETA=0:00:58
[08/06 11:54:49] d2.evaluation.evaluator INFO: Inference done 335/392. Dataloading: 0.0007 s/iter. Inference: 0.0578 s/iter. Eval: 0.8621 s/iter. Total: 0.9206 s/iter. ETA=0:00:52
[08/06 11:54:55] d2.evaluation.evaluator INFO: Inference done 341/392. Dataloading: 0.0007 s/iter. Inference: 0.0580 s/iter. Eval: 0.8619 s/iter. Total: 0.9206 s/iter. ETA=0:00:46
[08/06 11:55:01] d2.evaluation.evaluator INFO: Inference done 347/392. Dataloading: 0.0007 s/iter. Inference: 0.0582 s/iter. Eval: 0.8619 s/iter. Total: 0.9209 s/iter. ETA=0:00:41
[08/06 11:55:06] d2.evaluation.evaluator INFO: Inference done 353/392. Dataloading: 0.0007 s/iter. Inference: 0.0583 s/iter. Eval: 0.8618 s/iter. Total: 0.9209 s/iter. ETA=0:00:35
[08/06 11:55:12] d2.evaluation.evaluator INFO: Inference done 359/392. Dataloading: 0.0007 s/iter. Inference: 0.0585 s/iter. Eval: 0.8619 s/iter. Total: 0.9211 s/iter. ETA=0:00:30
[08/06 11:55:17] d2.evaluation.evaluator INFO: Inference done 365/392. Dataloading: 0.0007 s/iter. Inference: 0.0584 s/iter. Eval: 0.8619 s/iter. Total: 0.9210 s/iter. ETA=0:00:24
[08/06 11:55:23] d2.evaluation.evaluator INFO: Inference done 371/392. Dataloading: 0.0007 s/iter. Inference: 0.0584 s/iter. Eval: 0.8619 s/iter. Total: 0.9210 s/iter. ETA=0:00:19
[08/06 11:55:28] d2.evaluation.evaluator INFO: Inference done 377/392. Dataloading: 0.0007 s/iter. Inference: 0.0584 s/iter. Eval: 0.8622 s/iter. Total: 0.9214 s/iter. ETA=0:00:13
[08/06 11:55:34] d2.evaluation.evaluator INFO: Inference done 383/392. Dataloading: 0.0007 s/iter. Inference: 0.0585 s/iter. Eval: 0.8624 s/iter. Total: 0.9216 s/iter. ETA=0:00:08
[08/06 11:55:39] d2.evaluation.evaluator INFO: Inference done 389/392. Dataloading: 0.0007 s/iter. Inference: 0.0584 s/iter. Eval: 0.8624 s/iter. Total: 0.9215 s/iter. ETA=0:00:02
[08/06 11:55:42] d2.evaluation.evaluator INFO: Total inference time: 0:05:56.678577 (0.921650 s / iter per device, on 1 devices)
[08/06 11:55:42] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:22 (0.058325 s / iter per device, on 1 devices)
[08/06 11:55:43] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[08/06 11:55:43] d2.evaluation.coco_evaluation INFO: Saving results to ./R101_overlap/inference/coco_instances_results.json
[08/06 11:55:43] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[08/06 11:55:45] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 |  nan  | 0.000 |
[08/06 11:55:45] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/06 11:55:45] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|
| normal     | 0.000 | defect     | 0.000 |
[08/06 11:55:49] d2.evaluation.coco_evaluation INFO: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl   |
|:------:|:------:|:------:|:------:|:-----:|:------:|
| 92.863 | 98.659 | 98.180 | 49.048 |  nan  | 92.863 |
[08/06 11:55:49] d2.evaluation.coco_evaluation INFO: Some metrics cannot be computed and is shown as NaN.
[08/06 11:55:49] d2.evaluation.coco_evaluation INFO: Per-category segm AP: 
| category   | AP     | category   | AP     |
|:-----------|:-------|:-----------|:-------|
| normal     | 98.930 | defect     | 86.796 |
[08/06 11:55:49] d2.engine.defaults INFO: Evaluation results for chick_dataset_test_overlap in csv format:
[08/06 11:55:49] d2.evaluation.testing INFO: copypaste: Task: bbox
[08/06 11:55:49] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/06 11:55:49] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,nan,0.0000
[08/06 11:55:49] d2.evaluation.testing INFO: copypaste: Task: segm
[08/06 11:55:49] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[08/06 11:55:49] d2.evaluation.testing INFO: copypaste: 92.8632,98.6589,98.1798,49.0480,nan,92.8632
